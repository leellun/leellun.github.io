{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"source/img/bg-default.png","path":"img/bg-default.png","modified":0,"renderable":0},{"_id":"source/img/image-20220923174506204.png","path":"img/image-20220923174506204.png","modified":0,"renderable":0},{"_id":"source/img/leaf_icon.png","path":"img/leaf_icon.png","modified":0,"renderable":0},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight-dark.styl","path":"css/highlight-dark.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight.styl","path":"css/highlight.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","path":"img/default.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/fluid.png","path":"img/fluid.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","path":"img/loading.gif","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","path":"js/boot.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","path":"js/events.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","path":"js/plugins.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":0,"renderable":1}],"Cache":[{"_id":"source/_posts/hello-world.md","hash":"19955404bd782263a9a4aaa5af5436d5bbcd4952","modified":1663933296144},{"_id":"source/about/index.md","hash":"b4e7555b2aca09a86c3fa27f5e07a5482289f9ba","modified":1663937033415},{"_id":"source/_posts/hexo基本使用教程.md","hash":"8f1cdc09eba36b6d8e37563d8e29fc3facfc0fee","modified":1663941686575},{"_id":"source/_posts/hexo基本使用教程.assets/image-20220923180413762.png","hash":"ad270054c809292a0623228419e0baadf5628237","modified":1663933296154},{"_id":"source/img/image-20220923174506204.png","hash":"e7880a3a607fd6ddf60d2105490315c758a53ca1","modified":1663933296167},{"_id":"source/img/leaf_icon.png","hash":"563ff9136fa5afd9df7417b18de5e807b0adb67a","modified":1663933296170},{"_id":"source/_posts/hexo基本使用教程/image-20220923175440656.png","hash":"989525b7b2257ec1ce7d81484331e56168ba5df0","modified":1663933296149},{"_id":"source/_posts/hexo基本使用教程.assets/image-20220923174506204.png","hash":"e7880a3a607fd6ddf60d2105490315c758a53ca1","modified":1663933296147},{"_id":"source/_posts/hexo基本使用教程.assets/image-20220923175440656.png","hash":"989525b7b2257ec1ce7d81484331e56168ba5df0","modified":1663933296149},{"_id":"source/_posts/hexo基本使用教程.assets/image-20220923175557661.png","hash":"7c290bdced691a72ee88418085fccf194e575d54","modified":1663933296152},{"_id":"source/_posts/hexo基本使用教程/image-20220923180413762.png","hash":"ad270054c809292a0623228419e0baadf5628237","modified":1663933296154},{"_id":"source/_posts/hexo基本使用教程/image-20220923174506204.png","hash":"e7880a3a607fd6ddf60d2105490315c758a53ca1","modified":1663933296147},{"_id":"source/_posts/hexo基本使用教程/image-20220923175557661.png","hash":"7c290bdced691a72ee88418085fccf194e575d54","modified":1663933296152},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/_config.yml","hash":"39baa882da9b0af5178c7767306be14bcf992a55","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/package.json","hash":"91db1e4cf8baeede435f24295cb9e24c47babaf9","modified":1663933946320},{"_id":"node_modules/hexo-theme-fluid/languages/de.yml","hash":"0e7d455d9e004ff15d8924b7a0c35cea25ee5b1d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/en.yml","hash":"cb11b39f44ea069652c9647179606b6cecc98d50","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/eo.yml","hash":"a556251cc50a5680578c03f1efbf252b1f4ab860","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/es.yml","hash":"7112594259c88c04714be152af7fd377687dad40","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/ja.yml","hash":"3dd6d20f8d26585a7c154a8e59fe8d5d902f4c6a","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/ru.yml","hash":"7dc78f22696649a4c68dc65a9b52d9a992fa82a0","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/zh-CN.yml","hash":"f96a22f989897ecddc69d5867a206e1cf6b8f610","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/zh-HK.yml","hash":"80ed400a7adaa92ea54fc7f5d534c9af795bed00","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/zh-TW.yml","hash":"596d031dff3826ae8e4ffc8931fff28977b73247","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/404.ejs","hash":"9569c5c8f67d2783f372f671c57b93a00dc63c2f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/about.ejs","hash":"163bee643e6a38912d3ae70923c83c48d57222e7","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/archive.ejs","hash":"7c1f44005849791feae4abaa10fae4cb983d3277","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/categories.ejs","hash":"13859726c27b6c79b5876ec174176d0f9c1ee164","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/category.ejs","hash":"f099161b738a16a32253f42085b5444f902018ed","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/index.ejs","hash":"db000a6a0cec19d32a6e7e94cd4c478500d9c5ac","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/layout.ejs","hash":"7e0023474128fbe4d68c467704c41f1712432415","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/links.ejs","hash":"1cac32ec4579aaf7b9fa39d317497331d4c5e1dd","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/page.ejs","hash":"ed5007a3feb8f14d3d2843271bfb298eb0c56219","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/post.ejs","hash":"505bcc06e55066b7cc5551d9ac0694e7713bfab5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/tag.ejs","hash":"9d686364c4d16a1a9219471623af452035c5b966","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/tags.ejs","hash":"1d06af34b6cf1d8a20d2eb565e309326ceba309f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/archive-list.ejs","hash":"7520fbf91f762207c2ab06b2c293235cd5b23905","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/category-chains.ejs","hash":"18309584aab83bc4deb20723ebad832149dd2e24","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/category-list.ejs","hash":"f8d2f1907450e61968e6d54443e9be8138196a77","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments.ejs","hash":"24ef242aa01e5f5bc397cf3f83ae48b1e8353dab","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/css.ejs","hash":"85f6e051550907681ab4ed2e268ac8f6e9ebf931","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer.ejs","hash":"10ccfb8eef4e16182183c9a3e175c90d5b6397d3","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/head.ejs","hash":"7b7b1d098726e86687a15fe3d520d178577ffcae","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header.ejs","hash":"0d5e397d30051e5fbabe7b47cfd1f1e6a5820af1","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/markdown-plugins.ejs","hash":"fc4bdf7de0cf1a66d0e5e4fba1b31d6f7ed49468","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/paginator.ejs","hash":"0f38a2c238169edcb63fc46c23bfc529ff3859b7","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/scripts.ejs","hash":"da5810785105e5075861593c7ac22c7aa9665a72","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/search.ejs","hash":"70e1c929e084ca8a2648cedabf29b372511ea2b8","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/index.js","hash":"79de5a379b28cad759a49048351c7f6b8915bd7d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/default-injects.js","hash":"b2013ae8e189cd07ebc8a2ff48a78e153345210f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/locals.js","hash":"58d0fec976f6b1d35e7ea03edc45414088acf05c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/post-filter.js","hash":"d516b9db63067f9ea9c72cc75ae4ff358417e77d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/local-search.js","hash":"fc2c50405b771b06b7f6cfc4e9de97b992691555","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/pages.js","hash":"d9971f15fbb6b775e3d31a1b9b45011959395010","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/date.js","hash":"9bda6382f61b40a20c24af466fe10c8366ebb74c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/engine.js","hash":"d3a231d106795ce99cb0bc77eb65f9ae44515933","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/export-config.js","hash":"47e6dba7652a621a54067413490a11c8a89e3d7b","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/import.js","hash":"ca53e8dbf7d44cfd372cfa79ac60f35a7d5b0076","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/injects.js","hash":"1ad2ae6b11bd8806ee7dd6eb7140d8b54a95d613","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/page.js","hash":"4607607445233b3029ef20ed5e91de0da0a7f9c5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/scope.js","hash":"d41d9d658fcb54964b388598e996747aadb85b0f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/url.js","hash":"2a6a8288176d0e0f6ec008056bf2745a86e8943e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/utils.js","hash":"226f99b465ff513de075a8e78b321d6cb62592ca","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/wordcount.js","hash":"4543b8954c5c2ca91191cc0d53cf071b3f26faaa","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/button.js","hash":"3eb43a8cdea0a64576ad6b31b4df6c2bf5698d4c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/checkbox.js","hash":"4938610c3543a921a341bc074626d511cb1a4b45","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/group-image.js","hash":"4aeebb797026f1df25646a5d69f7fde79b1bcd26","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/label.js","hash":"f05a6d32cca79535b22907dc03edb9d3fa2d8176","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/mermaid.js","hash":"75160561e1ef3603b6d2ad2938464ab1cb77fd38","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/note.js","hash":"f52f3a005b41f48b4da274ac64710177c8d4502f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/compare-versions.js","hash":"dbbc928c914fc2bd242cd66aa0c45971aec13a5d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/object.js","hash":"33b57e4decdc5e75c518859f168c8ba80b2c665b","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/resolve.js","hash":"8c4a8b62aa8608f12f1e9046231dff04859dc3e9","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/url-join.js","hash":"718aab5e7b2059a06b093ca738de420d9afa44ba","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight-dark.styl","hash":"45695ef75c31a4aa57324dd408b7e2327a337018","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight.styl","hash":"a9efc52a646a9e585439c768557e3e3c9e3326dc","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","hash":"855ae5fe229c51afa57f7645f6997a27a705d7e4","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/README.md","hash":"6d752df6f2278033dc2512a7d5be22c8a8eb665a","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","hash":"ba63f7c3324bc1fdd050a90add9d8faaffc27e07","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","hash":"89e3561488a618ed0caeb9edf18e441978e29c25","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","hash":"2333494add51e5e1374602a4e81f0be36a05d4c2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","hash":"cebcda5991b6a9ab9307c69542389ce9013f04f7","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/changyan.ejs","hash":"c9b2d68ed3d375f1953e7007307d2a3f75ed6249","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/cusdis.ejs","hash":"5f9dc012be27040bbe874d0c093c0d53958cc987","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/disqus.ejs","hash":"aab4a4d24c55231a37db308ae94414319cecdd9b","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/giscus.ejs","hash":"95f8b866b158eff9352c381c243b332a155a5110","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/gitalk.ejs","hash":"843bc141a4545eb20d1c92fb63c85d459b4271ec","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/livere.ejs","hash":"2264758fed57542a7389c7aa9f00f1aefa17eb87","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/remark42.ejs","hash":"d4e9532feeb02aed61bd15eda536b5b631454dac","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/twikoo.ejs","hash":"e6820fb7f13662c42f8433ec95404238f4c1860c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/utterances.ejs","hash":"c7ccf7f28308334a6da6f5425b141a24b5eca0e2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/valine.ejs","hash":"19ba937553dddd317f827d682661a1066a7b1f30","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/waline.ejs","hash":"12727da7cf3ac83443270f550be4d1c06135b52b","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer/beian.ejs","hash":"4fb9b5dd3f3e41a586d6af44e5069afe7c81fff2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer/statistics.ejs","hash":"454d8dd4c39f9494ebeb03ca0746f5bc122af76a","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header/banner.ejs","hash":"e07757b59e7b89eea213d0e595cb5932f812fd32","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header/navigation.ejs","hash":"38990ed9dbccd88342ee4b4cb5e60818e9eb8e8a","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/analytics.ejs","hash":"1327395a4dde1ea06c476b047fb110bcd269149f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/anchorjs.ejs","hash":"40181442d3a2b8734783a0ad7caf2d2522e3f2ab","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/code-widget.ejs","hash":"3a505cba37942badf62a56bbb8b605b72af330aa","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/encrypt.ejs","hash":"e3713fa78e0fc14a239360b020068d8513573ae4","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/fancybox.ejs","hash":"9d1ea2a46b8c8ad8c168594d578f40764818ef13","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/highlight.ejs","hash":"7529dd215b09d3557804333942377b9e20fa554e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/math.ejs","hash":"dcbf9a381ee76f2f1f75fcbc22c50a502ec85023","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/mermaid.ejs","hash":"e49506e9895e255e0e53f34a11d325f83109c1b0","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/nprogress.ejs","hash":"4c2d39ce816b8a6dcd6b53113c8695f8bd650a23","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/typed.ejs","hash":"51faef29f8e464bcb2e73049b428b88c8dd8b40a","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/category-bar.ejs","hash":"8772bce97ed297e7a88523f4e939ed6436c22f87","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/copyright.ejs","hash":"9d13392cea94b66d86422ad17c66e5ae67ce1d32","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/meta-bottom.ejs","hash":"7079b27a7bc15a7dfa9209f6be6051bdec49ebad","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/meta-top.ejs","hash":"ce6e9f578f4faa45840abddf8f46af3f4b69c177","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/sidebar-left.ejs","hash":"9992c99b3eb728ad195970e1b84d665f2c8691c4","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/sidebar-right.ejs","hash":"d5fcc9b60e02f869a29a8c17a16a6028ecc1e6d8","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/toc.ejs","hash":"97e003371b76911522fb93c5180c9fdceed29488","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/compatible-configs.js","hash":"ef474d1fa5bbafc52619ced0f9dc7eaf2affb363","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/footnote.js","hash":"2ec2ae03c79bb1ae7ac3fcf7e00fb52d1af2898d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/hello.js","hash":"44c5eb97b98813a07c659d6afedd17fad63b1821","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/highlight.js","hash":"0f02df2244e275595e72163498d42f42bcf0de5e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/injects.js","hash":"5ae4b07204683e54b5a1b74e931702bbce2ac23e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/lazyload.js","hash":"9ba0d4bc224e22af8a5a48d6ff13e5a0fcfee2a4","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/merge-configs.js","hash":"7c944c43b2ece5dd84859bd9d1fe955d13427387","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_functions/base.styl","hash":"2e46f3f4e2c9fe34c1ff1c598738fc7349ae8188","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","hash":"45cc86f099db0a2c36ad49711ce66c2d598a2ab1","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/pages.styl","hash":"b8e887bc7fb3b765a1f8ec9448eff8603a41984f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_about/about.styl","hash":"97fe42516ea531fdad771489b68aa8b2a7f6ae46","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_archive/archive.styl","hash":"c475e6681546d30350eaed11f23081ecae80c375","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_mixins/base.styl","hash":"542e306ee9494e8a78e44d6d7d409605d94caeb3","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/base.styl","hash":"643284c567665f96915f0b64e59934dda315f74d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_variables/base.styl","hash":"4ed5f0ae105ef4c7dd92eaf652ceda176c38e502","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/keyframes.styl","hash":"94065ea50f5bef7566d184f2422f6ac20866ba22","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/inline.styl","hash":"411a3fa3f924a87e00ff04d18b5c83283b049a4d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-chain.styl","hash":"0cdf7ef50dfd0669d3b257821384ff31cd81b7c9","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/color-schema.styl","hash":"61279540c2623ea4bf93e40613d41380839b92d3","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-list.styl","hash":"7edfe1b571ecca7d08f5f4dbcf76f4ffdcfbf0b5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-bar.styl","hash":"cc6df43fef6bb3efecbfdd8b9e467424a1dea581","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/comment.styl","hash":"780f3788e7357bcd3f3262d781cb91bb53976a93","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_links/links.styl","hash":"5c7f2044e3f1da05a3229537c06bd879836f8d6e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_index/index.styl","hash":"0acbd71633bcc7191672ea4e1b2277bea350d73b","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/highlight.styl","hash":"4df764d298fe556e501db4afc2b05686fe6ebcfb","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post-page.styl","hash":"127bb5391370afe7fef2a297084d76406bc5e902","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tags.styl","hash":"65bfc01c76abc927fa1a23bf2422892b0d566c3f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/anchorjs.styl","hash":"e0cebda4a6f499aff75e71417d88caa7ceb13b94","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post-tag.styl","hash":"27f70062415ccf66a9b6f4952db124fc1471fda5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/board.styl","hash":"4397037fc3f0033dbe546c33cd9dbdabd8cb1632","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/code-widget.styl","hash":"b66ab013f0f37d724a149b85b3c7432afcf460ad","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/banner.styl","hash":"7a0bd629bc234fc75e3cc8e3715ffada92f09e73","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"ae9289cc89649af2042907f8a003303b987f3404","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footer.styl","hash":"2caaca71dd1ff63d583099ed817677dd267b457e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/copyright.styl","hash":"26f71a9cd60d96bb0cb5bbdf58150b8e524d9707","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/ngrogress.styl","hash":"5d225357b4a58d46118e6616377168336ed44cb2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/noscript.styl","hash":"0cf2f2bb44f456150d428016675d5876a9d2e2aa","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/pagination.styl","hash":"8bb1b68e5f3552cb48c2ffa31edbc53646a8fb4c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"78704a94c0436097abfb0e0a57abeb3429c749b7","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/header.styl","hash":"0aa512c21a4b74ef2e70009786a1858d7c2fae9c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/search.styl","hash":"10f7e91a91e681fb9fe46f9df7707b9ef78707c8","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/toc.styl","hash":"9e7452aa2372153f25d7a4675c9d36d281a65d24","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/LICENSE","hash":"26f9356fd6e84b5a88df6d9014378f41b65ba209","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/markdown.styl","hash":"1e3d3a82721e7c10bcfcecec6d81cf2979039452","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/modal.styl","hash":"adf6c1e5c8e1fb41c77ce6e2258001df61245aa2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"f0e429a27fa8a7658fcbddbb4d4dbe4afa12499a","modified":499162500000},{"_id":"source/img/bg-default.png","hash":"1259a57e221a288ad3b9048d781f15c8b01cb8a8","modified":1663933296165},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":499162500000},{"_id":"public/local-search.xml","hash":"b8d7ab15fec6aad3b86c31d943d0fef78c25f0a3","modified":1663981646708},{"_id":"public/about/index.html","hash":"50adf4d756602e3cef881f9eb61a07c8aaecbdff","modified":1663937601014},{"_id":"public/archives/index.html","hash":"c31b2ec2690de04f9d1c1808ad5c595278c768b5","modified":1663981646708},{"_id":"public/archives/2016/index.html","hash":"bce841edbe6b244193af3515e4e6d661333a7199","modified":1663936384089},{"_id":"public/archives/2016/10/index.html","hash":"c4334c443f1015ad98e69d639d4fa4d4f6732dc1","modified":1663936384089},{"_id":"public/archives/2022/index.html","hash":"5af9a0587bfcd4b9e0a376c1f64f05af64353e19","modified":1663981646708},{"_id":"public/archives/2022/09/index.html","hash":"ca314862e5538983931ec26a3c120cb80ba3d361","modified":1663944964999},{"_id":"public/categories/前端/index.html","hash":"9443fef8ab13a8c14e9decd55bab981a2a5a5b12","modified":1663945106040},{"_id":"public/tags/hexo/index.html","hash":"e1cd592ad948a0e2334dcb8e512af99c932b17d6","modified":1663945106040},{"_id":"public/tags/github/index.html","hash":"1b35190c6312cd7432db8cf4961e9445bf29a884","modified":1663945106040},{"_id":"public/tags/博客/index.html","hash":"ddfb727a3a134c7d4007ad2055a4671a5bd1d7fe","modified":1663945106040},{"_id":"public/index.html","hash":"167c5d8f87b85a76ccc5fd06f413003d40475bd3","modified":1663981646708},{"_id":"public/tags/index.html","hash":"7724535ebc28f6e1234ae0af95f000593b76bdd3","modified":1663981646708},{"_id":"public/categories/index.html","hash":"71a35688246ec912ab81cbd28b2c42ada9d51dae","modified":1663981646708},{"_id":"public/links/index.html","hash":"917d1fd684c827dc45cda6ebdbf3bca72a34b128","modified":1663936384089},{"_id":"public/404.html","hash":"4a8332fa773c8b7b353ecd0b4136549d88f843fd","modified":1663936384089},{"_id":"public/2022/09/23/hexo基本使用教程/index.html","hash":"6d568fb0306e5b3ec7ff149b1011733838f58026","modified":1663944545077},{"_id":"public/2016/10/19/hello-world/index.html","hash":"dcd8fd67e9ffcf7d57a8e1c2db642e2b6f7a21f8","modified":1663936384089},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1663936384089},{"_id":"public/img/image-20220923174506204.png","hash":"e7880a3a607fd6ddf60d2105490315c758a53ca1","modified":1663936384089},{"_id":"public/img/leaf_icon.png","hash":"563ff9136fa5afd9df7417b18de5e807b0adb67a","modified":1663936384089},{"_id":"public/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1663936384089},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1663936384089},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1663936384089},{"_id":"public/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1663936384089},{"_id":"public/2022/09/23/hexo基本使用教程/image-20220923180413762.png","hash":"ad270054c809292a0623228419e0baadf5628237","modified":1663936384089},{"_id":"public/2022/09/23/hexo基本使用教程/image-20220923175440656.png","hash":"989525b7b2257ec1ce7d81484331e56168ba5df0","modified":1663936384089},{"_id":"public/2022/09/23/hexo基本使用教程/image-20220923175557661.png","hash":"7c290bdced691a72ee88418085fccf194e575d54","modified":1663936384089},{"_id":"public/2022/09/23/hexo基本使用教程/image-20220923174506204.png","hash":"e7880a3a607fd6ddf60d2105490315c758a53ca1","modified":1663936384089},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1663936384089},{"_id":"public/css/highlight-dark.css","hash":"2b0daa6e5343da9dbb26d617d224b8397e48556b","modified":1663936384089},{"_id":"public/css/highlight.css","hash":"0f9a477d33d3b15ebe7e163e756fb7c54c7ded6b","modified":1663936384089},{"_id":"public/css/main.css","hash":"d3b6eb3ef0e222271f1453d3d1214f3ba053792d","modified":1663936384089},{"_id":"public/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":1663936384089},{"_id":"public/js/color-schema.js","hash":"ba63f7c3324bc1fdd050a90add9d8faaffc27e07","modified":1663936384089},{"_id":"public/js/events.js","hash":"89e3561488a618ed0caeb9edf18e441978e29c25","modified":1663936384089},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1663936384089},{"_id":"public/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1663936384089},{"_id":"public/js/local-search.js","hash":"cebcda5991b6a9ab9307c69542389ce9013f04f7","modified":1663936384089},{"_id":"public/js/plugins.js","hash":"2333494add51e5e1374602a4e81f0be36a05d4c2","modified":1663936384089},{"_id":"public/js/utils.js","hash":"45cc86f099db0a2c36ad49711ce66c2d598a2ab1","modified":1663936384089},{"_id":"public/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1663936384089},{"_id":"public/img/bg-default.png","hash":"1259a57e221a288ad3b9048d781f15c8b01cb8a8","modified":1663936384089},{"_id":"source/_posts/k8s持久化存储之OpenEBS .md","hash":"6acaa8bf2947b18f6dceea29e4adbd65328c1479","modified":1663942999371},{"_id":"public/archives/2022/07/index.html","hash":"6c6923c5293decee57cf7890b7a7df40ec93aef3","modified":1663981646708},{"_id":"public/categories/服务器/index.html","hash":"595817a71e0470c5629bfc8501d1e9cf16c10821","modified":1663981646708},{"_id":"public/tags/Kubernetes/index.html","hash":"4ec1ab8672a930040306afe4e5ffa8e6db2905a8","modified":1663943216427},{"_id":"public/2022/07/23/k8s持久化存储之OpenEBS /index.html","hash":"77f677514b25e8eb8d1f06c1c835443d52084679","modified":1663943026912},{"_id":"public/tags/openebs/index.html","hash":"8f703595b566f4733e0b0b95a79b5b81021e5d2c","modified":1663943216427},{"_id":"public/tags/k8s/index.html","hash":"689c5220a5d8950ef4cbaa2d493d66328a67a9eb","modified":1663981646708},{"_id":"source/_posts/k8s持久化存储之OpenEBS.md","hash":"c1821cafd262f917947c0fddcfc54e0722ed8917","modified":1663944104474},{"_id":"public/2022/07/23/k8s持久化存储之OpenEBS/index.html","hash":"1d24c7ddbc7779067d5cac5820213bd82cf7ef6e","modified":1663954159383},{"_id":"source/_posts/k8s快速集成KubeSphere.md","hash":"0bac760074dcd8ce4a062844fb046dc8602d1ab9","modified":1663946822994},{"_id":"source/_posts/k8s快速集成KubeSphere/1662953701465.png","hash":"044e7971f241e95ad05d567921eabf10b25d980f","modified":1662953701531},{"_id":"source/_posts/k8s快速集成KubeSphere/1662954670517.png","hash":"7d42d07b015071533dec19a97ef74bffd9ab5681","modified":1662954670553},{"_id":"source/_posts/k8s快速集成KubeSphere/1662954686176.png","hash":"98a165420fa80087e0b0b31133e007e807323d5c","modified":1662954686228},{"_id":"source/_posts/k8s快速集成KubeSphere/1662954729101.png","hash":"7d388ca385017cdec583618f93a6c905f9490201","modified":1662954729140},{"_id":"source/_posts/k8s快速集成KubeSphere/1662955217850.png","hash":"0ee42e16669283c5dac073ed9116645420fd421b","modified":1662955217909},{"_id":"source/_posts/k8s快速集成KubeSphere/1662955316163.png","hash":"ca0275e3b254b52615beeb8d34df614928edd3ac","modified":1662955316201},{"_id":"source/_posts/k8s快速集成KubeSphere/1662956356797.png","hash":"ecd4264fb176c3d441f47f6b595e835fedb7d816","modified":1662956356846},{"_id":"source/_posts/k8s快速集成KubeSphere/1662979858086.png","hash":"e22add50907284d9fa00faa01dc1d96d9f035495","modified":1662979858209},{"_id":"source/_posts/k8s快速集成KubeSphere/1662954363702.png","hash":"44904e21198490cff21381bf4c212d8bc05424e9","modified":1662954363779},{"_id":"source/_posts/k8s快速集成KubeSphere/1662954919071.png","hash":"3c87adbdddd59a8bfa81f63f34d10cd70ac19fac","modified":1662954919147},{"_id":"source/_posts/k8s快速集成KubeSphere/1662955108731.png","hash":"3b536ebfe6054ca4df458816b932d1fd5025280d","modified":1662955108809},{"_id":"source/_posts/k8s快速集成KubeSphere/1662955481272.png","hash":"fced7baad7b0410075e5df58703fe190746faafd","modified":1662955481320},{"_id":"source/_posts/k8s快速集成KubeSphere/1662955721051.png","hash":"405796acaa0b46a216b5cbfd38b66beae18124ae","modified":1662955721120},{"_id":"public/tags/kubernetes/index.html","hash":"02b4bcb2307ab4eff197ed47c97af8aa5eaebf77","modified":1663981646708},{"_id":"public/tags/kubesphere/index.html","hash":"2d87d3da066a62aafbe4351fa26916578a193bae","modified":1663946833063},{"_id":"public/tags/wordpress/index.html","hash":"9f7099e8e7c60851159d8be0867d017289a86c9b","modified":1663946833063},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/index.html","hash":"badc59309bf031084d3af67f34bc1ada9dc3ccd1","modified":1663948232686},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662953701465.png","hash":"044e7971f241e95ad05d567921eabf10b25d980f","modified":1663944545077},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662954670517.png","hash":"7d42d07b015071533dec19a97ef74bffd9ab5681","modified":1663944545077},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662954363702.png","hash":"44904e21198490cff21381bf4c212d8bc05424e9","modified":1663944545077},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662954686176.png","hash":"98a165420fa80087e0b0b31133e007e807323d5c","modified":1663944545077},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662955108731.png","hash":"3b536ebfe6054ca4df458816b932d1fd5025280d","modified":1663944545077},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662955217850.png","hash":"0ee42e16669283c5dac073ed9116645420fd421b","modified":1663944545077},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662955316163.png","hash":"ca0275e3b254b52615beeb8d34df614928edd3ac","modified":1663944545077},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662955481272.png","hash":"fced7baad7b0410075e5df58703fe190746faafd","modified":1663944545077},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662955721051.png","hash":"405796acaa0b46a216b5cbfd38b66beae18124ae","modified":1663944545077},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662979858086.png","hash":"e22add50907284d9fa00faa01dc1d96d9f035495","modified":1663944545077},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662956356797.png","hash":"ecd4264fb176c3d441f47f6b595e835fedb7d816","modified":1663944545077},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662954729101.png","hash":"7d388ca385017cdec583618f93a6c905f9490201","modified":1663944545077},{"_id":"public/2022/07/24/k8s快速集成KubeSphere/1662954919071.png","hash":"3c87adbdddd59a8bfa81f63f34d10cd70ac19fac","modified":1663944545077},{"_id":"source/_posts/如何用hexo在github上搭建自己的博客/image-20220923180413762.png","hash":"ad270054c809292a0623228419e0baadf5628237","modified":1663933296154},{"_id":"source/_posts/如何用hexo在github上搭建自己的博客/image-20220923175440656.png","hash":"989525b7b2257ec1ce7d81484331e56168ba5df0","modified":1663933296149},{"_id":"source/_posts/如何用hexo在github上搭建自己的博客/image-20220923174506204.png","hash":"e7880a3a607fd6ddf60d2105490315c758a53ca1","modified":1663933296147},{"_id":"source/_posts/如何用hexo在github上搭建自己的博客/image-20220923175557661.png","hash":"7c290bdced691a72ee88418085fccf194e575d54","modified":1663933296152},{"_id":"source/_posts/如何用hexo在github上搭建自己的博客.md","hash":"60b954de8998eac10cce60d99eeed95712fecbb7","modified":1663946712476},{"_id":"public/2022/09/23/如何用hexo在github上搭建自己的博客/index.html","hash":"0f0a4c122b0653c800f0318730d0976d36606604","modified":1663944964999},{"_id":"public/2022/09/23/如何用hexo在github上搭建自己的博客/image-20220923180413762.png","hash":"ad270054c809292a0623228419e0baadf5628237","modified":1663944964999},{"_id":"public/2022/09/23/如何用hexo在github上搭建自己的博客/image-20220923174506204.png","hash":"e7880a3a607fd6ddf60d2105490315c758a53ca1","modified":1663944964999},{"_id":"public/2022/09/23/如何用hexo在github上搭建自己的博客/image-20220923175440656.png","hash":"989525b7b2257ec1ce7d81484331e56168ba5df0","modified":1663944964999},{"_id":"public/2022/09/23/如何用hexo在github上搭建自己的博客/image-20220923175557661.png","hash":"7c290bdced691a72ee88418085fccf194e575d54","modified":1663944964999},{"_id":"public/archives/2019/01/index.html","hash":"13d1d0526a7d39a874efe08211807ebd97372dda","modified":1663981646708},{"_id":"public/archives/2019/index.html","hash":"9cf218eb9380971c3c01b7bee72a6d7ff09617c6","modified":1663981646708},{"_id":"public/2019/01/23/如何用hexo在github上搭建自己的博客/index.html","hash":"0f5cfea9bbd6a99c63f803fee60144ed086ca48b","modified":1663954159383},{"_id":"public/2019/01/23/如何用hexo在github上搭建自己的博客/image-20220923180413762.png","hash":"ad270054c809292a0623228419e0baadf5628237","modified":1663945106040},{"_id":"public/2019/01/23/如何用hexo在github上搭建自己的博客/image-20220923174506204.png","hash":"e7880a3a607fd6ddf60d2105490315c758a53ca1","modified":1663945106040},{"_id":"public/2019/01/23/如何用hexo在github上搭建自己的博客/image-20220923175440656.png","hash":"989525b7b2257ec1ce7d81484331e56168ba5df0","modified":1663945106040},{"_id":"public/2019/01/23/如何用hexo在github上搭建自己的博客/image-20220923175557661.png","hash":"7c290bdced691a72ee88418085fccf194e575d54","modified":1663945106040},{"_id":"source/_posts/devops安装配置SonarQube.md","hash":"6f88a5ce1701daa27bb9f07dbeacabed0be27168","modified":1663953342422},{"_id":"source/_posts/devops安装配置SonarQube/jenkins-projet-key.png","hash":"3f98b7c5441306f8e73d76b8857e6192daed00b2","modified":1663947061226},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-config-2.png","hash":"afa8e0104a04c384afc38591bbdfe51353abb6ef","modified":1662996351767},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-config-1.png","hash":"27a4f5b74f925809108ef746f94a05de009fc103","modified":1662996347597},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-example.png","hash":"eb1264593bb37e90b997db207a19cbbaf6222732","modified":1663091011511},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-webhook-1.png","hash":"55237134260bcc3d027dd99a3bdcd7648ee20189","modified":1662996366378},{"_id":"source/_posts/devops安装配置SonarQube/token-created.png","hash":"0b0e42ff5cb11bdbd1ab00a20862c13f26bd1ae7","modified":1663947074132},{"_id":"source/_posts/devops安装配置SonarQube/webhook-page-info.png","hash":"4da0736887df19ca884bb8755eb5e811c3706a2b","modified":1663090508840},{"_id":"source/_posts/devops安装配置SonarQube/1663084944194.png","hash":"d4f94a8480da42527e268a9a2cfc9fd653971960","modified":1663084944268},{"_id":"source/_posts/devops安装配置SonarQube/generate-a-token.png","hash":"e9cf4784dc5fb07f0f436877175421ba24fae8e9","modified":1663947067205},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-config-3.png","hash":"e884b502544e065a899fc7166ea6e0501f5e5a36","modified":1662996361641},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-webhook-2.png","hash":"ba0303efe81a563e3197edacc6a3f3048c561593","modified":1663090511585},{"_id":"source/_posts/devops安装配置SonarQube/add-credentials.png","hash":"c32d402bc4b80845b25f90b6c629695222dc9c21","modified":1663090496630},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-create-project.png","hash":"beae5112ac09dac86fb8c53a30b10d2bfd19adbd","modified":1663947050655},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-jenkins-settings.png","hash":"186dc55281aae88dbd0454713d5e0b3b7a158ab8","modified":1663090500384},{"_id":"public/tags/sonarqube/index.html","hash":"778d7ab4255341b878727cb6996cf56708de48fa","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/index.html","hash":"9550b1cff41b0e1e6e5144e367e3493743b406b2","modified":1663954159383},{"_id":"public/2022/07/25/devops安装配置SonarQube/sonarqube-config-1.png","hash":"27a4f5b74f925809108ef746f94a05de009fc103","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/sonarqube-config-2.png","hash":"afa8e0104a04c384afc38591bbdfe51353abb6ef","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/webhook-page-info.png","hash":"4da0736887df19ca884bb8755eb5e811c3706a2b","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/sonarqube-webhook-1.png","hash":"55237134260bcc3d027dd99a3bdcd7648ee20189","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/sonarqube-webhook-2.png","hash":"ba0303efe81a563e3197edacc6a3f3048c561593","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/sonarqube-create-project.png","hash":"beae5112ac09dac86fb8c53a30b10d2bfd19adbd","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/jenkins-projet-key.png","hash":"3f98b7c5441306f8e73d76b8857e6192daed00b2","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/token-created.png","hash":"0b0e42ff5cb11bdbd1ab00a20862c13f26bd1ae7","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/1663084944194.png","hash":"d4f94a8480da42527e268a9a2cfc9fd653971960","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/sonarqube-config-3.png","hash":"e884b502544e065a899fc7166ea6e0501f5e5a36","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/sonarqube-example.png","hash":"eb1264593bb37e90b997db207a19cbbaf6222732","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/generate-a-token.png","hash":"e9cf4784dc5fb07f0f436877175421ba24fae8e9","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/add-credentials.png","hash":"c32d402bc4b80845b25f90b6c629695222dc9c21","modified":1663948232686},{"_id":"public/2022/07/25/devops安装配置SonarQube/sonarqube-jenkins-settings.png","hash":"186dc55281aae88dbd0454713d5e0b3b7a158ab8","modified":1663948232686},{"_id":"source/_posts/devops之KubeSphere流水线部署.md","hash":"7f759797633c0d9b48a701e5f65cb2dd70edf8e3","modified":1663948671880},{"_id":"source/_posts/devops之KubeSphere流水线部署/1662995312671.png","hash":"2e833ac88b744a02229090241f933e4f18a713ed","modified":1662995312691},{"_id":"source/_posts/devops之KubeSphere流水线部署/1662997272162.png","hash":"e0b3ffcda08a51f2cb859524e5239392e7cc08a9","modified":1662997272198},{"_id":"source/_posts/devops之KubeSphere流水线部署/1662995264415.png","hash":"c3e7461a727b959ad32569a3725fc20e9d1452af","modified":1662995264438},{"_id":"source/_posts/devops之KubeSphere流水线部署/1662986862067.png","hash":"bc23d06dca69198bfa1a8ce316e956787ec6916d","modified":1662986862092},{"_id":"source/_posts/devops之KubeSphere流水线部署/1663057834843.png","hash":"3d408a753c5b919b0c28803349497602c2a5715c","modified":1663057834852},{"_id":"source/_posts/devops之KubeSphere流水线部署/1662990207401.png","hash":"1191df8669e02d50bf9f9e7904098a794b824bc5","modified":1662990207459},{"_id":"source/_posts/devops之KubeSphere流水线部署/1663136377931.png","hash":"3b1a4942849baa9d6d18b0c0916e223f8f5cd6f0","modified":1663136378004},{"_id":"source/_posts/devops之KubeSphere流水线部署/jenkins-edit--2.png","hash":"de15cb5acc9e61623f7319fb43f500f9e17b5079","modified":1663057310421},{"_id":"source/_posts/devops之KubeSphere流水线部署/pipeline-overview.png","hash":"28dcfba1310f00d12c181390d4324ab26b9d8193","modified":1663062848813},{"_id":"public/tags/kubeshpere/index.html","hash":"459679e9fe0afe05d33f71fbb798995150a4f339","modified":1663950814435},{"_id":"public/tags/流水线/index.html","hash":"3f0c752b1291e2e9f42373278ff0f6fa063a5790","modified":1663948709077},{"_id":"public/2022/07/26/devops之KubeSphere流水线部署/index.html","hash":"8cdbaae3339f7feecc4d4710eb36d9500fa18a37","modified":1663950814435},{"_id":"public/2022/07/26/devops之KubeSphere流水线部署/1662986862067.png","hash":"bc23d06dca69198bfa1a8ce316e956787ec6916d","modified":1663948709077},{"_id":"public/2022/07/26/devops之KubeSphere流水线部署/1662990207401.png","hash":"1191df8669e02d50bf9f9e7904098a794b824bc5","modified":1663948709077},{"_id":"public/2022/07/26/devops之KubeSphere流水线部署/1662995264415.png","hash":"c3e7461a727b959ad32569a3725fc20e9d1452af","modified":1663948709077},{"_id":"public/2022/07/26/devops之KubeSphere流水线部署/1662995312671.png","hash":"2e833ac88b744a02229090241f933e4f18a713ed","modified":1663948709077},{"_id":"public/2022/07/26/devops之KubeSphere流水线部署/1662997272162.png","hash":"e0b3ffcda08a51f2cb859524e5239392e7cc08a9","modified":1663948709077},{"_id":"public/2022/07/26/devops之KubeSphere流水线部署/1663057834843.png","hash":"3d408a753c5b919b0c28803349497602c2a5715c","modified":1663948709077},{"_id":"public/2022/07/26/devops之KubeSphere流水线部署/1663136377931.png","hash":"3b1a4942849baa9d6d18b0c0916e223f8f5cd6f0","modified":1663948709077},{"_id":"public/2022/07/26/devops之KubeSphere流水线部署/jenkins-edit--2.png","hash":"de15cb5acc9e61623f7319fb43f500f9e17b5079","modified":1663948709077},{"_id":"public/2022/07/26/devops之KubeSphere流水线部署/pipeline-overview.png","hash":"28dcfba1310f00d12c181390d4324ab26b9d8193","modified":1663948709077},{"_id":"source/_posts/KubeSphere部署应用/1663167746173.png","hash":"57a6d9d4c2b98caeaedcb5ad27285e79621c9bfb","modified":1663167746238},{"_id":"source/_posts/KubeSphere部署应用/1663167829480.png","hash":"596e16d64f418f78e1c834dbff9e1cc7a6ae5f1f","modified":1663167829537},{"_id":"source/_posts/KubeSphere部署应用/1663167951290.png","hash":"dc3cad24bf07ec78dba71eba8bffd1cf31b2f429","modified":1663167951317},{"_id":"source/_posts/KubeSphere部署应用/1663168060307.png","hash":"3237f820021f98ed2ddb699441d93bfb943451fc","modified":1663168060358},{"_id":"source/_posts/KubeSphere部署应用/1663169211109.png","hash":"9d033d64dd6379f25a5d4a1c73c147a000f4cddc","modified":1663169211138},{"_id":"source/_posts/KubeSphere部署应用/1663169165653.png","hash":"25600d5bc092351fd89e5c8f9c7d0a790cd1ef48","modified":1663169165692},{"_id":"source/_posts/KubeSphere部署应用/1663170735856.png","hash":"28a7f78dbf70b1969f6d471fb466ec05304d8838","modified":1663170735925},{"_id":"source/_posts/KubeSphere部署应用/1663212972285.png","hash":"12d044dcb6f3cdd93f5bf65afb57a301dd966fe6","modified":1663212972331},{"_id":"source/_posts/KubeSphere部署应用/1663213063308.png","hash":"6c4a803bed24a6ec939e469fc8b0c591357820d2","modified":1663213063351},{"_id":"source/_posts/KubeSphere部署应用/1663213143052.png","hash":"0fef54f29051dfee0212ac7dda97a7021a1cb8ac","modified":1663213143098},{"_id":"source/_posts/KubeSphere部署应用/1663220903688.png","hash":"aeb69d8912fc728ed6deb253712a3eafb9aca64d","modified":1663220903742},{"_id":"source/_posts/KubeSphere部署应用/1663227844337.png","hash":"0e8c2d964bcecf5f075e1ba450112ae04b2035a9","modified":1663227844386},{"_id":"source/_posts/KubeSphere部署应用/1663408063347.png","hash":"8084b106301c29492188e55733d87438005bba72","modified":1663408063403},{"_id":"source/_posts/KubeSphere部署应用/1663213016039.png","hash":"a62764953a7f6601088401444abf4390bc33aed1","modified":1663213016100},{"_id":"source/_posts/kubesphere快速部署mysql.md","hash":"7cb30c455b33f90c72a60b1b5e63a2ec35f72478","modified":1663950228369},{"_id":"source/_posts/kubesphere快速部署redis.md","hash":"d5f86dcf3b407bc32d93bd01f9806a753416271b","modified":1663950732685},{"_id":"source/_posts/kubesphere快速部署mysql/1663167746173.png","hash":"57a6d9d4c2b98caeaedcb5ad27285e79621c9bfb","modified":1663167746238},{"_id":"source/_posts/kubesphere快速部署mysql/1663167951290.png","hash":"dc3cad24bf07ec78dba71eba8bffd1cf31b2f429","modified":1663167951317},{"_id":"source/_posts/kubesphere快速部署mysql/1663168060307.png","hash":"3237f820021f98ed2ddb699441d93bfb943451fc","modified":1663168060358},{"_id":"source/_posts/kubesphere快速部署mysql/1663169165653.png","hash":"25600d5bc092351fd89e5c8f9c7d0a790cd1ef48","modified":1663169165692},{"_id":"source/_posts/kubesphere快速部署mysql/1663169211109.png","hash":"9d033d64dd6379f25a5d4a1c73c147a000f4cddc","modified":1663169211138},{"_id":"source/_posts/kubesphere快速部署mysql/1663170735856.png","hash":"28a7f78dbf70b1969f6d471fb466ec05304d8838","modified":1663170735925},{"_id":"source/_posts/kubesphere快速部署redis/1663220903688.png","hash":"aeb69d8912fc728ed6deb253712a3eafb9aca64d","modified":1663220903742},{"_id":"source/_posts/kubesphere快速部署redis/1663213016039.png","hash":"a62764953a7f6601088401444abf4390bc33aed1","modified":1663213016100},{"_id":"public/tags/mysql/index.html","hash":"efc998d73fb380300aa1a9b07503737035e0564b","modified":1663950814435},{"_id":"public/tags/redis/index.html","hash":"fe2da8267be846c22987ccf64fe8ab4a18bfe557","modified":1663950814435},{"_id":"public/2022/07/26/kubesphere快速部署mysql/index.html","hash":"305e1526db05d1d6e60f9149d14dd8e59aad7370","modified":1663950814435},{"_id":"public/2022/07/27/kubesphere快速部署redis/index.html","hash":"3245e55d27564eb8dfef6c2511849c3b4a9c6689","modified":1663950814435},{"_id":"public/2022/07/26/kubesphere快速部署mysql/1663169211109.png","hash":"9d033d64dd6379f25a5d4a1c73c147a000f4cddc","modified":1663950814435},{"_id":"public/2022/07/26/kubesphere快速部署mysql/1663167951290.png","hash":"dc3cad24bf07ec78dba71eba8bffd1cf31b2f429","modified":1663950814435},{"_id":"public/2022/07/26/kubesphere快速部署mysql/1663169165653.png","hash":"25600d5bc092351fd89e5c8f9c7d0a790cd1ef48","modified":1663950814435},{"_id":"public/2022/07/26/kubesphere快速部署mysql/1663168060307.png","hash":"3237f820021f98ed2ddb699441d93bfb943451fc","modified":1663950814435},{"_id":"public/2022/07/26/kubesphere快速部署mysql/1663167746173.png","hash":"57a6d9d4c2b98caeaedcb5ad27285e79621c9bfb","modified":1663950814435},{"_id":"public/2022/07/26/kubesphere快速部署mysql/1663170735856.png","hash":"28a7f78dbf70b1969f6d471fb466ec05304d8838","modified":1663950814435},{"_id":"public/2022/07/27/kubesphere快速部署redis/1663220903688.png","hash":"aeb69d8912fc728ed6deb253712a3eafb9aca64d","modified":1663950814435},{"_id":"public/2022/07/27/kubesphere快速部署redis/1663213016039.png","hash":"a62764953a7f6601088401444abf4390bc33aed1","modified":1663950814435},{"_id":"source/_posts/kubernetes组件.assets/image-1-1024x478.png","hash":"fe626c6fb9b6666ae81b4a93fc2f81ff28b8d0af","modified":1657900132549},{"_id":"source/_posts/kubernetes组件介绍/image-1-1024x478.png","hash":"fe626c6fb9b6666ae81b4a93fc2f81ff28b8d0af","modified":1657900132549},{"_id":"source/_posts/kubernetes的历史与介绍.assets/image-1024x388.png","hash":"d23e929a1a3594756868d9276f1813c29c5f1209","modified":1657900071960},{"_id":"source/_posts/kubernetes的历史与介绍/image-1024x388.png","hash":"d23e929a1a3594756868d9276f1813c29c5f1209","modified":1657900071960},{"_id":"source/_posts/k8s网络通讯方式/image-6.png","hash":"df4e93594deace8d4733c6d1c508bca88c547b48","modified":1657900493938},{"_id":"source/_posts/k8s网络通讯方式/1411165-20210604153215333-1022736403-990x1024.png","hash":"52ba6176fcf498b24fb99afe85ad0fee089aa22a","modified":1657900491219},{"_id":"source/_posts/k8s网络通讯方式/1411165-20210604153302687-2143265992.png","hash":"5ddf692b1d03068d032878d0f4c3b73e510bb757","modified":1657900488078},{"_id":"source/_posts/k8s网络通讯方式/1411165-20210604153732180-730315756.png","hash":"4202c1ef574ed3666e8a9b3ee6f739e36dfac5f7","modified":1657900486119},{"_id":"source/_posts/k8s网络通讯方式/image-2.png","hash":"d6e4f5f8876bc6e792640c44abab54a49ecc9a90","modified":1657900482004},{"_id":"source/_posts/k8s网络通讯方式/image-4.png","hash":"8a437a914b4e11f48ac5fe3b0092493de3d9b295","modified":1657900501928},{"_id":"source/_posts/k8s网络通讯方式/image-5.png","hash":"9effb540429e2ab69cf20cc42fe0e4748867dde1","modified":1657900499051},{"_id":"source/_posts/k8s网络通讯方式.md","hash":"f6cab90a3f23a8371769a55fb908bbca882197ba","modified":1663951817248},{"_id":"source/_posts/k8s集群开启firewalld防火墙.md","hash":"950d0b4778ec7e5cff37a47225a7e33820b3843d","modified":1663951901423},{"_id":"source/_posts/kubernetes kubectl常用命令.md","hash":"814650c1cd8f63731dd8388eb6510f6b81cb7202","modified":1663951568890},{"_id":"source/_posts/kubernetes的历史与介绍.md","hash":"b9981a501de82ec4a3744e6553b7e5f942dc38bf","modified":1663951418513},{"_id":"source/_posts/kubernetes组件介绍.md","hash":"a000f342a3e0e70475a6edc7f671b2a88914bbe1","modified":1663951313594},{"_id":"source/_posts/kubernetes调度器scheduler.md","hash":"54bee18429d1c331fad049852bf66d7731ab0a85","modified":1663952126724},{"_id":"source/_posts/k8s资源清单及常用字段.md","hash":"23517bfd19fda82091c4c84283c7c8c87b05e5ba","modified":1663951146839},{"_id":"public/archives/page/2/index.html","hash":"7cbb9629d3b87d77f4f3057670b2ac6a6557f0dc","modified":1663981646708},{"_id":"public/archives/2021/index.html","hash":"49bd8401a9356b2d754f5f46b0f1f73c77f43758","modified":1663981646708},{"_id":"public/archives/2021/07/index.html","hash":"fefcf15ab228c4f94ff5671c1420b411750ad9f7","modified":1663981646708},{"_id":"public/archives/2021/08/index.html","hash":"2e938ac26c73684f85ecd7c633bca7912d3c50dc","modified":1663981646708},{"_id":"public/categories/服务器/page/2/index.html","hash":"7168e94b1331cb0b49486328555d8f82684877a2","modified":1663981646708},{"_id":"public/tags/k8s/page/2/index.html","hash":"3e25d05c1617158fc90a2874218ca254e88b7e2b","modified":1663981646708},{"_id":"public/tags/kubernetes/page/2/index.html","hash":"f66e26d2614a3ae6e3ee7b7fbc3f977831309554","modified":1663981646708},{"_id":"public/tags/组件/index.html","hash":"7ca18fcd998204e9968d7af24041d1d0261a3ca0","modified":1663952257170},{"_id":"public/tags/kubectl/index.html","hash":"a2f6cb4f30ecf9c84eaa684dfb9ed8e6597c36cd","modified":1663952257170},{"_id":"public/tags/网络通讯/index.html","hash":"8852290196950610dd68e15166b4bb2118a0ed24","modified":1663952257170},{"_id":"public/tags/firewalld/index.html","hash":"85d5124633889b2dab62e0b3943ce8410197e1b8","modified":1663952257170},{"_id":"public/tags/防火墙/index.html","hash":"9074af16ab97c9934dced501bf783efaca527806","modified":1663952257170},{"_id":"public/tags/scheduler/index.html","hash":"ee29ab1fe5d965cf617d43b413f981c0c9821f8e","modified":1663952257170},{"_id":"public/tags/调度器/index.html","hash":"3e96d46545b13fb5d3f15f24c0b339defacec377","modified":1663952257170},{"_id":"public/2021/08/02/k8s集群开启firewalld防火墙/index.html","hash":"0d8c5d47d50c5626b59e335c189992d879ff06a9","modified":1663952865027},{"_id":"public/2021/08/02/kubernetes调度器scheduler/index.html","hash":"d8de67b5e7ae1957a37f33cfa380fdf3a00f3064","modified":1663952865027},{"_id":"public/2021/07/30/k8s网络通讯方式/index.html","hash":"0c0b91d3c22fb2b5fe23b635a6ca0895ffd89506","modified":1663952865027},{"_id":"public/2021/07/29/kubernetes组件介绍/index.html","hash":"8fc954fddee96605f96cba700a2436230892865b","modified":1663952257170},{"_id":"public/2021/07/27/k8s资源清单及常用字段/index.html","hash":"10b1d6eaa4278b7815c6aca38d98faccdf887b92","modified":1663952257170},{"_id":"public/2021/07/25/kubernetes kubectl常用命令/index.html","hash":"fc8a59c6ad176f2cc98df804a3e6b5970c568119","modified":1663952257170},{"_id":"public/2021/07/24/kubernetes的历史与介绍/index.html","hash":"beb032eeb0d61ed5ab3c193ca8e17dd89d0370af","modified":1663954159383},{"_id":"public/page/2/index.html","hash":"5b123fa13b2f5a22554ff33f7b860379120d64ed","modified":1663981646708},{"_id":"public/2021/07/30/k8s网络通讯方式/image-6.png","hash":"df4e93594deace8d4733c6d1c508bca88c547b48","modified":1663952257170},{"_id":"public/2021/07/24/kubernetes的历史与介绍/image-1024x388.png","hash":"d23e929a1a3594756868d9276f1813c29c5f1209","modified":1663952257170},{"_id":"public/2021/07/30/k8s网络通讯方式/1411165-20210604153215333-1022736403-990x1024.png","hash":"52ba6176fcf498b24fb99afe85ad0fee089aa22a","modified":1663952257170},{"_id":"public/2021/07/30/k8s网络通讯方式/1411165-20210604153302687-2143265992.png","hash":"5ddf692b1d03068d032878d0f4c3b73e510bb757","modified":1663952257170},{"_id":"public/2021/07/30/k8s网络通讯方式/image-2.png","hash":"d6e4f5f8876bc6e792640c44abab54a49ecc9a90","modified":1663952257170},{"_id":"public/2021/07/30/k8s网络通讯方式/image-4.png","hash":"8a437a914b4e11f48ac5fe3b0092493de3d9b295","modified":1663952257170},{"_id":"public/2021/07/30/k8s网络通讯方式/image-5.png","hash":"9effb540429e2ab69cf20cc42fe0e4748867dde1","modified":1663952257170},{"_id":"public/2021/07/29/kubernetes组件介绍/image-1-1024x478.png","hash":"fe626c6fb9b6666ae81b4a93fc2f81ff28b8d0af","modified":1663952257170},{"_id":"public/2021/07/30/k8s网络通讯方式/1411165-20210604153732180-730315756.png","hash":"4202c1ef574ed3666e8a9b3ee6f739e36dfac5f7","modified":1663952257170},{"_id":"source/_posts/k8s dashboard/1630835361904.png","hash":"394e5d333c947ac2f39e9cd24755fe435290b8ad","modified":1630835364000},{"_id":"source/_posts/k8s dashboard/1630834989795.png","hash":"a91ad100aa4c3543dd40341234063f2ef53c61cf","modified":1630834998000},{"_id":"source/_posts/kubeadm快速部署kubernetes集群.assets/image-25.png","hash":"cbe79eddd976660b3678ddd6ba6a8571ff841a68","modified":1657899877451},{"_id":"source/_posts/kubeadm快速部署kubernetes集群.assets/1629031322356.png","hash":"c652e5b972bbb4d839d74c3ec77f41381c104dbf","modified":1657899883103},{"_id":"source/_posts/kubeadm快速部署kubernetes集群/image-26.png","hash":"f4fcaf805b603d664464ee56cd5bb905ad2b057b","modified":1657899892089},{"_id":"source/_posts/kubeadm快速部署kubernetes集群/1629031322356.png","hash":"c652e5b972bbb4d839d74c3ec77f41381c104dbf","modified":1657899883103},{"_id":"source/_posts/kubeadm快速部署kubernetes集群/image-25.png","hash":"cbe79eddd976660b3678ddd6ba6a8571ff841a68","modified":1657899877451},{"_id":"source/_posts/k8s dashboard.md","hash":"1db5c62a56abda34c134697b97fcc7302ab2f866","modified":1663952555624},{"_id":"source/_posts/k8s常用控制器及特点.md","hash":"21e51f11c7d736c84ddd6a68a47d3c77bc857ad4","modified":1663952852298},{"_id":"source/_posts/kubeadm快速部署kubernetes集群.md","hash":"c5a296da8afc0bc6106378efd2db95853889dbec","modified":1663952713623},{"_id":"public/tags/dashboard/index.html","hash":"c46d0e24c1bb8ff8e65ce71970704ba235efc6c4","modified":1663952865027},{"_id":"public/tags/集群部署/index.html","hash":"97512ffe4d931bf590205d3e897ccf05ab3872af","modified":1663952865027},{"_id":"public/tags/控制器/index.html","hash":"76c70ba65f0b693d8f7b8a8bcfe944c67c909638","modified":1663954159383},{"_id":"public/2021/08/04/kubeadm快速部署kubernetes集群/index.html","hash":"4e912af628c1a5e1d268c82f290ece89ef188c7b","modified":1663981646708},{"_id":"public/2021/08/02/k8s dashboard/index.html","hash":"96b71a21535fb533dff39fcee6e162852d96fe75","modified":1663952865027},{"_id":"public/2021/08/01/k8s常用控制器及特点/index.html","hash":"18fa3171a74dbdc5bc71de3f54be09b43ca6b4d3","modified":1663952865027},{"_id":"public/2021/08/02/k8s dashboard/1630835361904.png","hash":"394e5d333c947ac2f39e9cd24755fe435290b8ad","modified":1663952865027},{"_id":"public/2021/08/04/kubeadm快速部署kubernetes集群/image-26.png","hash":"f4fcaf805b603d664464ee56cd5bb905ad2b057b","modified":1663952865027},{"_id":"public/2021/08/04/kubeadm快速部署kubernetes集群/image-25.png","hash":"cbe79eddd976660b3678ddd6ba6a8571ff841a68","modified":1663952865027},{"_id":"public/2021/08/04/kubeadm快速部署kubernetes集群/1629031322356.png","hash":"c652e5b972bbb4d839d74c3ec77f41381c104dbf","modified":1663952865027},{"_id":"public/2021/08/02/k8s dashboard/1630834989795.png","hash":"a91ad100aa4c3543dd40341234063f2ef53c61cf","modified":1663952865027},{"_id":"source/_posts/RC与RS与Deployment关联.assets/1657973507960.png","hash":"13d64cc408117d143b9e1ee640918ff845aa1280","modified":1657973507979},{"_id":"source/_posts/RC与RS与Deployment关联/1657973507960.png","hash":"13d64cc408117d143b9e1ee640918ff845aa1280","modified":1657973507979},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658045231642.png","hash":"ae62057f9082a9bde0d8e53597619ac271e30f42","modified":1658045231665},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658045368211.png","hash":"294458c5fefff55a0432ec9a6846d6a6a4c9cf56","modified":1658045368241},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658046066962.png","hash":"27765e9188f9a129bd1e31d144a56066499f0de8","modified":1658046066984},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658064476544.png","hash":"650b64d5817a2ca98daad19f650897d1c37a8721","modified":1658064476564},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658044977401.png","hash":"6222edfa653a0e2c1f3d321b45a8aef0d5fb1092","modified":1658044977448},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658044956049.png","hash":"d9aa1170d61000ca4c44c77e6eefa29ff532af6c","modified":1658044956103},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658045067670.png","hash":"90da50e026595ec55977d2d839a2255198b6b310","modified":1658045067784},{"_id":"source/_posts/k8s Service的概述、类型及代理模式.md","hash":"768329012a536a88bbe71b53e21fa23687b88856","modified":1663954116172},{"_id":"source/_posts/kubernetes控制器Job与CronJob.md","hash":"d9d2f715b734d4339630b0ee18dc36cc71621637","modified":1663953977623},{"_id":"source/_posts/kubernetes基础控制器.md","hash":"f12242a704801109fcd316634fda697db8500fb4","modified":1663953497500},{"_id":"source/_posts/kubernetes控制器DaemonSet.md","hash":"c43c8bd4c82d158aac069787d03a85fb990b620c","modified":1663953803753},{"_id":"source/_posts/RC与RS与Deployment关联.md","hash":"f8ba5a35f879568b8401bddcf8fd68791599ccf8","modified":1663953710824},{"_id":"source/_posts/devops安装配置SonarQube/1663953257964.png","hash":"77046da15ed2b3649a913e589f6f1f99f950787a","modified":1663953258077},{"_id":"public/2021/08/13/k8s Service的概述、类型及代理模式/index.html","hash":"4b75fc4c80f43a7bc39880265056a15619770b7a","modified":1663981646708},{"_id":"public/2021/06/30/kubernetes基础控制器/index.html","hash":"db6689a8f92fa3c297c5b01123bebd3c7444a481","modified":1663954159383},{"_id":"public/archives/page/3/index.html","hash":"d5f78f40adda17c149f3dcba0c12c61e40b9a11b","modified":1663981646708},{"_id":"public/archives/2021/page/2/index.html","hash":"d98fe1cbd22c76ece332d5928d3645d794e52951","modified":1663981646708},{"_id":"public/archives/2021/06/index.html","hash":"58b761a07a57deddff3fc0fe8ece5bef9f1d554e","modified":1663981646708},{"_id":"public/categories/服务器/page/3/index.html","hash":"9c8e755d5aa31b7e9fbf448842f545a222886245","modified":1663981646708},{"_id":"public/page/3/index.html","hash":"e65cfa8a1e8b0ec149e91a764f4773b2b8d83766","modified":1663981646708},{"_id":"public/tags/k8s/page/3/index.html","hash":"a2338a7069bb27a461966e1b6666a065c1d05a6e","modified":1663981646708},{"_id":"public/tags/daemonset/index.html","hash":"0cac60886e475e4edf44a9b23ee767426fc2b99f","modified":1663954159383},{"_id":"public/tags/cronjob/index.html","hash":"02d0adf3eef2120864a8c04ee15ec0fd3c585fdf","modified":1663954159383},{"_id":"public/tags/job/index.html","hash":"8906685ef348d517a573d6c6da23aba2a6627ada","modified":1663954159383},{"_id":"public/tags/service/index.html","hash":"8eb35aa616bff43669e20aab982e0c7e1ff80169","modified":1663954159383},{"_id":"public/2021/07/13/kubernetes控制器DaemonSet/index.html","hash":"f44aa5062e0a6ed6fa41b901deb88bf4a282a5cd","modified":1663954159383},{"_id":"public/2021/07/16/RC与RS与Deployment关联/index.html","hash":"b32ca4753be1a0ee246edbc59d381f4bd833f9d8","modified":1663954159383},{"_id":"public/2021/07/17/kubernetes控制器Job与CronJob/index.html","hash":"1bbc278017b80857d1691157e3929185ba052418","modified":1663954159383},{"_id":"public/2021/07/16/RC与RS与Deployment关联/1657973507960.png","hash":"13d64cc408117d143b9e1ee640918ff845aa1280","modified":1663954159383},{"_id":"public/2021/08/13/k8s Service的概述、类型及代理模式/1658045368211.png","hash":"294458c5fefff55a0432ec9a6846d6a6a4c9cf56","modified":1663954159383},{"_id":"public/2021/08/13/k8s Service的概述、类型及代理模式/1658045231642.png","hash":"ae62057f9082a9bde0d8e53597619ac271e30f42","modified":1663954159383},{"_id":"public/2021/08/13/k8s Service的概述、类型及代理模式/1658064476544.png","hash":"650b64d5817a2ca98daad19f650897d1c37a8721","modified":1663954159383},{"_id":"public/2021/08/13/k8s Service的概述、类型及代理模式/1658046066962.png","hash":"27765e9188f9a129bd1e31d144a56066499f0de8","modified":1663954159383},{"_id":"public/2022/07/25/devops安装配置SonarQube/1663953257964.png","hash":"77046da15ed2b3649a913e589f6f1f99f950787a","modified":1663954159383},{"_id":"public/2021/08/13/k8s Service的概述、类型及代理模式/1658044956049.png","hash":"d9aa1170d61000ca4c44c77e6eefa29ff532af6c","modified":1663954159383},{"_id":"public/2021/08/13/k8s Service的概述、类型及代理模式/1658045067670.png","hash":"90da50e026595ec55977d2d839a2255198b6b310","modified":1663954159383},{"_id":"public/2021/08/13/k8s Service的概述、类型及代理模式/1658044977401.png","hash":"6222edfa653a0e2c1f3d321b45a8aef0d5fb1092","modified":1663954159383},{"_id":"source/_posts/k8s pod生命周期.assets/1657944206659.png","hash":"aeae0c98c51034bc6a96f4c042a369febe1ebb03","modified":1657944260061},{"_id":"source/_posts/k8s pod生命周期/1657944206659.png","hash":"aeae0c98c51034bc6a96f4c042a369febe1ebb03","modified":1657944260061},{"_id":"source/_posts/k8s pod生命周期—探针.md","hash":"1ed4d249f023a56c37c6a9d1feecbb3b19e540eb","modified":1663954508924},{"_id":"source/_posts/k8s pod重启策略与状态.md","hash":"ef1575e83a8496dd8f1b649ea11e1692387e47e4","modified":1663954561364},{"_id":"source/_posts/k8s pod生命周期.md","hash":"693ff805af0387cc38ba568bd7d7e29b3ef6446e","modified":1663954442881},{"_id":"public/tags/kubernetes/page/3/index.html","hash":"1b7e565298f68410a9aff0759c4c3c24a292245f","modified":1663981646708},{"_id":"public/tags/pod/index.html","hash":"ec308746526ae397b5e2517d9f782b9608d3e02d","modified":1663981646708},{"_id":"public/tags/探针/index.html","hash":"2ec664a4bad8ad3b1650a69349f35e653db64fab","modified":1663981646708},{"_id":"public/tags/重启策略/index.html","hash":"75b8e7562ea2031924b3287352689a269e06365a","modified":1663981646708},{"_id":"public/2021/08/10/k8s pod重启策略与状态/index.html","hash":"37687531124efe35d8e19a72e5f05fc369e8b5e3","modified":1663981646708},{"_id":"public/2021/08/08/k8s pod生命周期—探针/index.html","hash":"d32c75842c1efcec77546b79222a32b39a48260b","modified":1663981646708},{"_id":"public/2021/08/06/k8s pod生命周期/index.html","hash":"9edaa53cfbbd6a67e35e0e7625379f23bfcc52e6","modified":1663981646708},{"_id":"public/2021/08/06/k8s pod生命周期/1657944206659.png","hash":"aeae0c98c51034bc6a96f4c042a369febe1ebb03","modified":1663981646708}],"Category":[{"name":"前端","_id":"cl8egrg0w0003lsvj1sevbxin"},{"name":"服务器","_id":"cl8ekpwbn0001aovjd1czgil3"}],"Data":[],"Page":[{"title":"about","layout":"abount1","date":"2022-09-23T05:19:04.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: about\nlayout: abount1\ndate: 2022-09-23 13:19:04\n---\n","updated":"2022-09-23T12:43:53.415Z","path":"about/index.html","_id":"cl8egrfzp0000lsvj3ztp60rj","comments":1,"content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"k8s持久化存储之OpenEBS","date":"2022-07-23T09:38:02.000Z","_content":"\n# 一、介绍\n\nOpenEBS 是 CNCF 项目的一部分，采用 Apache v2 许可证。是 Kubernetes 部署使用最广泛且易用的开源存储解决方案。\n\n**目的：**\n\n让持久化工作负载的存储和存储服务完全集成到环境中，这样每个团队和工作负载都可以从控制的粒度和 Kubernetes 原生行为中获益。\n\n**特点：**\n\n- 微服务架构，使用 Kubernetes 自身的能力来编排管理 OpenEBS 组件。\n\n- OpenEBS 支持一系列存储引擎，以便开发人员能够部署适合其应用程序设计目标的存储技术。\n\n  像 Cassandra 这样的分布式应用程序可以使用 LocalPV 引擎实现最低延迟的写操作。\n\n  像 MySQL 和 PostgreSQL 这样的独立应用程序可以使用 ZFS 引擎 (cStor) 进行恢复。\n\n  像 Kafka 这样的流媒体应用程序可以使用 NVMe 引擎 Mayastor 在边缘环境中获得最佳性能。\n\n  在各种引擎类型中，OpenEBS 为高可用性、快照、克隆和易管理性提供了一致的框架。\n\n- 管理员和开发人员可以使用 Kubernetes 提供的所有工具来交互和管理 OpenEBS。\n\n# 二、OpenEBS 存储引擎建议\n\n| 应用需求                                         | 存储类型                        | OpenEBS 卷类型                                               |\n| ------------------------------------------------ | ------------------------------- | ------------------------------------------------------------ |\n| 低时延、高可用性、同步复制、快照、克隆、精简配置 | SSD/ 云存储卷                   | OpenEBS Mayastor                                             |\n| 高可用性、同步复制、快照、克隆、精简配置         | 机械 /SSD/ 云存储卷             | OpenEBS cStor                                                |\n| 高可用性、同步复制、精简配置                     | 主机路径或外部挂载存储          | OpenEBS Jiva                                                 |\n| 低时延、本地 PV                                  | 主机路径或外部挂载存储          | Dynamic Local PV - Hostpath, Dynamic Local PV - Rawfile      |\n| 低时延、本地 PV                                  | 本地机械 /SSD/ 云存储卷等块设备 | Dynamic Local PV - Device                                    |\n| 低延迟，本地 PV，快照，克隆                      | 本地机械 /SSD/ 云存储卷等块设备 | OpenEBS Dynamic Local PV - ZFS , OpenEBS Dynamic Local PV - LVM |\n\n- 多机环境，如果有额外的块设备（非系统盘块设备）作为数据盘，选用 `OpenEBS Mayastor`、`OpenEBS cStor`\n- 多机环境，如果没有额外的块设备（非系统盘块设备）作为数据盘，仅单块系统盘块设备，选用 `OpenEBS Jiva`\n- 单机环境，建议本地路径 `Dynamic Local PV - Hostpath, Dynamic Local PV - Rawfile`，由于单机多用于测试环境，数据可靠性要求较低。\n\n# 三、安装\n\n[openobs官方安装文档](https://openebs.io/docs/2.12.x/user-guides/cstor)\n\n在安装openebs之前先去除污点，然后等安装完成再添加回来污点\n\n```\n# 去除污点\nkubectl taint nodes k8s-master01 node-role.kubernetes.io/master=:NoSchedule-\n# 添加污点\nkubectl taint nodes k8s-master01 node-role.kubernetes.io/master=:NoSchedule\n```\n\n添加helm repo\n\n```\nhelm repo add openebs https://openebs.github.io/charts\nhelm repo update\n```\n\n安装openebs（这里只会安装Jiva和Local组件）\n\n```\nhelm install openebs --namespace openebs openebs/openebs --create-namespace --version 3.0.x\n```\n\n添加cstor支持\n\n```\nhelm install openebs --namespace openebs openebs/openebs --create-namespace --set cstor.enabled=true --version 3.2.0\n```\n\n查看安装\n\n```\n# 查看安装pod\nkubectl get pod -n openebs\n# 查看安装blockdevice，这里的blockdevice是磁盘，当添加一块未分配的磁盘，就会有值\nkubectl get bd -n openebs\n```\n\nOpenEBS依赖与iSCSI做存储管理，因此需要先确保您的集群上已有安装openiscsi。 （这里当报错的时候可以安装试试）\n\n```\nyum -y install iscsi-initiator-utils\nsystemctl enable iscsid --now\nsystemctl start iscsid\n```\n\n查看安装状况：\n\n```\n[root@k8s-master01 ~]# kubectl get pod -n openebs\nNAME                                            READY   STATUS    RESTARTS         AGE\nopenebs-cstor-admission-server-b74f5487-lkz84   1/1     Running   1 (6m21s ago)    8h\nopenebs-cstor-csi-controller-0                  6/6     Running   0                4m44s\nopenebs-cstor-csi-node-4df4w                    2/2     Running   2 (61m ago)      8h\nopenebs-cstor-csi-node-x8bmt                    2/2     Running   6 (16m ago)      8h\nopenebs-cstor-csi-node-zzn4k                    2/2     Running   2 (6m21s ago)    8h\nopenebs-cstor-cspc-operator-84464fb479-fh949    1/1     Running   3 (16m ago)      8h\nopenebs-cstor-cvc-operator-646f6f676b-xhd44     1/1     Running   2 (16m ago)      46m\nopenebs-localpv-provisioner-55b65f8b55-zqj29    1/1     Running   13 (6m23s ago)   8h\nopenebs-ndm-429hl                               1/1     Running   2 (4m28s ago)    8h\nopenebs-ndm-9kkzd                               1/1     Running   1 (6m21s ago)    8h\nopenebs-ndm-operator-6c944d87b6-5ddxz           1/1     Running   2 (16m ago)      46m\nopenebs-ndm-sqnwx                               1/1     Running   6 (15m ago)      8h\n```\n\n# 四、添加磁盘\n\n```\n[root@k8s-master01 ~]# kubectl get bd -n openebs\nNAME                                           NODENAME       SIZE           CLAIMSTATE   STATUS     AGE\nblockdevice-57886fae032a3d3638badeb1282dd67e   k8s-node02     21473771008    Unclaimed    Active     53s\nblockdevice-d923fc382d96ff6eea7d9ab8efb66224   k8s-master01   21473771008    Unclaimed    Active     11m\nblockdevice-e5009ce419c80719025c4cc9409253ab   k8s-node01     21473771008    Unclaimed    Active     33s\n```\n\n# 五、配置\n\n## 5.1 创建cStor存储池\n\ncspc.yaml ：\n\n```\napiVersion: cstor.openebs.io/v1\nkind: CStorPoolCluster\nmetadata:\n name: cstor-disk-pool\n namespace: openebs\nspec:\n pools:\n   - nodeSelector:\n       kubernetes.io/hostname: \"k8s-master01\"\n     dataRaidGroups:\n       - blockDevices:\n           - blockDeviceName: \"blockdevice-d923fc382d96ff6eea7d9ab8efb66224\"\n     poolConfig:\n       dataRaidGroupType: \"stripe\"\n\n   - nodeSelector:\n       kubernetes.io/hostname: \"k8s-node01\"\n     dataRaidGroups:\n       - blockDevices:\n           - blockDeviceName: \"blockdevice-e5009ce419c80719025c4cc9409253ab\"\n     poolConfig:\n       dataRaidGroupType: \"stripe\"\n\n   - nodeSelector:\n       kubernetes.io/hostname: \"k8s-node02\"\n     dataRaidGroups:\n       - blockDevices:\n           - blockDeviceName: \"blockdevice-57886fae032a3d3638badeb1282dd67e\"\n     poolConfig:\n       dataRaidGroupType: \"stripe\"\n```\n\ndataRaidGroupType:可以根据您的需要设置为 `stripe` or `mirror` 。下面以配置为stripe为例。 \n\n```\n[root@k8s-master01 openebs]# kubectl get CStorPoolCluster -n openebs\nNAME              HEALTHYINSTANCES   PROVISIONEDINSTANCES   DESIREDINSTANCES   AGE\ncstor-disk-pool                      3                      3                  42s\n```\n\n## 5.2 storageclass创建\n\n### 5.2.1 cstor的创建\n\n```\nkind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: cstor-csi-disk\nprovisioner: cstor.csi.openebs.io\nallowVolumeExpansion: true\nparameters:\n  cas-type: cstor\n  # cstorPoolCluster should have the name of the CSPC\n  cstorPoolCluster: cstor-disk-pool\n  # replicaCount should be <= no. of CSPI created in the selected CSPC\n  replicaCount: \"3\"\n```\n\n添加硬盘后查看磁盘情况\n\n```\n磁盘 /dev/sdb：21.5 GB, 21474836480 字节，41943040 个扇区\nUnits = 扇区 of 1 * 512 = 512 bytes\n扇区大小(逻辑/物理)：512 字节 / 512 字节\nI/O 大小(最小/最佳)：512 字节 / 512 字节\n磁盘标签类型：gpt\nDisk identifier: ADA9C10B-8C31-4EE2-A29B-F2701E9554DC\n\n\n#         Start          End    Size  Type            Name\n 1         2048     41943006     20G  Linux filesyste OpenEBS_NDM\n```\n\n### 5.2.2 jiva \n\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: jiva-storageclass\n  annotations:\n    openebs.io/cas-type: jiva\n    cas.openebs.io/config: |\n      - name: StoragePool\n        value: default\nprovisioner: openebs.io/provisioner-iscsi\n```\n\n### 5.2.3  hostpath\n\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: localpv-hostpath-sc\n  annotations:\n    openebs.io/cas-type: local\n    cas.openebs.io/config: |\n      - name: BasePath\n        value: \"/var/openebs/local\"\n      - name: StorageType\n        value: \"hostpath\"\nprovisioner: openebs.io/local\n```\n\n### 5.2.4 device\n\n下面的类型需要添加硬盘\n\n```\n磁盘 /dev/sdc：21.5 GB, 21474836480 字节，41943040 个扇区\nUnits = 扇区 of 1 * 512 = 512 bytes\n扇区大小(逻辑/物理)：512 字节 / 512 字节\nI/O 大小(最小/最佳)：512 字节 / 512 字节\n磁盘标签类型：gpt\nDisk identifier: BAD0A706-0A9D-478A-85C6-319224EC5D1F\n\n\n#         Start          End    Size  Type            Name\n 1         2048     41943006     20G  Linux filesyste OpenEBS_NDM\n```\n\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: localpv-device-sc\n  annotations:\n    openebs.io/cas-type: local\n    cas.openebs.io/config: |\n      - name: StorageType\n        value: \"device\"\n      - name: FSType\n        value: ext4\nprovisioner: openebs.io/local\n```\n\n查看：\n\n```\n[root@k8s-master01 openebs]# kubectl get sc -n openebs\nNAME               PROVISIONER            RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\ncstor-csi-disk     cstor.csi.openebs.io   Delete          Immediate              true                   43s\nopenebs-device     openebs.io/local       Delete          WaitForFirstConsumer   false                  9h\nopenebs-hostpath   openebs.io/local       Delete          WaitForFirstConsumer   false                  9h\n```\n\n### 5.2.5 cStor、Jiva、LocalPV 特性比较：\n\n| 特性                 | Jiva  | cStor    | Local PV |\n| -------------------- | ----- | -------- | -------- |\n| 轻量级运行于用户空间 | Yes   | Yes      | Yes      |\n| 同步复制             | Yes   | Yes      | No       |\n| 适合低容量工作负载   | Yes   | Yes      | Yes      |\n| 支持快照，克隆       | Basic | Advanced | No       |\n| 数据一致性           | Yes   | Yes      | NA       |\n| 使用 Velero 恢复备份 | Yes   | Yes      | Yes      |\n| 适合高容量工作负载   | No    | Yes      | Yes      |\n| 自动精简配置         |       | Yes      | No       |\n| 磁盘池或聚合支持     |       | Yes      | No       |\n| 动态扩容             |       | Yes      | Yes      |\n| 数据弹性 (RAID 支持) |       | Yes      | No       |\n| 接近原生磁盘性能     | No    | No       | Yes      |\n\n大多数场景推荐 `cStor`，因其提供了强大的功能，包括快照 / 克隆、存储池功能（如精简资源调配、按需扩容等）。\n\n`Jiva` 适用于低容量需求的工作负载场景，例如 `5` 到 `50G`。尽管使用 `Jiva` 没有空间限制，但建议将其用于低容量工作负载。`Jiva` 非常易于使用，并提供企业级容器本地存储，而不需要专用硬盘。有快照和克隆功能的需求的场景，优先考虑使用 `cStor` 而不是 `Jiva`。\n\n## 5.3 默认sc\n\n```\nkubectl patch storageclass cstor-csi-disk -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}'\n```\n\n\n\n推荐文章：\n\nhttps://blog.csdn.net/easylife206/article/details/125213855\n\nhttps://zhuanlan.zhihu.com/p/519172233","source":"_posts/k8s持久化存储之OpenEBS.md","raw":"---\ntitle: k8s持久化存储之OpenEBS\ndate: 2022-07-23 17:38:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - openebs\n---\n\n# 一、介绍\n\nOpenEBS 是 CNCF 项目的一部分，采用 Apache v2 许可证。是 Kubernetes 部署使用最广泛且易用的开源存储解决方案。\n\n**目的：**\n\n让持久化工作负载的存储和存储服务完全集成到环境中，这样每个团队和工作负载都可以从控制的粒度和 Kubernetes 原生行为中获益。\n\n**特点：**\n\n- 微服务架构，使用 Kubernetes 自身的能力来编排管理 OpenEBS 组件。\n\n- OpenEBS 支持一系列存储引擎，以便开发人员能够部署适合其应用程序设计目标的存储技术。\n\n  像 Cassandra 这样的分布式应用程序可以使用 LocalPV 引擎实现最低延迟的写操作。\n\n  像 MySQL 和 PostgreSQL 这样的独立应用程序可以使用 ZFS 引擎 (cStor) 进行恢复。\n\n  像 Kafka 这样的流媒体应用程序可以使用 NVMe 引擎 Mayastor 在边缘环境中获得最佳性能。\n\n  在各种引擎类型中，OpenEBS 为高可用性、快照、克隆和易管理性提供了一致的框架。\n\n- 管理员和开发人员可以使用 Kubernetes 提供的所有工具来交互和管理 OpenEBS。\n\n# 二、OpenEBS 存储引擎建议\n\n| 应用需求                                         | 存储类型                        | OpenEBS 卷类型                                               |\n| ------------------------------------------------ | ------------------------------- | ------------------------------------------------------------ |\n| 低时延、高可用性、同步复制、快照、克隆、精简配置 | SSD/ 云存储卷                   | OpenEBS Mayastor                                             |\n| 高可用性、同步复制、快照、克隆、精简配置         | 机械 /SSD/ 云存储卷             | OpenEBS cStor                                                |\n| 高可用性、同步复制、精简配置                     | 主机路径或外部挂载存储          | OpenEBS Jiva                                                 |\n| 低时延、本地 PV                                  | 主机路径或外部挂载存储          | Dynamic Local PV - Hostpath, Dynamic Local PV - Rawfile      |\n| 低时延、本地 PV                                  | 本地机械 /SSD/ 云存储卷等块设备 | Dynamic Local PV - Device                                    |\n| 低延迟，本地 PV，快照，克隆                      | 本地机械 /SSD/ 云存储卷等块设备 | OpenEBS Dynamic Local PV - ZFS , OpenEBS Dynamic Local PV - LVM |\n\n- 多机环境，如果有额外的块设备（非系统盘块设备）作为数据盘，选用 `OpenEBS Mayastor`、`OpenEBS cStor`\n- 多机环境，如果没有额外的块设备（非系统盘块设备）作为数据盘，仅单块系统盘块设备，选用 `OpenEBS Jiva`\n- 单机环境，建议本地路径 `Dynamic Local PV - Hostpath, Dynamic Local PV - Rawfile`，由于单机多用于测试环境，数据可靠性要求较低。\n\n# 三、安装\n\n[openobs官方安装文档](https://openebs.io/docs/2.12.x/user-guides/cstor)\n\n在安装openebs之前先去除污点，然后等安装完成再添加回来污点\n\n```\n# 去除污点\nkubectl taint nodes k8s-master01 node-role.kubernetes.io/master=:NoSchedule-\n# 添加污点\nkubectl taint nodes k8s-master01 node-role.kubernetes.io/master=:NoSchedule\n```\n\n添加helm repo\n\n```\nhelm repo add openebs https://openebs.github.io/charts\nhelm repo update\n```\n\n安装openebs（这里只会安装Jiva和Local组件）\n\n```\nhelm install openebs --namespace openebs openebs/openebs --create-namespace --version 3.0.x\n```\n\n添加cstor支持\n\n```\nhelm install openebs --namespace openebs openebs/openebs --create-namespace --set cstor.enabled=true --version 3.2.0\n```\n\n查看安装\n\n```\n# 查看安装pod\nkubectl get pod -n openebs\n# 查看安装blockdevice，这里的blockdevice是磁盘，当添加一块未分配的磁盘，就会有值\nkubectl get bd -n openebs\n```\n\nOpenEBS依赖与iSCSI做存储管理，因此需要先确保您的集群上已有安装openiscsi。 （这里当报错的时候可以安装试试）\n\n```\nyum -y install iscsi-initiator-utils\nsystemctl enable iscsid --now\nsystemctl start iscsid\n```\n\n查看安装状况：\n\n```\n[root@k8s-master01 ~]# kubectl get pod -n openebs\nNAME                                            READY   STATUS    RESTARTS         AGE\nopenebs-cstor-admission-server-b74f5487-lkz84   1/1     Running   1 (6m21s ago)    8h\nopenebs-cstor-csi-controller-0                  6/6     Running   0                4m44s\nopenebs-cstor-csi-node-4df4w                    2/2     Running   2 (61m ago)      8h\nopenebs-cstor-csi-node-x8bmt                    2/2     Running   6 (16m ago)      8h\nopenebs-cstor-csi-node-zzn4k                    2/2     Running   2 (6m21s ago)    8h\nopenebs-cstor-cspc-operator-84464fb479-fh949    1/1     Running   3 (16m ago)      8h\nopenebs-cstor-cvc-operator-646f6f676b-xhd44     1/1     Running   2 (16m ago)      46m\nopenebs-localpv-provisioner-55b65f8b55-zqj29    1/1     Running   13 (6m23s ago)   8h\nopenebs-ndm-429hl                               1/1     Running   2 (4m28s ago)    8h\nopenebs-ndm-9kkzd                               1/1     Running   1 (6m21s ago)    8h\nopenebs-ndm-operator-6c944d87b6-5ddxz           1/1     Running   2 (16m ago)      46m\nopenebs-ndm-sqnwx                               1/1     Running   6 (15m ago)      8h\n```\n\n# 四、添加磁盘\n\n```\n[root@k8s-master01 ~]# kubectl get bd -n openebs\nNAME                                           NODENAME       SIZE           CLAIMSTATE   STATUS     AGE\nblockdevice-57886fae032a3d3638badeb1282dd67e   k8s-node02     21473771008    Unclaimed    Active     53s\nblockdevice-d923fc382d96ff6eea7d9ab8efb66224   k8s-master01   21473771008    Unclaimed    Active     11m\nblockdevice-e5009ce419c80719025c4cc9409253ab   k8s-node01     21473771008    Unclaimed    Active     33s\n```\n\n# 五、配置\n\n## 5.1 创建cStor存储池\n\ncspc.yaml ：\n\n```\napiVersion: cstor.openebs.io/v1\nkind: CStorPoolCluster\nmetadata:\n name: cstor-disk-pool\n namespace: openebs\nspec:\n pools:\n   - nodeSelector:\n       kubernetes.io/hostname: \"k8s-master01\"\n     dataRaidGroups:\n       - blockDevices:\n           - blockDeviceName: \"blockdevice-d923fc382d96ff6eea7d9ab8efb66224\"\n     poolConfig:\n       dataRaidGroupType: \"stripe\"\n\n   - nodeSelector:\n       kubernetes.io/hostname: \"k8s-node01\"\n     dataRaidGroups:\n       - blockDevices:\n           - blockDeviceName: \"blockdevice-e5009ce419c80719025c4cc9409253ab\"\n     poolConfig:\n       dataRaidGroupType: \"stripe\"\n\n   - nodeSelector:\n       kubernetes.io/hostname: \"k8s-node02\"\n     dataRaidGroups:\n       - blockDevices:\n           - blockDeviceName: \"blockdevice-57886fae032a3d3638badeb1282dd67e\"\n     poolConfig:\n       dataRaidGroupType: \"stripe\"\n```\n\ndataRaidGroupType:可以根据您的需要设置为 `stripe` or `mirror` 。下面以配置为stripe为例。 \n\n```\n[root@k8s-master01 openebs]# kubectl get CStorPoolCluster -n openebs\nNAME              HEALTHYINSTANCES   PROVISIONEDINSTANCES   DESIREDINSTANCES   AGE\ncstor-disk-pool                      3                      3                  42s\n```\n\n## 5.2 storageclass创建\n\n### 5.2.1 cstor的创建\n\n```\nkind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: cstor-csi-disk\nprovisioner: cstor.csi.openebs.io\nallowVolumeExpansion: true\nparameters:\n  cas-type: cstor\n  # cstorPoolCluster should have the name of the CSPC\n  cstorPoolCluster: cstor-disk-pool\n  # replicaCount should be <= no. of CSPI created in the selected CSPC\n  replicaCount: \"3\"\n```\n\n添加硬盘后查看磁盘情况\n\n```\n磁盘 /dev/sdb：21.5 GB, 21474836480 字节，41943040 个扇区\nUnits = 扇区 of 1 * 512 = 512 bytes\n扇区大小(逻辑/物理)：512 字节 / 512 字节\nI/O 大小(最小/最佳)：512 字节 / 512 字节\n磁盘标签类型：gpt\nDisk identifier: ADA9C10B-8C31-4EE2-A29B-F2701E9554DC\n\n\n#         Start          End    Size  Type            Name\n 1         2048     41943006     20G  Linux filesyste OpenEBS_NDM\n```\n\n### 5.2.2 jiva \n\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: jiva-storageclass\n  annotations:\n    openebs.io/cas-type: jiva\n    cas.openebs.io/config: |\n      - name: StoragePool\n        value: default\nprovisioner: openebs.io/provisioner-iscsi\n```\n\n### 5.2.3  hostpath\n\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: localpv-hostpath-sc\n  annotations:\n    openebs.io/cas-type: local\n    cas.openebs.io/config: |\n      - name: BasePath\n        value: \"/var/openebs/local\"\n      - name: StorageType\n        value: \"hostpath\"\nprovisioner: openebs.io/local\n```\n\n### 5.2.4 device\n\n下面的类型需要添加硬盘\n\n```\n磁盘 /dev/sdc：21.5 GB, 21474836480 字节，41943040 个扇区\nUnits = 扇区 of 1 * 512 = 512 bytes\n扇区大小(逻辑/物理)：512 字节 / 512 字节\nI/O 大小(最小/最佳)：512 字节 / 512 字节\n磁盘标签类型：gpt\nDisk identifier: BAD0A706-0A9D-478A-85C6-319224EC5D1F\n\n\n#         Start          End    Size  Type            Name\n 1         2048     41943006     20G  Linux filesyste OpenEBS_NDM\n```\n\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: localpv-device-sc\n  annotations:\n    openebs.io/cas-type: local\n    cas.openebs.io/config: |\n      - name: StorageType\n        value: \"device\"\n      - name: FSType\n        value: ext4\nprovisioner: openebs.io/local\n```\n\n查看：\n\n```\n[root@k8s-master01 openebs]# kubectl get sc -n openebs\nNAME               PROVISIONER            RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\ncstor-csi-disk     cstor.csi.openebs.io   Delete          Immediate              true                   43s\nopenebs-device     openebs.io/local       Delete          WaitForFirstConsumer   false                  9h\nopenebs-hostpath   openebs.io/local       Delete          WaitForFirstConsumer   false                  9h\n```\n\n### 5.2.5 cStor、Jiva、LocalPV 特性比较：\n\n| 特性                 | Jiva  | cStor    | Local PV |\n| -------------------- | ----- | -------- | -------- |\n| 轻量级运行于用户空间 | Yes   | Yes      | Yes      |\n| 同步复制             | Yes   | Yes      | No       |\n| 适合低容量工作负载   | Yes   | Yes      | Yes      |\n| 支持快照，克隆       | Basic | Advanced | No       |\n| 数据一致性           | Yes   | Yes      | NA       |\n| 使用 Velero 恢复备份 | Yes   | Yes      | Yes      |\n| 适合高容量工作负载   | No    | Yes      | Yes      |\n| 自动精简配置         |       | Yes      | No       |\n| 磁盘池或聚合支持     |       | Yes      | No       |\n| 动态扩容             |       | Yes      | Yes      |\n| 数据弹性 (RAID 支持) |       | Yes      | No       |\n| 接近原生磁盘性能     | No    | No       | Yes      |\n\n大多数场景推荐 `cStor`，因其提供了强大的功能，包括快照 / 克隆、存储池功能（如精简资源调配、按需扩容等）。\n\n`Jiva` 适用于低容量需求的工作负载场景，例如 `5` 到 `50G`。尽管使用 `Jiva` 没有空间限制，但建议将其用于低容量工作负载。`Jiva` 非常易于使用，并提供企业级容器本地存储，而不需要专用硬盘。有快照和克隆功能的需求的场景，优先考虑使用 `cStor` 而不是 `Jiva`。\n\n## 5.3 默认sc\n\n```\nkubectl patch storageclass cstor-csi-disk -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}'\n```\n\n\n\n推荐文章：\n\nhttps://blog.csdn.net/easylife206/article/details/125213855\n\nhttps://zhuanlan.zhihu.com/p/519172233","slug":"k8s持久化存储之OpenEBS","published":1,"updated":"2022-09-23T14:41:44.474Z","_id":"cl8ektvnt00008svjgpvt9grk","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、介绍\"><a href=\"#一、介绍\" class=\"headerlink\" title=\"一、介绍\"></a>一、介绍</h1><p>OpenEBS 是 CNCF 项目的一部分，采用 Apache v2 许可证。是 Kubernetes 部署使用最广泛且易用的开源存储解决方案。</p>\n<p><strong>目的：</strong></p>\n<p>让持久化工作负载的存储和存储服务完全集成到环境中，这样每个团队和工作负载都可以从控制的粒度和 Kubernetes 原生行为中获益。</p>\n<p><strong>特点：</strong></p>\n<ul>\n<li><p>微服务架构，使用 Kubernetes 自身的能力来编排管理 OpenEBS 组件。</p>\n</li>\n<li><p>OpenEBS 支持一系列存储引擎，以便开发人员能够部署适合其应用程序设计目标的存储技术。</p>\n<p>像 Cassandra 这样的分布式应用程序可以使用 LocalPV 引擎实现最低延迟的写操作。</p>\n<p>像 MySQL 和 PostgreSQL 这样的独立应用程序可以使用 ZFS 引擎 (cStor) 进行恢复。</p>\n<p>像 Kafka 这样的流媒体应用程序可以使用 NVMe 引擎 Mayastor 在边缘环境中获得最佳性能。</p>\n<p>在各种引擎类型中，OpenEBS 为高可用性、快照、克隆和易管理性提供了一致的框架。</p>\n</li>\n<li><p>管理员和开发人员可以使用 Kubernetes 提供的所有工具来交互和管理 OpenEBS。</p>\n</li>\n</ul>\n<h1 id=\"二、OpenEBS-存储引擎建议\"><a href=\"#二、OpenEBS-存储引擎建议\" class=\"headerlink\" title=\"二、OpenEBS 存储引擎建议\"></a>二、OpenEBS 存储引擎建议</h1><table>\n<thead>\n<tr>\n<th>应用需求</th>\n<th>存储类型</th>\n<th>OpenEBS 卷类型</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>低时延、高可用性、同步复制、快照、克隆、精简配置</td>\n<td>SSD/ 云存储卷</td>\n<td>OpenEBS Mayastor</td>\n</tr>\n<tr>\n<td>高可用性、同步复制、快照、克隆、精简配置</td>\n<td>机械 /SSD/ 云存储卷</td>\n<td>OpenEBS cStor</td>\n</tr>\n<tr>\n<td>高可用性、同步复制、精简配置</td>\n<td>主机路径或外部挂载存储</td>\n<td>OpenEBS Jiva</td>\n</tr>\n<tr>\n<td>低时延、本地 PV</td>\n<td>主机路径或外部挂载存储</td>\n<td>Dynamic Local PV - Hostpath, Dynamic Local PV - Rawfile</td>\n</tr>\n<tr>\n<td>低时延、本地 PV</td>\n<td>本地机械 /SSD/ 云存储卷等块设备</td>\n<td>Dynamic Local PV - Device</td>\n</tr>\n<tr>\n<td>低延迟，本地 PV，快照，克隆</td>\n<td>本地机械 /SSD/ 云存储卷等块设备</td>\n<td>OpenEBS Dynamic Local PV - ZFS , OpenEBS Dynamic Local PV - LVM</td>\n</tr>\n</tbody></table>\n<ul>\n<li>多机环境，如果有额外的块设备（非系统盘块设备）作为数据盘，选用 <code>OpenEBS Mayastor</code>、<code>OpenEBS cStor</code></li>\n<li>多机环境，如果没有额外的块设备（非系统盘块设备）作为数据盘，仅单块系统盘块设备，选用 <code>OpenEBS Jiva</code></li>\n<li>单机环境，建议本地路径 <code>Dynamic Local PV - Hostpath, Dynamic Local PV - Rawfile</code>，由于单机多用于测试环境，数据可靠性要求较低。</li>\n</ul>\n<h1 id=\"三、安装\"><a href=\"#三、安装\" class=\"headerlink\" title=\"三、安装\"></a>三、安装</h1><p><a href=\"https://openebs.io/docs/2.12.x/user-guides/cstor\">openobs官方安装文档</a></p>\n<p>在安装openebs之前先去除污点，然后等安装完成再添加回来污点</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\"><span class=\"hljs-comment\"># 去除污点</span><br>kubectl taint nodes k8s-master01 <span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-role</span>.kubernetes.io/<span class=\"hljs-attr\">master=</span>:NoSchedule-<br><span class=\"hljs-comment\"># 添加污点</span><br>kubectl taint nodes k8s-master01 <span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-role</span>.kubernetes.io/<span class=\"hljs-attr\">master=</span>:NoSchedule<br></code></pre></td></tr></table></figure>\n\n<p>添加helm repo</p>\n<figure class=\"highlight armasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs armasm\"><span class=\"hljs-symbol\">helm</span> repo <span class=\"hljs-keyword\">add</span> openebs https:<span class=\"hljs-comment\">//openebs.github.io/charts</span><br><span class=\"hljs-symbol\">helm</span> repo update<br></code></pre></td></tr></table></figure>\n\n<p>安装openebs（这里只会安装Jiva和Local组件）</p>\n<figure class=\"highlight brainfuck\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs brainfuck\"><span class=\"hljs-comment\">helm install openebs</span> <span class=\"hljs-literal\">--</span><span class=\"hljs-comment\">namespace openebs openebs/openebs</span> <span class=\"hljs-literal\">--</span><span class=\"hljs-comment\">create</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">namespace</span> <span class=\"hljs-literal\">--</span><span class=\"hljs-comment\">version 3</span><span class=\"hljs-string\">.</span><span class=\"hljs-comment\">0</span><span class=\"hljs-string\">.</span><span class=\"hljs-comment\">x</span><br></code></pre></td></tr></table></figure>\n\n<p>添加cstor支持</p>\n<figure class=\"highlight jboss-cli\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs jboss-cli\">helm install openebs <span class=\"hljs-params\">--namespace</span> openebs openebs/openebs <span class=\"hljs-params\">--create-namespace</span> <span class=\"hljs-params\">--set</span> cstor.enabled=<span class=\"hljs-literal\">true</span> <span class=\"hljs-params\">--version</span> 3.2.0<br></code></pre></td></tr></table></figure>\n\n<p>查看安装</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\"><span class=\"hljs-comment\"># 查看安装pod</span><br>kubectl <span class=\"hljs-built_in\">get</span> pod -n openebs<br><span class=\"hljs-comment\"># 查看安装blockdevice，这里的blockdevice是磁盘，当添加一块未分配的磁盘，就会有值</span><br>kubectl <span class=\"hljs-built_in\">get</span> bd -n openebs<br></code></pre></td></tr></table></figure>\n\n<p>OpenEBS依赖与iSCSI做存储管理，因此需要先确保您的集群上已有安装openiscsi。 （这里当报错的时候可以安装试试）</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">yum -y install iscsi-initiator-utils<br>systemctl <span class=\"hljs-keyword\">enable</span> iscsid <span class=\"hljs-comment\">--now</span><br>systemctl <span class=\"hljs-keyword\">start</span> iscsid<br></code></pre></td></tr></table></figure>\n\n<p>查看安装状况：</p>\n<figure class=\"highlight tap\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tap\">[root@k8s-master01 ~]<span class=\"hljs-comment\"># kubectl get pod -n openebs</span><br>NAME                                            READY   STATUS    RESTARTS         AGE<br>openebs-cstor-admission-server-b74f5487-lkz84   1/1     Running  <span class=\"hljs-number\"> 1 </span>(6m21s ago)    8h<br>openebs-cstor-csi-controller-0                  6/6     Running  <span class=\"hljs-number\"> 0 </span>               4m44s<br>openebs-cstor-csi-node-4df4w                    2/2     Running  <span class=\"hljs-number\"> 2 </span>(61m ago)      8h<br>openebs-cstor-csi-node-x8bmt                    2/2     Running  <span class=\"hljs-number\"> 6 </span>(16m ago)      8h<br>openebs-cstor-csi-node-zzn4k                    2/2     Running  <span class=\"hljs-number\"> 2 </span>(6m21s ago)    8h<br>openebs-cstor-cspc-operator-84464fb479-fh949    1/1     Running  <span class=\"hljs-number\"> 3 </span>(16m ago)      8h<br>openebs-cstor-cvc-operator-646f6f676b-xhd44     1/1     Running  <span class=\"hljs-number\"> 2 </span>(16m ago)      46m<br>openebs-localpv-provisioner-55b65f8b55-zqj29    1/1     Running  <span class=\"hljs-number\"> 13 </span>(6m23s ago)   8h<br>openebs-ndm-429hl                               1/1     Running  <span class=\"hljs-number\"> 2 </span>(4m28s ago)    8h<br>openebs-ndm-9kkzd                               1/1     Running  <span class=\"hljs-number\"> 1 </span>(6m21s ago)    8h<br>openebs-ndm-operator-6c944d87b6-5ddxz           1/1     Running  <span class=\"hljs-number\"> 2 </span>(16m ago)      46m<br>openebs-ndm-sqnwx                               1/1     Running  <span class=\"hljs-number\"> 6 </span>(15m ago)      8h<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"四、添加磁盘\"><a href=\"#四、添加磁盘\" class=\"headerlink\" title=\"四、添加磁盘\"></a>四、添加磁盘</h1><figure class=\"highlight llvm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs llvm\">[root<span class=\"hljs-title\">@k8s-master01</span> ~]# kubectl get bd -n openebs<br>NAME                                           NODENAME       SIZE           CLAIMSTATE   STATUS     AGE<br>blockdevice<span class=\"hljs-number\">-57886</span>fae<span class=\"hljs-number\">032</span>a<span class=\"hljs-number\">3</span>d<span class=\"hljs-number\">3638</span>badeb<span class=\"hljs-number\">1282</span>dd<span class=\"hljs-number\">67</span>e   k<span class=\"hljs-number\">8</span>s-node<span class=\"hljs-number\">02</span>     <span class=\"hljs-number\">21473771008</span>    Unclaimed    Active     <span class=\"hljs-number\">53</span>s<br>blockdevice-d<span class=\"hljs-number\">923</span>fc<span class=\"hljs-number\">382</span>d<span class=\"hljs-number\">96</span>ff<span class=\"hljs-number\">6</span>eea<span class=\"hljs-number\">7</span>d<span class=\"hljs-number\">9</span>ab<span class=\"hljs-number\">8</span>efb<span class=\"hljs-number\">66224</span>   k<span class=\"hljs-number\">8</span>s-master<span class=\"hljs-number\">01</span>   <span class=\"hljs-number\">21473771008</span>    Unclaimed    Active     <span class=\"hljs-number\">11</span>m<br>blockdevice-e<span class=\"hljs-number\">5009</span>ce<span class=\"hljs-number\">419</span><span class=\"hljs-keyword\">c</span><span class=\"hljs-number\">80719025</span><span class=\"hljs-keyword\">c</span><span class=\"hljs-number\">4</span><span class=\"hljs-keyword\">cc</span><span class=\"hljs-number\">9409253</span>ab   k<span class=\"hljs-number\">8</span>s-node<span class=\"hljs-number\">01</span>     <span class=\"hljs-number\">21473771008</span>    Unclaimed    Active     <span class=\"hljs-number\">33</span>s<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"五、配置\"><a href=\"#五、配置\" class=\"headerlink\" title=\"五、配置\"></a>五、配置</h1><h2 id=\"5-1-创建cStor存储池\"><a href=\"#5-1-创建cStor存储池\" class=\"headerlink\" title=\"5.1 创建cStor存储池\"></a>5.1 创建cStor存储池</h2><p>cspc.yaml ：</p>\n<figure class=\"highlight nestedtext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nestedtext\"><span class=\"hljs-attribute\">apiVersion</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">cstor.openebs.io/v1</span><br><span class=\"hljs-attribute\">kind</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">CStorPoolCluster</span><br><span class=\"hljs-attribute\">metadata</span><span class=\"hljs-punctuation\">:</span><br> <span class=\"hljs-attribute\">name</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">cstor-disk-pool</span><br> <span class=\"hljs-attribute\">namespace</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">openebs</span><br><span class=\"hljs-attribute\">spec</span><span class=\"hljs-punctuation\">:</span><br> <span class=\"hljs-attribute\">pools</span><span class=\"hljs-punctuation\">:</span><br>   <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">nodeSelector:</span><br>       <span class=\"hljs-attribute\">kubernetes.io/hostname</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;k8s-master01&quot;</span><br>     <span class=\"hljs-attribute\">dataRaidGroups</span><span class=\"hljs-punctuation\">:</span><br>       <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">blockDevices:</span><br>           <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">blockDeviceName: &quot;blockdevice-d923fc382d96ff6eea7d9ab8efb66224&quot;</span><br>     <span class=\"hljs-attribute\">poolConfig</span><span class=\"hljs-punctuation\">:</span><br>       <span class=\"hljs-attribute\">dataRaidGroupType</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;stripe&quot;</span><br><br>   <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">nodeSelector:</span><br>       <span class=\"hljs-attribute\">kubernetes.io/hostname</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;k8s-node01&quot;</span><br>     <span class=\"hljs-attribute\">dataRaidGroups</span><span class=\"hljs-punctuation\">:</span><br>       <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">blockDevices:</span><br>           <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">blockDeviceName: &quot;blockdevice-e5009ce419c80719025c4cc9409253ab&quot;</span><br>     <span class=\"hljs-attribute\">poolConfig</span><span class=\"hljs-punctuation\">:</span><br>       <span class=\"hljs-attribute\">dataRaidGroupType</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;stripe&quot;</span><br><br>   <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">nodeSelector:</span><br>       <span class=\"hljs-attribute\">kubernetes.io/hostname</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;k8s-node02&quot;</span><br>     <span class=\"hljs-attribute\">dataRaidGroups</span><span class=\"hljs-punctuation\">:</span><br>       <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">blockDevices:</span><br>           <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">blockDeviceName: &quot;blockdevice-57886fae032a3d3638badeb1282dd67e&quot;</span><br>     <span class=\"hljs-attribute\">poolConfig</span><span class=\"hljs-punctuation\">:</span><br>       <span class=\"hljs-attribute\">dataRaidGroupType</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;stripe&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>dataRaidGroupType:可以根据您的需要设置为 <code>stripe</code> or <code>mirror</code> 。下面以配置为stripe为例。 </p>\n<figure class=\"highlight tap\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tap\">[root@k8s-master01 openebs]<span class=\"hljs-comment\"># kubectl get CStorPoolCluster -n openebs</span><br>NAME              HEALTHYINSTANCES   PROVISIONEDINSTANCES   DESIREDINSTANCES   AGE<br>cstor-disk-pool                     <span class=\"hljs-number\"> 3 </span>                    <span class=\"hljs-number\"> 3 </span>                 42s<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-2-storageclass创建\"><a href=\"#5-2-storageclass创建\" class=\"headerlink\" title=\"5.2 storageclass创建\"></a>5.2 storageclass创建</h2><h3 id=\"5-2-1-cstor的创建\"><a href=\"#5-2-1-cstor的创建\" class=\"headerlink\" title=\"5.2.1 cstor的创建\"></a>5.2.1 cstor的创建</h3><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">StorageClass</span><br><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">storage.k8s.io/v1</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">cstor-csi-disk</span><br><span class=\"hljs-attr\">provisioner:</span> <span class=\"hljs-string\">cstor.csi.openebs.io</span><br><span class=\"hljs-attr\">allowVolumeExpansion:</span> <span class=\"hljs-literal\">true</span><br><span class=\"hljs-attr\">parameters:</span><br>  <span class=\"hljs-attr\">cas-type:</span> <span class=\"hljs-string\">cstor</span><br>  <span class=\"hljs-comment\"># cstorPoolCluster should have the name of the CSPC</span><br>  <span class=\"hljs-attr\">cstorPoolCluster:</span> <span class=\"hljs-string\">cstor-disk-pool</span><br>  <span class=\"hljs-comment\"># replicaCount should be &lt;= no. of CSPI created in the selected CSPC</span><br>  <span class=\"hljs-attr\">replicaCount:</span> <span class=\"hljs-string\">&quot;3&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>添加硬盘后查看磁盘情况</p>\n<figure class=\"highlight tap\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tap\">磁盘 /dev/sdb：21.5 GB,<span class=\"hljs-number\"> 21474836480 </span>字节，41943040 个扇区<br>Units = 扇区 of<span class=\"hljs-number\"> 1 </span>*<span class=\"hljs-number\"> 512 </span>=<span class=\"hljs-number\"> 512 </span>bytes<br>扇区大小(逻辑/物理)：512 字节 /<span class=\"hljs-number\"> 512 </span>字节<br>I/O 大小(最小/最佳)：512 字节 /<span class=\"hljs-number\"> 512 </span>字节<br>磁盘标签类型：gpt<br>Disk identifier: ADA9C10B-8C31-4EE2-A29B-F2701E9554DC<br><br><br><span class=\"hljs-comment\">#         Start          End    Size  Type            Name</span><br><span class=\"hljs-number\"> 1 </span>       <span class=\"hljs-number\"> 2048 </span>   <span class=\"hljs-number\"> 41943006 </span>    20G  Linux filesyste OpenEBS_NDM<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"5-2-2-jiva\"><a href=\"#5-2-2-jiva\" class=\"headerlink\" title=\"5.2.2 jiva\"></a>5.2.2 jiva</h3><figure class=\"highlight nestedtext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nestedtext\"><span class=\"hljs-attribute\">apiVersion</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">storage.k8s.io/v1</span><br><span class=\"hljs-attribute\">kind</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">StorageClass</span><br><span class=\"hljs-attribute\">metadata</span><span class=\"hljs-punctuation\">:</span><br>  <span class=\"hljs-attribute\">name</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">jiva-storageclass</span><br>  <span class=\"hljs-attribute\">annotations</span><span class=\"hljs-punctuation\">:</span><br>    <span class=\"hljs-attribute\">openebs.io/cas-type</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">jiva</span><br>    <span class=\"hljs-attribute\">cas.openebs.io/config</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">|</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">name: StoragePool</span><br>        <span class=\"hljs-attribute\">value</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attribute\">provisioner</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">openebs.io/provisioner-iscsi</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"5-2-3-hostpath\"><a href=\"#5-2-3-hostpath\" class=\"headerlink\" title=\"5.2.3  hostpath\"></a>5.2.3  hostpath</h3><figure class=\"highlight nestedtext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nestedtext\"><span class=\"hljs-attribute\">apiVersion</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">storage.k8s.io/v1</span><br><span class=\"hljs-attribute\">kind</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">StorageClass</span><br><span class=\"hljs-attribute\">metadata</span><span class=\"hljs-punctuation\">:</span><br>  <span class=\"hljs-attribute\">name</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">localpv-hostpath-sc</span><br>  <span class=\"hljs-attribute\">annotations</span><span class=\"hljs-punctuation\">:</span><br>    <span class=\"hljs-attribute\">openebs.io/cas-type</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">local</span><br>    <span class=\"hljs-attribute\">cas.openebs.io/config</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">|</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">name: BasePath</span><br>        <span class=\"hljs-attribute\">value</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;/var/openebs/local&quot;</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">name: StorageType</span><br>        <span class=\"hljs-attribute\">value</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;hostpath&quot;</span><br><span class=\"hljs-attribute\">provisioner</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">openebs.io/local</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"5-2-4-device\"><a href=\"#5-2-4-device\" class=\"headerlink\" title=\"5.2.4 device\"></a>5.2.4 device</h3><p>下面的类型需要添加硬盘</p>\n<figure class=\"highlight tap\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tap\">磁盘 /dev/sdc：21.5 GB,<span class=\"hljs-number\"> 21474836480 </span>字节，41943040 个扇区<br>Units = 扇区 of<span class=\"hljs-number\"> 1 </span>*<span class=\"hljs-number\"> 512 </span>=<span class=\"hljs-number\"> 512 </span>bytes<br>扇区大小(逻辑/物理)：512 字节 /<span class=\"hljs-number\"> 512 </span>字节<br>I/O 大小(最小/最佳)：512 字节 /<span class=\"hljs-number\"> 512 </span>字节<br>磁盘标签类型：gpt<br>Disk identifier: BAD0A706-0A9D-478A-85C6-319224EC5D1F<br><br><br><span class=\"hljs-comment\">#         Start          End    Size  Type            Name</span><br><span class=\"hljs-number\"> 1 </span>       <span class=\"hljs-number\"> 2048 </span>   <span class=\"hljs-number\"> 41943006 </span>    20G  Linux filesyste OpenEBS_NDM<br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight nestedtext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nestedtext\"><span class=\"hljs-attribute\">apiVersion</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">storage.k8s.io/v1</span><br><span class=\"hljs-attribute\">kind</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">StorageClass</span><br><span class=\"hljs-attribute\">metadata</span><span class=\"hljs-punctuation\">:</span><br>  <span class=\"hljs-attribute\">name</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">localpv-device-sc</span><br>  <span class=\"hljs-attribute\">annotations</span><span class=\"hljs-punctuation\">:</span><br>    <span class=\"hljs-attribute\">openebs.io/cas-type</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">local</span><br>    <span class=\"hljs-attribute\">cas.openebs.io/config</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">|</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">name: StorageType</span><br>        <span class=\"hljs-attribute\">value</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;device&quot;</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">name: FSType</span><br>        <span class=\"hljs-attribute\">value</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">ext4</span><br><span class=\"hljs-attribute\">provisioner</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">openebs.io/local</span><br></code></pre></td></tr></table></figure>\n\n<p>查看：</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">[root@k8s-master01 openebs]# kubectl <span class=\"hljs-keyword\">get</span> sc -n openebs<br><span class=\"hljs-type\">NAME</span>               PROVISIONER            RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE<br>cstor-csi-disk     cstor.csi.openebs.io   <span class=\"hljs-keyword\">Delete</span>          <span class=\"hljs-keyword\">Immediate</span>              <span class=\"hljs-keyword\">true</span>                   <span class=\"hljs-number\">43</span>s<br>openebs-device     openebs.io/<span class=\"hljs-keyword\">local</span>       <span class=\"hljs-keyword\">Delete</span>          WaitForFirstConsumer   <span class=\"hljs-keyword\">false</span>                  <span class=\"hljs-number\">9</span>h<br>openebs-hostpath   openebs.io/<span class=\"hljs-keyword\">local</span>       <span class=\"hljs-keyword\">Delete</span>          WaitForFirstConsumer   <span class=\"hljs-keyword\">false</span>                  <span class=\"hljs-number\">9</span>h<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"5-2-5-cStor、Jiva、LocalPV-特性比较：\"><a href=\"#5-2-5-cStor、Jiva、LocalPV-特性比较：\" class=\"headerlink\" title=\"5.2.5 cStor、Jiva、LocalPV 特性比较：\"></a>5.2.5 cStor、Jiva、LocalPV 特性比较：</h3><table>\n<thead>\n<tr>\n<th>特性</th>\n<th>Jiva</th>\n<th>cStor</th>\n<th>Local PV</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>轻量级运行于用户空间</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>同步复制</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>适合低容量工作负载</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>支持快照，克隆</td>\n<td>Basic</td>\n<td>Advanced</td>\n<td>No</td>\n</tr>\n<tr>\n<td>数据一致性</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>NA</td>\n</tr>\n<tr>\n<td>使用 Velero 恢复备份</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>适合高容量工作负载</td>\n<td>No</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>自动精简配置</td>\n<td></td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>磁盘池或聚合支持</td>\n<td></td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>动态扩容</td>\n<td></td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>数据弹性 (RAID 支持)</td>\n<td></td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>接近原生磁盘性能</td>\n<td>No</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n</tbody></table>\n<p>大多数场景推荐 <code>cStor</code>，因其提供了强大的功能，包括快照 / 克隆、存储池功能（如精简资源调配、按需扩容等）。</p>\n<p><code>Jiva</code> 适用于低容量需求的工作负载场景，例如 <code>5</code> 到 <code>50G</code>。尽管使用 <code>Jiva</code> 没有空间限制，但建议将其用于低容量工作负载。<code>Jiva</code> 非常易于使用，并提供企业级容器本地存储，而不需要专用硬盘。有快照和克隆功能的需求的场景，优先考虑使用 <code>cStor</code> 而不是 <code>Jiva</code>。</p>\n<h2 id=\"5-3-默认sc\"><a href=\"#5-3-默认sc\" class=\"headerlink\" title=\"5.3 默认sc\"></a>5.3 默认sc</h2><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs kotlin\">kubectl patch storage<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">cstor</span>-<span class=\"hljs-title\">csi</span>-<span class=\"hljs-title\">disk</span> -<span class=\"hljs-title\">p</span> &#x27;&#123;<span class=\"hljs-string\">&quot;metadata&quot;</span>: &#123;<span class=\"hljs-string\">&quot;annotations&quot;</span>:&#123;<span class=\"hljs-string\">&quot;storageclass.kubernetes.io/is-default-class&quot;</span>:<span class=\"hljs-string\">&quot;true&quot;</span>&#125;&#125;&#125;<span class=\"hljs-string\">&#x27;</span><br></code></pre></td></tr></table></figure>\n\n\n\n<p>推荐文章：</p>\n<p><a href=\"https://blog.csdn.net/easylife206/article/details/125213855\">https://blog.csdn.net/easylife206/article/details/125213855</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/519172233\">https://zhuanlan.zhihu.com/p/519172233</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、介绍\"><a href=\"#一、介绍\" class=\"headerlink\" title=\"一、介绍\"></a>一、介绍</h1><p>OpenEBS 是 CNCF 项目的一部分，采用 Apache v2 许可证。是 Kubernetes 部署使用最广泛且易用的开源存储解决方案。</p>\n<p><strong>目的：</strong></p>\n<p>让持久化工作负载的存储和存储服务完全集成到环境中，这样每个团队和工作负载都可以从控制的粒度和 Kubernetes 原生行为中获益。</p>\n<p><strong>特点：</strong></p>\n<ul>\n<li><p>微服务架构，使用 Kubernetes 自身的能力来编排管理 OpenEBS 组件。</p>\n</li>\n<li><p>OpenEBS 支持一系列存储引擎，以便开发人员能够部署适合其应用程序设计目标的存储技术。</p>\n<p>像 Cassandra 这样的分布式应用程序可以使用 LocalPV 引擎实现最低延迟的写操作。</p>\n<p>像 MySQL 和 PostgreSQL 这样的独立应用程序可以使用 ZFS 引擎 (cStor) 进行恢复。</p>\n<p>像 Kafka 这样的流媒体应用程序可以使用 NVMe 引擎 Mayastor 在边缘环境中获得最佳性能。</p>\n<p>在各种引擎类型中，OpenEBS 为高可用性、快照、克隆和易管理性提供了一致的框架。</p>\n</li>\n<li><p>管理员和开发人员可以使用 Kubernetes 提供的所有工具来交互和管理 OpenEBS。</p>\n</li>\n</ul>\n<h1 id=\"二、OpenEBS-存储引擎建议\"><a href=\"#二、OpenEBS-存储引擎建议\" class=\"headerlink\" title=\"二、OpenEBS 存储引擎建议\"></a>二、OpenEBS 存储引擎建议</h1><table>\n<thead>\n<tr>\n<th>应用需求</th>\n<th>存储类型</th>\n<th>OpenEBS 卷类型</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>低时延、高可用性、同步复制、快照、克隆、精简配置</td>\n<td>SSD/ 云存储卷</td>\n<td>OpenEBS Mayastor</td>\n</tr>\n<tr>\n<td>高可用性、同步复制、快照、克隆、精简配置</td>\n<td>机械 /SSD/ 云存储卷</td>\n<td>OpenEBS cStor</td>\n</tr>\n<tr>\n<td>高可用性、同步复制、精简配置</td>\n<td>主机路径或外部挂载存储</td>\n<td>OpenEBS Jiva</td>\n</tr>\n<tr>\n<td>低时延、本地 PV</td>\n<td>主机路径或外部挂载存储</td>\n<td>Dynamic Local PV - Hostpath, Dynamic Local PV - Rawfile</td>\n</tr>\n<tr>\n<td>低时延、本地 PV</td>\n<td>本地机械 /SSD/ 云存储卷等块设备</td>\n<td>Dynamic Local PV - Device</td>\n</tr>\n<tr>\n<td>低延迟，本地 PV，快照，克隆</td>\n<td>本地机械 /SSD/ 云存储卷等块设备</td>\n<td>OpenEBS Dynamic Local PV - ZFS , OpenEBS Dynamic Local PV - LVM</td>\n</tr>\n</tbody></table>\n<ul>\n<li>多机环境，如果有额外的块设备（非系统盘块设备）作为数据盘，选用 <code>OpenEBS Mayastor</code>、<code>OpenEBS cStor</code></li>\n<li>多机环境，如果没有额外的块设备（非系统盘块设备）作为数据盘，仅单块系统盘块设备，选用 <code>OpenEBS Jiva</code></li>\n<li>单机环境，建议本地路径 <code>Dynamic Local PV - Hostpath, Dynamic Local PV - Rawfile</code>，由于单机多用于测试环境，数据可靠性要求较低。</li>\n</ul>\n<h1 id=\"三、安装\"><a href=\"#三、安装\" class=\"headerlink\" title=\"三、安装\"></a>三、安装</h1><p><a href=\"https://openebs.io/docs/2.12.x/user-guides/cstor\">openobs官方安装文档</a></p>\n<p>在安装openebs之前先去除污点，然后等安装完成再添加回来污点</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\"><span class=\"hljs-comment\"># 去除污点</span><br>kubectl taint nodes k8s-master01 <span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-role</span>.kubernetes.io/<span class=\"hljs-attr\">master=</span>:NoSchedule-<br><span class=\"hljs-comment\"># 添加污点</span><br>kubectl taint nodes k8s-master01 <span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-role</span>.kubernetes.io/<span class=\"hljs-attr\">master=</span>:NoSchedule<br></code></pre></td></tr></table></figure>\n\n<p>添加helm repo</p>\n<figure class=\"highlight armasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs armasm\"><span class=\"hljs-symbol\">helm</span> repo <span class=\"hljs-keyword\">add</span> openebs https:<span class=\"hljs-comment\">//openebs.github.io/charts</span><br><span class=\"hljs-symbol\">helm</span> repo update<br></code></pre></td></tr></table></figure>\n\n<p>安装openebs（这里只会安装Jiva和Local组件）</p>\n<figure class=\"highlight brainfuck\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs brainfuck\"><span class=\"hljs-comment\">helm install openebs</span> <span class=\"hljs-literal\">--</span><span class=\"hljs-comment\">namespace openebs openebs/openebs</span> <span class=\"hljs-literal\">--</span><span class=\"hljs-comment\">create</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">namespace</span> <span class=\"hljs-literal\">--</span><span class=\"hljs-comment\">version 3</span><span class=\"hljs-string\">.</span><span class=\"hljs-comment\">0</span><span class=\"hljs-string\">.</span><span class=\"hljs-comment\">x</span><br></code></pre></td></tr></table></figure>\n\n<p>添加cstor支持</p>\n<figure class=\"highlight jboss-cli\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs jboss-cli\">helm install openebs <span class=\"hljs-params\">--namespace</span> openebs openebs/openebs <span class=\"hljs-params\">--create-namespace</span> <span class=\"hljs-params\">--set</span> cstor.enabled=<span class=\"hljs-literal\">true</span> <span class=\"hljs-params\">--version</span> 3.2.0<br></code></pre></td></tr></table></figure>\n\n<p>查看安装</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\"><span class=\"hljs-comment\"># 查看安装pod</span><br>kubectl <span class=\"hljs-built_in\">get</span> pod -n openebs<br><span class=\"hljs-comment\"># 查看安装blockdevice，这里的blockdevice是磁盘，当添加一块未分配的磁盘，就会有值</span><br>kubectl <span class=\"hljs-built_in\">get</span> bd -n openebs<br></code></pre></td></tr></table></figure>\n\n<p>OpenEBS依赖与iSCSI做存储管理，因此需要先确保您的集群上已有安装openiscsi。 （这里当报错的时候可以安装试试）</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">yum -y install iscsi-initiator-utils<br>systemctl <span class=\"hljs-keyword\">enable</span> iscsid <span class=\"hljs-comment\">--now</span><br>systemctl <span class=\"hljs-keyword\">start</span> iscsid<br></code></pre></td></tr></table></figure>\n\n<p>查看安装状况：</p>\n<figure class=\"highlight tap\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tap\">[root@k8s-master01 ~]<span class=\"hljs-comment\"># kubectl get pod -n openebs</span><br>NAME                                            READY   STATUS    RESTARTS         AGE<br>openebs-cstor-admission-server-b74f5487-lkz84   1/1     Running  <span class=\"hljs-number\"> 1 </span>(6m21s ago)    8h<br>openebs-cstor-csi-controller-0                  6/6     Running  <span class=\"hljs-number\"> 0 </span>               4m44s<br>openebs-cstor-csi-node-4df4w                    2/2     Running  <span class=\"hljs-number\"> 2 </span>(61m ago)      8h<br>openebs-cstor-csi-node-x8bmt                    2/2     Running  <span class=\"hljs-number\"> 6 </span>(16m ago)      8h<br>openebs-cstor-csi-node-zzn4k                    2/2     Running  <span class=\"hljs-number\"> 2 </span>(6m21s ago)    8h<br>openebs-cstor-cspc-operator-84464fb479-fh949    1/1     Running  <span class=\"hljs-number\"> 3 </span>(16m ago)      8h<br>openebs-cstor-cvc-operator-646f6f676b-xhd44     1/1     Running  <span class=\"hljs-number\"> 2 </span>(16m ago)      46m<br>openebs-localpv-provisioner-55b65f8b55-zqj29    1/1     Running  <span class=\"hljs-number\"> 13 </span>(6m23s ago)   8h<br>openebs-ndm-429hl                               1/1     Running  <span class=\"hljs-number\"> 2 </span>(4m28s ago)    8h<br>openebs-ndm-9kkzd                               1/1     Running  <span class=\"hljs-number\"> 1 </span>(6m21s ago)    8h<br>openebs-ndm-operator-6c944d87b6-5ddxz           1/1     Running  <span class=\"hljs-number\"> 2 </span>(16m ago)      46m<br>openebs-ndm-sqnwx                               1/1     Running  <span class=\"hljs-number\"> 6 </span>(15m ago)      8h<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"四、添加磁盘\"><a href=\"#四、添加磁盘\" class=\"headerlink\" title=\"四、添加磁盘\"></a>四、添加磁盘</h1><figure class=\"highlight llvm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs llvm\">[root<span class=\"hljs-title\">@k8s-master01</span> ~]# kubectl get bd -n openebs<br>NAME                                           NODENAME       SIZE           CLAIMSTATE   STATUS     AGE<br>blockdevice<span class=\"hljs-number\">-57886</span>fae<span class=\"hljs-number\">032</span>a<span class=\"hljs-number\">3</span>d<span class=\"hljs-number\">3638</span>badeb<span class=\"hljs-number\">1282</span>dd<span class=\"hljs-number\">67</span>e   k<span class=\"hljs-number\">8</span>s-node<span class=\"hljs-number\">02</span>     <span class=\"hljs-number\">21473771008</span>    Unclaimed    Active     <span class=\"hljs-number\">53</span>s<br>blockdevice-d<span class=\"hljs-number\">923</span>fc<span class=\"hljs-number\">382</span>d<span class=\"hljs-number\">96</span>ff<span class=\"hljs-number\">6</span>eea<span class=\"hljs-number\">7</span>d<span class=\"hljs-number\">9</span>ab<span class=\"hljs-number\">8</span>efb<span class=\"hljs-number\">66224</span>   k<span class=\"hljs-number\">8</span>s-master<span class=\"hljs-number\">01</span>   <span class=\"hljs-number\">21473771008</span>    Unclaimed    Active     <span class=\"hljs-number\">11</span>m<br>blockdevice-e<span class=\"hljs-number\">5009</span>ce<span class=\"hljs-number\">419</span><span class=\"hljs-keyword\">c</span><span class=\"hljs-number\">80719025</span><span class=\"hljs-keyword\">c</span><span class=\"hljs-number\">4</span><span class=\"hljs-keyword\">cc</span><span class=\"hljs-number\">9409253</span>ab   k<span class=\"hljs-number\">8</span>s-node<span class=\"hljs-number\">01</span>     <span class=\"hljs-number\">21473771008</span>    Unclaimed    Active     <span class=\"hljs-number\">33</span>s<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"五、配置\"><a href=\"#五、配置\" class=\"headerlink\" title=\"五、配置\"></a>五、配置</h1><h2 id=\"5-1-创建cStor存储池\"><a href=\"#5-1-创建cStor存储池\" class=\"headerlink\" title=\"5.1 创建cStor存储池\"></a>5.1 创建cStor存储池</h2><p>cspc.yaml ：</p>\n<figure class=\"highlight nestedtext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nestedtext\"><span class=\"hljs-attribute\">apiVersion</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">cstor.openebs.io/v1</span><br><span class=\"hljs-attribute\">kind</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">CStorPoolCluster</span><br><span class=\"hljs-attribute\">metadata</span><span class=\"hljs-punctuation\">:</span><br> <span class=\"hljs-attribute\">name</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">cstor-disk-pool</span><br> <span class=\"hljs-attribute\">namespace</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">openebs</span><br><span class=\"hljs-attribute\">spec</span><span class=\"hljs-punctuation\">:</span><br> <span class=\"hljs-attribute\">pools</span><span class=\"hljs-punctuation\">:</span><br>   <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">nodeSelector:</span><br>       <span class=\"hljs-attribute\">kubernetes.io/hostname</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;k8s-master01&quot;</span><br>     <span class=\"hljs-attribute\">dataRaidGroups</span><span class=\"hljs-punctuation\">:</span><br>       <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">blockDevices:</span><br>           <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">blockDeviceName: &quot;blockdevice-d923fc382d96ff6eea7d9ab8efb66224&quot;</span><br>     <span class=\"hljs-attribute\">poolConfig</span><span class=\"hljs-punctuation\">:</span><br>       <span class=\"hljs-attribute\">dataRaidGroupType</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;stripe&quot;</span><br><br>   <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">nodeSelector:</span><br>       <span class=\"hljs-attribute\">kubernetes.io/hostname</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;k8s-node01&quot;</span><br>     <span class=\"hljs-attribute\">dataRaidGroups</span><span class=\"hljs-punctuation\">:</span><br>       <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">blockDevices:</span><br>           <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">blockDeviceName: &quot;blockdevice-e5009ce419c80719025c4cc9409253ab&quot;</span><br>     <span class=\"hljs-attribute\">poolConfig</span><span class=\"hljs-punctuation\">:</span><br>       <span class=\"hljs-attribute\">dataRaidGroupType</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;stripe&quot;</span><br><br>   <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">nodeSelector:</span><br>       <span class=\"hljs-attribute\">kubernetes.io/hostname</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;k8s-node02&quot;</span><br>     <span class=\"hljs-attribute\">dataRaidGroups</span><span class=\"hljs-punctuation\">:</span><br>       <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">blockDevices:</span><br>           <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">blockDeviceName: &quot;blockdevice-57886fae032a3d3638badeb1282dd67e&quot;</span><br>     <span class=\"hljs-attribute\">poolConfig</span><span class=\"hljs-punctuation\">:</span><br>       <span class=\"hljs-attribute\">dataRaidGroupType</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;stripe&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>dataRaidGroupType:可以根据您的需要设置为 <code>stripe</code> or <code>mirror</code> 。下面以配置为stripe为例。 </p>\n<figure class=\"highlight tap\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tap\">[root@k8s-master01 openebs]<span class=\"hljs-comment\"># kubectl get CStorPoolCluster -n openebs</span><br>NAME              HEALTHYINSTANCES   PROVISIONEDINSTANCES   DESIREDINSTANCES   AGE<br>cstor-disk-pool                     <span class=\"hljs-number\"> 3 </span>                    <span class=\"hljs-number\"> 3 </span>                 42s<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-2-storageclass创建\"><a href=\"#5-2-storageclass创建\" class=\"headerlink\" title=\"5.2 storageclass创建\"></a>5.2 storageclass创建</h2><h3 id=\"5-2-1-cstor的创建\"><a href=\"#5-2-1-cstor的创建\" class=\"headerlink\" title=\"5.2.1 cstor的创建\"></a>5.2.1 cstor的创建</h3><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">StorageClass</span><br><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">storage.k8s.io/v1</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">cstor-csi-disk</span><br><span class=\"hljs-attr\">provisioner:</span> <span class=\"hljs-string\">cstor.csi.openebs.io</span><br><span class=\"hljs-attr\">allowVolumeExpansion:</span> <span class=\"hljs-literal\">true</span><br><span class=\"hljs-attr\">parameters:</span><br>  <span class=\"hljs-attr\">cas-type:</span> <span class=\"hljs-string\">cstor</span><br>  <span class=\"hljs-comment\"># cstorPoolCluster should have the name of the CSPC</span><br>  <span class=\"hljs-attr\">cstorPoolCluster:</span> <span class=\"hljs-string\">cstor-disk-pool</span><br>  <span class=\"hljs-comment\"># replicaCount should be &lt;= no. of CSPI created in the selected CSPC</span><br>  <span class=\"hljs-attr\">replicaCount:</span> <span class=\"hljs-string\">&quot;3&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>添加硬盘后查看磁盘情况</p>\n<figure class=\"highlight tap\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tap\">磁盘 /dev/sdb：21.5 GB,<span class=\"hljs-number\"> 21474836480 </span>字节，41943040 个扇区<br>Units = 扇区 of<span class=\"hljs-number\"> 1 </span>*<span class=\"hljs-number\"> 512 </span>=<span class=\"hljs-number\"> 512 </span>bytes<br>扇区大小(逻辑/物理)：512 字节 /<span class=\"hljs-number\"> 512 </span>字节<br>I/O 大小(最小/最佳)：512 字节 /<span class=\"hljs-number\"> 512 </span>字节<br>磁盘标签类型：gpt<br>Disk identifier: ADA9C10B-8C31-4EE2-A29B-F2701E9554DC<br><br><br><span class=\"hljs-comment\">#         Start          End    Size  Type            Name</span><br><span class=\"hljs-number\"> 1 </span>       <span class=\"hljs-number\"> 2048 </span>   <span class=\"hljs-number\"> 41943006 </span>    20G  Linux filesyste OpenEBS_NDM<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"5-2-2-jiva\"><a href=\"#5-2-2-jiva\" class=\"headerlink\" title=\"5.2.2 jiva\"></a>5.2.2 jiva</h3><figure class=\"highlight nestedtext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nestedtext\"><span class=\"hljs-attribute\">apiVersion</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">storage.k8s.io/v1</span><br><span class=\"hljs-attribute\">kind</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">StorageClass</span><br><span class=\"hljs-attribute\">metadata</span><span class=\"hljs-punctuation\">:</span><br>  <span class=\"hljs-attribute\">name</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">jiva-storageclass</span><br>  <span class=\"hljs-attribute\">annotations</span><span class=\"hljs-punctuation\">:</span><br>    <span class=\"hljs-attribute\">openebs.io/cas-type</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">jiva</span><br>    <span class=\"hljs-attribute\">cas.openebs.io/config</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">|</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">name: StoragePool</span><br>        <span class=\"hljs-attribute\">value</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attribute\">provisioner</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">openebs.io/provisioner-iscsi</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"5-2-3-hostpath\"><a href=\"#5-2-3-hostpath\" class=\"headerlink\" title=\"5.2.3  hostpath\"></a>5.2.3  hostpath</h3><figure class=\"highlight nestedtext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nestedtext\"><span class=\"hljs-attribute\">apiVersion</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">storage.k8s.io/v1</span><br><span class=\"hljs-attribute\">kind</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">StorageClass</span><br><span class=\"hljs-attribute\">metadata</span><span class=\"hljs-punctuation\">:</span><br>  <span class=\"hljs-attribute\">name</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">localpv-hostpath-sc</span><br>  <span class=\"hljs-attribute\">annotations</span><span class=\"hljs-punctuation\">:</span><br>    <span class=\"hljs-attribute\">openebs.io/cas-type</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">local</span><br>    <span class=\"hljs-attribute\">cas.openebs.io/config</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">|</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">name: BasePath</span><br>        <span class=\"hljs-attribute\">value</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;/var/openebs/local&quot;</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">name: StorageType</span><br>        <span class=\"hljs-attribute\">value</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;hostpath&quot;</span><br><span class=\"hljs-attribute\">provisioner</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">openebs.io/local</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"5-2-4-device\"><a href=\"#5-2-4-device\" class=\"headerlink\" title=\"5.2.4 device\"></a>5.2.4 device</h3><p>下面的类型需要添加硬盘</p>\n<figure class=\"highlight tap\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tap\">磁盘 /dev/sdc：21.5 GB,<span class=\"hljs-number\"> 21474836480 </span>字节，41943040 个扇区<br>Units = 扇区 of<span class=\"hljs-number\"> 1 </span>*<span class=\"hljs-number\"> 512 </span>=<span class=\"hljs-number\"> 512 </span>bytes<br>扇区大小(逻辑/物理)：512 字节 /<span class=\"hljs-number\"> 512 </span>字节<br>I/O 大小(最小/最佳)：512 字节 /<span class=\"hljs-number\"> 512 </span>字节<br>磁盘标签类型：gpt<br>Disk identifier: BAD0A706-0A9D-478A-85C6-319224EC5D1F<br><br><br><span class=\"hljs-comment\">#         Start          End    Size  Type            Name</span><br><span class=\"hljs-number\"> 1 </span>       <span class=\"hljs-number\"> 2048 </span>   <span class=\"hljs-number\"> 41943006 </span>    20G  Linux filesyste OpenEBS_NDM<br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight nestedtext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nestedtext\"><span class=\"hljs-attribute\">apiVersion</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">storage.k8s.io/v1</span><br><span class=\"hljs-attribute\">kind</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">StorageClass</span><br><span class=\"hljs-attribute\">metadata</span><span class=\"hljs-punctuation\">:</span><br>  <span class=\"hljs-attribute\">name</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">localpv-device-sc</span><br>  <span class=\"hljs-attribute\">annotations</span><span class=\"hljs-punctuation\">:</span><br>    <span class=\"hljs-attribute\">openebs.io/cas-type</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">local</span><br>    <span class=\"hljs-attribute\">cas.openebs.io/config</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">|</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">name: StorageType</span><br>        <span class=\"hljs-attribute\">value</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">&quot;device&quot;</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">name: FSType</span><br>        <span class=\"hljs-attribute\">value</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">ext4</span><br><span class=\"hljs-attribute\">provisioner</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">openebs.io/local</span><br></code></pre></td></tr></table></figure>\n\n<p>查看：</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">[root@k8s-master01 openebs]# kubectl <span class=\"hljs-keyword\">get</span> sc -n openebs<br><span class=\"hljs-type\">NAME</span>               PROVISIONER            RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE<br>cstor-csi-disk     cstor.csi.openebs.io   <span class=\"hljs-keyword\">Delete</span>          <span class=\"hljs-keyword\">Immediate</span>              <span class=\"hljs-keyword\">true</span>                   <span class=\"hljs-number\">43</span>s<br>openebs-device     openebs.io/<span class=\"hljs-keyword\">local</span>       <span class=\"hljs-keyword\">Delete</span>          WaitForFirstConsumer   <span class=\"hljs-keyword\">false</span>                  <span class=\"hljs-number\">9</span>h<br>openebs-hostpath   openebs.io/<span class=\"hljs-keyword\">local</span>       <span class=\"hljs-keyword\">Delete</span>          WaitForFirstConsumer   <span class=\"hljs-keyword\">false</span>                  <span class=\"hljs-number\">9</span>h<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"5-2-5-cStor、Jiva、LocalPV-特性比较：\"><a href=\"#5-2-5-cStor、Jiva、LocalPV-特性比较：\" class=\"headerlink\" title=\"5.2.5 cStor、Jiva、LocalPV 特性比较：\"></a>5.2.5 cStor、Jiva、LocalPV 特性比较：</h3><table>\n<thead>\n<tr>\n<th>特性</th>\n<th>Jiva</th>\n<th>cStor</th>\n<th>Local PV</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>轻量级运行于用户空间</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>同步复制</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>适合低容量工作负载</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>支持快照，克隆</td>\n<td>Basic</td>\n<td>Advanced</td>\n<td>No</td>\n</tr>\n<tr>\n<td>数据一致性</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>NA</td>\n</tr>\n<tr>\n<td>使用 Velero 恢复备份</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>适合高容量工作负载</td>\n<td>No</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>自动精简配置</td>\n<td></td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>磁盘池或聚合支持</td>\n<td></td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>动态扩容</td>\n<td></td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>数据弹性 (RAID 支持)</td>\n<td></td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr>\n<td>接近原生磁盘性能</td>\n<td>No</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n</tbody></table>\n<p>大多数场景推荐 <code>cStor</code>，因其提供了强大的功能，包括快照 / 克隆、存储池功能（如精简资源调配、按需扩容等）。</p>\n<p><code>Jiva</code> 适用于低容量需求的工作负载场景，例如 <code>5</code> 到 <code>50G</code>。尽管使用 <code>Jiva</code> 没有空间限制，但建议将其用于低容量工作负载。<code>Jiva</code> 非常易于使用，并提供企业级容器本地存储，而不需要专用硬盘。有快照和克隆功能的需求的场景，优先考虑使用 <code>cStor</code> 而不是 <code>Jiva</code>。</p>\n<h2 id=\"5-3-默认sc\"><a href=\"#5-3-默认sc\" class=\"headerlink\" title=\"5.3 默认sc\"></a>5.3 默认sc</h2><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs kotlin\">kubectl patch storage<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">cstor</span>-<span class=\"hljs-title\">csi</span>-<span class=\"hljs-title\">disk</span> -<span class=\"hljs-title\">p</span> &#x27;&#123;<span class=\"hljs-string\">&quot;metadata&quot;</span>: &#123;<span class=\"hljs-string\">&quot;annotations&quot;</span>:&#123;<span class=\"hljs-string\">&quot;storageclass.kubernetes.io/is-default-class&quot;</span>:<span class=\"hljs-string\">&quot;true&quot;</span>&#125;&#125;&#125;<span class=\"hljs-string\">&#x27;</span><br></code></pre></td></tr></table></figure>\n\n\n\n<p>推荐文章：</p>\n<p><a href=\"https://blog.csdn.net/easylife206/article/details/125213855\">https://blog.csdn.net/easylife206/article/details/125213855</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/519172233\">https://zhuanlan.zhihu.com/p/519172233</a></p>\n"},{"title":"k8s快速集成KubeSphere","date":"2022-07-24T09:38:02.000Z","_content":"\n# 一、KubeSphere 介绍\n\nKubeSphere 是在 Kubernetes 之上构建的面向云原生应用的**分布式操作系统**，完全开源，支持多云与多集群管理，提供全栈的 IT 自动化运维能力，简化企业的 DevOps 工作流。它的架构可以非常方便地使第三方应用与云原生生态组件进行即插即用 (plug-and-play) 的集成。 \n\n功能：\n\n- 多云与多集群管理\n- Kubernetes 资源管理\n- DevOps\n- 应用生命周期管理\n- 微服务治理（服务网格）\n- 日志查询与收集\n- 服务与网络\n- 多租户管理\n- 监控告警\n- 事件与审计查询\n- 存储管理\n- 访问权限控制\n- GPU 支持\n- 网络策略\n- 镜像仓库管理\n- 安全管理等 \n\n# 二、部署 KubeSphere\n\n当卸载重新安装时，执行下面 的脚本全面卸载：\n\n```\nhttps://github.com/kubesphere/ks-installer/edit/master/scripts/kubesphere-delete.sh\n```\n\n## 2.1 执行以下命令以开始安装：\n\n```\nkubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.2.1/kubesphere-installer.yaml\nkubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.2.1/cluster-configuration.yaml\n\n#默认sc\n kubectl patch sc openebs-hostpath -p '{\"metadata\": {\"annotations\": {\"storageclass.beta.kubernetes.io/is-default-class\": \"true\"}}}'\n```\n## 2.2 检查安装\n\n日志查看：\n\n```\nkubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f\n\n结果：\nCollecting installation results ...\n#####################################################\n###              Welcome to KubeSphere!           ###\n#####################################################\n\nConsole: http://192.168.66.10:30880\nAccount: admin\nPassword: P@88w0rd\n```\n安装服务查看：\n\n使用 `kubectl get pod --all-namespaces` 查看所有 Pod 在 KubeSphere 相关的命名空间是否正常运行。如果是正常运行，请通过以下命令来检查控制台的端口（默认为 30880，可以通过默认帐户和密码 (`admin/P@88w0rd`) 访问 Web 控制台。）：\n\n```\nkubectl get svc/ks-console -n kubesphere-system\n```\n重置密码：\n\n```\nkubectl patch users <USERNAME> -p '{\"spec\":{\"password\":\"<YOURPASSWORD>\"}}' --type='merge' && kubectl annotate users <USERNAME> iam.kubesphere.io/password-encrypted-\n\nkubectl patch users admin -p '{\"spec\":{\"password\":\"P@88w0rd\"}}' --type='merge' && kubectl annotate users admin iam.kubesphere.io/password-encrypted-\n```\n# 三、示例wordpress部署\n\n这里使用project-regular权限账号进行登录，可以通过admin用户添加指定账号，然后创建空间demo-wordspace，并且创建demo-project项目\n\n## 3.1 密钥创建\n\n选择**类型**为 Opaque（默认）\n\nmysql密钥：\n\n```\n名称：mysql-secret\n键值：MYSQL_ROOT_PASSWORD=123456\n```\n\n创建 WordPress 密钥：\n\n```\n名称：wordpress-secret\n键值：WORDPRESS_DB_PASSWORD =123456\n   \n```\n\n![1662953701465](k8s快速集成KubeSphere/1662953701465.png)\n\n## 3.2 创建持久卷声明\n\n创建持久券：wordpress-pvc ，选择（存储类、访问模式、卷容量）\n\n## 3.3 创建应用程序\n\n### 3.3.1 添加 MySQL 后端组件\n\n（1）创建应用\n\n![1662954670517](k8s快速集成KubeSphere/1662954670517.png)\n\n（2）创建mysql服务\n\n![1662954686176](k8s快速集成KubeSphere/1662954686176.png)\n\n（3）选择有状态服务\n\n![1662954729101](k8s快速集成KubeSphere/1662954729101.png)\n\n（4）容器配置\n\n在搜索框中输入 `mysql:5.6`，按下**回车键**，然后点击**使用默认端口**。\n\n![1662954919071](k8s快速集成KubeSphere/1662954919071.png)\n\n（5）环境变量配置\n\n向下滚动到**环境变量**，点击**来自保密字典**。输入名称 `MYSQL_ROOT_PASSWORD`，然后选择资源 `mysql-secret` 和前面步骤中创建的密钥 `MYSQL_ROOT_PASSWORD`\n\n![1662955108731](k8s快速集成KubeSphere/1662955108731.png)\n\n（6）存储设置\n\n选择**存储设置**中的**添加持久卷声明模板**，输入 PVC 名称前缀 (`mysql`) 和**挂载路径**（模式：`读写`，路径：/var/lib/mysql）的值。\n\n![1662955217850](k8s快速集成KubeSphere/1662955217850.png)\n\n\n\n（7）随后直接添加\n\n### 3.3.2 wordpress服务添加\n\n（1）无状态服务添加\n\n![1662955316163](k8s快速集成KubeSphere/1662955316163.png)\n\n（2）容器配置\n\n在搜索栏中输入 wordpress:4.8-apache 并按下**回车键**，然后点击**使用默认端口**。\n\n![1662955481272](k8s快速集成KubeSphere/1662955481272.png)\n\n\n\n(3) 环境变量\n\n向下滚动到**环境变量**，点击**来自保密字典**。这里需要添加两个环境变量，请输入以下值：\n\n- 对于 `WORDPRESS_DB_PASSWORD`，请选择在步骤 1 中创建的 `wordpress-secret` 和 `WORDPRESS_DB_PASSWORD`。\n- 点击**添加环境变量**，分别输入 `WORDPRESS_DB_HOST` 和 `mysql` 作为键 (Key) 和值 (Value)。\n\n![1662955721051](k8s快速集成KubeSphere/1662955721051.png)\n\n(4) 存储设置\n\n选择上一步创建的 `wordpress-pvc`，将模式设置为`读写`，并输入挂载路径 `/var/www/html`\n\n![1662956356797](k8s快速集成KubeSphere/1662956356797.png)\n\n（5）路由设置\n\n**路由设置**中设置路由规则（应用路由 Ingress），也可以直接点击**创建**。创建成功后，应用将显示在应用列表中。\n\n### 3.3.3 验证资源\n\n在**工作负载**中，分别检查**部署**和**有状态副本集**中 `wordpress-v1` 和 `mysql-v1` 的状态。如果它们的运行状态为**运行中**，就意味着 WordPress 已经成功创建。\n\n### 3.3.4 通过 NodePort 访问 WordPress\n\n1. 若要在集群外访问服务，选择左侧导航栏中的**应用负载 > 服务**。点击 `wordpress` 右侧的三个点后，选择**编辑外部访问**。\n2. 在**访问方式**中选择 `NodePort`，然后点击**确定**。\n3. 点击**服务**进入详情页，可以在**端口**处查看暴露的端口。\n4. 通过 `{Node IP}:{NodePort}` 访问此应用程序，可以看到下图：\n\n# 四、查看结果\n\n![1662979858086](k8s快速集成KubeSphere/1662979858086.png)","source":"_posts/k8s快速集成KubeSphere.md","raw":"---\ntitle: k8s快速集成KubeSphere\ndate: 2022-07-24 17:38:02\ncategories:\n  - 服务器\ntags:\n  - k8s\n  - kubernetes \n  - kubesphere\n  - wordpress\n---\n\n# 一、KubeSphere 介绍\n\nKubeSphere 是在 Kubernetes 之上构建的面向云原生应用的**分布式操作系统**，完全开源，支持多云与多集群管理，提供全栈的 IT 自动化运维能力，简化企业的 DevOps 工作流。它的架构可以非常方便地使第三方应用与云原生生态组件进行即插即用 (plug-and-play) 的集成。 \n\n功能：\n\n- 多云与多集群管理\n- Kubernetes 资源管理\n- DevOps\n- 应用生命周期管理\n- 微服务治理（服务网格）\n- 日志查询与收集\n- 服务与网络\n- 多租户管理\n- 监控告警\n- 事件与审计查询\n- 存储管理\n- 访问权限控制\n- GPU 支持\n- 网络策略\n- 镜像仓库管理\n- 安全管理等 \n\n# 二、部署 KubeSphere\n\n当卸载重新安装时，执行下面 的脚本全面卸载：\n\n```\nhttps://github.com/kubesphere/ks-installer/edit/master/scripts/kubesphere-delete.sh\n```\n\n## 2.1 执行以下命令以开始安装：\n\n```\nkubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.2.1/kubesphere-installer.yaml\nkubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.2.1/cluster-configuration.yaml\n\n#默认sc\n kubectl patch sc openebs-hostpath -p '{\"metadata\": {\"annotations\": {\"storageclass.beta.kubernetes.io/is-default-class\": \"true\"}}}'\n```\n## 2.2 检查安装\n\n日志查看：\n\n```\nkubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f\n\n结果：\nCollecting installation results ...\n#####################################################\n###              Welcome to KubeSphere!           ###\n#####################################################\n\nConsole: http://192.168.66.10:30880\nAccount: admin\nPassword: P@88w0rd\n```\n安装服务查看：\n\n使用 `kubectl get pod --all-namespaces` 查看所有 Pod 在 KubeSphere 相关的命名空间是否正常运行。如果是正常运行，请通过以下命令来检查控制台的端口（默认为 30880，可以通过默认帐户和密码 (`admin/P@88w0rd`) 访问 Web 控制台。）：\n\n```\nkubectl get svc/ks-console -n kubesphere-system\n```\n重置密码：\n\n```\nkubectl patch users <USERNAME> -p '{\"spec\":{\"password\":\"<YOURPASSWORD>\"}}' --type='merge' && kubectl annotate users <USERNAME> iam.kubesphere.io/password-encrypted-\n\nkubectl patch users admin -p '{\"spec\":{\"password\":\"P@88w0rd\"}}' --type='merge' && kubectl annotate users admin iam.kubesphere.io/password-encrypted-\n```\n# 三、示例wordpress部署\n\n这里使用project-regular权限账号进行登录，可以通过admin用户添加指定账号，然后创建空间demo-wordspace，并且创建demo-project项目\n\n## 3.1 密钥创建\n\n选择**类型**为 Opaque（默认）\n\nmysql密钥：\n\n```\n名称：mysql-secret\n键值：MYSQL_ROOT_PASSWORD=123456\n```\n\n创建 WordPress 密钥：\n\n```\n名称：wordpress-secret\n键值：WORDPRESS_DB_PASSWORD =123456\n   \n```\n\n![1662953701465](k8s快速集成KubeSphere/1662953701465.png)\n\n## 3.2 创建持久卷声明\n\n创建持久券：wordpress-pvc ，选择（存储类、访问模式、卷容量）\n\n## 3.3 创建应用程序\n\n### 3.3.1 添加 MySQL 后端组件\n\n（1）创建应用\n\n![1662954670517](k8s快速集成KubeSphere/1662954670517.png)\n\n（2）创建mysql服务\n\n![1662954686176](k8s快速集成KubeSphere/1662954686176.png)\n\n（3）选择有状态服务\n\n![1662954729101](k8s快速集成KubeSphere/1662954729101.png)\n\n（4）容器配置\n\n在搜索框中输入 `mysql:5.6`，按下**回车键**，然后点击**使用默认端口**。\n\n![1662954919071](k8s快速集成KubeSphere/1662954919071.png)\n\n（5）环境变量配置\n\n向下滚动到**环境变量**，点击**来自保密字典**。输入名称 `MYSQL_ROOT_PASSWORD`，然后选择资源 `mysql-secret` 和前面步骤中创建的密钥 `MYSQL_ROOT_PASSWORD`\n\n![1662955108731](k8s快速集成KubeSphere/1662955108731.png)\n\n（6）存储设置\n\n选择**存储设置**中的**添加持久卷声明模板**，输入 PVC 名称前缀 (`mysql`) 和**挂载路径**（模式：`读写`，路径：/var/lib/mysql）的值。\n\n![1662955217850](k8s快速集成KubeSphere/1662955217850.png)\n\n\n\n（7）随后直接添加\n\n### 3.3.2 wordpress服务添加\n\n（1）无状态服务添加\n\n![1662955316163](k8s快速集成KubeSphere/1662955316163.png)\n\n（2）容器配置\n\n在搜索栏中输入 wordpress:4.8-apache 并按下**回车键**，然后点击**使用默认端口**。\n\n![1662955481272](k8s快速集成KubeSphere/1662955481272.png)\n\n\n\n(3) 环境变量\n\n向下滚动到**环境变量**，点击**来自保密字典**。这里需要添加两个环境变量，请输入以下值：\n\n- 对于 `WORDPRESS_DB_PASSWORD`，请选择在步骤 1 中创建的 `wordpress-secret` 和 `WORDPRESS_DB_PASSWORD`。\n- 点击**添加环境变量**，分别输入 `WORDPRESS_DB_HOST` 和 `mysql` 作为键 (Key) 和值 (Value)。\n\n![1662955721051](k8s快速集成KubeSphere/1662955721051.png)\n\n(4) 存储设置\n\n选择上一步创建的 `wordpress-pvc`，将模式设置为`读写`，并输入挂载路径 `/var/www/html`\n\n![1662956356797](k8s快速集成KubeSphere/1662956356797.png)\n\n（5）路由设置\n\n**路由设置**中设置路由规则（应用路由 Ingress），也可以直接点击**创建**。创建成功后，应用将显示在应用列表中。\n\n### 3.3.3 验证资源\n\n在**工作负载**中，分别检查**部署**和**有状态副本集**中 `wordpress-v1` 和 `mysql-v1` 的状态。如果它们的运行状态为**运行中**，就意味着 WordPress 已经成功创建。\n\n### 3.3.4 通过 NodePort 访问 WordPress\n\n1. 若要在集群外访问服务，选择左侧导航栏中的**应用负载 > 服务**。点击 `wordpress` 右侧的三个点后，选择**编辑外部访问**。\n2. 在**访问方式**中选择 `NodePort`，然后点击**确定**。\n3. 点击**服务**进入详情页，可以在**端口**处查看暴露的端口。\n4. 通过 `{Node IP}:{NodePort}` 访问此应用程序，可以看到下图：\n\n# 四、查看结果\n\n![1662979858086](k8s快速集成KubeSphere/1662979858086.png)","slug":"k8s快速集成KubeSphere","published":1,"updated":"2022-09-23T15:27:02.994Z","_id":"cl8elmh7x0000o0vjfg954bo2","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、KubeSphere-介绍\"><a href=\"#一、KubeSphere-介绍\" class=\"headerlink\" title=\"一、KubeSphere 介绍\"></a>一、KubeSphere 介绍</h1><p>KubeSphere 是在 Kubernetes 之上构建的面向云原生应用的<strong>分布式操作系统</strong>，完全开源，支持多云与多集群管理，提供全栈的 IT 自动化运维能力，简化企业的 DevOps 工作流。它的架构可以非常方便地使第三方应用与云原生生态组件进行即插即用 (plug-and-play) 的集成。 </p>\n<p>功能：</p>\n<ul>\n<li>多云与多集群管理</li>\n<li>Kubernetes 资源管理</li>\n<li>DevOps</li>\n<li>应用生命周期管理</li>\n<li>微服务治理（服务网格）</li>\n<li>日志查询与收集</li>\n<li>服务与网络</li>\n<li>多租户管理</li>\n<li>监控告警</li>\n<li>事件与审计查询</li>\n<li>存储管理</li>\n<li>访问权限控制</li>\n<li>GPU 支持</li>\n<li>网络策略</li>\n<li>镜像仓库管理</li>\n<li>安全管理等 </li>\n</ul>\n<h1 id=\"二、部署-KubeSphere\"><a href=\"#二、部署-KubeSphere\" class=\"headerlink\" title=\"二、部署 KubeSphere\"></a>二、部署 KubeSphere</h1><p>当卸载重新安装时，执行下面 的脚本全面卸载：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">https:<span class=\"hljs-regexp\">//gi</span>thub.com<span class=\"hljs-regexp\">/kubesphere/</span>ks-installer<span class=\"hljs-regexp\">/edit/m</span>aster<span class=\"hljs-regexp\">/scripts/</span>kubesphere-<span class=\"hljs-keyword\">delete</span>.sh<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-1-执行以下命令以开始安装：\"><a href=\"#2-1-执行以下命令以开始安装：\" class=\"headerlink\" title=\"2.1 执行以下命令以开始安装：\"></a>2.1 执行以下命令以开始安装：</h2><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">kubectl apply -f https:<span class=\"hljs-regexp\">//gi</span>thub.com<span class=\"hljs-regexp\">/kubesphere/</span>ks-installer<span class=\"hljs-regexp\">/releases/</span>download<span class=\"hljs-regexp\">/v3.2.1/</span>kubesphere-installer.yaml<br>kubectl apply -f https:<span class=\"hljs-regexp\">//gi</span>thub.com<span class=\"hljs-regexp\">/kubesphere/</span>ks-installer<span class=\"hljs-regexp\">/releases/</span>download<span class=\"hljs-regexp\">/v3.2.1/</span>cluster-configuration.yaml<br><br><span class=\"hljs-comment\">#默认sc</span><br> kubectl patch sc openebs-hostpath -p <span class=\"hljs-string\">&#x27;&#123;&quot;metadata&quot;: &#123;&quot;annotations&quot;: &#123;&quot;storageclass.beta.kubernetes.io/is-default-class&quot;: &quot;true&quot;&#125;&#125;&#125;&#x27;</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"2-2-检查安装\"><a href=\"#2-2-检查安装\" class=\"headerlink\" title=\"2.2 检查安装\"></a>2.2 检查安装</h2><p>日志查看：</p>\n<figure class=\"highlight clean\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs clean\">kubectl logs -n kubesphere-<span class=\"hljs-keyword\">system</span> $(kubectl get pod -n kubesphere-<span class=\"hljs-keyword\">system</span> -l <span class=\"hljs-string\">&#x27;app in (ks-install, ks-installer)&#x27;</span> -o jsonpath=<span class=\"hljs-string\">&#x27;&#123;.items[0].metadata.name&#125;&#x27;</span>) -f<br><br>结果：<br>Collecting installation results ...<br>#####################################################<br>###              Welcome to KubeSphere!           ###<br>#####################################################<br><br>Console: http:<span class=\"hljs-comment\">//192.168.66.10:30880</span><br>Account: admin<br>Password: P@<span class=\"hljs-number\">88</span>w0rd<br></code></pre></td></tr></table></figure>\n<p>安装服务查看：</p>\n<p>使用 <code>kubectl get pod --all-namespaces</code> 查看所有 Pod 在 KubeSphere 相关的命名空间是否正常运行。如果是正常运行，请通过以下命令来检查控制台的端口（默认为 30880，可以通过默认帐户和密码 (<code>admin/P@88w0rd</code>) 访问 Web 控制台。）：</p>\n<figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs livecodeserver\">kubectl <span class=\"hljs-built_in\">get</span> svc/ks-console -n kubesphere-<span class=\"hljs-keyword\">system</span><br></code></pre></td></tr></table></figure>\n<p>重置密码：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">kubectl patch <span class=\"hljs-built_in\">users</span> &lt;USERNAME&gt; -p <span class=\"hljs-string\">&#x27;&#123;&quot;spec&quot;:&#123;&quot;password&quot;:&quot;&lt;YOURPASSWORD&gt;&quot;&#125;&#125;&#x27;</span> --<span class=\"hljs-built_in\">type</span>=<span class=\"hljs-string\">&#x27;merge&#x27;</span> &amp;&amp; kubectl annotate <span class=\"hljs-built_in\">users</span> &lt;USERNAME&gt; iam.kubesphere.io/password-encrypted-<br><br>kubectl patch <span class=\"hljs-built_in\">users</span> admin -p <span class=\"hljs-string\">&#x27;&#123;&quot;spec&quot;:&#123;&quot;password&quot;:&quot;P@88w0rd&quot;&#125;&#125;&#x27;</span> --<span class=\"hljs-built_in\">type</span>=<span class=\"hljs-string\">&#x27;merge&#x27;</span> &amp;&amp; kubectl annotate <span class=\"hljs-built_in\">users</span> admin iam.kubesphere.io/password-encrypted-<br></code></pre></td></tr></table></figure>\n<h1 id=\"三、示例wordpress部署\"><a href=\"#三、示例wordpress部署\" class=\"headerlink\" title=\"三、示例wordpress部署\"></a>三、示例wordpress部署</h1><p>这里使用project-regular权限账号进行登录，可以通过admin用户添加指定账号，然后创建空间demo-wordspace，并且创建demo-project项目</p>\n<h2 id=\"3-1-密钥创建\"><a href=\"#3-1-密钥创建\" class=\"headerlink\" title=\"3.1 密钥创建\"></a>3.1 密钥创建</h2><p>选择<strong>类型</strong>为 Opaque（默认）</p>\n<p>mysql密钥：</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">名称：mysql-secret<br>键值：<span class=\"hljs-attribute\">MYSQL_ROOT_PASSWORD</span>=123456<br></code></pre></td></tr></table></figure>\n\n<p>创建 WordPress 密钥：</p>\n<figure class=\"highlight abnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs abnf\">名称：wordpress-secret<br>键值：WORDPRESS_DB_PASSWORD <span class=\"hljs-operator\">=</span><span class=\"hljs-number\">123456</span><br>   <br></code></pre></td></tr></table></figure>\n\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662953701465.png\" class=\"\" width=\"1662953701465\">\n\n<h2 id=\"3-2-创建持久卷声明\"><a href=\"#3-2-创建持久卷声明\" class=\"headerlink\" title=\"3.2 创建持久卷声明\"></a>3.2 创建持久卷声明</h2><p>创建持久券：wordpress-pvc ，选择（存储类、访问模式、卷容量）</p>\n<h2 id=\"3-3-创建应用程序\"><a href=\"#3-3-创建应用程序\" class=\"headerlink\" title=\"3.3 创建应用程序\"></a>3.3 创建应用程序</h2><h3 id=\"3-3-1-添加-MySQL-后端组件\"><a href=\"#3-3-1-添加-MySQL-后端组件\" class=\"headerlink\" title=\"3.3.1 添加 MySQL 后端组件\"></a>3.3.1 添加 MySQL 后端组件</h3><p>（1）创建应用</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662954670517.png\" class=\"\" width=\"1662954670517\">\n\n<p>（2）创建mysql服务</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662954686176.png\" class=\"\" width=\"1662954686176\">\n\n<p>（3）选择有状态服务</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662954729101.png\" class=\"\" width=\"1662954729101\">\n\n<p>（4）容器配置</p>\n<p>在搜索框中输入 <code>mysql:5.6</code>，按下<strong>回车键</strong>，然后点击<strong>使用默认端口</strong>。</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662954919071.png\" class=\"\" width=\"1662954919071\">\n\n<p>（5）环境变量配置</p>\n<p>向下滚动到<strong>环境变量</strong>，点击<strong>来自保密字典</strong>。输入名称 <code>MYSQL_ROOT_PASSWORD</code>，然后选择资源 <code>mysql-secret</code> 和前面步骤中创建的密钥 <code>MYSQL_ROOT_PASSWORD</code></p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662955108731.png\" class=\"\" width=\"1662955108731\">\n\n<p>（6）存储设置</p>\n<p>选择<strong>存储设置</strong>中的<strong>添加持久卷声明模板</strong>，输入 PVC 名称前缀 (<code>mysql</code>) 和<strong>挂载路径</strong>（模式：<code>读写</code>，路径：/var/lib/mysql）的值。</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662955217850.png\" class=\"\" width=\"1662955217850\">\n\n\n\n<p>（7）随后直接添加</p>\n<h3 id=\"3-3-2-wordpress服务添加\"><a href=\"#3-3-2-wordpress服务添加\" class=\"headerlink\" title=\"3.3.2 wordpress服务添加\"></a>3.3.2 wordpress服务添加</h3><p>（1）无状态服务添加</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662955316163.png\" class=\"\" width=\"1662955316163\">\n\n<p>（2）容器配置</p>\n<p>在搜索栏中输入 wordpress:4.8-apache 并按下<strong>回车键</strong>，然后点击<strong>使用默认端口</strong>。</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662955481272.png\" class=\"\" width=\"1662955481272\">\n\n\n\n<p>(3) 环境变量</p>\n<p>向下滚动到<strong>环境变量</strong>，点击<strong>来自保密字典</strong>。这里需要添加两个环境变量，请输入以下值：</p>\n<ul>\n<li>对于 <code>WORDPRESS_DB_PASSWORD</code>，请选择在步骤 1 中创建的 <code>wordpress-secret</code> 和 <code>WORDPRESS_DB_PASSWORD</code>。</li>\n<li>点击<strong>添加环境变量</strong>，分别输入 <code>WORDPRESS_DB_HOST</code> 和 <code>mysql</code> 作为键 (Key) 和值 (Value)。</li>\n</ul>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662955721051.png\" class=\"\" width=\"1662955721051\">\n\n<p>(4) 存储设置</p>\n<p>选择上一步创建的 <code>wordpress-pvc</code>，将模式设置为<code>读写</code>，并输入挂载路径 <code>/var/www/html</code></p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662956356797.png\" class=\"\" width=\"1662956356797\">\n\n<p>（5）路由设置</p>\n<p><strong>路由设置</strong>中设置路由规则（应用路由 Ingress），也可以直接点击<strong>创建</strong>。创建成功后，应用将显示在应用列表中。</p>\n<h3 id=\"3-3-3-验证资源\"><a href=\"#3-3-3-验证资源\" class=\"headerlink\" title=\"3.3.3 验证资源\"></a>3.3.3 验证资源</h3><p>在<strong>工作负载</strong>中，分别检查<strong>部署</strong>和<strong>有状态副本集</strong>中 <code>wordpress-v1</code> 和 <code>mysql-v1</code> 的状态。如果它们的运行状态为<strong>运行中</strong>，就意味着 WordPress 已经成功创建。</p>\n<h3 id=\"3-3-4-通过-NodePort-访问-WordPress\"><a href=\"#3-3-4-通过-NodePort-访问-WordPress\" class=\"headerlink\" title=\"3.3.4 通过 NodePort 访问 WordPress\"></a>3.3.4 通过 NodePort 访问 WordPress</h3><ol>\n<li>若要在集群外访问服务，选择左侧导航栏中的<strong>应用负载 &gt; 服务</strong>。点击 <code>wordpress</code> 右侧的三个点后，选择<strong>编辑外部访问</strong>。</li>\n<li>在<strong>访问方式</strong>中选择 <code>NodePort</code>，然后点击<strong>确定</strong>。</li>\n<li>点击<strong>服务</strong>进入详情页，可以在<strong>端口</strong>处查看暴露的端口。</li>\n<li>通过 <code>&#123;Node IP&#125;:&#123;NodePort&#125;</code> 访问此应用程序，可以看到下图：</li>\n</ol>\n<h1 id=\"四、查看结果\"><a href=\"#四、查看结果\" class=\"headerlink\" title=\"四、查看结果\"></a>四、查看结果</h1><img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662979858086.png\" class=\"\" width=\"1662979858086\">","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、KubeSphere-介绍\"><a href=\"#一、KubeSphere-介绍\" class=\"headerlink\" title=\"一、KubeSphere 介绍\"></a>一、KubeSphere 介绍</h1><p>KubeSphere 是在 Kubernetes 之上构建的面向云原生应用的<strong>分布式操作系统</strong>，完全开源，支持多云与多集群管理，提供全栈的 IT 自动化运维能力，简化企业的 DevOps 工作流。它的架构可以非常方便地使第三方应用与云原生生态组件进行即插即用 (plug-and-play) 的集成。 </p>\n<p>功能：</p>\n<ul>\n<li>多云与多集群管理</li>\n<li>Kubernetes 资源管理</li>\n<li>DevOps</li>\n<li>应用生命周期管理</li>\n<li>微服务治理（服务网格）</li>\n<li>日志查询与收集</li>\n<li>服务与网络</li>\n<li>多租户管理</li>\n<li>监控告警</li>\n<li>事件与审计查询</li>\n<li>存储管理</li>\n<li>访问权限控制</li>\n<li>GPU 支持</li>\n<li>网络策略</li>\n<li>镜像仓库管理</li>\n<li>安全管理等 </li>\n</ul>\n<h1 id=\"二、部署-KubeSphere\"><a href=\"#二、部署-KubeSphere\" class=\"headerlink\" title=\"二、部署 KubeSphere\"></a>二、部署 KubeSphere</h1><p>当卸载重新安装时，执行下面 的脚本全面卸载：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">https:<span class=\"hljs-regexp\">//gi</span>thub.com<span class=\"hljs-regexp\">/kubesphere/</span>ks-installer<span class=\"hljs-regexp\">/edit/m</span>aster<span class=\"hljs-regexp\">/scripts/</span>kubesphere-<span class=\"hljs-keyword\">delete</span>.sh<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-1-执行以下命令以开始安装：\"><a href=\"#2-1-执行以下命令以开始安装：\" class=\"headerlink\" title=\"2.1 执行以下命令以开始安装：\"></a>2.1 执行以下命令以开始安装：</h2><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">kubectl apply -f https:<span class=\"hljs-regexp\">//gi</span>thub.com<span class=\"hljs-regexp\">/kubesphere/</span>ks-installer<span class=\"hljs-regexp\">/releases/</span>download<span class=\"hljs-regexp\">/v3.2.1/</span>kubesphere-installer.yaml<br>kubectl apply -f https:<span class=\"hljs-regexp\">//gi</span>thub.com<span class=\"hljs-regexp\">/kubesphere/</span>ks-installer<span class=\"hljs-regexp\">/releases/</span>download<span class=\"hljs-regexp\">/v3.2.1/</span>cluster-configuration.yaml<br><br><span class=\"hljs-comment\">#默认sc</span><br> kubectl patch sc openebs-hostpath -p <span class=\"hljs-string\">&#x27;&#123;&quot;metadata&quot;: &#123;&quot;annotations&quot;: &#123;&quot;storageclass.beta.kubernetes.io/is-default-class&quot;: &quot;true&quot;&#125;&#125;&#125;&#x27;</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"2-2-检查安装\"><a href=\"#2-2-检查安装\" class=\"headerlink\" title=\"2.2 检查安装\"></a>2.2 检查安装</h2><p>日志查看：</p>\n<figure class=\"highlight clean\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs clean\">kubectl logs -n kubesphere-<span class=\"hljs-keyword\">system</span> $(kubectl get pod -n kubesphere-<span class=\"hljs-keyword\">system</span> -l <span class=\"hljs-string\">&#x27;app in (ks-install, ks-installer)&#x27;</span> -o jsonpath=<span class=\"hljs-string\">&#x27;&#123;.items[0].metadata.name&#125;&#x27;</span>) -f<br><br>结果：<br>Collecting installation results ...<br>#####################################################<br>###              Welcome to KubeSphere!           ###<br>#####################################################<br><br>Console: http:<span class=\"hljs-comment\">//192.168.66.10:30880</span><br>Account: admin<br>Password: P@<span class=\"hljs-number\">88</span>w0rd<br></code></pre></td></tr></table></figure>\n<p>安装服务查看：</p>\n<p>使用 <code>kubectl get pod --all-namespaces</code> 查看所有 Pod 在 KubeSphere 相关的命名空间是否正常运行。如果是正常运行，请通过以下命令来检查控制台的端口（默认为 30880，可以通过默认帐户和密码 (<code>admin/P@88w0rd</code>) 访问 Web 控制台。）：</p>\n<figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs livecodeserver\">kubectl <span class=\"hljs-built_in\">get</span> svc/ks-console -n kubesphere-<span class=\"hljs-keyword\">system</span><br></code></pre></td></tr></table></figure>\n<p>重置密码：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">kubectl patch <span class=\"hljs-built_in\">users</span> &lt;USERNAME&gt; -p <span class=\"hljs-string\">&#x27;&#123;&quot;spec&quot;:&#123;&quot;password&quot;:&quot;&lt;YOURPASSWORD&gt;&quot;&#125;&#125;&#x27;</span> --<span class=\"hljs-built_in\">type</span>=<span class=\"hljs-string\">&#x27;merge&#x27;</span> &amp;&amp; kubectl annotate <span class=\"hljs-built_in\">users</span> &lt;USERNAME&gt; iam.kubesphere.io/password-encrypted-<br><br>kubectl patch <span class=\"hljs-built_in\">users</span> admin -p <span class=\"hljs-string\">&#x27;&#123;&quot;spec&quot;:&#123;&quot;password&quot;:&quot;P@88w0rd&quot;&#125;&#125;&#x27;</span> --<span class=\"hljs-built_in\">type</span>=<span class=\"hljs-string\">&#x27;merge&#x27;</span> &amp;&amp; kubectl annotate <span class=\"hljs-built_in\">users</span> admin iam.kubesphere.io/password-encrypted-<br></code></pre></td></tr></table></figure>\n<h1 id=\"三、示例wordpress部署\"><a href=\"#三、示例wordpress部署\" class=\"headerlink\" title=\"三、示例wordpress部署\"></a>三、示例wordpress部署</h1><p>这里使用project-regular权限账号进行登录，可以通过admin用户添加指定账号，然后创建空间demo-wordspace，并且创建demo-project项目</p>\n<h2 id=\"3-1-密钥创建\"><a href=\"#3-1-密钥创建\" class=\"headerlink\" title=\"3.1 密钥创建\"></a>3.1 密钥创建</h2><p>选择<strong>类型</strong>为 Opaque（默认）</p>\n<p>mysql密钥：</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">名称：mysql-secret<br>键值：<span class=\"hljs-attribute\">MYSQL_ROOT_PASSWORD</span>=123456<br></code></pre></td></tr></table></figure>\n\n<p>创建 WordPress 密钥：</p>\n<figure class=\"highlight abnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs abnf\">名称：wordpress-secret<br>键值：WORDPRESS_DB_PASSWORD <span class=\"hljs-operator\">=</span><span class=\"hljs-number\">123456</span><br>   <br></code></pre></td></tr></table></figure>\n\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662953701465.png\" class=\"\" width=\"1662953701465\">\n\n<h2 id=\"3-2-创建持久卷声明\"><a href=\"#3-2-创建持久卷声明\" class=\"headerlink\" title=\"3.2 创建持久卷声明\"></a>3.2 创建持久卷声明</h2><p>创建持久券：wordpress-pvc ，选择（存储类、访问模式、卷容量）</p>\n<h2 id=\"3-3-创建应用程序\"><a href=\"#3-3-创建应用程序\" class=\"headerlink\" title=\"3.3 创建应用程序\"></a>3.3 创建应用程序</h2><h3 id=\"3-3-1-添加-MySQL-后端组件\"><a href=\"#3-3-1-添加-MySQL-后端组件\" class=\"headerlink\" title=\"3.3.1 添加 MySQL 后端组件\"></a>3.3.1 添加 MySQL 后端组件</h3><p>（1）创建应用</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662954670517.png\" class=\"\" width=\"1662954670517\">\n\n<p>（2）创建mysql服务</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662954686176.png\" class=\"\" width=\"1662954686176\">\n\n<p>（3）选择有状态服务</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662954729101.png\" class=\"\" width=\"1662954729101\">\n\n<p>（4）容器配置</p>\n<p>在搜索框中输入 <code>mysql:5.6</code>，按下<strong>回车键</strong>，然后点击<strong>使用默认端口</strong>。</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662954919071.png\" class=\"\" width=\"1662954919071\">\n\n<p>（5）环境变量配置</p>\n<p>向下滚动到<strong>环境变量</strong>，点击<strong>来自保密字典</strong>。输入名称 <code>MYSQL_ROOT_PASSWORD</code>，然后选择资源 <code>mysql-secret</code> 和前面步骤中创建的密钥 <code>MYSQL_ROOT_PASSWORD</code></p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662955108731.png\" class=\"\" width=\"1662955108731\">\n\n<p>（6）存储设置</p>\n<p>选择<strong>存储设置</strong>中的<strong>添加持久卷声明模板</strong>，输入 PVC 名称前缀 (<code>mysql</code>) 和<strong>挂载路径</strong>（模式：<code>读写</code>，路径：/var/lib/mysql）的值。</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662955217850.png\" class=\"\" width=\"1662955217850\">\n\n\n\n<p>（7）随后直接添加</p>\n<h3 id=\"3-3-2-wordpress服务添加\"><a href=\"#3-3-2-wordpress服务添加\" class=\"headerlink\" title=\"3.3.2 wordpress服务添加\"></a>3.3.2 wordpress服务添加</h3><p>（1）无状态服务添加</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662955316163.png\" class=\"\" width=\"1662955316163\">\n\n<p>（2）容器配置</p>\n<p>在搜索栏中输入 wordpress:4.8-apache 并按下<strong>回车键</strong>，然后点击<strong>使用默认端口</strong>。</p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662955481272.png\" class=\"\" width=\"1662955481272\">\n\n\n\n<p>(3) 环境变量</p>\n<p>向下滚动到<strong>环境变量</strong>，点击<strong>来自保密字典</strong>。这里需要添加两个环境变量，请输入以下值：</p>\n<ul>\n<li>对于 <code>WORDPRESS_DB_PASSWORD</code>，请选择在步骤 1 中创建的 <code>wordpress-secret</code> 和 <code>WORDPRESS_DB_PASSWORD</code>。</li>\n<li>点击<strong>添加环境变量</strong>，分别输入 <code>WORDPRESS_DB_HOST</code> 和 <code>mysql</code> 作为键 (Key) 和值 (Value)。</li>\n</ul>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662955721051.png\" class=\"\" width=\"1662955721051\">\n\n<p>(4) 存储设置</p>\n<p>选择上一步创建的 <code>wordpress-pvc</code>，将模式设置为<code>读写</code>，并输入挂载路径 <code>/var/www/html</code></p>\n<img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662956356797.png\" class=\"\" width=\"1662956356797\">\n\n<p>（5）路由设置</p>\n<p><strong>路由设置</strong>中设置路由规则（应用路由 Ingress），也可以直接点击<strong>创建</strong>。创建成功后，应用将显示在应用列表中。</p>\n<h3 id=\"3-3-3-验证资源\"><a href=\"#3-3-3-验证资源\" class=\"headerlink\" title=\"3.3.3 验证资源\"></a>3.3.3 验证资源</h3><p>在<strong>工作负载</strong>中，分别检查<strong>部署</strong>和<strong>有状态副本集</strong>中 <code>wordpress-v1</code> 和 <code>mysql-v1</code> 的状态。如果它们的运行状态为<strong>运行中</strong>，就意味着 WordPress 已经成功创建。</p>\n<h3 id=\"3-3-4-通过-NodePort-访问-WordPress\"><a href=\"#3-3-4-通过-NodePort-访问-WordPress\" class=\"headerlink\" title=\"3.3.4 通过 NodePort 访问 WordPress\"></a>3.3.4 通过 NodePort 访问 WordPress</h3><ol>\n<li>若要在集群外访问服务，选择左侧导航栏中的<strong>应用负载 &gt; 服务</strong>。点击 <code>wordpress</code> 右侧的三个点后，选择<strong>编辑外部访问</strong>。</li>\n<li>在<strong>访问方式</strong>中选择 <code>NodePort</code>，然后点击<strong>确定</strong>。</li>\n<li>点击<strong>服务</strong>进入详情页，可以在<strong>端口</strong>处查看暴露的端口。</li>\n<li>通过 <code>&#123;Node IP&#125;:&#123;NodePort&#125;</code> 访问此应用程序，可以看到下图：</li>\n</ol>\n<h1 id=\"四、查看结果\"><a href=\"#四、查看结果\" class=\"headerlink\" title=\"四、查看结果\"></a>四、查看结果</h1><img src=\"/2022/07/24/k8s%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90KubeSphere/1662979858086.png\" class=\"\" width=\"1662979858086\">"},{"title":"如何用hexo在github上搭建自己的博客","date":"2019-01-23T09:38:02.000Z","author":"leellun","_content":"\n# 一、github仓库创建\n\n在github创建仓库，仓库名称为[username].github.io。\n\n![image-20220923174506204](如何用hexo在github上搭建自己的博客/image-20220923174506204.png)\n\n然后选择设置\n\n![image-20220923175440656](如何用hexo在github上搭建自己的博客/image-20220923175440656.png)\n\n设置网站的访问host并且制定分支为主分支\n\n![image-20220923175557661](如何用hexo在github上搭建自己的博客/image-20220923175557661.png)\n\n配置git免登录认证信息\n\n![image-20220923180413762](如何用hexo在github上搭建自己的博客/image-20220923180413762.png)\n\n\n\n# 二、hexo使用\n\n## 1.1 安装hexo\n\n全局安装hexo\n\n```\nnpm install -g hexo\n# 发布支持\nnpm install --save hexo-deployer-git\n\n```\n\n## 1.2 创建hexo项目并且推到github上\n\n```\n# 创建文件夹 [username].github.io\nmkdir [username].github.io\n# 执行hexo初始化操作\nhexo init\n# 将 github [username].github.io的.git的文件夹放入项目中，指定分支developer或其它分支作为hexo项目源码存放分支\n\n# 构建静态页面\nhexo generate\n\n# 发布 到master\nhexo deploy\n```\n\n## 1.3 hexo 配置修改\n\n```\ntitle: 青叶水间 - 一个IT技术文章分享博客\nsubtitle: ''\ndescription: ''\nkeywords:\nauthor: leellun\nlanguage: zh-CN\ntimezone: ''\npost_asset_folder: true\n## 主题配置，我这里用的fluid主题\ntheme: fluid  \n\n# 发布信息 git，地址是repo配置，分支branch ，需要发布必须配置了git的ssh-gen\n# 这里还需要安装了 插件hexo-deployer-git，npm install --save hexo-deployer-git\ndeploy:\n  type: git\n  repo: git@github.com:leellun/leellun.github.io.git\n  branch: master\n```\n\n## 1.4 markdown图片支持\n\n修改_config.yml\n\n```\npost_asset_folder: true\n```\n\n安装依赖支持：\n\n```\n npm install hexo-image-link --save\n```\n\n## 1.5 主题添加\n\n```\n npm install hexo-theme-fluid --save\n```\n\n主题配置：_config.fluid.yml\n\n```\nfavicon: /img/leaf_icon.png\n\nnavbar:\n  # 导航栏左侧的标题，为空则按 hexo config 中 `title` 显示\n  # The title on the left side of the navigation bar. If empty, it is based on `title` in hexo config\n  blog_title: \"青叶水间\"\nindex:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\n  slogan:\n    enable: true\n\n    # 为空则按 hexo config.subtitle 显示\n    # If empty, text based on `subtitle` in hexo config\n    text: \"一个Java、SpringBoot、SpringCloud、服务器等文章分享博客网站\"\npost:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\narchive:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\ncategory:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\ntag:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\nabout:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\npage:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\npage404:\n  banner_img: /img/bg-default.png\n  banner_img_height: 60\nlinks:\n  enable: true\n  banner_img: /img/bg-default.png\n\n#---------------------------\n# 页脚\n# Footer\n#---------------------------\nfooter:\n  # 页脚第一行文字的 HTML，建议保留 Fluid 的链接，用于向更多人推广本主题\n  # HTML of the first line of the footer, it is recommended to keep the Fluid link to promote this theme to more people\n  content: '\n    <a href=\"https://hexo.io\" target=\"_blank\" rel=\"nofollow noopener\"><span>Hexo</span></a>\n    <i class=\"iconfont icon-love\"></i>\n    <a href=\"https://github.com/leellun\" target=\"_blank\" rel=\"nofollow noopener\"><span>我的github</span></a>\n```\n\n# 三、页面与文章\n\n创建页面：\n\n```\n# 创建about页面\nhexo new page about\n```\n\n创建文章：\n\n```\nhexo new \"My New Post\"\n```\n\n文章头信息：\n\n| Data       | Description                                             |\n| ---------- | ------------------------------------------------------- |\n| `title`    | 标题                                                    |\n| `slug`     | 地址                                                    |\n| `layout`   | 布局                                                    |\n| `path`     | 路径。Hexo默认情况下基于new_post_path设置构建post路径。 |\n| `date`     | 日期 默认当前                                           |\n| tags       | 标签                                                    |\n| categories | 类别                                                    |\n| author     | 作者                                                    |\n\n更多：https://hexo.io/docs/variables.html\n\n启动服务：\n\n```bash\n$ hexo server\n```\n\n构建静态文件：\n\n```bash\n$ hexo generate\n```\n\n推送到github，提供网页浏览：\n\n```bash\n$ hexo deploy\n```\n\n\n\n这里是我的博客网站源码配置（deveploer分支）：https://github.com/leellun/leellun.github.io\n\n","source":"_posts/如何用hexo在github上搭建自己的博客.md","raw":"---\ntitle: 如何用hexo在github上搭建自己的博客\ndate: 2019-01-23 17:38:02\ncategories:\n  - 前端\ntags:\n  - hexo\n  - github\n  - 博客\nauthor: leellun\n---\n\n# 一、github仓库创建\n\n在github创建仓库，仓库名称为[username].github.io。\n\n![image-20220923174506204](如何用hexo在github上搭建自己的博客/image-20220923174506204.png)\n\n然后选择设置\n\n![image-20220923175440656](如何用hexo在github上搭建自己的博客/image-20220923175440656.png)\n\n设置网站的访问host并且制定分支为主分支\n\n![image-20220923175557661](如何用hexo在github上搭建自己的博客/image-20220923175557661.png)\n\n配置git免登录认证信息\n\n![image-20220923180413762](如何用hexo在github上搭建自己的博客/image-20220923180413762.png)\n\n\n\n# 二、hexo使用\n\n## 1.1 安装hexo\n\n全局安装hexo\n\n```\nnpm install -g hexo\n# 发布支持\nnpm install --save hexo-deployer-git\n\n```\n\n## 1.2 创建hexo项目并且推到github上\n\n```\n# 创建文件夹 [username].github.io\nmkdir [username].github.io\n# 执行hexo初始化操作\nhexo init\n# 将 github [username].github.io的.git的文件夹放入项目中，指定分支developer或其它分支作为hexo项目源码存放分支\n\n# 构建静态页面\nhexo generate\n\n# 发布 到master\nhexo deploy\n```\n\n## 1.3 hexo 配置修改\n\n```\ntitle: 青叶水间 - 一个IT技术文章分享博客\nsubtitle: ''\ndescription: ''\nkeywords:\nauthor: leellun\nlanguage: zh-CN\ntimezone: ''\npost_asset_folder: true\n## 主题配置，我这里用的fluid主题\ntheme: fluid  \n\n# 发布信息 git，地址是repo配置，分支branch ，需要发布必须配置了git的ssh-gen\n# 这里还需要安装了 插件hexo-deployer-git，npm install --save hexo-deployer-git\ndeploy:\n  type: git\n  repo: git@github.com:leellun/leellun.github.io.git\n  branch: master\n```\n\n## 1.4 markdown图片支持\n\n修改_config.yml\n\n```\npost_asset_folder: true\n```\n\n安装依赖支持：\n\n```\n npm install hexo-image-link --save\n```\n\n## 1.5 主题添加\n\n```\n npm install hexo-theme-fluid --save\n```\n\n主题配置：_config.fluid.yml\n\n```\nfavicon: /img/leaf_icon.png\n\nnavbar:\n  # 导航栏左侧的标题，为空则按 hexo config 中 `title` 显示\n  # The title on the left side of the navigation bar. If empty, it is based on `title` in hexo config\n  blog_title: \"青叶水间\"\nindex:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\n  slogan:\n    enable: true\n\n    # 为空则按 hexo config.subtitle 显示\n    # If empty, text based on `subtitle` in hexo config\n    text: \"一个Java、SpringBoot、SpringCloud、服务器等文章分享博客网站\"\npost:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\narchive:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\ncategory:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\ntag:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\nabout:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\npage:\n  banner_img_height: 60\n  banner_img: /img/bg-default.png\npage404:\n  banner_img: /img/bg-default.png\n  banner_img_height: 60\nlinks:\n  enable: true\n  banner_img: /img/bg-default.png\n\n#---------------------------\n# 页脚\n# Footer\n#---------------------------\nfooter:\n  # 页脚第一行文字的 HTML，建议保留 Fluid 的链接，用于向更多人推广本主题\n  # HTML of the first line of the footer, it is recommended to keep the Fluid link to promote this theme to more people\n  content: '\n    <a href=\"https://hexo.io\" target=\"_blank\" rel=\"nofollow noopener\"><span>Hexo</span></a>\n    <i class=\"iconfont icon-love\"></i>\n    <a href=\"https://github.com/leellun\" target=\"_blank\" rel=\"nofollow noopener\"><span>我的github</span></a>\n```\n\n# 三、页面与文章\n\n创建页面：\n\n```\n# 创建about页面\nhexo new page about\n```\n\n创建文章：\n\n```\nhexo new \"My New Post\"\n```\n\n文章头信息：\n\n| Data       | Description                                             |\n| ---------- | ------------------------------------------------------- |\n| `title`    | 标题                                                    |\n| `slug`     | 地址                                                    |\n| `layout`   | 布局                                                    |\n| `path`     | 路径。Hexo默认情况下基于new_post_path设置构建post路径。 |\n| `date`     | 日期 默认当前                                           |\n| tags       | 标签                                                    |\n| categories | 类别                                                    |\n| author     | 作者                                                    |\n\n更多：https://hexo.io/docs/variables.html\n\n启动服务：\n\n```bash\n$ hexo server\n```\n\n构建静态文件：\n\n```bash\n$ hexo generate\n```\n\n推送到github，提供网页浏览：\n\n```bash\n$ hexo deploy\n```\n\n\n\n这里是我的博客网站源码配置（deveploer分支）：https://github.com/leellun/leellun.github.io\n\n","slug":"如何用hexo在github上搭建自己的博客","published":1,"updated":"2022-09-23T15:25:12.476Z","_id":"cl8elutuq0000i4vj4ix9e6w8","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、github仓库创建\"><a href=\"#一、github仓库创建\" class=\"headerlink\" title=\"一、github仓库创建\"></a>一、github仓库创建</h1><p>在github创建仓库，仓库名称为[username].github.io。</p>\n<img src=\"/2019/01/23/%E5%A6%82%E4%BD%95%E7%94%A8hexo%E5%9C%A8github%E4%B8%8A%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/image-20220923174506204.png\" class=\"\" title=\"image-20220923174506204\">\n\n<p>然后选择设置</p>\n<img src=\"/2019/01/23/%E5%A6%82%E4%BD%95%E7%94%A8hexo%E5%9C%A8github%E4%B8%8A%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/image-20220923175440656.png\" class=\"\" title=\"image-20220923175440656\">\n\n<p>设置网站的访问host并且制定分支为主分支</p>\n<img src=\"/2019/01/23/%E5%A6%82%E4%BD%95%E7%94%A8hexo%E5%9C%A8github%E4%B8%8A%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/image-20220923175557661.png\" class=\"\" title=\"image-20220923175557661\">\n\n<p>配置git免登录认证信息</p>\n<img src=\"/2019/01/23/%E5%A6%82%E4%BD%95%E7%94%A8hexo%E5%9C%A8github%E4%B8%8A%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/image-20220923180413762.png\" class=\"\" title=\"image-20220923180413762\">\n\n\n\n<h1 id=\"二、hexo使用\"><a href=\"#二、hexo使用\" class=\"headerlink\" title=\"二、hexo使用\"></a>二、hexo使用</h1><h2 id=\"1-1-安装hexo\"><a href=\"#1-1-安装hexo\" class=\"headerlink\" title=\"1.1 安装hexo\"></a>1.1 安装hexo</h2><p>全局安装hexo</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cmake\">npm <span class=\"hljs-keyword\">install</span> -g hexo<br><span class=\"hljs-comment\"># 发布支持</span><br>npm <span class=\"hljs-keyword\">install</span> --save hexo-deployer-git<br><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"1-2-创建hexo项目并且推到github上\"><a href=\"#1-2-创建hexo项目并且推到github上\" class=\"headerlink\" title=\"1.2 创建hexo项目并且推到github上\"></a>1.2 创建hexo项目并且推到github上</h2><figure class=\"highlight jboss-cli\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs jboss-cli\"><span class=\"hljs-comment\"># 创建文件夹 [username].github.io</span><br>mkdir [username]<span class=\"hljs-string\">.github.io</span><br><span class=\"hljs-comment\"># 执行hexo初始化操作</span><br>hexo init<br><span class=\"hljs-comment\"># 将 github [username].github.io的.git的文件夹放入项目中，指定分支developer或其它分支作为hexo项目源码存放分支</span><br><br><span class=\"hljs-comment\"># 构建静态页面</span><br>hexo generate<br><br><span class=\"hljs-comment\"># 发布 到master</span><br>hexo <span class=\"hljs-keyword\">deploy</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"1-3-hexo-配置修改\"><a href=\"#1-3-hexo-配置修改\" class=\"headerlink\" title=\"1.3 hexo 配置修改\"></a>1.3 hexo 配置修改</h2><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">title:</span> <span class=\"hljs-string\">青叶水间</span> <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">一个IT技术文章分享博客</span><br><span class=\"hljs-attr\">subtitle:</span> <span class=\"hljs-string\">&#x27;&#x27;</span><br><span class=\"hljs-attr\">description:</span> <span class=\"hljs-string\">&#x27;&#x27;</span><br><span class=\"hljs-attr\">keywords:</span><br><span class=\"hljs-attr\">author:</span> <span class=\"hljs-string\">leellun</span><br><span class=\"hljs-attr\">language:</span> <span class=\"hljs-string\">zh-CN</span><br><span class=\"hljs-attr\">timezone:</span> <span class=\"hljs-string\">&#x27;&#x27;</span><br><span class=\"hljs-attr\">post_asset_folder:</span> <span class=\"hljs-literal\">true</span><br><span class=\"hljs-comment\">## 主题配置，我这里用的fluid主题</span><br><span class=\"hljs-attr\">theme:</span> <span class=\"hljs-string\">fluid</span>  <br><br><span class=\"hljs-comment\"># 发布信息 git，地址是repo配置，分支branch ，需要发布必须配置了git的ssh-gen</span><br><span class=\"hljs-comment\"># 这里还需要安装了 插件hexo-deployer-git，npm install --save hexo-deployer-git</span><br><span class=\"hljs-attr\">deploy:</span><br>  <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">git</span><br>  <span class=\"hljs-attr\">repo:</span> <span class=\"hljs-string\">git@github.com:leellun/leellun.github.io.git</span><br>  <span class=\"hljs-attr\">branch:</span> <span class=\"hljs-string\">master</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"1-4-markdown图片支持\"><a href=\"#1-4-markdown图片支持\" class=\"headerlink\" title=\"1.4 markdown图片支持\"></a>1.4 markdown图片支持</h2><p>修改_config.yml</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">post_asset_folder:</span> <span class=\"hljs-literal\">true</span><br></code></pre></td></tr></table></figure>\n\n<p>安装依赖支持：</p>\n<figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">npm install hexo-<span class=\"hljs-built_in\">image</span>-link --<span class=\"hljs-built_in\">save</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"1-5-主题添加\"><a href=\"#1-5-主题添加\" class=\"headerlink\" title=\"1.5 主题添加\"></a>1.5 主题添加</h2><figure class=\"highlight ada\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ada\">npm install hexo-theme-fluid <span class=\"hljs-comment\">--save</span><br></code></pre></td></tr></table></figure>\n\n<p>主题配置：_config.fluid.yml</p>\n<figure class=\"highlight dts\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dts\"><span class=\"hljs-symbol\">favicon:</span> <span class=\"hljs-keyword\">/img/</span>leaf_icon.png<br><span class=\"hljs-symbol\"></span><br><span class=\"hljs-symbol\">navbar:</span><br>  <span class=\"hljs-meta\"># 导航栏左侧的标题，为空则按 hexo config 中 `title` 显示</span><br>  <span class=\"hljs-meta\"># The title on the left side of the navigation bar. If empty, it is based on `title` in hexo config</span><br><span class=\"hljs-symbol\">  blog_title:</span> <span class=\"hljs-string\">&quot;青叶水间&quot;</span><br><span class=\"hljs-symbol\">index:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">  slogan:</span><br><span class=\"hljs-symbol\">    enable:</span> true<br><br>    <span class=\"hljs-meta\"># 为空则按 hexo config.subtitle 显示</span><br>    <span class=\"hljs-meta\"># If empty, text based on `subtitle` in hexo config</span><br><span class=\"hljs-symbol\">    text:</span> <span class=\"hljs-string\">&quot;一个Java、SpringBoot、SpringCloud、服务器等文章分享博客网站&quot;</span><br><span class=\"hljs-symbol\">post:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">archive:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">category:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">tag:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">about:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">page:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">page404:</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">links:</span><br><span class=\"hljs-symbol\">  enable:</span> true<br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><br><span class=\"hljs-meta\">#---------------------------</span><br><span class=\"hljs-meta\"># 页脚</span><br><span class=\"hljs-meta\"># Footer</span><br><span class=\"hljs-meta\">#---------------------------</span><br><span class=\"hljs-symbol\">footer:</span><br>  <span class=\"hljs-meta\"># 页脚第一行文字的 HTML，建议保留 Fluid 的链接，用于向更多人推广本主题</span><br>  <span class=\"hljs-meta\"># HTML of the first line of the footer, it is recommended to keep the Fluid link to promote this theme to more people</span><br><span class=\"hljs-symbol\">  content:</span> &#x27;<br>    <span class=\"hljs-params\">&lt;a href=&quot;https://hexo.io&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;</span><span class=\"hljs-params\">&lt;span&gt;</span>Hexo<span class=\"hljs-params\">&lt;/span&gt;</span><span class=\"hljs-params\">&lt;/a&gt;</span><br>    <span class=\"hljs-params\">&lt;i class=&quot;iconfont icon-love&quot;&gt;</span><span class=\"hljs-params\">&lt;/i&gt;</span><br>    <span class=\"hljs-params\">&lt;a href=&quot;https://github.com/leellun&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;</span><span class=\"hljs-params\">&lt;span&gt;</span>我的github<span class=\"hljs-params\">&lt;/span&gt;</span><span class=\"hljs-params\">&lt;/a&gt;</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"三、页面与文章\"><a href=\"#三、页面与文章\" class=\"headerlink\" title=\"三、页面与文章\"></a>三、页面与文章</h1><p>创建页面：</p>\n<figure class=\"highlight haxe\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs haxe\"><span class=\"hljs-meta\"># 创建about页面</span><br>hexo <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">page</span> about<br></code></pre></td></tr></table></figure>\n\n<p>创建文章：</p>\n<figure class=\"highlight actionscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs actionscript\">hexo <span class=\"hljs-keyword\">new</span> <span class=\"hljs-string\">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>文章头信息：</p>\n<table>\n<thead>\n<tr>\n<th>Data</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>title</code></td>\n<td>标题</td>\n</tr>\n<tr>\n<td><code>slug</code></td>\n<td>地址</td>\n</tr>\n<tr>\n<td><code>layout</code></td>\n<td>布局</td>\n</tr>\n<tr>\n<td><code>path</code></td>\n<td>路径。Hexo默认情况下基于new_post_path设置构建post路径。</td>\n</tr>\n<tr>\n<td><code>date</code></td>\n<td>日期 默认当前</td>\n</tr>\n<tr>\n<td>tags</td>\n<td>标签</td>\n</tr>\n<tr>\n<td>categories</td>\n<td>类别</td>\n</tr>\n<tr>\n<td>author</td>\n<td>作者</td>\n</tr>\n</tbody></table>\n<p>更多：<a href=\"https://hexo.io/docs/variables.html\">https://hexo.io/docs/variables.html</a></p>\n<p>启动服务：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo server<br></code></pre></td></tr></table></figure>\n\n<p>构建静态文件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo generate<br></code></pre></td></tr></table></figure>\n\n<p>推送到github，提供网页浏览：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo deploy<br></code></pre></td></tr></table></figure>\n\n\n\n<p>这里是我的博客网站源码配置（deveploer分支）：<a href=\"https://github.com/leellun/leellun.github.io\">https://github.com/leellun/leellun.github.io</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、github仓库创建\"><a href=\"#一、github仓库创建\" class=\"headerlink\" title=\"一、github仓库创建\"></a>一、github仓库创建</h1><p>在github创建仓库，仓库名称为[username].github.io。</p>\n<img src=\"/2019/01/23/%E5%A6%82%E4%BD%95%E7%94%A8hexo%E5%9C%A8github%E4%B8%8A%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/image-20220923174506204.png\" class=\"\" title=\"image-20220923174506204\">\n\n<p>然后选择设置</p>\n<img src=\"/2019/01/23/%E5%A6%82%E4%BD%95%E7%94%A8hexo%E5%9C%A8github%E4%B8%8A%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/image-20220923175440656.png\" class=\"\" title=\"image-20220923175440656\">\n\n<p>设置网站的访问host并且制定分支为主分支</p>\n<img src=\"/2019/01/23/%E5%A6%82%E4%BD%95%E7%94%A8hexo%E5%9C%A8github%E4%B8%8A%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/image-20220923175557661.png\" class=\"\" title=\"image-20220923175557661\">\n\n<p>配置git免登录认证信息</p>\n<img src=\"/2019/01/23/%E5%A6%82%E4%BD%95%E7%94%A8hexo%E5%9C%A8github%E4%B8%8A%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/image-20220923180413762.png\" class=\"\" title=\"image-20220923180413762\">\n\n\n\n<h1 id=\"二、hexo使用\"><a href=\"#二、hexo使用\" class=\"headerlink\" title=\"二、hexo使用\"></a>二、hexo使用</h1><h2 id=\"1-1-安装hexo\"><a href=\"#1-1-安装hexo\" class=\"headerlink\" title=\"1.1 安装hexo\"></a>1.1 安装hexo</h2><p>全局安装hexo</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cmake\">npm <span class=\"hljs-keyword\">install</span> -g hexo<br><span class=\"hljs-comment\"># 发布支持</span><br>npm <span class=\"hljs-keyword\">install</span> --save hexo-deployer-git<br><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"1-2-创建hexo项目并且推到github上\"><a href=\"#1-2-创建hexo项目并且推到github上\" class=\"headerlink\" title=\"1.2 创建hexo项目并且推到github上\"></a>1.2 创建hexo项目并且推到github上</h2><figure class=\"highlight jboss-cli\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs jboss-cli\"><span class=\"hljs-comment\"># 创建文件夹 [username].github.io</span><br>mkdir [username]<span class=\"hljs-string\">.github.io</span><br><span class=\"hljs-comment\"># 执行hexo初始化操作</span><br>hexo init<br><span class=\"hljs-comment\"># 将 github [username].github.io的.git的文件夹放入项目中，指定分支developer或其它分支作为hexo项目源码存放分支</span><br><br><span class=\"hljs-comment\"># 构建静态页面</span><br>hexo generate<br><br><span class=\"hljs-comment\"># 发布 到master</span><br>hexo <span class=\"hljs-keyword\">deploy</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"1-3-hexo-配置修改\"><a href=\"#1-3-hexo-配置修改\" class=\"headerlink\" title=\"1.3 hexo 配置修改\"></a>1.3 hexo 配置修改</h2><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">title:</span> <span class=\"hljs-string\">青叶水间</span> <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">一个IT技术文章分享博客</span><br><span class=\"hljs-attr\">subtitle:</span> <span class=\"hljs-string\">&#x27;&#x27;</span><br><span class=\"hljs-attr\">description:</span> <span class=\"hljs-string\">&#x27;&#x27;</span><br><span class=\"hljs-attr\">keywords:</span><br><span class=\"hljs-attr\">author:</span> <span class=\"hljs-string\">leellun</span><br><span class=\"hljs-attr\">language:</span> <span class=\"hljs-string\">zh-CN</span><br><span class=\"hljs-attr\">timezone:</span> <span class=\"hljs-string\">&#x27;&#x27;</span><br><span class=\"hljs-attr\">post_asset_folder:</span> <span class=\"hljs-literal\">true</span><br><span class=\"hljs-comment\">## 主题配置，我这里用的fluid主题</span><br><span class=\"hljs-attr\">theme:</span> <span class=\"hljs-string\">fluid</span>  <br><br><span class=\"hljs-comment\"># 发布信息 git，地址是repo配置，分支branch ，需要发布必须配置了git的ssh-gen</span><br><span class=\"hljs-comment\"># 这里还需要安装了 插件hexo-deployer-git，npm install --save hexo-deployer-git</span><br><span class=\"hljs-attr\">deploy:</span><br>  <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">git</span><br>  <span class=\"hljs-attr\">repo:</span> <span class=\"hljs-string\">git@github.com:leellun/leellun.github.io.git</span><br>  <span class=\"hljs-attr\">branch:</span> <span class=\"hljs-string\">master</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"1-4-markdown图片支持\"><a href=\"#1-4-markdown图片支持\" class=\"headerlink\" title=\"1.4 markdown图片支持\"></a>1.4 markdown图片支持</h2><p>修改_config.yml</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">post_asset_folder:</span> <span class=\"hljs-literal\">true</span><br></code></pre></td></tr></table></figure>\n\n<p>安装依赖支持：</p>\n<figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">npm install hexo-<span class=\"hljs-built_in\">image</span>-link --<span class=\"hljs-built_in\">save</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"1-5-主题添加\"><a href=\"#1-5-主题添加\" class=\"headerlink\" title=\"1.5 主题添加\"></a>1.5 主题添加</h2><figure class=\"highlight ada\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ada\">npm install hexo-theme-fluid <span class=\"hljs-comment\">--save</span><br></code></pre></td></tr></table></figure>\n\n<p>主题配置：_config.fluid.yml</p>\n<figure class=\"highlight dts\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dts\"><span class=\"hljs-symbol\">favicon:</span> <span class=\"hljs-keyword\">/img/</span>leaf_icon.png<br><span class=\"hljs-symbol\"></span><br><span class=\"hljs-symbol\">navbar:</span><br>  <span class=\"hljs-meta\"># 导航栏左侧的标题，为空则按 hexo config 中 `title` 显示</span><br>  <span class=\"hljs-meta\"># The title on the left side of the navigation bar. If empty, it is based on `title` in hexo config</span><br><span class=\"hljs-symbol\">  blog_title:</span> <span class=\"hljs-string\">&quot;青叶水间&quot;</span><br><span class=\"hljs-symbol\">index:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">  slogan:</span><br><span class=\"hljs-symbol\">    enable:</span> true<br><br>    <span class=\"hljs-meta\"># 为空则按 hexo config.subtitle 显示</span><br>    <span class=\"hljs-meta\"># If empty, text based on `subtitle` in hexo config</span><br><span class=\"hljs-symbol\">    text:</span> <span class=\"hljs-string\">&quot;一个Java、SpringBoot、SpringCloud、服务器等文章分享博客网站&quot;</span><br><span class=\"hljs-symbol\">post:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">archive:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">category:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">tag:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">about:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">page:</span><br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">page404:</span><br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><span class=\"hljs-symbol\">  banner_img_height:</span> <span class=\"hljs-number\">60</span><br><span class=\"hljs-symbol\">links:</span><br><span class=\"hljs-symbol\">  enable:</span> true<br><span class=\"hljs-symbol\">  banner_img:</span> <span class=\"hljs-keyword\">/img/</span>bg-default.png<br><br><span class=\"hljs-meta\">#---------------------------</span><br><span class=\"hljs-meta\"># 页脚</span><br><span class=\"hljs-meta\"># Footer</span><br><span class=\"hljs-meta\">#---------------------------</span><br><span class=\"hljs-symbol\">footer:</span><br>  <span class=\"hljs-meta\"># 页脚第一行文字的 HTML，建议保留 Fluid 的链接，用于向更多人推广本主题</span><br>  <span class=\"hljs-meta\"># HTML of the first line of the footer, it is recommended to keep the Fluid link to promote this theme to more people</span><br><span class=\"hljs-symbol\">  content:</span> &#x27;<br>    <span class=\"hljs-params\">&lt;a href=&quot;https://hexo.io&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;</span><span class=\"hljs-params\">&lt;span&gt;</span>Hexo<span class=\"hljs-params\">&lt;/span&gt;</span><span class=\"hljs-params\">&lt;/a&gt;</span><br>    <span class=\"hljs-params\">&lt;i class=&quot;iconfont icon-love&quot;&gt;</span><span class=\"hljs-params\">&lt;/i&gt;</span><br>    <span class=\"hljs-params\">&lt;a href=&quot;https://github.com/leellun&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;</span><span class=\"hljs-params\">&lt;span&gt;</span>我的github<span class=\"hljs-params\">&lt;/span&gt;</span><span class=\"hljs-params\">&lt;/a&gt;</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"三、页面与文章\"><a href=\"#三、页面与文章\" class=\"headerlink\" title=\"三、页面与文章\"></a>三、页面与文章</h1><p>创建页面：</p>\n<figure class=\"highlight haxe\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs haxe\"><span class=\"hljs-meta\"># 创建about页面</span><br>hexo <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">page</span> about<br></code></pre></td></tr></table></figure>\n\n<p>创建文章：</p>\n<figure class=\"highlight actionscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs actionscript\">hexo <span class=\"hljs-keyword\">new</span> <span class=\"hljs-string\">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>文章头信息：</p>\n<table>\n<thead>\n<tr>\n<th>Data</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>title</code></td>\n<td>标题</td>\n</tr>\n<tr>\n<td><code>slug</code></td>\n<td>地址</td>\n</tr>\n<tr>\n<td><code>layout</code></td>\n<td>布局</td>\n</tr>\n<tr>\n<td><code>path</code></td>\n<td>路径。Hexo默认情况下基于new_post_path设置构建post路径。</td>\n</tr>\n<tr>\n<td><code>date</code></td>\n<td>日期 默认当前</td>\n</tr>\n<tr>\n<td>tags</td>\n<td>标签</td>\n</tr>\n<tr>\n<td>categories</td>\n<td>类别</td>\n</tr>\n<tr>\n<td>author</td>\n<td>作者</td>\n</tr>\n</tbody></table>\n<p>更多：<a href=\"https://hexo.io/docs/variables.html\">https://hexo.io/docs/variables.html</a></p>\n<p>启动服务：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo server<br></code></pre></td></tr></table></figure>\n\n<p>构建静态文件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo generate<br></code></pre></td></tr></table></figure>\n\n<p>推送到github，提供网页浏览：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo deploy<br></code></pre></td></tr></table></figure>\n\n\n\n<p>这里是我的博客网站源码配置（deveploer分支）：<a href=\"https://github.com/leellun/leellun.github.io\">https://github.com/leellun/leellun.github.io</a></p>\n"},{"title":"devops安装配置SonarQube","date":"2022-07-25T09:38:02.000Z","_content":"\n# 一、介绍\n\nSonarQube 是一种主流的代码质量持续检测工具。您可以将其用于代码库的静态和动态分析。SonarQube 集成到 KubeSphere 流水线后，如果在运行的流水线中检测到问题，您可以直接在仪表板上查看常见代码问题，例如 Bug 和漏洞。\n\n需要启用 KubeSphere DevOps 系统。\n\n# 二、安装 SonarQube 服务器\n\n```\nhelm upgrade --install sonarqube sonarqube --repo https://charts.kubesphere.io/main -n kubesphere-devops-system  --create-namespace --set service.type=NodePort\n```\n\n查看：\n\n```\n[root@k8s-master01 kubesphere]# kubectl get pod  -n kubesphere-devops-system\nNAME                                   READY   STATUS      RESTARTS        AGE\n...\nsonarqube-postgresql-0                 1/1     Running     0               7m6s\nsonarqube-sonarqube-84f6585f85-jnsz6   1/1     Running     1 (2m59s ago)   7m8s\n```\n\n获取 SonarQube 控制台地址:\n\n```\nexport NODE_PORT=$(kubectl get --namespace kubesphere-devops-system -o jsonpath=\"{.spec.ports[0].nodePort}\" services sonarqube-sonarqube)\nexport NODE_IP=$(kubectl get nodes --namespace kubesphere-devops-system -o jsonpath=\"{.items[0].status.addresses[0].address}\")\necho http://$NODE_IP:$NODE_PORT\n```\n\n结果：\n\n```\nhttp://192.168.66.10:30759\n```\n\n# 三、配置 SonarQube 服务器\n\n## 3.1 访问 SonarQube 控制台\n\n1. 在浏览器中访问 SonarQube 控制台 `http://<Node IP>:<NodePort>`。\n2. 点击右上角的 **Log in**，然后使用默认帐户 `admin/admin` 登录。\n\n## 3.2 创建 SonarQube 管理员令牌 (Token)\n\n1. 点击右上角字母 **A**，然后从菜单中选择 **My Account** 以转到 **Profile** 页面。\n\n   ![SonarQube 配置-1](devops安装配置SonarQube/sonarqube-config-1.png)\n\n2. 点击 **Security** 并输入令牌名称，例如 `kubesphere`。得到：68b67a9ac9f2fcfc6e2dd956b3a969a440996cf9 \n\n   ![SonarQube 配置-2](devops安装配置SonarQube/sonarqube-config-2.png)\n\n## 3.3 创建 Webhook 服务器\n\n1. 执行以下命令获取 SonarQube Webhook 的地址。\n\n   ```\n   export NODE_PORT=$(kubectl get --namespace kubesphere-devops-system -o jsonpath=\"{.spec.ports[0].nodePort}\" services devops-jenkins)\n   export NODE_IP=$(kubectl get nodes --namespace kubesphere-devops-system -o jsonpath=\"{.items[0].status.addresses[0].address}\")\n   echo http://$NODE_IP:$NODE_PORT/sonarqube-webhook/\n   ```\n\n2. 预期输出结果：\n\n   ```\n   http://192.168.66.10:30180/sonarqube-webhook/\n   ```\n\n3. 依次点击 **Administration**、**Configuration** 和 **Webhooks** 创建一个 Webhook。\n\n   ![SonarQube Webhook-1](devops安装配置SonarQube/sonarqube-webhook-1.png)\n\n4. 点击 **Create**。\n\n   ![SonarQube Webhook-2](devops安装配置SonarQube/sonarqube-webhook-2.png)\n\n5. 在弹出的对话框中输入 **Name** 和 **Jenkins Console URL**（即 SonarQube Webhook 地址）。点击 **Create** 完成操作。\n\n   ![Webhook 页面信息](devops安装配置SonarQube/webhook-page-info.png)\n\n## 3.4 将 SonarQube 配置添加到 ks-installer\n\n1. 执行以下命令编辑 `ks-installer`。\n\n   ```\n   kubectl edit cc -n kubesphere-system ks-installer\n   ```\n\n2. 搜寻至 `devops`。添加字段 `sonarqube` 并在其下方指定 `externalSonarUrl` 和 `externalSonarToken`。\n\n   ```\n   devops:\n     enabled: true\n     jenkinsJavaOpts_MaxRAM: 2g\n     jenkinsJavaOpts_Xms: 512m\n     jenkinsJavaOpts_Xmx: 512m\n     jenkinsMemoryLim: 2Gi\n     jenkinsMemoryReq: 1500Mi\n     jenkinsVolumeSize: 8Gi\n     sonarqube: # Add this field manually.\n       externalSonarUrl: http://192.168.66.10:30759 # The SonarQube IP address.\n       externalSonarToken: 68b67a9ac9f2fcfc6e2dd956b3a969a440996cf9  # The SonarQube admin token created above.\n   ```\n\n3. 完成操作后保存此文件。\n\n## 3.5 将 SonarQube 服务器添加至 Jenkins\n\n1. 执行以下命令获取 Jenkins 的地址。\n\n   ```\n   export NODE_PORT=$(kubectl get --namespace kubesphere-devops-system -o jsonpath=\"{.spec.ports[0].nodePort}\" services devops-jenkins)\n   export NODE_IP=$(kubectl get nodes --namespace kubesphere-devops-system -o jsonpath=\"{.items[0].status.addresses[0].address}\")\n   echo http://$NODE_IP:$NODE_PORT\n   ```\n\n2. 您可以获得以下输出，获取 Jenkins 的端口号。\n\n   ```\n   http://192.168.66.10:30180\n   ```\n\n3. 可以直接用kubesphere账号登录`admin/P@88w0rd`\n\n   ![1663084944194](devops安装配置SonarQube/1663084944194.png)\n\n4. 点击左侧导航栏中的**系统管理**—**系统配置**。搜寻到 **SonarQube servers**，然后点击 **Add SonarQube**。\n\n5. 输入 **Name** 和 **Server URL** (`http://<Node IP>:<NodePort>`)。点击**添加**，选择 **Jenkins**，然后在弹出的对话框中用 SonarQube 管理员令牌创建凭证（如下方第二张截图所示）。创建凭证后，从 **Server authentication token** 旁边的下拉列表中选择该凭证。点击**应用**完成操作。\n\n   ![sonarqube-jenkins-settings](devops安装配置SonarQube/sonarqube-jenkins-settings.png)\n\n   配置id为sonarqube的密钥：\n\n   ![add-credentials](devops安装配置SonarQube/add-credentials.png)\n\n## 3.6 将 sonarqubeURL 添加到 KubeSphere 控制台\n\n您需要指定 `sonarqubeURL`，以便可以直接从 KubeSphere 控制台访问 SonarQube。\n\n1 执行以下命令：\n\n```\nkubectl edit  cm -n kubesphere-system  ks-console-config\n```\n2 搜寻到 `data.client.enableKubeConfig`，在下方添加 `devops` 字段并指定 `sonarqubeURL`。\n\n```\nclient:\n  enableKubeConfig: true\n  devops: # 手动添加该字段。\n    sonarqubeURL: http://192.168.66.10:30759 # SonarQube IP 地址。\n```\n3 重启服务\n\n```\nkubectl -n kubesphere-devops-system rollout restart deploy devops-apiserver\nkubectl -n kubesphere-system rollout restart deploy ks-console\n```\n\n![1663953257964](devops安装配置SonarQube/1663953257964.png)\n\n## 3.7 为新项目创建 SonarQube Token\n\n您需要一个 SonarQube 令牌，以便您的流水线可以在运行时与 SonarQube 通信。\n\n1. 在 SonarQube 控制台上，点击 **Create new project**。\n\n   ![SonarQube 创建项目](devops安装配置SonarQube/sonarqube-create-project.png)\n\n2. 输入项目密钥，例如 `java-demo`，然后点击 **Set Up**。\n\n   ![Jenkins 项目密钥](devops安装配置SonarQube/jenkins-projet-key.png)\n\n3. 输入项目名称，例如 `java-sample`，然后点击 **Generate**。token：b0aa4ba3f0661297c10640f3e4e1e2c918a7b188\n\n   ![创建令牌](devops安装配置SonarQube/generate-a-token.png)\n\n4. 创建令牌后，点击 **Continue**。\n\n   ![令牌已创建](devops安装配置SonarQube/token-created.png)\n\n5. 分别选择 **Java** 和 **Maven**。\n\n   ```\n   mvn sonar:sonar \\\n     -Dsonar.projectKey=java-demo \\\n     -Dsonar.host.url=http://192.168.66.10:30759 \\\n     -Dsonar.login=b0aa4ba3f0661297c10640f3e4e1e2c918a7b188\n   ```\n\n   ![sonarqube-example](devops安装配置SonarQube/sonarqube-example.png)\n\n ","source":"_posts/devops安装配置SonarQube.md","raw":"---\ntitle: devops安装配置SonarQube\ndate: 2022-07-25 17:38:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - sonarqube\n---\n\n# 一、介绍\n\nSonarQube 是一种主流的代码质量持续检测工具。您可以将其用于代码库的静态和动态分析。SonarQube 集成到 KubeSphere 流水线后，如果在运行的流水线中检测到问题，您可以直接在仪表板上查看常见代码问题，例如 Bug 和漏洞。\n\n需要启用 KubeSphere DevOps 系统。\n\n# 二、安装 SonarQube 服务器\n\n```\nhelm upgrade --install sonarqube sonarqube --repo https://charts.kubesphere.io/main -n kubesphere-devops-system  --create-namespace --set service.type=NodePort\n```\n\n查看：\n\n```\n[root@k8s-master01 kubesphere]# kubectl get pod  -n kubesphere-devops-system\nNAME                                   READY   STATUS      RESTARTS        AGE\n...\nsonarqube-postgresql-0                 1/1     Running     0               7m6s\nsonarqube-sonarqube-84f6585f85-jnsz6   1/1     Running     1 (2m59s ago)   7m8s\n```\n\n获取 SonarQube 控制台地址:\n\n```\nexport NODE_PORT=$(kubectl get --namespace kubesphere-devops-system -o jsonpath=\"{.spec.ports[0].nodePort}\" services sonarqube-sonarqube)\nexport NODE_IP=$(kubectl get nodes --namespace kubesphere-devops-system -o jsonpath=\"{.items[0].status.addresses[0].address}\")\necho http://$NODE_IP:$NODE_PORT\n```\n\n结果：\n\n```\nhttp://192.168.66.10:30759\n```\n\n# 三、配置 SonarQube 服务器\n\n## 3.1 访问 SonarQube 控制台\n\n1. 在浏览器中访问 SonarQube 控制台 `http://<Node IP>:<NodePort>`。\n2. 点击右上角的 **Log in**，然后使用默认帐户 `admin/admin` 登录。\n\n## 3.2 创建 SonarQube 管理员令牌 (Token)\n\n1. 点击右上角字母 **A**，然后从菜单中选择 **My Account** 以转到 **Profile** 页面。\n\n   ![SonarQube 配置-1](devops安装配置SonarQube/sonarqube-config-1.png)\n\n2. 点击 **Security** 并输入令牌名称，例如 `kubesphere`。得到：68b67a9ac9f2fcfc6e2dd956b3a969a440996cf9 \n\n   ![SonarQube 配置-2](devops安装配置SonarQube/sonarqube-config-2.png)\n\n## 3.3 创建 Webhook 服务器\n\n1. 执行以下命令获取 SonarQube Webhook 的地址。\n\n   ```\n   export NODE_PORT=$(kubectl get --namespace kubesphere-devops-system -o jsonpath=\"{.spec.ports[0].nodePort}\" services devops-jenkins)\n   export NODE_IP=$(kubectl get nodes --namespace kubesphere-devops-system -o jsonpath=\"{.items[0].status.addresses[0].address}\")\n   echo http://$NODE_IP:$NODE_PORT/sonarqube-webhook/\n   ```\n\n2. 预期输出结果：\n\n   ```\n   http://192.168.66.10:30180/sonarqube-webhook/\n   ```\n\n3. 依次点击 **Administration**、**Configuration** 和 **Webhooks** 创建一个 Webhook。\n\n   ![SonarQube Webhook-1](devops安装配置SonarQube/sonarqube-webhook-1.png)\n\n4. 点击 **Create**。\n\n   ![SonarQube Webhook-2](devops安装配置SonarQube/sonarqube-webhook-2.png)\n\n5. 在弹出的对话框中输入 **Name** 和 **Jenkins Console URL**（即 SonarQube Webhook 地址）。点击 **Create** 完成操作。\n\n   ![Webhook 页面信息](devops安装配置SonarQube/webhook-page-info.png)\n\n## 3.4 将 SonarQube 配置添加到 ks-installer\n\n1. 执行以下命令编辑 `ks-installer`。\n\n   ```\n   kubectl edit cc -n kubesphere-system ks-installer\n   ```\n\n2. 搜寻至 `devops`。添加字段 `sonarqube` 并在其下方指定 `externalSonarUrl` 和 `externalSonarToken`。\n\n   ```\n   devops:\n     enabled: true\n     jenkinsJavaOpts_MaxRAM: 2g\n     jenkinsJavaOpts_Xms: 512m\n     jenkinsJavaOpts_Xmx: 512m\n     jenkinsMemoryLim: 2Gi\n     jenkinsMemoryReq: 1500Mi\n     jenkinsVolumeSize: 8Gi\n     sonarqube: # Add this field manually.\n       externalSonarUrl: http://192.168.66.10:30759 # The SonarQube IP address.\n       externalSonarToken: 68b67a9ac9f2fcfc6e2dd956b3a969a440996cf9  # The SonarQube admin token created above.\n   ```\n\n3. 完成操作后保存此文件。\n\n## 3.5 将 SonarQube 服务器添加至 Jenkins\n\n1. 执行以下命令获取 Jenkins 的地址。\n\n   ```\n   export NODE_PORT=$(kubectl get --namespace kubesphere-devops-system -o jsonpath=\"{.spec.ports[0].nodePort}\" services devops-jenkins)\n   export NODE_IP=$(kubectl get nodes --namespace kubesphere-devops-system -o jsonpath=\"{.items[0].status.addresses[0].address}\")\n   echo http://$NODE_IP:$NODE_PORT\n   ```\n\n2. 您可以获得以下输出，获取 Jenkins 的端口号。\n\n   ```\n   http://192.168.66.10:30180\n   ```\n\n3. 可以直接用kubesphere账号登录`admin/P@88w0rd`\n\n   ![1663084944194](devops安装配置SonarQube/1663084944194.png)\n\n4. 点击左侧导航栏中的**系统管理**—**系统配置**。搜寻到 **SonarQube servers**，然后点击 **Add SonarQube**。\n\n5. 输入 **Name** 和 **Server URL** (`http://<Node IP>:<NodePort>`)。点击**添加**，选择 **Jenkins**，然后在弹出的对话框中用 SonarQube 管理员令牌创建凭证（如下方第二张截图所示）。创建凭证后，从 **Server authentication token** 旁边的下拉列表中选择该凭证。点击**应用**完成操作。\n\n   ![sonarqube-jenkins-settings](devops安装配置SonarQube/sonarqube-jenkins-settings.png)\n\n   配置id为sonarqube的密钥：\n\n   ![add-credentials](devops安装配置SonarQube/add-credentials.png)\n\n## 3.6 将 sonarqubeURL 添加到 KubeSphere 控制台\n\n您需要指定 `sonarqubeURL`，以便可以直接从 KubeSphere 控制台访问 SonarQube。\n\n1 执行以下命令：\n\n```\nkubectl edit  cm -n kubesphere-system  ks-console-config\n```\n2 搜寻到 `data.client.enableKubeConfig`，在下方添加 `devops` 字段并指定 `sonarqubeURL`。\n\n```\nclient:\n  enableKubeConfig: true\n  devops: # 手动添加该字段。\n    sonarqubeURL: http://192.168.66.10:30759 # SonarQube IP 地址。\n```\n3 重启服务\n\n```\nkubectl -n kubesphere-devops-system rollout restart deploy devops-apiserver\nkubectl -n kubesphere-system rollout restart deploy ks-console\n```\n\n![1663953257964](devops安装配置SonarQube/1663953257964.png)\n\n## 3.7 为新项目创建 SonarQube Token\n\n您需要一个 SonarQube 令牌，以便您的流水线可以在运行时与 SonarQube 通信。\n\n1. 在 SonarQube 控制台上，点击 **Create new project**。\n\n   ![SonarQube 创建项目](devops安装配置SonarQube/sonarqube-create-project.png)\n\n2. 输入项目密钥，例如 `java-demo`，然后点击 **Set Up**。\n\n   ![Jenkins 项目密钥](devops安装配置SonarQube/jenkins-projet-key.png)\n\n3. 输入项目名称，例如 `java-sample`，然后点击 **Generate**。token：b0aa4ba3f0661297c10640f3e4e1e2c918a7b188\n\n   ![创建令牌](devops安装配置SonarQube/generate-a-token.png)\n\n4. 创建令牌后，点击 **Continue**。\n\n   ![令牌已创建](devops安装配置SonarQube/token-created.png)\n\n5. 分别选择 **Java** 和 **Maven**。\n\n   ```\n   mvn sonar:sonar \\\n     -Dsonar.projectKey=java-demo \\\n     -Dsonar.host.url=http://192.168.66.10:30759 \\\n     -Dsonar.login=b0aa4ba3f0661297c10640f3e4e1e2c918a7b188\n   ```\n\n   ![sonarqube-example](devops安装配置SonarQube/sonarqube-example.png)\n\n ","slug":"devops安装配置SonarQube","published":1,"updated":"2022-09-23T17:15:42.422Z","_id":"cl8en1r1700015cvj9hl88xej","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、介绍\"><a href=\"#一、介绍\" class=\"headerlink\" title=\"一、介绍\"></a>一、介绍</h1><p>SonarQube 是一种主流的代码质量持续检测工具。您可以将其用于代码库的静态和动态分析。SonarQube 集成到 KubeSphere 流水线后，如果在运行的流水线中检测到问题，您可以直接在仪表板上查看常见代码问题，例如 Bug 和漏洞。</p>\n<p>需要启用 KubeSphere DevOps 系统。</p>\n<h1 id=\"二、安装-SonarQube-服务器\"><a href=\"#二、安装-SonarQube-服务器\" class=\"headerlink\" title=\"二、安装 SonarQube 服务器\"></a>二、安装 SonarQube 服务器</h1><figure class=\"highlight jboss-cli\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs jboss-cli\">helm upgrade <span class=\"hljs-params\">--install</span> sonarqube sonarqube <span class=\"hljs-params\">--repo</span> https:<span class=\"hljs-string\">//charts.kubesphere.io/main</span> -n kubesphere-devops-system  <span class=\"hljs-params\">--create-namespace</span> <span class=\"hljs-params\">--set</span> service.type=NodePort<br></code></pre></td></tr></table></figure>\n\n<p>查看：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\">[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 kubesphere]# kubectl <span class=\"hljs-keyword\">get</span> pod  <span class=\"hljs-operator\">-</span>n kubesphere<span class=\"hljs-operator\">-</span>devops<span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">system</span><br>NAME                                   READY   STATUS      RESTARTS        AGE<br>...<br>sonarqube<span class=\"hljs-operator\">-</span>postgresql<span class=\"hljs-number\">-0</span>                 <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>               <span class=\"hljs-number\">7</span>m6s<br>sonarqube<span class=\"hljs-operator\">-</span>sonarqube<span class=\"hljs-number\">-84</span>f6585f85<span class=\"hljs-operator\">-</span>jnsz6   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">1</span> (<span class=\"hljs-number\">2</span>m59s ago)   <span class=\"hljs-number\">7</span>m8s<br></code></pre></td></tr></table></figure>\n\n<p>获取 SonarQube 控制台地址:</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\">export NODE_PORT=<span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> --<span class=\"hljs-params\">namespace</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=<span class=\"hljs-string\">&quot;&#123;.spec.ports[0].nodePort&#125;&quot;</span> <span class=\"hljs-params\">services</span> <span class=\"hljs-params\">sonarqube</span>-<span class=\"hljs-params\">sonarqube</span>)</span><br>export NODE_IP=<span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> <span class=\"hljs-params\">nodes</span> --<span class=\"hljs-params\">namespace</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=<span class=\"hljs-string\">&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;</span>)</span><br>echo http:<span class=\"hljs-comment\">//$NODE_IP:$NODE_PORT</span><br></code></pre></td></tr></table></figure>\n\n<p>结果：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">http:<span class=\"hljs-regexp\">//</span><span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">66.10</span>:<span class=\"hljs-number\">30759</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"三、配置-SonarQube-服务器\"><a href=\"#三、配置-SonarQube-服务器\" class=\"headerlink\" title=\"三、配置 SonarQube 服务器\"></a>三、配置 SonarQube 服务器</h1><h2 id=\"3-1-访问-SonarQube-控制台\"><a href=\"#3-1-访问-SonarQube-控制台\" class=\"headerlink\" title=\"3.1 访问 SonarQube 控制台\"></a>3.1 访问 SonarQube 控制台</h2><ol>\n<li>在浏览器中访问 SonarQube 控制台 <code>http://&lt;Node IP&gt;:&lt;NodePort&gt;</code>。</li>\n<li>点击右上角的 <strong>Log in</strong>，然后使用默认帐户 <code>admin/admin</code> 登录。</li>\n</ol>\n<h2 id=\"3-2-创建-SonarQube-管理员令牌-Token\"><a href=\"#3-2-创建-SonarQube-管理员令牌-Token\" class=\"headerlink\" title=\"3.2 创建 SonarQube 管理员令牌 (Token)\"></a>3.2 创建 SonarQube 管理员令牌 (Token)</h2><ol>\n<li><p>点击右上角字母 <strong>A</strong>，然后从菜单中选择 <strong>My Account</strong> 以转到 <strong>Profile</strong> 页面。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-config-1.png\" class=\"\" title=\"SonarQube 配置-1\"></li>\n<li><p>点击 <strong>Security</strong> 并输入令牌名称，例如 <code>kubesphere</code>。得到：68b67a9ac9f2fcfc6e2dd956b3a969a440996cf9 </p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-config-2.png\" class=\"\" title=\"SonarQube 配置-2\"></li>\n</ol>\n<h2 id=\"3-3-创建-Webhook-服务器\"><a href=\"#3-3-创建-Webhook-服务器\" class=\"headerlink\" title=\"3.3 创建 Webhook 服务器\"></a>3.3 创建 Webhook 服务器</h2><ol>\n<li><p>执行以下命令获取 SonarQube Webhook 的地址。</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\">export NODE_PORT=<span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> --<span class=\"hljs-params\">namespace</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=<span class=\"hljs-string\">&quot;&#123;.spec.ports[0].nodePort&#125;&quot;</span> <span class=\"hljs-params\">services</span> <span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">jenkins</span>)</span><br>export NODE_IP=<span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> <span class=\"hljs-params\">nodes</span> --<span class=\"hljs-params\">namespace</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=<span class=\"hljs-string\">&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;</span>)</span><br>echo http:<span class=\"hljs-comment\">//$NODE_IP:$NODE_PORT/sonarqube-webhook/</span><br></code></pre></td></tr></table></figure></li>\n<li><p>预期输出结果：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">http:<span class=\"hljs-regexp\">//</span><span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">66.10</span>:<span class=\"hljs-number\">30180</span><span class=\"hljs-regexp\">/sonarqube-webhook/</span><br></code></pre></td></tr></table></figure></li>\n<li><p>依次点击 <strong>Administration</strong>、<strong>Configuration</strong> 和 <strong>Webhooks</strong> 创建一个 Webhook。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-webhook-1.png\" class=\"\" title=\"SonarQube Webhook-1\"></li>\n<li><p>点击 <strong>Create</strong>。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-webhook-2.png\" class=\"\" title=\"SonarQube Webhook-2\"></li>\n<li><p>在弹出的对话框中输入 <strong>Name</strong> 和 <strong>Jenkins Console URL</strong>（即 SonarQube Webhook 地址）。点击 <strong>Create</strong> 完成操作。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/webhook-page-info.png\" class=\"\" title=\"Webhook 页面信息\"></li>\n</ol>\n<h2 id=\"3-4-将-SonarQube-配置添加到-ks-installer\"><a href=\"#3-4-将-SonarQube-配置添加到-ks-installer\" class=\"headerlink\" title=\"3.4 将 SonarQube 配置添加到 ks-installer\"></a>3.4 将 SonarQube 配置添加到 ks-installer</h2><ol>\n<li><p>执行以下命令编辑 <code>ks-installer</code>。</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs vim\">kubectl <span class=\"hljs-keyword\">edit</span> <span class=\"hljs-keyword\">cc</span> -n kubesphere-<span class=\"hljs-built_in\">system</span> ks-installer<br></code></pre></td></tr></table></figure></li>\n<li><p>搜寻至 <code>devops</code>。添加字段 <code>sonarqube</code> 并在其下方指定 <code>externalSonarUrl</code> 和 <code>externalSonarToken</code>。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">devops:</span><br>  <span class=\"hljs-attr\">enabled:</span> <span class=\"hljs-literal\">true</span><br>  <span class=\"hljs-attr\">jenkinsJavaOpts_MaxRAM:</span> <span class=\"hljs-string\">2g</span><br>  <span class=\"hljs-attr\">jenkinsJavaOpts_Xms:</span> <span class=\"hljs-string\">512m</span><br>  <span class=\"hljs-attr\">jenkinsJavaOpts_Xmx:</span> <span class=\"hljs-string\">512m</span><br>  <span class=\"hljs-attr\">jenkinsMemoryLim:</span> <span class=\"hljs-string\">2Gi</span><br>  <span class=\"hljs-attr\">jenkinsMemoryReq:</span> <span class=\"hljs-string\">1500Mi</span><br>  <span class=\"hljs-attr\">jenkinsVolumeSize:</span> <span class=\"hljs-string\">8Gi</span><br>  <span class=\"hljs-attr\">sonarqube:</span> <span class=\"hljs-comment\"># Add this field manually.</span><br>    <span class=\"hljs-attr\">externalSonarUrl:</span> <span class=\"hljs-string\">http://192.168.66.10:30759</span> <span class=\"hljs-comment\"># The SonarQube IP address.</span><br>    <span class=\"hljs-attr\">externalSonarToken:</span> <span class=\"hljs-string\">68b67a9ac9f2fcfc6e2dd956b3a969a440996cf9</span>  <span class=\"hljs-comment\"># The SonarQube admin token created above.</span><br></code></pre></td></tr></table></figure></li>\n<li><p>完成操作后保存此文件。</p>\n</li>\n</ol>\n<h2 id=\"3-5-将-SonarQube-服务器添加至-Jenkins\"><a href=\"#3-5-将-SonarQube-服务器添加至-Jenkins\" class=\"headerlink\" title=\"3.5 将 SonarQube 服务器添加至 Jenkins\"></a>3.5 将 SonarQube 服务器添加至 Jenkins</h2><ol>\n<li><p>执行以下命令获取 Jenkins 的地址。</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\">export NODE_PORT=<span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> --<span class=\"hljs-params\">namespace</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=<span class=\"hljs-string\">&quot;&#123;.spec.ports[0].nodePort&#125;&quot;</span> <span class=\"hljs-params\">services</span> <span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">jenkins</span>)</span><br>export NODE_IP=<span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> <span class=\"hljs-params\">nodes</span> --<span class=\"hljs-params\">namespace</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=<span class=\"hljs-string\">&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;</span>)</span><br>echo http:<span class=\"hljs-comment\">//$NODE_IP:$NODE_PORT</span><br></code></pre></td></tr></table></figure></li>\n<li><p>您可以获得以下输出，获取 Jenkins 的端口号。</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">http:<span class=\"hljs-regexp\">//</span><span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">66.10</span>:<span class=\"hljs-number\">30180</span><br></code></pre></td></tr></table></figure></li>\n<li><p>可以直接用kubesphere账号登录<code>admin/P@88w0rd</code></p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/1663084944194.png\" class=\"\" width=\"1663084944194\"></li>\n<li><p>点击左侧导航栏中的<strong>系统管理</strong>—<strong>系统配置</strong>。搜寻到 <strong>SonarQube servers</strong>，然后点击 <strong>Add SonarQube</strong>。</p>\n</li>\n<li><p>输入 <strong>Name</strong> 和 <strong>Server URL</strong> (<code>http://&lt;Node IP&gt;:&lt;NodePort&gt;</code>)。点击<strong>添加</strong>，选择 <strong>Jenkins</strong>，然后在弹出的对话框中用 SonarQube 管理员令牌创建凭证（如下方第二张截图所示）。创建凭证后，从 <strong>Server authentication token</strong> 旁边的下拉列表中选择该凭证。点击<strong>应用</strong>完成操作。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-jenkins-settings.png\" class=\"\" title=\"sonarqube-jenkins-settings\">\n\n<p>配置id为sonarqube的密钥：</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/add-credentials.png\" class=\"\" title=\"add-credentials\"></li>\n</ol>\n<h2 id=\"3-6-将-sonarqubeURL-添加到-KubeSphere-控制台\"><a href=\"#3-6-将-sonarqubeURL-添加到-KubeSphere-控制台\" class=\"headerlink\" title=\"3.6 将 sonarqubeURL 添加到 KubeSphere 控制台\"></a>3.6 将 sonarqubeURL 添加到 KubeSphere 控制台</h2><p>您需要指定 <code>sonarqubeURL</code>，以便可以直接从 KubeSphere 控制台访问 SonarQube。</p>\n<p>1 执行以下命令：</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs vim\">kubectl <span class=\"hljs-keyword\">edit</span>  <span class=\"hljs-keyword\">cm</span> -n kubesphere-<span class=\"hljs-built_in\">system</span>  ks-console-config<br></code></pre></td></tr></table></figure>\n<p>2 搜寻到 <code>data.client.enableKubeConfig</code>，在下方添加 <code>devops</code> 字段并指定 <code>sonarqubeURL</code>。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">client:</span><br>  <span class=\"hljs-attr\">enableKubeConfig:</span> <span class=\"hljs-literal\">true</span><br>  <span class=\"hljs-attr\">devops:</span> <span class=\"hljs-comment\"># 手动添加该字段。</span><br>    <span class=\"hljs-attr\">sonarqubeURL:</span> <span class=\"hljs-string\">http://192.168.66.10:30759</span> <span class=\"hljs-comment\"># SonarQube IP 地址。</span><br></code></pre></td></tr></table></figure>\n<p>3 重启服务</p>\n<figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">kubectl -n kubesphere-devops-<span class=\"hljs-built_in\">system</span> rollout <span class=\"hljs-built_in\">restart</span> deploy devops-apiserver<br>kubectl -n kubesphere-<span class=\"hljs-built_in\">system</span> rollout <span class=\"hljs-built_in\">restart</span> deploy ks-console<br></code></pre></td></tr></table></figure>\n\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/1663953257964.png\" class=\"\" width=\"1663953257964\">\n\n<h2 id=\"3-7-为新项目创建-SonarQube-Token\"><a href=\"#3-7-为新项目创建-SonarQube-Token\" class=\"headerlink\" title=\"3.7 为新项目创建 SonarQube Token\"></a>3.7 为新项目创建 SonarQube Token</h2><p>您需要一个 SonarQube 令牌，以便您的流水线可以在运行时与 SonarQube 通信。</p>\n<ol>\n<li><p>在 SonarQube 控制台上，点击 <strong>Create new project</strong>。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-create-project.png\" class=\"\" title=\"SonarQube 创建项目\"></li>\n<li><p>输入项目密钥，例如 <code>java-demo</code>，然后点击 <strong>Set Up</strong>。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/jenkins-projet-key.png\" class=\"\" title=\"Jenkins 项目密钥\"></li>\n<li><p>输入项目名称，例如 <code>java-sample</code>，然后点击 <strong>Generate</strong>。token：b0aa4ba3f0661297c10640f3e4e1e2c918a7b188</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/generate-a-token.png\" class=\"\" title=\"创建令牌\"></li>\n<li><p>创建令牌后，点击 <strong>Continue</strong>。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/token-created.png\" class=\"\" title=\"令牌已创建\"></li>\n<li><p>分别选择 <strong>Java</strong> 和 <strong>Maven</strong>。</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">mvn sonar:sonar \\<br>  -Dsonar.<span class=\"hljs-attribute\">projectKey</span>=java-demo \\<br>  -Dsonar.host.<span class=\"hljs-attribute\">url</span>=http://192.168.66.10:30759 \\<br>  -Dsonar.<span class=\"hljs-attribute\">login</span>=b0aa4ba3f0661297c10640f3e4e1e2c918a7b188<br></code></pre></td></tr></table></figure>\n\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-example.png\" class=\"\" title=\"sonarqube-example\"></li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、介绍\"><a href=\"#一、介绍\" class=\"headerlink\" title=\"一、介绍\"></a>一、介绍</h1><p>SonarQube 是一种主流的代码质量持续检测工具。您可以将其用于代码库的静态和动态分析。SonarQube 集成到 KubeSphere 流水线后，如果在运行的流水线中检测到问题，您可以直接在仪表板上查看常见代码问题，例如 Bug 和漏洞。</p>\n<p>需要启用 KubeSphere DevOps 系统。</p>\n<h1 id=\"二、安装-SonarQube-服务器\"><a href=\"#二、安装-SonarQube-服务器\" class=\"headerlink\" title=\"二、安装 SonarQube 服务器\"></a>二、安装 SonarQube 服务器</h1><figure class=\"highlight jboss-cli\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs jboss-cli\">helm upgrade <span class=\"hljs-params\">--install</span> sonarqube sonarqube <span class=\"hljs-params\">--repo</span> https:<span class=\"hljs-string\">//charts.kubesphere.io/main</span> -n kubesphere-devops-system  <span class=\"hljs-params\">--create-namespace</span> <span class=\"hljs-params\">--set</span> service.type=NodePort<br></code></pre></td></tr></table></figure>\n\n<p>查看：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\">[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 kubesphere]# kubectl <span class=\"hljs-keyword\">get</span> pod  <span class=\"hljs-operator\">-</span>n kubesphere<span class=\"hljs-operator\">-</span>devops<span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">system</span><br>NAME                                   READY   STATUS      RESTARTS        AGE<br>...<br>sonarqube<span class=\"hljs-operator\">-</span>postgresql<span class=\"hljs-number\">-0</span>                 <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>               <span class=\"hljs-number\">7</span>m6s<br>sonarqube<span class=\"hljs-operator\">-</span>sonarqube<span class=\"hljs-number\">-84</span>f6585f85<span class=\"hljs-operator\">-</span>jnsz6   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">1</span> (<span class=\"hljs-number\">2</span>m59s ago)   <span class=\"hljs-number\">7</span>m8s<br></code></pre></td></tr></table></figure>\n\n<p>获取 SonarQube 控制台地址:</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\">export NODE_PORT=<span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> --<span class=\"hljs-params\">namespace</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=<span class=\"hljs-string\">&quot;&#123;.spec.ports[0].nodePort&#125;&quot;</span> <span class=\"hljs-params\">services</span> <span class=\"hljs-params\">sonarqube</span>-<span class=\"hljs-params\">sonarqube</span>)</span><br>export NODE_IP=<span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> <span class=\"hljs-params\">nodes</span> --<span class=\"hljs-params\">namespace</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=<span class=\"hljs-string\">&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;</span>)</span><br>echo http:<span class=\"hljs-comment\">//$NODE_IP:$NODE_PORT</span><br></code></pre></td></tr></table></figure>\n\n<p>结果：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">http:<span class=\"hljs-regexp\">//</span><span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">66.10</span>:<span class=\"hljs-number\">30759</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"三、配置-SonarQube-服务器\"><a href=\"#三、配置-SonarQube-服务器\" class=\"headerlink\" title=\"三、配置 SonarQube 服务器\"></a>三、配置 SonarQube 服务器</h1><h2 id=\"3-1-访问-SonarQube-控制台\"><a href=\"#3-1-访问-SonarQube-控制台\" class=\"headerlink\" title=\"3.1 访问 SonarQube 控制台\"></a>3.1 访问 SonarQube 控制台</h2><ol>\n<li>在浏览器中访问 SonarQube 控制台 <code>http://&lt;Node IP&gt;:&lt;NodePort&gt;</code>。</li>\n<li>点击右上角的 <strong>Log in</strong>，然后使用默认帐户 <code>admin/admin</code> 登录。</li>\n</ol>\n<h2 id=\"3-2-创建-SonarQube-管理员令牌-Token\"><a href=\"#3-2-创建-SonarQube-管理员令牌-Token\" class=\"headerlink\" title=\"3.2 创建 SonarQube 管理员令牌 (Token)\"></a>3.2 创建 SonarQube 管理员令牌 (Token)</h2><ol>\n<li><p>点击右上角字母 <strong>A</strong>，然后从菜单中选择 <strong>My Account</strong> 以转到 <strong>Profile</strong> 页面。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-config-1.png\" class=\"\" title=\"SonarQube 配置-1\"></li>\n<li><p>点击 <strong>Security</strong> 并输入令牌名称，例如 <code>kubesphere</code>。得到：68b67a9ac9f2fcfc6e2dd956b3a969a440996cf9 </p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-config-2.png\" class=\"\" title=\"SonarQube 配置-2\"></li>\n</ol>\n<h2 id=\"3-3-创建-Webhook-服务器\"><a href=\"#3-3-创建-Webhook-服务器\" class=\"headerlink\" title=\"3.3 创建 Webhook 服务器\"></a>3.3 创建 Webhook 服务器</h2><ol>\n<li><p>执行以下命令获取 SonarQube Webhook 的地址。</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\">export NODE_PORT=<span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> --<span class=\"hljs-params\">namespace</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=<span class=\"hljs-string\">&quot;&#123;.spec.ports[0].nodePort&#125;&quot;</span> <span class=\"hljs-params\">services</span> <span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">jenkins</span>)</span><br>export NODE_IP=<span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> <span class=\"hljs-params\">nodes</span> --<span class=\"hljs-params\">namespace</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=<span class=\"hljs-string\">&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;</span>)</span><br>echo http:<span class=\"hljs-comment\">//$NODE_IP:$NODE_PORT/sonarqube-webhook/</span><br></code></pre></td></tr></table></figure></li>\n<li><p>预期输出结果：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">http:<span class=\"hljs-regexp\">//</span><span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">66.10</span>:<span class=\"hljs-number\">30180</span><span class=\"hljs-regexp\">/sonarqube-webhook/</span><br></code></pre></td></tr></table></figure></li>\n<li><p>依次点击 <strong>Administration</strong>、<strong>Configuration</strong> 和 <strong>Webhooks</strong> 创建一个 Webhook。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-webhook-1.png\" class=\"\" title=\"SonarQube Webhook-1\"></li>\n<li><p>点击 <strong>Create</strong>。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-webhook-2.png\" class=\"\" title=\"SonarQube Webhook-2\"></li>\n<li><p>在弹出的对话框中输入 <strong>Name</strong> 和 <strong>Jenkins Console URL</strong>（即 SonarQube Webhook 地址）。点击 <strong>Create</strong> 完成操作。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/webhook-page-info.png\" class=\"\" title=\"Webhook 页面信息\"></li>\n</ol>\n<h2 id=\"3-4-将-SonarQube-配置添加到-ks-installer\"><a href=\"#3-4-将-SonarQube-配置添加到-ks-installer\" class=\"headerlink\" title=\"3.4 将 SonarQube 配置添加到 ks-installer\"></a>3.4 将 SonarQube 配置添加到 ks-installer</h2><ol>\n<li><p>执行以下命令编辑 <code>ks-installer</code>。</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs vim\">kubectl <span class=\"hljs-keyword\">edit</span> <span class=\"hljs-keyword\">cc</span> -n kubesphere-<span class=\"hljs-built_in\">system</span> ks-installer<br></code></pre></td></tr></table></figure></li>\n<li><p>搜寻至 <code>devops</code>。添加字段 <code>sonarqube</code> 并在其下方指定 <code>externalSonarUrl</code> 和 <code>externalSonarToken</code>。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">devops:</span><br>  <span class=\"hljs-attr\">enabled:</span> <span class=\"hljs-literal\">true</span><br>  <span class=\"hljs-attr\">jenkinsJavaOpts_MaxRAM:</span> <span class=\"hljs-string\">2g</span><br>  <span class=\"hljs-attr\">jenkinsJavaOpts_Xms:</span> <span class=\"hljs-string\">512m</span><br>  <span class=\"hljs-attr\">jenkinsJavaOpts_Xmx:</span> <span class=\"hljs-string\">512m</span><br>  <span class=\"hljs-attr\">jenkinsMemoryLim:</span> <span class=\"hljs-string\">2Gi</span><br>  <span class=\"hljs-attr\">jenkinsMemoryReq:</span> <span class=\"hljs-string\">1500Mi</span><br>  <span class=\"hljs-attr\">jenkinsVolumeSize:</span> <span class=\"hljs-string\">8Gi</span><br>  <span class=\"hljs-attr\">sonarqube:</span> <span class=\"hljs-comment\"># Add this field manually.</span><br>    <span class=\"hljs-attr\">externalSonarUrl:</span> <span class=\"hljs-string\">http://192.168.66.10:30759</span> <span class=\"hljs-comment\"># The SonarQube IP address.</span><br>    <span class=\"hljs-attr\">externalSonarToken:</span> <span class=\"hljs-string\">68b67a9ac9f2fcfc6e2dd956b3a969a440996cf9</span>  <span class=\"hljs-comment\"># The SonarQube admin token created above.</span><br></code></pre></td></tr></table></figure></li>\n<li><p>完成操作后保存此文件。</p>\n</li>\n</ol>\n<h2 id=\"3-5-将-SonarQube-服务器添加至-Jenkins\"><a href=\"#3-5-将-SonarQube-服务器添加至-Jenkins\" class=\"headerlink\" title=\"3.5 将 SonarQube 服务器添加至 Jenkins\"></a>3.5 将 SonarQube 服务器添加至 Jenkins</h2><ol>\n<li><p>执行以下命令获取 Jenkins 的地址。</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\">export NODE_PORT=<span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> --<span class=\"hljs-params\">namespace</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=<span class=\"hljs-string\">&quot;&#123;.spec.ports[0].nodePort&#125;&quot;</span> <span class=\"hljs-params\">services</span> <span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">jenkins</span>)</span><br>export NODE_IP=<span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> <span class=\"hljs-params\">nodes</span> --<span class=\"hljs-params\">namespace</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">devops</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=<span class=\"hljs-string\">&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;</span>)</span><br>echo http:<span class=\"hljs-comment\">//$NODE_IP:$NODE_PORT</span><br></code></pre></td></tr></table></figure></li>\n<li><p>您可以获得以下输出，获取 Jenkins 的端口号。</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">http:<span class=\"hljs-regexp\">//</span><span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">66.10</span>:<span class=\"hljs-number\">30180</span><br></code></pre></td></tr></table></figure></li>\n<li><p>可以直接用kubesphere账号登录<code>admin/P@88w0rd</code></p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/1663084944194.png\" class=\"\" width=\"1663084944194\"></li>\n<li><p>点击左侧导航栏中的<strong>系统管理</strong>—<strong>系统配置</strong>。搜寻到 <strong>SonarQube servers</strong>，然后点击 <strong>Add SonarQube</strong>。</p>\n</li>\n<li><p>输入 <strong>Name</strong> 和 <strong>Server URL</strong> (<code>http://&lt;Node IP&gt;:&lt;NodePort&gt;</code>)。点击<strong>添加</strong>，选择 <strong>Jenkins</strong>，然后在弹出的对话框中用 SonarQube 管理员令牌创建凭证（如下方第二张截图所示）。创建凭证后，从 <strong>Server authentication token</strong> 旁边的下拉列表中选择该凭证。点击<strong>应用</strong>完成操作。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-jenkins-settings.png\" class=\"\" title=\"sonarqube-jenkins-settings\">\n\n<p>配置id为sonarqube的密钥：</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/add-credentials.png\" class=\"\" title=\"add-credentials\"></li>\n</ol>\n<h2 id=\"3-6-将-sonarqubeURL-添加到-KubeSphere-控制台\"><a href=\"#3-6-将-sonarqubeURL-添加到-KubeSphere-控制台\" class=\"headerlink\" title=\"3.6 将 sonarqubeURL 添加到 KubeSphere 控制台\"></a>3.6 将 sonarqubeURL 添加到 KubeSphere 控制台</h2><p>您需要指定 <code>sonarqubeURL</code>，以便可以直接从 KubeSphere 控制台访问 SonarQube。</p>\n<p>1 执行以下命令：</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs vim\">kubectl <span class=\"hljs-keyword\">edit</span>  <span class=\"hljs-keyword\">cm</span> -n kubesphere-<span class=\"hljs-built_in\">system</span>  ks-console-config<br></code></pre></td></tr></table></figure>\n<p>2 搜寻到 <code>data.client.enableKubeConfig</code>，在下方添加 <code>devops</code> 字段并指定 <code>sonarqubeURL</code>。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">client:</span><br>  <span class=\"hljs-attr\">enableKubeConfig:</span> <span class=\"hljs-literal\">true</span><br>  <span class=\"hljs-attr\">devops:</span> <span class=\"hljs-comment\"># 手动添加该字段。</span><br>    <span class=\"hljs-attr\">sonarqubeURL:</span> <span class=\"hljs-string\">http://192.168.66.10:30759</span> <span class=\"hljs-comment\"># SonarQube IP 地址。</span><br></code></pre></td></tr></table></figure>\n<p>3 重启服务</p>\n<figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">kubectl -n kubesphere-devops-<span class=\"hljs-built_in\">system</span> rollout <span class=\"hljs-built_in\">restart</span> deploy devops-apiserver<br>kubectl -n kubesphere-<span class=\"hljs-built_in\">system</span> rollout <span class=\"hljs-built_in\">restart</span> deploy ks-console<br></code></pre></td></tr></table></figure>\n\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/1663953257964.png\" class=\"\" width=\"1663953257964\">\n\n<h2 id=\"3-7-为新项目创建-SonarQube-Token\"><a href=\"#3-7-为新项目创建-SonarQube-Token\" class=\"headerlink\" title=\"3.7 为新项目创建 SonarQube Token\"></a>3.7 为新项目创建 SonarQube Token</h2><p>您需要一个 SonarQube 令牌，以便您的流水线可以在运行时与 SonarQube 通信。</p>\n<ol>\n<li><p>在 SonarQube 控制台上，点击 <strong>Create new project</strong>。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-create-project.png\" class=\"\" title=\"SonarQube 创建项目\"></li>\n<li><p>输入项目密钥，例如 <code>java-demo</code>，然后点击 <strong>Set Up</strong>。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/jenkins-projet-key.png\" class=\"\" title=\"Jenkins 项目密钥\"></li>\n<li><p>输入项目名称，例如 <code>java-sample</code>，然后点击 <strong>Generate</strong>。token：b0aa4ba3f0661297c10640f3e4e1e2c918a7b188</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/generate-a-token.png\" class=\"\" title=\"创建令牌\"></li>\n<li><p>创建令牌后，点击 <strong>Continue</strong>。</p>\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/token-created.png\" class=\"\" title=\"令牌已创建\"></li>\n<li><p>分别选择 <strong>Java</strong> 和 <strong>Maven</strong>。</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">mvn sonar:sonar \\<br>  -Dsonar.<span class=\"hljs-attribute\">projectKey</span>=java-demo \\<br>  -Dsonar.host.<span class=\"hljs-attribute\">url</span>=http://192.168.66.10:30759 \\<br>  -Dsonar.<span class=\"hljs-attribute\">login</span>=b0aa4ba3f0661297c10640f3e4e1e2c918a7b188<br></code></pre></td></tr></table></figure>\n\n<img src=\"/2022/07/25/devops%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AESonarQube/sonarqube-example.png\" class=\"\" title=\"sonarqube-example\"></li>\n</ol>\n"},{"title":"devops之KubeSphere流水线部署","date":"2022-07-26T04:38:02.000Z","_content":"\n![流水线概览](devops之KubeSphere流水线部署/pipeline-overview.png) \n\n- **阶段 1：Checkout SCM**：从 GitHub 仓库检出源代码。\n- **阶段 2：单元测试**：待该测试通过后才会进行下一阶段。\n- **阶段 3：SonarQube 分析**：SonarQube 代码质量分析。\n- **阶段 4：构建并推送快照镜像**：根据**策略设置**中选定的分支来构建镜像，并将 `SNAPSHOT-$BRANCH_NAME-$BUILD_NUMBER` 标签推送至 Docker Hub，其中 `$BUILD_NUMBER` 为流水线活动列表中的运行序号。\n- **阶段 5：推送最新镜像**：将 SonarQube 分支标记为 `latest`，并推送至 Docker Hub。\n- **阶段 6：部署至开发环境**：将 SonarQube 分支部署到开发环境，此阶段需要审核。\n- **阶段 7：带标签推送**：生成标签并发布到 GitHub，该标签会推送到 Docker Hub。\n- **阶段 8：部署至生产环境**：将已发布的标签部署到生产环境。\n\n# 一、开启devops\n\ncluster-configuration.yaml\n\n```\ndevops:\n  enabled: true # 将“false”更改为“true”。\n```\n\n执行：\n\n```\nkubectl apply -f cluster-configuration.yaml\n```\n\n查看安装情况：\n\n```\nkubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f\n```\n\n查看结果：\n\n```\n[root@k8s-master01 kubesphere]# kubectl get pod --all-namespaces\nNAMESPACE                      NAME                                                              READY   STATUS      RESTARTS         AGE\nargocd                         devops-argocd-application-controller-0                            0/1     Running     9 (29s ago)      24m\nargocd                         devops-argocd-applicationset-controller-b88d4b875-hztm8           1/1     Running     0                24m\nargocd                         devops-argocd-dex-server-5f4c69cdb8-26d9x                         1/1     Running     0                24m\nargocd                         devops-argocd-notifications-controller-6d86f8974f-twlk6           1/1     Running     0                24m\nargocd                         devops-argocd-redis-655969589d-vbzfq                              1/1     Running     0                24m\nargocd                         devops-argocd-repo-server-f77687668-l46fj                         1/1     Running     0                24m\nargocd                         devops-argocd-server-6c55bbb84f-tgdv6                             1/1     Running     0                24m\n....\n```\n\n![1662990207401](devops之KubeSphere流水线部署/1662990207401.png)\n\njdk11:\n\n在**配置字典**页面的搜索框中输入 `jenkins-casc-config` 并按**回车键**。 \n\n\n\n# 二、创建凭证\n\n## 1.1 创建dockerhub凭证\n\n1. 登录 Docker Hub，点击右上角的帐户，并从菜单中选择 **Account Settings**。\n\n2. 在左侧导航栏点击 **Security**，然后点击 **New Access Token**。\n\n3. 在弹出的对话框中，输入令牌名称（`go-project-token`），点击 **Create**。\n\n   ```\n   dockerhub-id\n   用户名：leellun\n   密码：dckr_pat_P9abXAwRM9TU96yyERoODoyThRY\n   ```\n\n4. 点击 **Copy and Close** 并务必保存该访问令牌。\n\n![1662995312671](devops之KubeSphere流水线部署/1662995312671.png)\n\n## 1.2 github凭证\n\ngithub-id\n\n用户名和token添加\n\n## 1.3 kubeconfig凭证添加\n\n可以用root/.kube/config内容，也可以生成用户认证kubeconfig\n\n![1662995264415](devops之KubeSphere流水线部署/1662995264415.png)\n\n## 1.4 SonarQube凭证添加\n\nsonar-token\n\n进入sonarqube添加项目并且生成token：**caea718fe1c8d61628c85cc642998605247c4de9** \n\n![1662997272162](devops之KubeSphere流水线部署/1662997272162.png) \n\n配置sonarqube凭证：\n\n用户名和token添加\n\n```\nuser: \ntoken: caea718fe1c8d61628c85cc642998605247c4de9\n```\n\n\n\n# 三、修改 Jenkinsfile\n\n![jenkins-edit--2](devops之KubeSphere流水线部署/jenkins-edit--2.png)\n\n| 条目                     | 值                     | 描述信息                                                     |\n| ------------------------ | ---------------------- | ------------------------------------------------------------ |\n| DOCKER_CREDENTIAL_ID     | dockerhub-id           | 您在 KubeSphere 中为 Docker Hub 帐户设置的**名称**。         |\n| GITHUB_CREDENTIAL_ID     | github-id              | 您在 KubeSphere 中为 GitHub 帐户设置的**名称**，用于将标签推送至您的 GitHub 仓库。 |\n| KUBECONFIG_CREDENTIAL_ID | demo-kubeconfig        | 您在 KubeSphere 中为 kubeconfig 设置的**名称**，用于访问运行中的 Kubernetes 集群。 |\n| REGISTRY                 | docker.io              | 默认为 `docker.io`，用作推送镜像的地址。                     |\n| DOCKERHUB_NAMESPACE      | your-dockerhub-account | 请替换为您的 Docker Hub 帐户名，也可以替换为该帐户下的 Organization 名称。 |\n| GITHUB_ACCOUNT           | your-github-account    | 请替换为您的 GitHub 帐户名。例如，如果您的 GitHub 地址是 `https://github.com/kubesphere/`，则您的 GitHub 帐户名为 `kubesphere`，也可以替换为该帐户下的 Organization 名称。 |\n| APP_NAME                 | devops-maven-sample    | 应用名称。                                                   |\n| SONAR_CREDENTIAL_ID      | sonar-token            | 您在 KubeSphere 中为 SonarQube 令牌设置的**名称**，用于代码质量检测。 |\n\n# 四、具体Jenkinsfile根据项目而定\n\n下面选用的代码仓库是码云、docker镜像仓库是dockerhub、代码分析sonar是自己部署的\n\n流水线步骤：拉取镜像——单元测试——代码质量分析——编译 & 推送——推送最新——发布开发环境——推送正式版本——发布生产环境\n\n```\npipeline {\n  agent {\n    node {\n      label 'maven'\n    }\n\n  }\n  environment {\n    DOCKER_CREDENTIAL_ID = 'dockerhub-id'\n    GITEE_CREDENTIAL_ID = 'gitee-id'\n    KUBECONFIG_CREDENTIAL_ID = 'kubeconfig'\n    REGISTRY = 'docker.io'\n    DOCKERHUB_NAMESPACE = 'leellun'\n    GIT_ACCOUNT = 'myselfyou'\n    SONAR_CREDENTIAL_ID = 'sonar-token'\n    BRANCH_NAME = 'master'\n  }\n  parameters {\n    string(name: 'PROJECT_VERSION', defaultValue: '', description: '版本')\n    string(name: 'PROJECT_NAME', defaultValue: '', description: '项目名称')\n  }\n  stages {\n    stage('拉取代码') {\n      steps {\n        sh \"echo 正在构建 $PROJECT_NAME 版本号：$PROJECT_VERSION 将会提交给 $REGISTRY 镜像仓库\"\n        git(url: 'https://gitee.com/myselfyou/gulimall-learng.git', credentialsId: \"$GITEE_CREDENTIAL_ID\", branch: 'master', changelog: true, poll: false)\n      }\n    }\n    stage ('单元测试') {\n        steps {\n            container ('maven') {\n                sh 'java -version'\n                sh 'mvn clean test'\n            }\n        }\n    }\n    stage('代码质量分析') {\n      steps {\n        container('maven') {\n          withCredentials([string(credentialsId: \"$SONAR_CREDENTIAL_ID\", variable: 'SONAR_TOKEN')]) {\n            withSonarQubeEnv('sonar') {\n              sh \"mvn sonar:sonar -Dsonar.login=$SONAR_TOKEN\"\n            }\n          }\n        }\n      }\n    }\n    stage ('编译 & 推送') {\n        steps {\n            container ('maven') {\n                sh 'mvn clean package -DskipTests'\n                sh 'cd $PROJECT_NAME && docker build -f Dockerfile -t $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:SNAPSHOT-$BRANCH_NAME-$BUILD_NUMBER .'\n                withCredentials([usernamePassword(passwordVariable : 'DOCKER_PASSWORD' ,usernameVariable : 'DOCKER_USERNAME' ,credentialsId : \"$DOCKER_CREDENTIAL_ID\" ,)]) {\n                    sh 'echo \"$DOCKER_PASSWORD\" | docker login $REGISTRY -u \"$DOCKER_USERNAME\" --password-stdin'\n                    sh 'docker push  $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:SNAPSHOT-$BRANCH_NAME-$BUILD_NUMBER'\n                }\n            }\n        }\n    }\n    stage('推送最新'){\n       when{\n         branch 'master'\n       }\n       steps{\n            container ('maven') {\n              sh 'docker tag  $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:SNAPSHOT-$BRANCH_NAME-$BUILD_NUMBER $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:latest '\n              sh 'docker push  $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:latest '\n            }\n       }\n    }\n    stage('发布开发环境') {\n      when{\n        branch 'master'\n      }\n      steps {\n        input(id: 'deploy-to-dev', message: '是否发布到开发环境?')\n        container ('maven') {\n            withCredentials([\n                kubeconfigFile(\n                credentialsId: env.KUBECONFIG_CREDENTIAL_ID,\n                variable: 'KUBECONFIG')\n                ]) {\n                sh 'envsubst < $PROJECT_NAME/deploy/$PROJECT_NAME-deploy.yaml | kubectl apply -f -'\n            }\n        }\n      }\n    }\n    stage('推送正式版本'){\n      when{\n        expression{\n          return params.PROJECT_VERSION =~ /v.*/\n        }\n      }\n      steps {\n          container ('maven') {\n            input(id: 'release-image-with-tag', message: '是否发布镜像版本$PROJECT_NAME:$PROJECT_VERSION?')\n              withCredentials([usernamePassword(credentialsId: \"$GITEE_CREDENTIAL_ID\", passwordVariable: 'GIT_PASSWORD', usernameVariable: 'GIT_USERNAME')]) {\n                sh 'git config --global user.email \"kubesphere@qq.com\" '\n                sh 'git config --global user.name \"kubesphere\" '\n                sh 'git tag -a $PROJECT_NAME-$PROJECT_VERSION -m \"$PROJECT_NAME-$PROJECT_VERSION\" '\n                sh 'echo $GIT_ACCOUNT'\n                sh 'git push http://$GIT_USERNAME:$GIT_PASSWORD@gitee.com/$GIT_ACCOUNT/gulimall-learng.git --tags --ipv4'\n              }\n            sh 'docker tag  $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:SNAPSHOT-$BRANCH_NAME-$BUILD_NUMBER $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:$PROJECT_VERSION '\n            sh 'docker push  $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:$PROJECT_VERSION '\n        }\n      }\n    }\n    stage('发布生产环境') {\n      when{\n        expression{\n          return params.PROJECT_VERSION =~ /v.*/\n        }\n      }\n      steps {\n        input(id: 'deploy-to-production', message: '是否发布生产环境?')\n        container ('maven') {\n            withCredentials([\n                kubeconfigFile(\n                credentialsId: env.KUBECONFIG_CREDENTIAL_ID,\n                variable: 'KUBECONFIG')\n                ]) {\n                sh 'envsubst < $PROJECT_NAME/deploy/$PROJECT_NAME-deploy.yaml | kubectl apply -f -'\n            }\n        }\n      }\n    }\n  }\n}\n```\n\n","source":"_posts/devops之KubeSphere流水线部署.md","raw":"---\ntitle: devops之KubeSphere流水线部署\ndate: 2022-07-26 12:38:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - kubeshpere\n  - 流水线\n---\n\n![流水线概览](devops之KubeSphere流水线部署/pipeline-overview.png) \n\n- **阶段 1：Checkout SCM**：从 GitHub 仓库检出源代码。\n- **阶段 2：单元测试**：待该测试通过后才会进行下一阶段。\n- **阶段 3：SonarQube 分析**：SonarQube 代码质量分析。\n- **阶段 4：构建并推送快照镜像**：根据**策略设置**中选定的分支来构建镜像，并将 `SNAPSHOT-$BRANCH_NAME-$BUILD_NUMBER` 标签推送至 Docker Hub，其中 `$BUILD_NUMBER` 为流水线活动列表中的运行序号。\n- **阶段 5：推送最新镜像**：将 SonarQube 分支标记为 `latest`，并推送至 Docker Hub。\n- **阶段 6：部署至开发环境**：将 SonarQube 分支部署到开发环境，此阶段需要审核。\n- **阶段 7：带标签推送**：生成标签并发布到 GitHub，该标签会推送到 Docker Hub。\n- **阶段 8：部署至生产环境**：将已发布的标签部署到生产环境。\n\n# 一、开启devops\n\ncluster-configuration.yaml\n\n```\ndevops:\n  enabled: true # 将“false”更改为“true”。\n```\n\n执行：\n\n```\nkubectl apply -f cluster-configuration.yaml\n```\n\n查看安装情况：\n\n```\nkubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f\n```\n\n查看结果：\n\n```\n[root@k8s-master01 kubesphere]# kubectl get pod --all-namespaces\nNAMESPACE                      NAME                                                              READY   STATUS      RESTARTS         AGE\nargocd                         devops-argocd-application-controller-0                            0/1     Running     9 (29s ago)      24m\nargocd                         devops-argocd-applicationset-controller-b88d4b875-hztm8           1/1     Running     0                24m\nargocd                         devops-argocd-dex-server-5f4c69cdb8-26d9x                         1/1     Running     0                24m\nargocd                         devops-argocd-notifications-controller-6d86f8974f-twlk6           1/1     Running     0                24m\nargocd                         devops-argocd-redis-655969589d-vbzfq                              1/1     Running     0                24m\nargocd                         devops-argocd-repo-server-f77687668-l46fj                         1/1     Running     0                24m\nargocd                         devops-argocd-server-6c55bbb84f-tgdv6                             1/1     Running     0                24m\n....\n```\n\n![1662990207401](devops之KubeSphere流水线部署/1662990207401.png)\n\njdk11:\n\n在**配置字典**页面的搜索框中输入 `jenkins-casc-config` 并按**回车键**。 \n\n\n\n# 二、创建凭证\n\n## 1.1 创建dockerhub凭证\n\n1. 登录 Docker Hub，点击右上角的帐户，并从菜单中选择 **Account Settings**。\n\n2. 在左侧导航栏点击 **Security**，然后点击 **New Access Token**。\n\n3. 在弹出的对话框中，输入令牌名称（`go-project-token`），点击 **Create**。\n\n   ```\n   dockerhub-id\n   用户名：leellun\n   密码：dckr_pat_P9abXAwRM9TU96yyERoODoyThRY\n   ```\n\n4. 点击 **Copy and Close** 并务必保存该访问令牌。\n\n![1662995312671](devops之KubeSphere流水线部署/1662995312671.png)\n\n## 1.2 github凭证\n\ngithub-id\n\n用户名和token添加\n\n## 1.3 kubeconfig凭证添加\n\n可以用root/.kube/config内容，也可以生成用户认证kubeconfig\n\n![1662995264415](devops之KubeSphere流水线部署/1662995264415.png)\n\n## 1.4 SonarQube凭证添加\n\nsonar-token\n\n进入sonarqube添加项目并且生成token：**caea718fe1c8d61628c85cc642998605247c4de9** \n\n![1662997272162](devops之KubeSphere流水线部署/1662997272162.png) \n\n配置sonarqube凭证：\n\n用户名和token添加\n\n```\nuser: \ntoken: caea718fe1c8d61628c85cc642998605247c4de9\n```\n\n\n\n# 三、修改 Jenkinsfile\n\n![jenkins-edit--2](devops之KubeSphere流水线部署/jenkins-edit--2.png)\n\n| 条目                     | 值                     | 描述信息                                                     |\n| ------------------------ | ---------------------- | ------------------------------------------------------------ |\n| DOCKER_CREDENTIAL_ID     | dockerhub-id           | 您在 KubeSphere 中为 Docker Hub 帐户设置的**名称**。         |\n| GITHUB_CREDENTIAL_ID     | github-id              | 您在 KubeSphere 中为 GitHub 帐户设置的**名称**，用于将标签推送至您的 GitHub 仓库。 |\n| KUBECONFIG_CREDENTIAL_ID | demo-kubeconfig        | 您在 KubeSphere 中为 kubeconfig 设置的**名称**，用于访问运行中的 Kubernetes 集群。 |\n| REGISTRY                 | docker.io              | 默认为 `docker.io`，用作推送镜像的地址。                     |\n| DOCKERHUB_NAMESPACE      | your-dockerhub-account | 请替换为您的 Docker Hub 帐户名，也可以替换为该帐户下的 Organization 名称。 |\n| GITHUB_ACCOUNT           | your-github-account    | 请替换为您的 GitHub 帐户名。例如，如果您的 GitHub 地址是 `https://github.com/kubesphere/`，则您的 GitHub 帐户名为 `kubesphere`，也可以替换为该帐户下的 Organization 名称。 |\n| APP_NAME                 | devops-maven-sample    | 应用名称。                                                   |\n| SONAR_CREDENTIAL_ID      | sonar-token            | 您在 KubeSphere 中为 SonarQube 令牌设置的**名称**，用于代码质量检测。 |\n\n# 四、具体Jenkinsfile根据项目而定\n\n下面选用的代码仓库是码云、docker镜像仓库是dockerhub、代码分析sonar是自己部署的\n\n流水线步骤：拉取镜像——单元测试——代码质量分析——编译 & 推送——推送最新——发布开发环境——推送正式版本——发布生产环境\n\n```\npipeline {\n  agent {\n    node {\n      label 'maven'\n    }\n\n  }\n  environment {\n    DOCKER_CREDENTIAL_ID = 'dockerhub-id'\n    GITEE_CREDENTIAL_ID = 'gitee-id'\n    KUBECONFIG_CREDENTIAL_ID = 'kubeconfig'\n    REGISTRY = 'docker.io'\n    DOCKERHUB_NAMESPACE = 'leellun'\n    GIT_ACCOUNT = 'myselfyou'\n    SONAR_CREDENTIAL_ID = 'sonar-token'\n    BRANCH_NAME = 'master'\n  }\n  parameters {\n    string(name: 'PROJECT_VERSION', defaultValue: '', description: '版本')\n    string(name: 'PROJECT_NAME', defaultValue: '', description: '项目名称')\n  }\n  stages {\n    stage('拉取代码') {\n      steps {\n        sh \"echo 正在构建 $PROJECT_NAME 版本号：$PROJECT_VERSION 将会提交给 $REGISTRY 镜像仓库\"\n        git(url: 'https://gitee.com/myselfyou/gulimall-learng.git', credentialsId: \"$GITEE_CREDENTIAL_ID\", branch: 'master', changelog: true, poll: false)\n      }\n    }\n    stage ('单元测试') {\n        steps {\n            container ('maven') {\n                sh 'java -version'\n                sh 'mvn clean test'\n            }\n        }\n    }\n    stage('代码质量分析') {\n      steps {\n        container('maven') {\n          withCredentials([string(credentialsId: \"$SONAR_CREDENTIAL_ID\", variable: 'SONAR_TOKEN')]) {\n            withSonarQubeEnv('sonar') {\n              sh \"mvn sonar:sonar -Dsonar.login=$SONAR_TOKEN\"\n            }\n          }\n        }\n      }\n    }\n    stage ('编译 & 推送') {\n        steps {\n            container ('maven') {\n                sh 'mvn clean package -DskipTests'\n                sh 'cd $PROJECT_NAME && docker build -f Dockerfile -t $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:SNAPSHOT-$BRANCH_NAME-$BUILD_NUMBER .'\n                withCredentials([usernamePassword(passwordVariable : 'DOCKER_PASSWORD' ,usernameVariable : 'DOCKER_USERNAME' ,credentialsId : \"$DOCKER_CREDENTIAL_ID\" ,)]) {\n                    sh 'echo \"$DOCKER_PASSWORD\" | docker login $REGISTRY -u \"$DOCKER_USERNAME\" --password-stdin'\n                    sh 'docker push  $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:SNAPSHOT-$BRANCH_NAME-$BUILD_NUMBER'\n                }\n            }\n        }\n    }\n    stage('推送最新'){\n       when{\n         branch 'master'\n       }\n       steps{\n            container ('maven') {\n              sh 'docker tag  $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:SNAPSHOT-$BRANCH_NAME-$BUILD_NUMBER $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:latest '\n              sh 'docker push  $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:latest '\n            }\n       }\n    }\n    stage('发布开发环境') {\n      when{\n        branch 'master'\n      }\n      steps {\n        input(id: 'deploy-to-dev', message: '是否发布到开发环境?')\n        container ('maven') {\n            withCredentials([\n                kubeconfigFile(\n                credentialsId: env.KUBECONFIG_CREDENTIAL_ID,\n                variable: 'KUBECONFIG')\n                ]) {\n                sh 'envsubst < $PROJECT_NAME/deploy/$PROJECT_NAME-deploy.yaml | kubectl apply -f -'\n            }\n        }\n      }\n    }\n    stage('推送正式版本'){\n      when{\n        expression{\n          return params.PROJECT_VERSION =~ /v.*/\n        }\n      }\n      steps {\n          container ('maven') {\n            input(id: 'release-image-with-tag', message: '是否发布镜像版本$PROJECT_NAME:$PROJECT_VERSION?')\n              withCredentials([usernamePassword(credentialsId: \"$GITEE_CREDENTIAL_ID\", passwordVariable: 'GIT_PASSWORD', usernameVariable: 'GIT_USERNAME')]) {\n                sh 'git config --global user.email \"kubesphere@qq.com\" '\n                sh 'git config --global user.name \"kubesphere\" '\n                sh 'git tag -a $PROJECT_NAME-$PROJECT_VERSION -m \"$PROJECT_NAME-$PROJECT_VERSION\" '\n                sh 'echo $GIT_ACCOUNT'\n                sh 'git push http://$GIT_USERNAME:$GIT_PASSWORD@gitee.com/$GIT_ACCOUNT/gulimall-learng.git --tags --ipv4'\n              }\n            sh 'docker tag  $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:SNAPSHOT-$BRANCH_NAME-$BUILD_NUMBER $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:$PROJECT_VERSION '\n            sh 'docker push  $REGISTRY/$DOCKERHUB_NAMESPACE/$PROJECT_NAME:$PROJECT_VERSION '\n        }\n      }\n    }\n    stage('发布生产环境') {\n      when{\n        expression{\n          return params.PROJECT_VERSION =~ /v.*/\n        }\n      }\n      steps {\n        input(id: 'deploy-to-production', message: '是否发布生产环境?')\n        container ('maven') {\n            withCredentials([\n                kubeconfigFile(\n                credentialsId: env.KUBECONFIG_CREDENTIAL_ID,\n                variable: 'KUBECONFIG')\n                ]) {\n                sh 'envsubst < $PROJECT_NAME/deploy/$PROJECT_NAME-deploy.yaml | kubectl apply -f -'\n            }\n        }\n      }\n    }\n  }\n}\n```\n\n","slug":"devops之KubeSphere流水线部署","published":1,"updated":"2022-09-23T15:57:51.880Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl8eo3tp80000yovjd055c90n","content":"<img src=\"/2022/07/26/devops%E4%B9%8BKubeSphere%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%83%A8%E7%BD%B2/pipeline-overview.png\" class=\"\" title=\"流水线概览\"> \n\n<ul>\n<li><strong>阶段 1：Checkout SCM</strong>：从 GitHub 仓库检出源代码。</li>\n<li><strong>阶段 2：单元测试</strong>：待该测试通过后才会进行下一阶段。</li>\n<li><strong>阶段 3：SonarQube 分析</strong>：SonarQube 代码质量分析。</li>\n<li><strong>阶段 4：构建并推送快照镜像</strong>：根据<strong>策略设置</strong>中选定的分支来构建镜像，并将 <code>SNAPSHOT-$BRANCH_NAME-$BUILD_NUMBER</code> 标签推送至 Docker Hub，其中 <code>$BUILD_NUMBER</code> 为流水线活动列表中的运行序号。</li>\n<li><strong>阶段 5：推送最新镜像</strong>：将 SonarQube 分支标记为 <code>latest</code>，并推送至 Docker Hub。</li>\n<li><strong>阶段 6：部署至开发环境</strong>：将 SonarQube 分支部署到开发环境，此阶段需要审核。</li>\n<li><strong>阶段 7：带标签推送</strong>：生成标签并发布到 GitHub，该标签会推送到 Docker Hub。</li>\n<li><strong>阶段 8：部署至生产环境</strong>：将已发布的标签部署到生产环境。</li>\n</ul>\n<h1 id=\"一、开启devops\"><a href=\"#一、开启devops\" class=\"headerlink\" title=\"一、开启devops\"></a>一、开启devops</h1><p>cluster-configuration.yaml</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">devops:</span><br>  <span class=\"hljs-attr\">enabled:</span> <span class=\"hljs-literal\">true</span> <span class=\"hljs-comment\"># 将“false”更改为“true”。</span><br></code></pre></td></tr></table></figure>\n\n<p>执行：</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">kubectl apply -f <span class=\"hljs-keyword\">cluster</span>-<span class=\"hljs-keyword\">configuration</span>.yaml<br></code></pre></td></tr></table></figure>\n\n<p>查看安装情况：</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\">kubectl logs -n kubesphere-system <span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> <span class=\"hljs-params\">pod</span> -<span class=\"hljs-params\">n</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">l</span> &#x27;<span class=\"hljs-params\">app</span> <span class=\"hljs-params\">in</span> (<span class=\"hljs-params\">ks</span>-<span class=\"hljs-params\">install</span>, <span class=\"hljs-params\">ks</span>-<span class=\"hljs-params\">installer</span>)</span>&#x27; -o jsonpath=&#x27;&#123;.items<span class=\"hljs-literal\">[<span class=\"hljs-number\">0</span>]</span>.metadata.name&#125;&#x27;) -f<br></code></pre></td></tr></table></figure>\n\n<p>查看结果：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\">[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 kubesphere]# kubectl <span class=\"hljs-keyword\">get</span> pod <span class=\"hljs-comment\">--all-namespaces</span><br>NAMESPACE                      NAME                                                              READY   STATUS      RESTARTS         AGE<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>application<span class=\"hljs-operator\">-</span>controller<span class=\"hljs-number\">-0</span>                            <span class=\"hljs-number\">0</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">9</span> (<span class=\"hljs-number\">29</span>s ago)      <span class=\"hljs-number\">24</span>m<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>applicationset<span class=\"hljs-operator\">-</span>controller<span class=\"hljs-operator\">-</span>b88d4b875<span class=\"hljs-operator\">-</span>hztm8           <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>                <span class=\"hljs-number\">24</span>m<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>dex<span class=\"hljs-operator\">-</span>server<span class=\"hljs-number\">-5</span>f4c69cdb8<span class=\"hljs-number\">-26</span>d9x                         <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>                <span class=\"hljs-number\">24</span>m<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>notifications<span class=\"hljs-operator\">-</span>controller<span class=\"hljs-number\">-6</span>d86f8974f<span class=\"hljs-operator\">-</span>twlk6           <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>                <span class=\"hljs-number\">24</span>m<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>redis<span class=\"hljs-number\">-655969589</span>d<span class=\"hljs-operator\">-</span>vbzfq                              <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>                <span class=\"hljs-number\">24</span>m<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>repo<span class=\"hljs-operator\">-</span>server<span class=\"hljs-operator\">-</span>f77687668<span class=\"hljs-operator\">-</span>l46fj                         <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>                <span class=\"hljs-number\">24</span>m<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>server<span class=\"hljs-number\">-6</span>c55bbb84f<span class=\"hljs-operator\">-</span>tgdv6                             <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>                <span class=\"hljs-number\">24</span>m<br>....<br></code></pre></td></tr></table></figure>\n\n<img src=\"/2022/07/26/devops%E4%B9%8BKubeSphere%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%83%A8%E7%BD%B2/1662990207401.png\" class=\"\" width=\"1662990207401\">\n\n<p>jdk11:</p>\n<p>在<strong>配置字典</strong>页面的搜索框中输入 <code>jenkins-casc-config</code> 并按<strong>回车键</strong>。 </p>\n<h1 id=\"二、创建凭证\"><a href=\"#二、创建凭证\" class=\"headerlink\" title=\"二、创建凭证\"></a>二、创建凭证</h1><h2 id=\"1-1-创建dockerhub凭证\"><a href=\"#1-1-创建dockerhub凭证\" class=\"headerlink\" title=\"1.1 创建dockerhub凭证\"></a>1.1 创建dockerhub凭证</h2><ol>\n<li><p>登录 Docker Hub，点击右上角的帐户，并从菜单中选择 <strong>Account Settings</strong>。</p>\n</li>\n<li><p>在左侧导航栏点击 <strong>Security</strong>，然后点击 <strong>New Access Token</strong>。</p>\n</li>\n<li><p>在弹出的对话框中，输入令牌名称（<code>go-project-token</code>），点击 <strong>Create</strong>。</p>\n<figure class=\"highlight applescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs applescript\">dockerhub-<span class=\"hljs-built_in\">id</span><br>用户名：leellun<br>密码：dckr_pat_P9abXAwRM9TU96yyERoODoyThRY<br></code></pre></td></tr></table></figure></li>\n<li><p>点击 <strong>Copy and Close</strong> 并务必保存该访问令牌。</p>\n</li>\n</ol>\n<img src=\"/2022/07/26/devops%E4%B9%8BKubeSphere%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%83%A8%E7%BD%B2/1662995312671.png\" class=\"\" width=\"1662995312671\">\n\n<h2 id=\"1-2-github凭证\"><a href=\"#1-2-github凭证\" class=\"headerlink\" title=\"1.2 github凭证\"></a>1.2 github凭证</h2><p>github-id</p>\n<p>用户名和token添加</p>\n<h2 id=\"1-3-kubeconfig凭证添加\"><a href=\"#1-3-kubeconfig凭证添加\" class=\"headerlink\" title=\"1.3 kubeconfig凭证添加\"></a>1.3 kubeconfig凭证添加</h2><p>可以用root/.kube/config内容，也可以生成用户认证kubeconfig</p>\n<img src=\"/2022/07/26/devops%E4%B9%8BKubeSphere%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%83%A8%E7%BD%B2/1662995264415.png\" class=\"\" width=\"1662995264415\">\n\n<h2 id=\"1-4-SonarQube凭证添加\"><a href=\"#1-4-SonarQube凭证添加\" class=\"headerlink\" title=\"1.4 SonarQube凭证添加\"></a>1.4 SonarQube凭证添加</h2><p>sonar-token</p>\n<p>进入sonarqube添加项目并且生成token：<strong>caea718fe1c8d61628c85cc642998605247c4de9</strong> </p>\n<img src=\"/2022/07/26/devops%E4%B9%8BKubeSphere%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%83%A8%E7%BD%B2/1662997272162.png\" class=\"\" width=\"1662997272162\"> \n\n<p>配置sonarqube凭证：</p>\n<p>用户名和token添加</p>\n<figure class=\"highlight llvm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs llvm\"><span class=\"hljs-symbol\">user:</span> <br><span class=\"hljs-symbol\">token:</span> caea<span class=\"hljs-number\">718</span>fe<span class=\"hljs-number\">1</span><span class=\"hljs-keyword\">c</span><span class=\"hljs-number\">8</span>d<span class=\"hljs-number\">61628</span><span class=\"hljs-keyword\">c</span><span class=\"hljs-number\">85</span><span class=\"hljs-keyword\">cc</span><span class=\"hljs-number\">642998605247</span><span class=\"hljs-keyword\">c</span><span class=\"hljs-number\">4</span>de<span class=\"hljs-number\">9</span><br></code></pre></td></tr></table></figure>\n\n\n\n<h1 id=\"三、修改-Jenkinsfile\"><a href=\"#三、修改-Jenkinsfile\" class=\"headerlink\" title=\"三、修改 Jenkinsfile\"></a>三、修改 Jenkinsfile</h1><img src=\"/2022/07/26/devops%E4%B9%8BKubeSphere%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%83%A8%E7%BD%B2/jenkins-edit--2.png\" class=\"\" title=\"jenkins-edit--2\">\n\n<table>\n<thead>\n<tr>\n<th>条目</th>\n<th>值</th>\n<th>描述信息</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>DOCKER_CREDENTIAL_ID</td>\n<td>dockerhub-id</td>\n<td>您在 KubeSphere 中为 Docker Hub 帐户设置的<strong>名称</strong>。</td>\n</tr>\n<tr>\n<td>GITHUB_CREDENTIAL_ID</td>\n<td>github-id</td>\n<td>您在 KubeSphere 中为 GitHub 帐户设置的<strong>名称</strong>，用于将标签推送至您的 GitHub 仓库。</td>\n</tr>\n<tr>\n<td>KUBECONFIG_CREDENTIAL_ID</td>\n<td>demo-kubeconfig</td>\n<td>您在 KubeSphere 中为 kubeconfig 设置的<strong>名称</strong>，用于访问运行中的 Kubernetes 集群。</td>\n</tr>\n<tr>\n<td>REGISTRY</td>\n<td>docker.io</td>\n<td>默认为 <code>docker.io</code>，用作推送镜像的地址。</td>\n</tr>\n<tr>\n<td>DOCKERHUB_NAMESPACE</td>\n<td>your-dockerhub-account</td>\n<td>请替换为您的 Docker Hub 帐户名，也可以替换为该帐户下的 Organization 名称。</td>\n</tr>\n<tr>\n<td>GITHUB_ACCOUNT</td>\n<td>your-github-account</td>\n<td>请替换为您的 GitHub 帐户名。例如，如果您的 GitHub 地址是 <code>https://github.com/kubesphere/</code>，则您的 GitHub 帐户名为 <code>kubesphere</code>，也可以替换为该帐户下的 Organization 名称。</td>\n</tr>\n<tr>\n<td>APP_NAME</td>\n<td>devops-maven-sample</td>\n<td>应用名称。</td>\n</tr>\n<tr>\n<td>SONAR_CREDENTIAL_ID</td>\n<td>sonar-token</td>\n<td>您在 KubeSphere 中为 SonarQube 令牌设置的<strong>名称</strong>，用于代码质量检测。</td>\n</tr>\n</tbody></table>\n<h1 id=\"四、具体Jenkinsfile根据项目而定\"><a href=\"#四、具体Jenkinsfile根据项目而定\" class=\"headerlink\" title=\"四、具体Jenkinsfile根据项目而定\"></a>四、具体Jenkinsfile根据项目而定</h1><p>下面选用的代码仓库是码云、docker镜像仓库是dockerhub、代码分析sonar是自己部署的</p>\n<p>流水线步骤：拉取镜像——单元测试——代码质量分析——编译 &amp; 推送——推送最新——发布开发环境——推送正式版本——发布生产环境</p>\n<figure class=\"highlight puppet\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs puppet\"><span class=\"hljs-keyword\">pipeline</span> &#123;<br>  agent &#123;<br>    <span class=\"hljs-keyword\">node</span> &#123;<br>      label <span class=\"hljs-string\">&#x27;maven&#x27;</span><br>    &#125;<br><br>  &#125;<br>  <span class=\"hljs-keyword\">environment</span> &#123;<br>    DOCKER_CREDENTIAL_ID = <span class=\"hljs-string\">&#x27;dockerhub-id&#x27;</span><br>    GITEE_CREDENTIAL_ID = <span class=\"hljs-string\">&#x27;gitee-id&#x27;</span><br>    KUBECONFIG_CREDENTIAL_ID = <span class=\"hljs-string\">&#x27;kubeconfig&#x27;</span><br>    REGISTRY = <span class=\"hljs-string\">&#x27;docker.io&#x27;</span><br>    DOCKERHUB_NAMESPACE = <span class=\"hljs-string\">&#x27;leellun&#x27;</span><br>    GIT_ACCOUNT = <span class=\"hljs-string\">&#x27;myselfyou&#x27;</span><br>    SONAR_CREDENTIAL_ID = <span class=\"hljs-string\">&#x27;sonar-token&#x27;</span><br>    BRANCH_NAME = <span class=\"hljs-string\">&#x27;master&#x27;</span><br>  &#125;<br>  <span class=\"hljs-keyword\">parameters</span> &#123;<br>    string(<span class=\"hljs-literal\">name</span>: <span class=\"hljs-string\">&#x27;PROJECT_VERSION&#x27;</span>, defaultValue: <span class=\"hljs-string\">&#x27;&#x27;</span>, <span class=\"hljs-literal\">description</span>: <span class=\"hljs-string\">&#x27;版本&#x27;</span>)<br>    string(<span class=\"hljs-literal\">name</span>: <span class=\"hljs-string\">&#x27;PROJECT_NAME&#x27;</span>, defaultValue: <span class=\"hljs-string\">&#x27;&#x27;</span>, <span class=\"hljs-literal\">description</span>: <span class=\"hljs-string\">&#x27;项目名称&#x27;</span>)<br>  &#125;<br>  <span class=\"hljs-keyword\">stages</span> &#123;<br>    stage(<span class=\"hljs-string\">&#x27;拉取代码&#x27;</span>) &#123;<br>      steps &#123;<br>        sh <span class=\"hljs-string\">&quot;echo 正在构建 <span class=\"hljs-variable\">$PROJECT_NAME</span> 版本号：<span class=\"hljs-variable\">$PROJECT_VERSION</span> 将会提交给 <span class=\"hljs-variable\">$REGISTRY</span> 镜像仓库&quot;</span><br>        git(url: <span class=\"hljs-string\">&#x27;https://gitee.com/myselfyou/gulimall-learng.git&#x27;</span>, credentialsId: <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$GITEE_CREDENTIAL_ID</span>&quot;</span>, branch: <span class=\"hljs-string\">&#x27;master&#x27;</span>, changelog: <span class=\"hljs-keyword\">true</span>, poll: <span class=\"hljs-keyword\">false</span>)<br>      &#125;<br>    &#125;<br>    stage (<span class=\"hljs-string\">&#x27;单元测试&#x27;</span>) &#123;<br>        <span class=\"hljs-keyword\">steps</span> &#123;<br>            container (<span class=\"hljs-string\">&#x27;maven&#x27;</span>) &#123;<br>                sh <span class=\"hljs-string\">&#x27;java -version&#x27;</span><br>                sh <span class=\"hljs-string\">&#x27;mvn clean test&#x27;</span><br>            &#125;<br>        &#125;<br>    &#125;<br>    stage(<span class=\"hljs-string\">&#x27;代码质量分析&#x27;</span>) &#123;<br>      <span class=\"hljs-keyword\">steps</span> &#123;<br>        container(<span class=\"hljs-string\">&#x27;maven&#x27;</span>) &#123;<br>          withCredentials([string(credentialsId: <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$SONAR_CREDENTIAL_ID</span>&quot;</span>, variable: <span class=\"hljs-string\">&#x27;SONAR_TOKEN&#x27;</span>)]) &#123;<br>            withSonarQubeEnv(<span class=\"hljs-string\">&#x27;sonar&#x27;</span>) &#123;<br>              sh <span class=\"hljs-string\">&quot;mvn sonar:sonar -Dsonar.login=<span class=\"hljs-variable\">$SONAR_TOKEN</span>&quot;</span><br>            &#125;<br>          &#125;<br>        &#125;<br>      &#125;<br>    &#125;<br>    stage (<span class=\"hljs-string\">&#x27;编译 &amp; 推送&#x27;</span>) &#123;<br>        <span class=\"hljs-keyword\">steps</span> &#123;<br>            container (<span class=\"hljs-string\">&#x27;maven&#x27;</span>) &#123;<br>                sh <span class=\"hljs-string\">&#x27;mvn clean package -DskipTests&#x27;</span><br>                sh <span class=\"hljs-string\">&#x27;cd <span class=\"hljs-variable\">$PROJECT_NAME</span> &amp;&amp; docker build -f Dockerfile -t <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:SNAPSHOT-<span class=\"hljs-variable\">$BRANCH_NAME</span>-<span class=\"hljs-variable\">$BUILD_NUMBER</span> .&#x27;</span><br>                withCredentials([usernamePassword(passwordVariable : <span class=\"hljs-string\">&#x27;DOCKER_PASSWORD&#x27;</span> ,usernameVariable : <span class=\"hljs-string\">&#x27;DOCKER_USERNAME&#x27;</span> ,credentialsId : <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$DOCKER_CREDENTIAL_ID</span>&quot;</span> ,)]) &#123;<br>                    sh <span class=\"hljs-string\">&#x27;echo &quot;<span class=\"hljs-variable\">$DOCKER_PASSWORD</span>&quot; | docker login <span class=\"hljs-variable\">$REGISTRY</span> -u &quot;<span class=\"hljs-variable\">$DOCKER_USERNAME</span>&quot; --password-stdin&#x27;</span><br>                    sh <span class=\"hljs-string\">&#x27;docker push  <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:SNAPSHOT-<span class=\"hljs-variable\">$BRANCH_NAME</span>-<span class=\"hljs-variable\">$BUILD_NUMBER</span>&#x27;</span><br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>    stage(<span class=\"hljs-string\">&#x27;推送最新&#x27;</span>)&#123;<br>       when&#123;<br>         branch <span class=\"hljs-string\">&#x27;master&#x27;</span><br>       &#125;<br>       steps&#123;<br>            container (<span class=\"hljs-string\">&#x27;maven&#x27;</span>) &#123;<br>              sh <span class=\"hljs-string\">&#x27;docker tag  <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:SNAPSHOT-<span class=\"hljs-variable\">$BRANCH_NAME</span>-<span class=\"hljs-variable\">$BUILD_NUMBER</span> <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:latest &#x27;</span><br>              sh <span class=\"hljs-string\">&#x27;docker push  <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:latest &#x27;</span><br>            &#125;<br>       &#125;<br>    &#125;<br>    stage(<span class=\"hljs-string\">&#x27;发布开发环境&#x27;</span>) &#123;<br>      when&#123;<br>        branch <span class=\"hljs-string\">&#x27;master&#x27;</span><br>      &#125;<br>      <span class=\"hljs-keyword\">steps</span> &#123;<br>        input(<span class=\"hljs-built_in\">id</span>: <span class=\"hljs-string\">&#x27;deploy-to-dev&#x27;</span>, <span class=\"hljs-literal\">message</span>: <span class=\"hljs-string\">&#x27;是否发布到开发环境?&#x27;</span>)<br>        container (<span class=\"hljs-string\">&#x27;maven&#x27;</span>) &#123;<br>            withCredentials([<br>                kubeconfigFile(<br>                credentialsId: env.KUBECONFIG_CREDENTIAL_ID,<br>                variable: <span class=\"hljs-string\">&#x27;KUBECONFIG&#x27;</span>)<br>                ]) &#123;<br>                sh <span class=\"hljs-string\">&#x27;envsubst &lt; <span class=\"hljs-variable\">$PROJECT_NAME</span>/deploy/<span class=\"hljs-variable\">$PROJECT_NAME</span>-deploy.yaml | kubectl apply -f -&#x27;</span><br>            &#125;<br>        &#125;<br>      &#125;<br>    &#125;<br>    stage(<span class=\"hljs-string\">&#x27;推送正式版本&#x27;</span>)&#123;<br>      when&#123;<br>        expression&#123;<br>          return params.PROJECT_VERSION =~ /v.*/<br>        &#125;<br>      &#125;<br>      <span class=\"hljs-keyword\">steps</span> &#123;<br>          container (<span class=\"hljs-string\">&#x27;maven&#x27;</span>) &#123;<br>            input(<span class=\"hljs-built_in\">id</span>: <span class=\"hljs-string\">&#x27;release-image-with-tag&#x27;</span>, <span class=\"hljs-literal\">message</span>: <span class=\"hljs-string\">&#x27;是否发布镜像版本<span class=\"hljs-variable\">$PROJECT_NAME</span>:<span class=\"hljs-variable\">$PROJECT_VERSION</span>?&#x27;</span>)<br>              withCredentials([usernamePassword(credentialsId: <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$GITEE_CREDENTIAL_ID</span>&quot;</span>, passwordVariable: <span class=\"hljs-string\">&#x27;GIT_PASSWORD&#x27;</span>, usernameVariable: <span class=\"hljs-string\">&#x27;GIT_USERNAME&#x27;</span>)]) &#123;<br>                sh <span class=\"hljs-string\">&#x27;git config --global user.email &quot;kubesphere@qq.com&quot; &#x27;</span><br>                sh <span class=\"hljs-string\">&#x27;git config --global user.name &quot;kubesphere&quot; &#x27;</span><br>                sh <span class=\"hljs-string\">&#x27;git tag -a <span class=\"hljs-variable\">$PROJECT_NAME</span>-<span class=\"hljs-variable\">$PROJECT_VERSION</span> -m &quot;<span class=\"hljs-variable\">$PROJECT_NAME</span>-<span class=\"hljs-variable\">$PROJECT_VERSION</span>&quot; &#x27;</span><br>                sh <span class=\"hljs-string\">&#x27;echo <span class=\"hljs-variable\">$GIT_ACCOUNT</span>&#x27;</span><br>                sh <span class=\"hljs-string\">&#x27;git push http://<span class=\"hljs-variable\">$GIT_USERNAME</span>:<span class=\"hljs-variable\">$GIT_PASSWORD</span>@gitee.com/<span class=\"hljs-variable\">$GIT_ACCOUNT</span>/gulimall-learng.git --tags --ipv4&#x27;</span><br>              &#125;<br>            <span class=\"hljs-keyword\">sh</span> &#x27;docker tag  <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:SNAPSHOT-<span class=\"hljs-variable\">$BRANCH_NAME</span>-<span class=\"hljs-variable\">$BUILD_NUMBER</span> <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:<span class=\"hljs-variable\">$PROJECT_VERSION</span> <span class=\"hljs-string\">&#x27;</span><br><span class=\"hljs-string\">            sh &#x27;</span>docker push  <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:<span class=\"hljs-variable\">$PROJECT_VERSION</span> <span class=\"hljs-string\">&#x27;</span><br><span class=\"hljs-string\">        &#125;</span><br><span class=\"hljs-string\">      &#125;</span><br><span class=\"hljs-string\">    &#125;</span><br><span class=\"hljs-string\">    stage(&#x27;</span>发布生产环境<span class=\"hljs-string\">&#x27;) &#123;</span><br><span class=\"hljs-string\">      when&#123;</span><br><span class=\"hljs-string\">        expression&#123;</span><br><span class=\"hljs-string\">          return params.PROJECT_VERSION =~ /v.*/</span><br><span class=\"hljs-string\">        &#125;</span><br><span class=\"hljs-string\">      &#125;</span><br><span class=\"hljs-string\">      steps &#123;</span><br><span class=\"hljs-string\">        input(id: &#x27;</span>deploy-to-production<span class=\"hljs-string\">&#x27;, message: &#x27;</span>是否发布生产环境?<span class=\"hljs-string\">&#x27;)</span><br><span class=\"hljs-string\">        container (&#x27;</span>maven<span class=\"hljs-string\">&#x27;) &#123;</span><br><span class=\"hljs-string\">            withCredentials([</span><br><span class=\"hljs-string\">                kubeconfigFile(</span><br><span class=\"hljs-string\">                credentialsId: env.KUBECONFIG_CREDENTIAL_ID,</span><br><span class=\"hljs-string\">                variable: &#x27;</span>KUBECONFIG<span class=\"hljs-string\">&#x27;)</span><br><span class=\"hljs-string\">                ]) &#123;</span><br><span class=\"hljs-string\">                sh &#x27;</span>envsubst &lt; <span class=\"hljs-variable\">$PROJECT_NAME</span>/deploy/<span class=\"hljs-variable\">$PROJECT_NAME</span>-deploy.yaml | kubectl apply -f -<span class=\"hljs-string\">&#x27;</span><br><span class=\"hljs-string\">            &#125;</span><br><span class=\"hljs-string\">        &#125;</span><br><span class=\"hljs-string\">      &#125;</span><br><span class=\"hljs-string\">    &#125;</span><br><span class=\"hljs-string\">  &#125;</span><br><span class=\"hljs-string\">&#125;</span><br></code></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<img src=\"/2022/07/26/devops%E4%B9%8BKubeSphere%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%83%A8%E7%BD%B2/pipeline-overview.png\" class=\"\" title=\"流水线概览\"> \n\n<ul>\n<li><strong>阶段 1：Checkout SCM</strong>：从 GitHub 仓库检出源代码。</li>\n<li><strong>阶段 2：单元测试</strong>：待该测试通过后才会进行下一阶段。</li>\n<li><strong>阶段 3：SonarQube 分析</strong>：SonarQube 代码质量分析。</li>\n<li><strong>阶段 4：构建并推送快照镜像</strong>：根据<strong>策略设置</strong>中选定的分支来构建镜像，并将 <code>SNAPSHOT-$BRANCH_NAME-$BUILD_NUMBER</code> 标签推送至 Docker Hub，其中 <code>$BUILD_NUMBER</code> 为流水线活动列表中的运行序号。</li>\n<li><strong>阶段 5：推送最新镜像</strong>：将 SonarQube 分支标记为 <code>latest</code>，并推送至 Docker Hub。</li>\n<li><strong>阶段 6：部署至开发环境</strong>：将 SonarQube 分支部署到开发环境，此阶段需要审核。</li>\n<li><strong>阶段 7：带标签推送</strong>：生成标签并发布到 GitHub，该标签会推送到 Docker Hub。</li>\n<li><strong>阶段 8：部署至生产环境</strong>：将已发布的标签部署到生产环境。</li>\n</ul>\n<h1 id=\"一、开启devops\"><a href=\"#一、开启devops\" class=\"headerlink\" title=\"一、开启devops\"></a>一、开启devops</h1><p>cluster-configuration.yaml</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">devops:</span><br>  <span class=\"hljs-attr\">enabled:</span> <span class=\"hljs-literal\">true</span> <span class=\"hljs-comment\"># 将“false”更改为“true”。</span><br></code></pre></td></tr></table></figure>\n\n<p>执行：</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">kubectl apply -f <span class=\"hljs-keyword\">cluster</span>-<span class=\"hljs-keyword\">configuration</span>.yaml<br></code></pre></td></tr></table></figure>\n\n<p>查看安装情况：</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\">kubectl logs -n kubesphere-system <span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> <span class=\"hljs-params\">pod</span> -<span class=\"hljs-params\">n</span> <span class=\"hljs-params\">kubesphere</span>-<span class=\"hljs-params\">system</span> -<span class=\"hljs-params\">l</span> &#x27;<span class=\"hljs-params\">app</span> <span class=\"hljs-params\">in</span> (<span class=\"hljs-params\">ks</span>-<span class=\"hljs-params\">install</span>, <span class=\"hljs-params\">ks</span>-<span class=\"hljs-params\">installer</span>)</span>&#x27; -o jsonpath=&#x27;&#123;.items<span class=\"hljs-literal\">[<span class=\"hljs-number\">0</span>]</span>.metadata.name&#125;&#x27;) -f<br></code></pre></td></tr></table></figure>\n\n<p>查看结果：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\">[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 kubesphere]# kubectl <span class=\"hljs-keyword\">get</span> pod <span class=\"hljs-comment\">--all-namespaces</span><br>NAMESPACE                      NAME                                                              READY   STATUS      RESTARTS         AGE<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>application<span class=\"hljs-operator\">-</span>controller<span class=\"hljs-number\">-0</span>                            <span class=\"hljs-number\">0</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">9</span> (<span class=\"hljs-number\">29</span>s ago)      <span class=\"hljs-number\">24</span>m<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>applicationset<span class=\"hljs-operator\">-</span>controller<span class=\"hljs-operator\">-</span>b88d4b875<span class=\"hljs-operator\">-</span>hztm8           <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>                <span class=\"hljs-number\">24</span>m<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>dex<span class=\"hljs-operator\">-</span>server<span class=\"hljs-number\">-5</span>f4c69cdb8<span class=\"hljs-number\">-26</span>d9x                         <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>                <span class=\"hljs-number\">24</span>m<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>notifications<span class=\"hljs-operator\">-</span>controller<span class=\"hljs-number\">-6</span>d86f8974f<span class=\"hljs-operator\">-</span>twlk6           <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>                <span class=\"hljs-number\">24</span>m<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>redis<span class=\"hljs-number\">-655969589</span>d<span class=\"hljs-operator\">-</span>vbzfq                              <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>                <span class=\"hljs-number\">24</span>m<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>repo<span class=\"hljs-operator\">-</span>server<span class=\"hljs-operator\">-</span>f77687668<span class=\"hljs-operator\">-</span>l46fj                         <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>                <span class=\"hljs-number\">24</span>m<br>argocd                         devops<span class=\"hljs-operator\">-</span>argocd<span class=\"hljs-operator\">-</span>server<span class=\"hljs-number\">-6</span>c55bbb84f<span class=\"hljs-operator\">-</span>tgdv6                             <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>     <span class=\"hljs-number\">0</span>                <span class=\"hljs-number\">24</span>m<br>....<br></code></pre></td></tr></table></figure>\n\n<img src=\"/2022/07/26/devops%E4%B9%8BKubeSphere%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%83%A8%E7%BD%B2/1662990207401.png\" class=\"\" width=\"1662990207401\">\n\n<p>jdk11:</p>\n<p>在<strong>配置字典</strong>页面的搜索框中输入 <code>jenkins-casc-config</code> 并按<strong>回车键</strong>。 </p>\n<h1 id=\"二、创建凭证\"><a href=\"#二、创建凭证\" class=\"headerlink\" title=\"二、创建凭证\"></a>二、创建凭证</h1><h2 id=\"1-1-创建dockerhub凭证\"><a href=\"#1-1-创建dockerhub凭证\" class=\"headerlink\" title=\"1.1 创建dockerhub凭证\"></a>1.1 创建dockerhub凭证</h2><ol>\n<li><p>登录 Docker Hub，点击右上角的帐户，并从菜单中选择 <strong>Account Settings</strong>。</p>\n</li>\n<li><p>在左侧导航栏点击 <strong>Security</strong>，然后点击 <strong>New Access Token</strong>。</p>\n</li>\n<li><p>在弹出的对话框中，输入令牌名称（<code>go-project-token</code>），点击 <strong>Create</strong>。</p>\n<figure class=\"highlight applescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs applescript\">dockerhub-<span class=\"hljs-built_in\">id</span><br>用户名：leellun<br>密码：dckr_pat_P9abXAwRM9TU96yyERoODoyThRY<br></code></pre></td></tr></table></figure></li>\n<li><p>点击 <strong>Copy and Close</strong> 并务必保存该访问令牌。</p>\n</li>\n</ol>\n<img src=\"/2022/07/26/devops%E4%B9%8BKubeSphere%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%83%A8%E7%BD%B2/1662995312671.png\" class=\"\" width=\"1662995312671\">\n\n<h2 id=\"1-2-github凭证\"><a href=\"#1-2-github凭证\" class=\"headerlink\" title=\"1.2 github凭证\"></a>1.2 github凭证</h2><p>github-id</p>\n<p>用户名和token添加</p>\n<h2 id=\"1-3-kubeconfig凭证添加\"><a href=\"#1-3-kubeconfig凭证添加\" class=\"headerlink\" title=\"1.3 kubeconfig凭证添加\"></a>1.3 kubeconfig凭证添加</h2><p>可以用root/.kube/config内容，也可以生成用户认证kubeconfig</p>\n<img src=\"/2022/07/26/devops%E4%B9%8BKubeSphere%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%83%A8%E7%BD%B2/1662995264415.png\" class=\"\" width=\"1662995264415\">\n\n<h2 id=\"1-4-SonarQube凭证添加\"><a href=\"#1-4-SonarQube凭证添加\" class=\"headerlink\" title=\"1.4 SonarQube凭证添加\"></a>1.4 SonarQube凭证添加</h2><p>sonar-token</p>\n<p>进入sonarqube添加项目并且生成token：<strong>caea718fe1c8d61628c85cc642998605247c4de9</strong> </p>\n<img src=\"/2022/07/26/devops%E4%B9%8BKubeSphere%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%83%A8%E7%BD%B2/1662997272162.png\" class=\"\" width=\"1662997272162\"> \n\n<p>配置sonarqube凭证：</p>\n<p>用户名和token添加</p>\n<figure class=\"highlight llvm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs llvm\"><span class=\"hljs-symbol\">user:</span> <br><span class=\"hljs-symbol\">token:</span> caea<span class=\"hljs-number\">718</span>fe<span class=\"hljs-number\">1</span><span class=\"hljs-keyword\">c</span><span class=\"hljs-number\">8</span>d<span class=\"hljs-number\">61628</span><span class=\"hljs-keyword\">c</span><span class=\"hljs-number\">85</span><span class=\"hljs-keyword\">cc</span><span class=\"hljs-number\">642998605247</span><span class=\"hljs-keyword\">c</span><span class=\"hljs-number\">4</span>de<span class=\"hljs-number\">9</span><br></code></pre></td></tr></table></figure>\n\n\n\n<h1 id=\"三、修改-Jenkinsfile\"><a href=\"#三、修改-Jenkinsfile\" class=\"headerlink\" title=\"三、修改 Jenkinsfile\"></a>三、修改 Jenkinsfile</h1><img src=\"/2022/07/26/devops%E4%B9%8BKubeSphere%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%83%A8%E7%BD%B2/jenkins-edit--2.png\" class=\"\" title=\"jenkins-edit--2\">\n\n<table>\n<thead>\n<tr>\n<th>条目</th>\n<th>值</th>\n<th>描述信息</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>DOCKER_CREDENTIAL_ID</td>\n<td>dockerhub-id</td>\n<td>您在 KubeSphere 中为 Docker Hub 帐户设置的<strong>名称</strong>。</td>\n</tr>\n<tr>\n<td>GITHUB_CREDENTIAL_ID</td>\n<td>github-id</td>\n<td>您在 KubeSphere 中为 GitHub 帐户设置的<strong>名称</strong>，用于将标签推送至您的 GitHub 仓库。</td>\n</tr>\n<tr>\n<td>KUBECONFIG_CREDENTIAL_ID</td>\n<td>demo-kubeconfig</td>\n<td>您在 KubeSphere 中为 kubeconfig 设置的<strong>名称</strong>，用于访问运行中的 Kubernetes 集群。</td>\n</tr>\n<tr>\n<td>REGISTRY</td>\n<td>docker.io</td>\n<td>默认为 <code>docker.io</code>，用作推送镜像的地址。</td>\n</tr>\n<tr>\n<td>DOCKERHUB_NAMESPACE</td>\n<td>your-dockerhub-account</td>\n<td>请替换为您的 Docker Hub 帐户名，也可以替换为该帐户下的 Organization 名称。</td>\n</tr>\n<tr>\n<td>GITHUB_ACCOUNT</td>\n<td>your-github-account</td>\n<td>请替换为您的 GitHub 帐户名。例如，如果您的 GitHub 地址是 <code>https://github.com/kubesphere/</code>，则您的 GitHub 帐户名为 <code>kubesphere</code>，也可以替换为该帐户下的 Organization 名称。</td>\n</tr>\n<tr>\n<td>APP_NAME</td>\n<td>devops-maven-sample</td>\n<td>应用名称。</td>\n</tr>\n<tr>\n<td>SONAR_CREDENTIAL_ID</td>\n<td>sonar-token</td>\n<td>您在 KubeSphere 中为 SonarQube 令牌设置的<strong>名称</strong>，用于代码质量检测。</td>\n</tr>\n</tbody></table>\n<h1 id=\"四、具体Jenkinsfile根据项目而定\"><a href=\"#四、具体Jenkinsfile根据项目而定\" class=\"headerlink\" title=\"四、具体Jenkinsfile根据项目而定\"></a>四、具体Jenkinsfile根据项目而定</h1><p>下面选用的代码仓库是码云、docker镜像仓库是dockerhub、代码分析sonar是自己部署的</p>\n<p>流水线步骤：拉取镜像——单元测试——代码质量分析——编译 &amp; 推送——推送最新——发布开发环境——推送正式版本——发布生产环境</p>\n<figure class=\"highlight puppet\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs puppet\"><span class=\"hljs-keyword\">pipeline</span> &#123;<br>  agent &#123;<br>    <span class=\"hljs-keyword\">node</span> &#123;<br>      label <span class=\"hljs-string\">&#x27;maven&#x27;</span><br>    &#125;<br><br>  &#125;<br>  <span class=\"hljs-keyword\">environment</span> &#123;<br>    DOCKER_CREDENTIAL_ID = <span class=\"hljs-string\">&#x27;dockerhub-id&#x27;</span><br>    GITEE_CREDENTIAL_ID = <span class=\"hljs-string\">&#x27;gitee-id&#x27;</span><br>    KUBECONFIG_CREDENTIAL_ID = <span class=\"hljs-string\">&#x27;kubeconfig&#x27;</span><br>    REGISTRY = <span class=\"hljs-string\">&#x27;docker.io&#x27;</span><br>    DOCKERHUB_NAMESPACE = <span class=\"hljs-string\">&#x27;leellun&#x27;</span><br>    GIT_ACCOUNT = <span class=\"hljs-string\">&#x27;myselfyou&#x27;</span><br>    SONAR_CREDENTIAL_ID = <span class=\"hljs-string\">&#x27;sonar-token&#x27;</span><br>    BRANCH_NAME = <span class=\"hljs-string\">&#x27;master&#x27;</span><br>  &#125;<br>  <span class=\"hljs-keyword\">parameters</span> &#123;<br>    string(<span class=\"hljs-literal\">name</span>: <span class=\"hljs-string\">&#x27;PROJECT_VERSION&#x27;</span>, defaultValue: <span class=\"hljs-string\">&#x27;&#x27;</span>, <span class=\"hljs-literal\">description</span>: <span class=\"hljs-string\">&#x27;版本&#x27;</span>)<br>    string(<span class=\"hljs-literal\">name</span>: <span class=\"hljs-string\">&#x27;PROJECT_NAME&#x27;</span>, defaultValue: <span class=\"hljs-string\">&#x27;&#x27;</span>, <span class=\"hljs-literal\">description</span>: <span class=\"hljs-string\">&#x27;项目名称&#x27;</span>)<br>  &#125;<br>  <span class=\"hljs-keyword\">stages</span> &#123;<br>    stage(<span class=\"hljs-string\">&#x27;拉取代码&#x27;</span>) &#123;<br>      steps &#123;<br>        sh <span class=\"hljs-string\">&quot;echo 正在构建 <span class=\"hljs-variable\">$PROJECT_NAME</span> 版本号：<span class=\"hljs-variable\">$PROJECT_VERSION</span> 将会提交给 <span class=\"hljs-variable\">$REGISTRY</span> 镜像仓库&quot;</span><br>        git(url: <span class=\"hljs-string\">&#x27;https://gitee.com/myselfyou/gulimall-learng.git&#x27;</span>, credentialsId: <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$GITEE_CREDENTIAL_ID</span>&quot;</span>, branch: <span class=\"hljs-string\">&#x27;master&#x27;</span>, changelog: <span class=\"hljs-keyword\">true</span>, poll: <span class=\"hljs-keyword\">false</span>)<br>      &#125;<br>    &#125;<br>    stage (<span class=\"hljs-string\">&#x27;单元测试&#x27;</span>) &#123;<br>        <span class=\"hljs-keyword\">steps</span> &#123;<br>            container (<span class=\"hljs-string\">&#x27;maven&#x27;</span>) &#123;<br>                sh <span class=\"hljs-string\">&#x27;java -version&#x27;</span><br>                sh <span class=\"hljs-string\">&#x27;mvn clean test&#x27;</span><br>            &#125;<br>        &#125;<br>    &#125;<br>    stage(<span class=\"hljs-string\">&#x27;代码质量分析&#x27;</span>) &#123;<br>      <span class=\"hljs-keyword\">steps</span> &#123;<br>        container(<span class=\"hljs-string\">&#x27;maven&#x27;</span>) &#123;<br>          withCredentials([string(credentialsId: <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$SONAR_CREDENTIAL_ID</span>&quot;</span>, variable: <span class=\"hljs-string\">&#x27;SONAR_TOKEN&#x27;</span>)]) &#123;<br>            withSonarQubeEnv(<span class=\"hljs-string\">&#x27;sonar&#x27;</span>) &#123;<br>              sh <span class=\"hljs-string\">&quot;mvn sonar:sonar -Dsonar.login=<span class=\"hljs-variable\">$SONAR_TOKEN</span>&quot;</span><br>            &#125;<br>          &#125;<br>        &#125;<br>      &#125;<br>    &#125;<br>    stage (<span class=\"hljs-string\">&#x27;编译 &amp; 推送&#x27;</span>) &#123;<br>        <span class=\"hljs-keyword\">steps</span> &#123;<br>            container (<span class=\"hljs-string\">&#x27;maven&#x27;</span>) &#123;<br>                sh <span class=\"hljs-string\">&#x27;mvn clean package -DskipTests&#x27;</span><br>                sh <span class=\"hljs-string\">&#x27;cd <span class=\"hljs-variable\">$PROJECT_NAME</span> &amp;&amp; docker build -f Dockerfile -t <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:SNAPSHOT-<span class=\"hljs-variable\">$BRANCH_NAME</span>-<span class=\"hljs-variable\">$BUILD_NUMBER</span> .&#x27;</span><br>                withCredentials([usernamePassword(passwordVariable : <span class=\"hljs-string\">&#x27;DOCKER_PASSWORD&#x27;</span> ,usernameVariable : <span class=\"hljs-string\">&#x27;DOCKER_USERNAME&#x27;</span> ,credentialsId : <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$DOCKER_CREDENTIAL_ID</span>&quot;</span> ,)]) &#123;<br>                    sh <span class=\"hljs-string\">&#x27;echo &quot;<span class=\"hljs-variable\">$DOCKER_PASSWORD</span>&quot; | docker login <span class=\"hljs-variable\">$REGISTRY</span> -u &quot;<span class=\"hljs-variable\">$DOCKER_USERNAME</span>&quot; --password-stdin&#x27;</span><br>                    sh <span class=\"hljs-string\">&#x27;docker push  <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:SNAPSHOT-<span class=\"hljs-variable\">$BRANCH_NAME</span>-<span class=\"hljs-variable\">$BUILD_NUMBER</span>&#x27;</span><br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>    stage(<span class=\"hljs-string\">&#x27;推送最新&#x27;</span>)&#123;<br>       when&#123;<br>         branch <span class=\"hljs-string\">&#x27;master&#x27;</span><br>       &#125;<br>       steps&#123;<br>            container (<span class=\"hljs-string\">&#x27;maven&#x27;</span>) &#123;<br>              sh <span class=\"hljs-string\">&#x27;docker tag  <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:SNAPSHOT-<span class=\"hljs-variable\">$BRANCH_NAME</span>-<span class=\"hljs-variable\">$BUILD_NUMBER</span> <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:latest &#x27;</span><br>              sh <span class=\"hljs-string\">&#x27;docker push  <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:latest &#x27;</span><br>            &#125;<br>       &#125;<br>    &#125;<br>    stage(<span class=\"hljs-string\">&#x27;发布开发环境&#x27;</span>) &#123;<br>      when&#123;<br>        branch <span class=\"hljs-string\">&#x27;master&#x27;</span><br>      &#125;<br>      <span class=\"hljs-keyword\">steps</span> &#123;<br>        input(<span class=\"hljs-built_in\">id</span>: <span class=\"hljs-string\">&#x27;deploy-to-dev&#x27;</span>, <span class=\"hljs-literal\">message</span>: <span class=\"hljs-string\">&#x27;是否发布到开发环境?&#x27;</span>)<br>        container (<span class=\"hljs-string\">&#x27;maven&#x27;</span>) &#123;<br>            withCredentials([<br>                kubeconfigFile(<br>                credentialsId: env.KUBECONFIG_CREDENTIAL_ID,<br>                variable: <span class=\"hljs-string\">&#x27;KUBECONFIG&#x27;</span>)<br>                ]) &#123;<br>                sh <span class=\"hljs-string\">&#x27;envsubst &lt; <span class=\"hljs-variable\">$PROJECT_NAME</span>/deploy/<span class=\"hljs-variable\">$PROJECT_NAME</span>-deploy.yaml | kubectl apply -f -&#x27;</span><br>            &#125;<br>        &#125;<br>      &#125;<br>    &#125;<br>    stage(<span class=\"hljs-string\">&#x27;推送正式版本&#x27;</span>)&#123;<br>      when&#123;<br>        expression&#123;<br>          return params.PROJECT_VERSION =~ /v.*/<br>        &#125;<br>      &#125;<br>      <span class=\"hljs-keyword\">steps</span> &#123;<br>          container (<span class=\"hljs-string\">&#x27;maven&#x27;</span>) &#123;<br>            input(<span class=\"hljs-built_in\">id</span>: <span class=\"hljs-string\">&#x27;release-image-with-tag&#x27;</span>, <span class=\"hljs-literal\">message</span>: <span class=\"hljs-string\">&#x27;是否发布镜像版本<span class=\"hljs-variable\">$PROJECT_NAME</span>:<span class=\"hljs-variable\">$PROJECT_VERSION</span>?&#x27;</span>)<br>              withCredentials([usernamePassword(credentialsId: <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$GITEE_CREDENTIAL_ID</span>&quot;</span>, passwordVariable: <span class=\"hljs-string\">&#x27;GIT_PASSWORD&#x27;</span>, usernameVariable: <span class=\"hljs-string\">&#x27;GIT_USERNAME&#x27;</span>)]) &#123;<br>                sh <span class=\"hljs-string\">&#x27;git config --global user.email &quot;kubesphere@qq.com&quot; &#x27;</span><br>                sh <span class=\"hljs-string\">&#x27;git config --global user.name &quot;kubesphere&quot; &#x27;</span><br>                sh <span class=\"hljs-string\">&#x27;git tag -a <span class=\"hljs-variable\">$PROJECT_NAME</span>-<span class=\"hljs-variable\">$PROJECT_VERSION</span> -m &quot;<span class=\"hljs-variable\">$PROJECT_NAME</span>-<span class=\"hljs-variable\">$PROJECT_VERSION</span>&quot; &#x27;</span><br>                sh <span class=\"hljs-string\">&#x27;echo <span class=\"hljs-variable\">$GIT_ACCOUNT</span>&#x27;</span><br>                sh <span class=\"hljs-string\">&#x27;git push http://<span class=\"hljs-variable\">$GIT_USERNAME</span>:<span class=\"hljs-variable\">$GIT_PASSWORD</span>@gitee.com/<span class=\"hljs-variable\">$GIT_ACCOUNT</span>/gulimall-learng.git --tags --ipv4&#x27;</span><br>              &#125;<br>            <span class=\"hljs-keyword\">sh</span> &#x27;docker tag  <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:SNAPSHOT-<span class=\"hljs-variable\">$BRANCH_NAME</span>-<span class=\"hljs-variable\">$BUILD_NUMBER</span> <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:<span class=\"hljs-variable\">$PROJECT_VERSION</span> <span class=\"hljs-string\">&#x27;</span><br><span class=\"hljs-string\">            sh &#x27;</span>docker push  <span class=\"hljs-variable\">$REGISTRY</span>/<span class=\"hljs-variable\">$DOCKERHUB_NAMESPACE</span>/<span class=\"hljs-variable\">$PROJECT_NAME</span>:<span class=\"hljs-variable\">$PROJECT_VERSION</span> <span class=\"hljs-string\">&#x27;</span><br><span class=\"hljs-string\">        &#125;</span><br><span class=\"hljs-string\">      &#125;</span><br><span class=\"hljs-string\">    &#125;</span><br><span class=\"hljs-string\">    stage(&#x27;</span>发布生产环境<span class=\"hljs-string\">&#x27;) &#123;</span><br><span class=\"hljs-string\">      when&#123;</span><br><span class=\"hljs-string\">        expression&#123;</span><br><span class=\"hljs-string\">          return params.PROJECT_VERSION =~ /v.*/</span><br><span class=\"hljs-string\">        &#125;</span><br><span class=\"hljs-string\">      &#125;</span><br><span class=\"hljs-string\">      steps &#123;</span><br><span class=\"hljs-string\">        input(id: &#x27;</span>deploy-to-production<span class=\"hljs-string\">&#x27;, message: &#x27;</span>是否发布生产环境?<span class=\"hljs-string\">&#x27;)</span><br><span class=\"hljs-string\">        container (&#x27;</span>maven<span class=\"hljs-string\">&#x27;) &#123;</span><br><span class=\"hljs-string\">            withCredentials([</span><br><span class=\"hljs-string\">                kubeconfigFile(</span><br><span class=\"hljs-string\">                credentialsId: env.KUBECONFIG_CREDENTIAL_ID,</span><br><span class=\"hljs-string\">                variable: &#x27;</span>KUBECONFIG<span class=\"hljs-string\">&#x27;)</span><br><span class=\"hljs-string\">                ]) &#123;</span><br><span class=\"hljs-string\">                sh &#x27;</span>envsubst &lt; <span class=\"hljs-variable\">$PROJECT_NAME</span>/deploy/<span class=\"hljs-variable\">$PROJECT_NAME</span>-deploy.yaml | kubectl apply -f -<span class=\"hljs-string\">&#x27;</span><br><span class=\"hljs-string\">            &#125;</span><br><span class=\"hljs-string\">        &#125;</span><br><span class=\"hljs-string\">      &#125;</span><br><span class=\"hljs-string\">    &#125;</span><br><span class=\"hljs-string\">  &#125;</span><br><span class=\"hljs-string\">&#125;</span><br></code></pre></td></tr></table></figure>\n\n"},{"title":"kubesphere快速部署mysql","date":"2022-07-26T10:38:02.000Z","_content":"\n# 一、docker部署方式\n\n```\ndocker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:8.0 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci\n```\n\n\n\n# 二、k8s有状态部署方式\n\n## 2.1 准备配置文件\n\n创建my-cnf的ConfigMap，键为my.cnf\n\n```\n[client]\ndefault-character-set=utf8mb4\n[mysql]\ndefault-character-set=utf8mb4\n[mysqld]\nmax_connections = 2000\nsecure_file_priv=/var/lib/mysql\nbasedir=/var/lib/mysql\ndatadir=/var/lib/mysql/data\nsql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION\nskip-name-resolve\nopen_files_limit = 65535\ntable_open_cache = 128\nlog_error = /var/lib/mysql/mysql-error.log\nslow_query_log = 1\nlong_query_time = 1\nslow_query_log_file = /var/lib/mysql/mysql-slow.log\ndefault-storage-engine = InnoDB\ninnodb_file_per_table = 1\ninnodb_open_files = 500\ninnodb_buffer_pool_size = 64M\ninnodb_write_io_threads = 4\ninnodb_read_io_threads = 4\ninnodb_thread_concurrency = 0\ninnodb_purge_threads = 1\ninnodb_flush_log_at_trx_commit = 2\ninnodb_log_buffer_size = 2M\ninnodb_log_file_size = 32M\ninnodb_log_files_in_group = 3\ninnodb_max_dirty_pages_pct = 90\ninnodb_lock_wait_timeout = 120\nbulk_insert_buffer_size = 8M\nmyisam_sort_buffer_size = 8M\nmyisam_max_sort_file_size = 10G\nmyisam_repair_threads = 1\ninteractive_timeout = 28800\nwait_timeout = 28800\n[mysqldump]\nquick\nmax_allowed_packet = 16M\n[myisamchk]\nkey_buffer_size = 8M\nsort_buffer_size = 8M\nread_buffer = 4M\nwrite_buffer = 4M\n```\n\n![1663167746173](kubesphere快速部署mysql/1663167746173.png)\n\n![1663170735856](kubesphere快速部署mysql/1663170735856.png)\n\n\n\n\n\n## 2.2 mysql有状态持久卷创建\n\n![1663167951290](kubesphere快速部署mysql/1663167951290.png)\n\n## 2.3 创建mysql服务\n\n![1663168060307](kubesphere快速部署mysql/1663168060307.png)\n\n配置文件挂在：持久卷可以创建也可以指定持久卷模板，地址 /var/lib/mysql\n\n![1663169165653](kubesphere快速部署mysql/1663169165653.png)\n\n存储卷挂载：挂载配置文件my.cnf，挂载/etc/mysql/my.cnf\n\n![1663169211109](kubesphere快速部署mysql/1663169211109.png)\n\n# ","source":"_posts/kubesphere快速部署mysql.md","raw":"---\ntitle: kubesphere快速部署mysql\ndate: 2022-07-26 18:38:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - kubeshpere\n  - mysql\n---\n\n# 一、docker部署方式\n\n```\ndocker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:8.0 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci\n```\n\n\n\n# 二、k8s有状态部署方式\n\n## 2.1 准备配置文件\n\n创建my-cnf的ConfigMap，键为my.cnf\n\n```\n[client]\ndefault-character-set=utf8mb4\n[mysql]\ndefault-character-set=utf8mb4\n[mysqld]\nmax_connections = 2000\nsecure_file_priv=/var/lib/mysql\nbasedir=/var/lib/mysql\ndatadir=/var/lib/mysql/data\nsql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION\nskip-name-resolve\nopen_files_limit = 65535\ntable_open_cache = 128\nlog_error = /var/lib/mysql/mysql-error.log\nslow_query_log = 1\nlong_query_time = 1\nslow_query_log_file = /var/lib/mysql/mysql-slow.log\ndefault-storage-engine = InnoDB\ninnodb_file_per_table = 1\ninnodb_open_files = 500\ninnodb_buffer_pool_size = 64M\ninnodb_write_io_threads = 4\ninnodb_read_io_threads = 4\ninnodb_thread_concurrency = 0\ninnodb_purge_threads = 1\ninnodb_flush_log_at_trx_commit = 2\ninnodb_log_buffer_size = 2M\ninnodb_log_file_size = 32M\ninnodb_log_files_in_group = 3\ninnodb_max_dirty_pages_pct = 90\ninnodb_lock_wait_timeout = 120\nbulk_insert_buffer_size = 8M\nmyisam_sort_buffer_size = 8M\nmyisam_max_sort_file_size = 10G\nmyisam_repair_threads = 1\ninteractive_timeout = 28800\nwait_timeout = 28800\n[mysqldump]\nquick\nmax_allowed_packet = 16M\n[myisamchk]\nkey_buffer_size = 8M\nsort_buffer_size = 8M\nread_buffer = 4M\nwrite_buffer = 4M\n```\n\n![1663167746173](kubesphere快速部署mysql/1663167746173.png)\n\n![1663170735856](kubesphere快速部署mysql/1663170735856.png)\n\n\n\n\n\n## 2.2 mysql有状态持久卷创建\n\n![1663167951290](kubesphere快速部署mysql/1663167951290.png)\n\n## 2.3 创建mysql服务\n\n![1663168060307](kubesphere快速部署mysql/1663168060307.png)\n\n配置文件挂在：持久卷可以创建也可以指定持久卷模板，地址 /var/lib/mysql\n\n![1663169165653](kubesphere快速部署mysql/1663169165653.png)\n\n存储卷挂载：挂载配置文件my.cnf，挂载/etc/mysql/my.cnf\n\n![1663169211109](kubesphere快速部署mysql/1663169211109.png)\n\n# ","slug":"kubesphere快速部署mysql","published":1,"updated":"2022-09-23T16:23:48.369Z","_id":"cl8eoklci00004kvj0jo71dt3","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、docker部署方式\"><a href=\"#一、docker部署方式\" class=\"headerlink\" title=\"一、docker部署方式\"></a>一、docker部署方式</h1><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">docker <span class=\"hljs-built_in\">run</span> --name some-mysql -e <span class=\"hljs-attribute\">MYSQL_ROOT_PASSWORD</span>=my-secret-pw -d mysql:8.0 <span class=\"hljs-attribute\">--character-set-server</span>=utf8mb4 <span class=\"hljs-attribute\">--collation-server</span>=utf8mb4_unicode_ci<br></code></pre></td></tr></table></figure>\n\n\n\n<h1 id=\"二、k8s有状态部署方式\"><a href=\"#二、k8s有状态部署方式\" class=\"headerlink\" title=\"二、k8s有状态部署方式\"></a>二、k8s有状态部署方式</h1><h2 id=\"2-1-准备配置文件\"><a href=\"#2-1-准备配置文件\" class=\"headerlink\" title=\"2.1 准备配置文件\"></a>2.1 准备配置文件</h2><p>创建my-cnf的ConfigMap，键为my.cnf</p>\n<figure class=\"highlight gams\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gams\">[client]<br>default-character-<span class=\"hljs-keyword\">set</span>=utf8mb4<br>[mysql]<br>default-character-<span class=\"hljs-keyword\">set</span>=utf8mb4<br>[mysqld]<br>max_connections <span class=\"hljs-comment\">= 2000</span><br>secure_file_priv=/var/lib/mysql<br>basedir=/var/lib/mysql<br>datadir=/var/lib/mysql/data<br>sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION<br>skip-name-resolve<br>open_files_limit <span class=\"hljs-comment\">= 65535</span><br>table_open_cache <span class=\"hljs-comment\">= 128</span><br>log_error <span class=\"hljs-comment\">=</span> /var/<span class=\"hljs-comment\">lib</span>/mysql/<span class=\"hljs-comment\">mysql-error.log</span><br>slow_query_log <span class=\"hljs-comment\">= 1</span><br>long_query_time <span class=\"hljs-comment\">= 1</span><br>slow_query_log_file <span class=\"hljs-comment\">=</span> /var/<span class=\"hljs-comment\">lib</span>/mysql/<span class=\"hljs-comment\">mysql-slow.log</span><br>default-storage-engine <span class=\"hljs-comment\">= InnoDB</span><br>innodb_file_per_table <span class=\"hljs-comment\">= 1</span><br>innodb_open_files <span class=\"hljs-comment\">= 500</span><br>innodb_buffer_pool_size <span class=\"hljs-comment\">= 64M</span><br>innodb_write_io_threads <span class=\"hljs-comment\">= 4</span><br>innodb_read_io_threads <span class=\"hljs-comment\">= 4</span><br>innodb_thread_concurrency <span class=\"hljs-comment\">= 0</span><br>innodb_purge_threads <span class=\"hljs-comment\">= 1</span><br>innodb_flush_log_at_trx_commit <span class=\"hljs-comment\">= 2</span><br>innodb_log_buffer_size <span class=\"hljs-comment\">= 2M</span><br>innodb_log_file_size <span class=\"hljs-comment\">= 32M</span><br>innodb_log_files_in_group <span class=\"hljs-comment\">= 3</span><br>innodb_max_dirty_pages_pct <span class=\"hljs-comment\">= 90</span><br>innodb_lock_wait_timeout <span class=\"hljs-comment\">= 120</span><br>bulk_insert_buffer_size <span class=\"hljs-comment\">= 8M</span><br>myisam_sort_buffer_size <span class=\"hljs-comment\">= 8M</span><br>myisam_max_sort_file_size <span class=\"hljs-comment\">= 10G</span><br>myisam_repair_threads <span class=\"hljs-comment\">= 1</span><br>interactive_timeout <span class=\"hljs-comment\">= 28800</span><br>wait_timeout <span class=\"hljs-comment\">= 28800</span><br>[mysqldump]<br>quick<br>max_allowed_packet <span class=\"hljs-comment\">= 16M</span><br>[myisamchk]<br>key_buffer_size <span class=\"hljs-comment\">= 8M</span><br>sort_buffer_size <span class=\"hljs-comment\">= 8M</span><br>read_buffer <span class=\"hljs-comment\">= 4M</span><br>write_buffer <span class=\"hljs-comment\">= 4M</span><br></code></pre></td></tr></table></figure>\n\n<img src=\"/2022/07/26/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2mysql/1663167746173.png\" class=\"\" width=\"1663167746173\">\n\n<img src=\"/2022/07/26/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2mysql/1663170735856.png\" class=\"\" width=\"1663170735856\">\n\n\n\n\n\n<h2 id=\"2-2-mysql有状态持久卷创建\"><a href=\"#2-2-mysql有状态持久卷创建\" class=\"headerlink\" title=\"2.2 mysql有状态持久卷创建\"></a>2.2 mysql有状态持久卷创建</h2><img src=\"/2022/07/26/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2mysql/1663167951290.png\" class=\"\" width=\"1663167951290\">\n\n<h2 id=\"2-3-创建mysql服务\"><a href=\"#2-3-创建mysql服务\" class=\"headerlink\" title=\"2.3 创建mysql服务\"></a>2.3 创建mysql服务</h2><img src=\"/2022/07/26/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2mysql/1663168060307.png\" class=\"\" width=\"1663168060307\">\n\n<p>配置文件挂在：持久卷可以创建也可以指定持久卷模板，地址 /var/lib/mysql</p>\n<img src=\"/2022/07/26/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2mysql/1663169165653.png\" class=\"\" width=\"1663169165653\">\n\n<p>存储卷挂载：挂载配置文件my.cnf，挂载/etc/mysql/my.cnf</p>\n<img src=\"/2022/07/26/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2mysql/1663169211109.png\" class=\"\" width=\"1663169211109\">\n\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、docker部署方式\"><a href=\"#一、docker部署方式\" class=\"headerlink\" title=\"一、docker部署方式\"></a>一、docker部署方式</h1><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">docker <span class=\"hljs-built_in\">run</span> --name some-mysql -e <span class=\"hljs-attribute\">MYSQL_ROOT_PASSWORD</span>=my-secret-pw -d mysql:8.0 <span class=\"hljs-attribute\">--character-set-server</span>=utf8mb4 <span class=\"hljs-attribute\">--collation-server</span>=utf8mb4_unicode_ci<br></code></pre></td></tr></table></figure>\n\n\n\n<h1 id=\"二、k8s有状态部署方式\"><a href=\"#二、k8s有状态部署方式\" class=\"headerlink\" title=\"二、k8s有状态部署方式\"></a>二、k8s有状态部署方式</h1><h2 id=\"2-1-准备配置文件\"><a href=\"#2-1-准备配置文件\" class=\"headerlink\" title=\"2.1 准备配置文件\"></a>2.1 准备配置文件</h2><p>创建my-cnf的ConfigMap，键为my.cnf</p>\n<figure class=\"highlight gams\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gams\">[client]<br>default-character-<span class=\"hljs-keyword\">set</span>=utf8mb4<br>[mysql]<br>default-character-<span class=\"hljs-keyword\">set</span>=utf8mb4<br>[mysqld]<br>max_connections <span class=\"hljs-comment\">= 2000</span><br>secure_file_priv=/var/lib/mysql<br>basedir=/var/lib/mysql<br>datadir=/var/lib/mysql/data<br>sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION<br>skip-name-resolve<br>open_files_limit <span class=\"hljs-comment\">= 65535</span><br>table_open_cache <span class=\"hljs-comment\">= 128</span><br>log_error <span class=\"hljs-comment\">=</span> /var/<span class=\"hljs-comment\">lib</span>/mysql/<span class=\"hljs-comment\">mysql-error.log</span><br>slow_query_log <span class=\"hljs-comment\">= 1</span><br>long_query_time <span class=\"hljs-comment\">= 1</span><br>slow_query_log_file <span class=\"hljs-comment\">=</span> /var/<span class=\"hljs-comment\">lib</span>/mysql/<span class=\"hljs-comment\">mysql-slow.log</span><br>default-storage-engine <span class=\"hljs-comment\">= InnoDB</span><br>innodb_file_per_table <span class=\"hljs-comment\">= 1</span><br>innodb_open_files <span class=\"hljs-comment\">= 500</span><br>innodb_buffer_pool_size <span class=\"hljs-comment\">= 64M</span><br>innodb_write_io_threads <span class=\"hljs-comment\">= 4</span><br>innodb_read_io_threads <span class=\"hljs-comment\">= 4</span><br>innodb_thread_concurrency <span class=\"hljs-comment\">= 0</span><br>innodb_purge_threads <span class=\"hljs-comment\">= 1</span><br>innodb_flush_log_at_trx_commit <span class=\"hljs-comment\">= 2</span><br>innodb_log_buffer_size <span class=\"hljs-comment\">= 2M</span><br>innodb_log_file_size <span class=\"hljs-comment\">= 32M</span><br>innodb_log_files_in_group <span class=\"hljs-comment\">= 3</span><br>innodb_max_dirty_pages_pct <span class=\"hljs-comment\">= 90</span><br>innodb_lock_wait_timeout <span class=\"hljs-comment\">= 120</span><br>bulk_insert_buffer_size <span class=\"hljs-comment\">= 8M</span><br>myisam_sort_buffer_size <span class=\"hljs-comment\">= 8M</span><br>myisam_max_sort_file_size <span class=\"hljs-comment\">= 10G</span><br>myisam_repair_threads <span class=\"hljs-comment\">= 1</span><br>interactive_timeout <span class=\"hljs-comment\">= 28800</span><br>wait_timeout <span class=\"hljs-comment\">= 28800</span><br>[mysqldump]<br>quick<br>max_allowed_packet <span class=\"hljs-comment\">= 16M</span><br>[myisamchk]<br>key_buffer_size <span class=\"hljs-comment\">= 8M</span><br>sort_buffer_size <span class=\"hljs-comment\">= 8M</span><br>read_buffer <span class=\"hljs-comment\">= 4M</span><br>write_buffer <span class=\"hljs-comment\">= 4M</span><br></code></pre></td></tr></table></figure>\n\n<img src=\"/2022/07/26/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2mysql/1663167746173.png\" class=\"\" width=\"1663167746173\">\n\n<img src=\"/2022/07/26/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2mysql/1663170735856.png\" class=\"\" width=\"1663170735856\">\n\n\n\n\n\n<h2 id=\"2-2-mysql有状态持久卷创建\"><a href=\"#2-2-mysql有状态持久卷创建\" class=\"headerlink\" title=\"2.2 mysql有状态持久卷创建\"></a>2.2 mysql有状态持久卷创建</h2><img src=\"/2022/07/26/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2mysql/1663167951290.png\" class=\"\" width=\"1663167951290\">\n\n<h2 id=\"2-3-创建mysql服务\"><a href=\"#2-3-创建mysql服务\" class=\"headerlink\" title=\"2.3 创建mysql服务\"></a>2.3 创建mysql服务</h2><img src=\"/2022/07/26/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2mysql/1663168060307.png\" class=\"\" width=\"1663168060307\">\n\n<p>配置文件挂在：持久卷可以创建也可以指定持久卷模板，地址 /var/lib/mysql</p>\n<img src=\"/2022/07/26/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2mysql/1663169165653.png\" class=\"\" width=\"1663169165653\">\n\n<p>存储卷挂载：挂载配置文件my.cnf，挂载/etc/mysql/my.cnf</p>\n<img src=\"/2022/07/26/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2mysql/1663169211109.png\" class=\"\" width=\"1663169211109\">\n\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>"},{"title":"kubesphere快速部署redis","date":"2022-07-27T11:38:02.000Z","_content":"\n# 一、配置文件创建\n\nredis-conf：redis.conf\n\n```\ncluster-enabled yes #开启集群\ncluster-config-file nodes.conf #集群node\ncluster-node-timeout 5000 # 集群延迟\nappendonly yes # aof文件开启\nmasterauth 123456 # 密码\nrequirepass 123456 # 认证密码\n```\n\n# 二、redis有状态服务副本集创建\n\n存储卷模板：\n\n![1663220903688](kubesphere快速部署redis/1663220903688.png)\n\nredis 容器设置即启动命令配置\n\n```\nredis-server /etc/redis/redis.conf\n```\n\n![1663213016039](kubesphere快速部署redis/1663213016039.png)\n\n```\n[root@k8s-master01 kubesphere]# kubectl get pod,pvc -n gulimall\nNAME                    READY   STATUS    RESTARTS   AGE\npod/mysql-master-v1-0   1/1     Running   0          13h\npod/redis-cluster-0     1/1     Running   0          30m\npod/redis-cluster-1     1/1     Running   0          26m\npod/redis-cluster-2     1/1     Running   0          26m\npod/redis-cluster-3     1/1     Running   0          26m\npod/redis-cluster-4     1/1     Running   0          26m\npod/redis-cluster-5     1/1     Running   0          26m\n\nNAME                                              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       AGE\npersistentvolumeclaim/mysql-pvc                   Bound    pvc-c912ac48-fce5-4ced-9763-2b4c31687fab   30Gi       RWO            openebs-hostpath   14h\npersistentvolumeclaim/pvc-redis-redis-cluster-0   Bound    pvc-9638569c-0095-4022-9a10-31b50602ad6d   10Gi       RWO            openebs-hostpath   30m\npersistentvolumeclaim/pvc-redis-redis-cluster-1   Bound    pvc-b2f190ed-720b-491b-8d09-7350854c3f46   10Gi       RWO            openebs-hostpath   26m\npersistentvolumeclaim/pvc-redis-redis-cluster-2   Bound    pvc-36a96ab2-7dc1-4cfd-8c7d-7f733d37e817   10Gi       RWO            openebs-hostpath   26m\npersistentvolumeclaim/pvc-redis-redis-cluster-3   Bound    pvc-0a37fdd9-4b74-4fc0-b009-a5ed06ecac9c   10Gi       RWO            openebs-hostpath   26m\npersistentvolumeclaim/pvc-redis-redis-cluster-4   Bound    pvc-ff8a3d3b-2ec2-4132-9d09-498a25dcc506   10Gi       RWO            openebs-hostpath   26m\npersistentvolumeclaim/pvc-redis-redis-cluster-5   Bound    pvc-20635271-fb88-4904-af26-77754bd64385   10Gi       RWO            openebs-hostpath   26m\n```\n\n# 三、查看ip\n\n```\n[root@k8s-master01 kubesphere]# kubectl get pods -l app=redis-cluster -n gulimall -o jsonpath='{range.items[*]}{.status.podIP}:6379 '      \n10.244.0.79:6379 10.244.0.81:6379 10.244.0.83:6379 10.244.0.85:6379 10.244.0.87:6379 10.244.0.89:6379\n```\n\n# 四、集群\n\n这里通过ip集群，最好通过pod.svc。例如：redis-cluster-0.redis-cluster-85pg,redis-cluster-1.redis-cluster-85pg,redis-cluster-2.redis-cluster-85pg,redis-cluster-3.redis-cluster-85pg,redis-cluster-4.redis-cluster-85pg,redis-cluster-5.redis-cluster-85pg\n\n```\nkubectl exec -it redis-cluster-0 -n gulimall -- redis-cli --cluster create --cluster-replicas 1 $(kubectl get pods -l app=redis-cluster -n gulimall -o jsonpath='{range.items[*]}{.status.podIP}:6379 ') -a 123456\n```\n\n结果打印：\n\n```\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\n>>> Performing hash slots allocation on 6 nodes...\nMaster[0] -> Slots 0 - 5460\nMaster[1] -> Slots 5461 - 10922\nMaster[2] -> Slots 10923 - 16383\nAdding replica 10.244.0.87:6379 to 10.244.0.79:6379\nAdding replica 10.244.0.89:6379 to 10.244.0.81:6379\nAdding replica 10.244.0.85:6379 to 10.244.0.83:6379\nM: 6a8be8e3baaff7e6569484b68173f9ae929687a4 10.244.0.79:6379\n   slots:[0-5460] (5461 slots) master\nM: c902a47a859884e9d8e9e98463c998bafa8c456b 10.244.0.81:6379\n   slots:[5461-10922] (5462 slots) master\nM: edbddb2005e23a357f371fed804fc490bcabbdc0 10.244.0.83:6379\n   slots:[10923-16383] (5461 slots) master\nS: 6255f444e9f53ba7d4e0c3714111820347f60ab8 10.244.0.85:6379\n   replicates edbddb2005e23a357f371fed804fc490bcabbdc0\nS: 4563856b15f4a6325c9f22dcc4f3b49b5867adc4 10.244.0.87:6379\n   replicates 6a8be8e3baaff7e6569484b68173f9ae929687a4\nS: db1d355eb2cf0ffa12240658aceadf737e00cfd3 10.244.0.89:6379\n   replicates c902a47a859884e9d8e9e98463c998bafa8c456b\nCan I set the above configuration? (type 'yes' to accept): yes\n>>> Nodes configuration updated\n>>> Assign a different config epoch to each node\n>>> Sending CLUSTER MEET messages to join the cluster\nWaiting for the cluster to join\n.\n>>> Performing Cluster Check (using node 10.244.0.79:6379)\nM: 6a8be8e3baaff7e6569484b68173f9ae929687a4 10.244.0.79:6379\n   slots:[0-5460] (5461 slots) master\n   1 additional replica(s)\nS: db1d355eb2cf0ffa12240658aceadf737e00cfd3 10.244.0.89:6379\n   slots: (0 slots) slave\n   replicates c902a47a859884e9d8e9e98463c998bafa8c456b\nS: 6255f444e9f53ba7d4e0c3714111820347f60ab8 10.244.0.85:6379\n   slots: (0 slots) slave\n   replicates edbddb2005e23a357f371fed804fc490bcabbdc0\nS: 4563856b15f4a6325c9f22dcc4f3b49b5867adc4 10.244.0.87:6379\n   slots: (0 slots) slave\n   replicates 6a8be8e3baaff7e6569484b68173f9ae929687a4\nM: c902a47a859884e9d8e9e98463c998bafa8c456b 10.244.0.81:6379\n   slots:[5461-10922] (5462 slots) master\n   1 additional replica(s)\nM: edbddb2005e23a357f371fed804fc490bcabbdc0 10.244.0.83:6379\n   slots:[10923-16383] (5461 slots) master\n   1 additional replica(s)\n[OK] All nodes agree about slots configuration.\n>>> Check for open slots...\n>>> Check slots coverage...\n[OK] All 16384 slots covered.\n```\n\n验证集群：\n\n```\nkubectl exec -it redis-cluster-0 -n gulimall -- redis-cli cluster info \n```\n\n角色查看：\n\n```\n[root@k8s-master01 src]# for x in $(seq 0 5); do echo \"redis-cluster-$x\"; kubectl exec redis-cluster-$x -n gulimall -- redis-cli -a 123456 role; echo; done \nredis-cluster-0\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\nmaster\n2215\n10.244.0.87\n6379\n2215\n\nredis-cluster-1\nmaster\n2156\n10.244.0.89\n6379\n2156\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\n\nredis-cluster-2\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\nmaster\n2156\n10.244.0.85\n6379\n2156\n\nredis-cluster-3\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\nslave\n10.244.0.83\n6379\nconnected\n2156\n\nredis-cluster-4\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\nslave\n10.244.0.79\n6379\nconnected\n2229\n\nredis-cluster-5\nslave\n10.244.0.81\n6379\nconnected\n2156\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\n```\n\n启动集群：\n\n```\nkubectl exec -it redis-cluster-0 -n gulimall -- redis-cli redis-cli -c -p 6379\n```\n\n测试：\n\n```\n[root@k8s-master01 src]# kubectl exec redis-cluster-3 -n gulimall -it -- /bin/sh\n# redis-cli -c -a 123456\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\n127.0.0.1:6379> get aa\n-> Redirected to slot [1180] located at 10.244.0.79:6379\n\"234234\"\n```\n\n# 五、整理操作\n\n软件版本：redis:5.0\n\n配置文件：redis-conf：redis.conf\n\n```\ncluster-enabled yes #开启集群\ncluster-config-file nodes.conf #集群node\ncluster-node-timeout 5000 # 集群延迟\nappendonly yes # aof文件开启\nmasterauth 123456 # 密码\nrequirepass 123456 # 认证密码\n```\n\n配置文件挂载：/etc/redis/redis.conf\n\n数据挂载：/data\n\n启动命令：\n\n```\nredis-server /etc/redis/redis.conf\n```\n\n集群：\n\n```\nkubectl exec -it redis-cluster-0 -n gulimall -- redis-cli --cluster create --cluster-replicas 1 redis-cluster-0.redis-cluster.gulimall,redis-cluster-1.redis-cluster.gulimall,redis-cluster-2.redis-cluster.gulimall,redis-cluster-3.redis-cluster.gulimall,redis-cluster-4.redis-cluster.gulimall,redis-cluster-5.redis-cluster.gulimall -a 123456\n```\n\n验证集群：\n\n```\nkubectl exec -it redis-cluster-0 -n gulimall -- redis-cli cluster info \n```\n\n角色查看：\n\n```\nfor x in $(seq 0 5); do echo \"redis-cluster-$x\"; kubectl exec redis-cluster-$x -n gulimall -- redis-cli -a 123456 role; echo; done \n```\n\n启动集群：\n\n```\nkubectl exec -it redis-cluster-0 -n gulimall -- redis-cli redis-cli -c -p 6379\n```\n\n","source":"_posts/kubesphere快速部署redis.md","raw":"---\ntitle: kubesphere快速部署redis\ndate: 2022-07-27 19:38:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - kubeshpere\n  - redis\n---\n\n# 一、配置文件创建\n\nredis-conf：redis.conf\n\n```\ncluster-enabled yes #开启集群\ncluster-config-file nodes.conf #集群node\ncluster-node-timeout 5000 # 集群延迟\nappendonly yes # aof文件开启\nmasterauth 123456 # 密码\nrequirepass 123456 # 认证密码\n```\n\n# 二、redis有状态服务副本集创建\n\n存储卷模板：\n\n![1663220903688](kubesphere快速部署redis/1663220903688.png)\n\nredis 容器设置即启动命令配置\n\n```\nredis-server /etc/redis/redis.conf\n```\n\n![1663213016039](kubesphere快速部署redis/1663213016039.png)\n\n```\n[root@k8s-master01 kubesphere]# kubectl get pod,pvc -n gulimall\nNAME                    READY   STATUS    RESTARTS   AGE\npod/mysql-master-v1-0   1/1     Running   0          13h\npod/redis-cluster-0     1/1     Running   0          30m\npod/redis-cluster-1     1/1     Running   0          26m\npod/redis-cluster-2     1/1     Running   0          26m\npod/redis-cluster-3     1/1     Running   0          26m\npod/redis-cluster-4     1/1     Running   0          26m\npod/redis-cluster-5     1/1     Running   0          26m\n\nNAME                                              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       AGE\npersistentvolumeclaim/mysql-pvc                   Bound    pvc-c912ac48-fce5-4ced-9763-2b4c31687fab   30Gi       RWO            openebs-hostpath   14h\npersistentvolumeclaim/pvc-redis-redis-cluster-0   Bound    pvc-9638569c-0095-4022-9a10-31b50602ad6d   10Gi       RWO            openebs-hostpath   30m\npersistentvolumeclaim/pvc-redis-redis-cluster-1   Bound    pvc-b2f190ed-720b-491b-8d09-7350854c3f46   10Gi       RWO            openebs-hostpath   26m\npersistentvolumeclaim/pvc-redis-redis-cluster-2   Bound    pvc-36a96ab2-7dc1-4cfd-8c7d-7f733d37e817   10Gi       RWO            openebs-hostpath   26m\npersistentvolumeclaim/pvc-redis-redis-cluster-3   Bound    pvc-0a37fdd9-4b74-4fc0-b009-a5ed06ecac9c   10Gi       RWO            openebs-hostpath   26m\npersistentvolumeclaim/pvc-redis-redis-cluster-4   Bound    pvc-ff8a3d3b-2ec2-4132-9d09-498a25dcc506   10Gi       RWO            openebs-hostpath   26m\npersistentvolumeclaim/pvc-redis-redis-cluster-5   Bound    pvc-20635271-fb88-4904-af26-77754bd64385   10Gi       RWO            openebs-hostpath   26m\n```\n\n# 三、查看ip\n\n```\n[root@k8s-master01 kubesphere]# kubectl get pods -l app=redis-cluster -n gulimall -o jsonpath='{range.items[*]}{.status.podIP}:6379 '      \n10.244.0.79:6379 10.244.0.81:6379 10.244.0.83:6379 10.244.0.85:6379 10.244.0.87:6379 10.244.0.89:6379\n```\n\n# 四、集群\n\n这里通过ip集群，最好通过pod.svc。例如：redis-cluster-0.redis-cluster-85pg,redis-cluster-1.redis-cluster-85pg,redis-cluster-2.redis-cluster-85pg,redis-cluster-3.redis-cluster-85pg,redis-cluster-4.redis-cluster-85pg,redis-cluster-5.redis-cluster-85pg\n\n```\nkubectl exec -it redis-cluster-0 -n gulimall -- redis-cli --cluster create --cluster-replicas 1 $(kubectl get pods -l app=redis-cluster -n gulimall -o jsonpath='{range.items[*]}{.status.podIP}:6379 ') -a 123456\n```\n\n结果打印：\n\n```\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\n>>> Performing hash slots allocation on 6 nodes...\nMaster[0] -> Slots 0 - 5460\nMaster[1] -> Slots 5461 - 10922\nMaster[2] -> Slots 10923 - 16383\nAdding replica 10.244.0.87:6379 to 10.244.0.79:6379\nAdding replica 10.244.0.89:6379 to 10.244.0.81:6379\nAdding replica 10.244.0.85:6379 to 10.244.0.83:6379\nM: 6a8be8e3baaff7e6569484b68173f9ae929687a4 10.244.0.79:6379\n   slots:[0-5460] (5461 slots) master\nM: c902a47a859884e9d8e9e98463c998bafa8c456b 10.244.0.81:6379\n   slots:[5461-10922] (5462 slots) master\nM: edbddb2005e23a357f371fed804fc490bcabbdc0 10.244.0.83:6379\n   slots:[10923-16383] (5461 slots) master\nS: 6255f444e9f53ba7d4e0c3714111820347f60ab8 10.244.0.85:6379\n   replicates edbddb2005e23a357f371fed804fc490bcabbdc0\nS: 4563856b15f4a6325c9f22dcc4f3b49b5867adc4 10.244.0.87:6379\n   replicates 6a8be8e3baaff7e6569484b68173f9ae929687a4\nS: db1d355eb2cf0ffa12240658aceadf737e00cfd3 10.244.0.89:6379\n   replicates c902a47a859884e9d8e9e98463c998bafa8c456b\nCan I set the above configuration? (type 'yes' to accept): yes\n>>> Nodes configuration updated\n>>> Assign a different config epoch to each node\n>>> Sending CLUSTER MEET messages to join the cluster\nWaiting for the cluster to join\n.\n>>> Performing Cluster Check (using node 10.244.0.79:6379)\nM: 6a8be8e3baaff7e6569484b68173f9ae929687a4 10.244.0.79:6379\n   slots:[0-5460] (5461 slots) master\n   1 additional replica(s)\nS: db1d355eb2cf0ffa12240658aceadf737e00cfd3 10.244.0.89:6379\n   slots: (0 slots) slave\n   replicates c902a47a859884e9d8e9e98463c998bafa8c456b\nS: 6255f444e9f53ba7d4e0c3714111820347f60ab8 10.244.0.85:6379\n   slots: (0 slots) slave\n   replicates edbddb2005e23a357f371fed804fc490bcabbdc0\nS: 4563856b15f4a6325c9f22dcc4f3b49b5867adc4 10.244.0.87:6379\n   slots: (0 slots) slave\n   replicates 6a8be8e3baaff7e6569484b68173f9ae929687a4\nM: c902a47a859884e9d8e9e98463c998bafa8c456b 10.244.0.81:6379\n   slots:[5461-10922] (5462 slots) master\n   1 additional replica(s)\nM: edbddb2005e23a357f371fed804fc490bcabbdc0 10.244.0.83:6379\n   slots:[10923-16383] (5461 slots) master\n   1 additional replica(s)\n[OK] All nodes agree about slots configuration.\n>>> Check for open slots...\n>>> Check slots coverage...\n[OK] All 16384 slots covered.\n```\n\n验证集群：\n\n```\nkubectl exec -it redis-cluster-0 -n gulimall -- redis-cli cluster info \n```\n\n角色查看：\n\n```\n[root@k8s-master01 src]# for x in $(seq 0 5); do echo \"redis-cluster-$x\"; kubectl exec redis-cluster-$x -n gulimall -- redis-cli -a 123456 role; echo; done \nredis-cluster-0\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\nmaster\n2215\n10.244.0.87\n6379\n2215\n\nredis-cluster-1\nmaster\n2156\n10.244.0.89\n6379\n2156\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\n\nredis-cluster-2\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\nmaster\n2156\n10.244.0.85\n6379\n2156\n\nredis-cluster-3\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\nslave\n10.244.0.83\n6379\nconnected\n2156\n\nredis-cluster-4\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\nslave\n10.244.0.79\n6379\nconnected\n2229\n\nredis-cluster-5\nslave\n10.244.0.81\n6379\nconnected\n2156\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\n```\n\n启动集群：\n\n```\nkubectl exec -it redis-cluster-0 -n gulimall -- redis-cli redis-cli -c -p 6379\n```\n\n测试：\n\n```\n[root@k8s-master01 src]# kubectl exec redis-cluster-3 -n gulimall -it -- /bin/sh\n# redis-cli -c -a 123456\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\n127.0.0.1:6379> get aa\n-> Redirected to slot [1180] located at 10.244.0.79:6379\n\"234234\"\n```\n\n# 五、整理操作\n\n软件版本：redis:5.0\n\n配置文件：redis-conf：redis.conf\n\n```\ncluster-enabled yes #开启集群\ncluster-config-file nodes.conf #集群node\ncluster-node-timeout 5000 # 集群延迟\nappendonly yes # aof文件开启\nmasterauth 123456 # 密码\nrequirepass 123456 # 认证密码\n```\n\n配置文件挂载：/etc/redis/redis.conf\n\n数据挂载：/data\n\n启动命令：\n\n```\nredis-server /etc/redis/redis.conf\n```\n\n集群：\n\n```\nkubectl exec -it redis-cluster-0 -n gulimall -- redis-cli --cluster create --cluster-replicas 1 redis-cluster-0.redis-cluster.gulimall,redis-cluster-1.redis-cluster.gulimall,redis-cluster-2.redis-cluster.gulimall,redis-cluster-3.redis-cluster.gulimall,redis-cluster-4.redis-cluster.gulimall,redis-cluster-5.redis-cluster.gulimall -a 123456\n```\n\n验证集群：\n\n```\nkubectl exec -it redis-cluster-0 -n gulimall -- redis-cli cluster info \n```\n\n角色查看：\n\n```\nfor x in $(seq 0 5); do echo \"redis-cluster-$x\"; kubectl exec redis-cluster-$x -n gulimall -- redis-cli -a 123456 role; echo; done \n```\n\n启动集群：\n\n```\nkubectl exec -it redis-cluster-0 -n gulimall -- redis-cli redis-cli -c -p 6379\n```\n\n","slug":"kubesphere快速部署redis","published":1,"updated":"2022-09-23T16:32:12.685Z","_id":"cl8ep14ml000e4kvj8rm76xxp","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、配置文件创建\"><a href=\"#一、配置文件创建\" class=\"headerlink\" title=\"一、配置文件创建\"></a>一、配置文件创建</h1><p>redis-conf：redis.conf</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">cluster-enabled yes <span class=\"hljs-comment\">#开启集群</span><br>cluster-config-file nodes.conf <span class=\"hljs-comment\">#集群node</span><br>cluster-<span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-timeout</span> <span class=\"hljs-number\">5000</span> <span class=\"hljs-comment\"># 集群延迟</span><br>appendonly yes <span class=\"hljs-comment\"># aof文件开启</span><br>masterauth <span class=\"hljs-number\">123456</span> <span class=\"hljs-comment\"># 密码</span><br>requirepass <span class=\"hljs-number\">123456</span> <span class=\"hljs-comment\"># 认证密码</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"二、redis有状态服务副本集创建\"><a href=\"#二、redis有状态服务副本集创建\" class=\"headerlink\" title=\"二、redis有状态服务副本集创建\"></a>二、redis有状态服务副本集创建</h1><p>存储卷模板：</p>\n<img src=\"/2022/07/27/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2redis/1663220903688.png\" class=\"\" width=\"1663220903688\">\n\n<p>redis 容器设置即启动命令配置</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">redis-server <span class=\"hljs-regexp\">/etc/</span>redis/redis.conf<br></code></pre></td></tr></table></figure>\n\n<img src=\"/2022/07/27/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2redis/1663213016039.png\" class=\"\" width=\"1663213016039\">\n\n<figure class=\"highlight subunit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs subunit\">[root@k8s-master01 kubesphere]# kubectl get pod,pvc -n gulimall<br>NAME                    READY   STATUS    RESTARTS   AGE<br>pod/mysql-master-v1<span class=\"hljs-string\">-0</span>   1/1     Running   0          13h<br>pod/redis-cluster<span class=\"hljs-string\">-0</span>     1/1     Running   0          30m<br>pod/redis-cluster<span class=\"hljs-string\">-1</span>     1/1     Running   0          26m<br>pod/redis-cluster<span class=\"hljs-string\">-2</span>     1/1     Running   0          26m<br>pod/redis-cluster<span class=\"hljs-string\">-3</span>     1/1     Running   0          26m<br>pod/redis-cluster<span class=\"hljs-string\">-4</span>     1/1     Running   0          26m<br>pod/redis-cluster<span class=\"hljs-string\">-5</span>     1/1     Running   0          26m<br><br>NAME                                              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       AGE<br>persistentvolumeclaim/mysql-pvc                   Bound    pvc-c912ac48-fce5<span class=\"hljs-string\">-4</span>ced<span class=\"hljs-string\">-9763</span><span class=\"hljs-string\">-2</span>b4c31687fab   30Gi       RWO            openebs-hostpath   14h<br>persistentvolumeclaim/pvc-redis-redis-cluster<span class=\"hljs-string\">-0</span>   Bound    pvc<span class=\"hljs-string\">-9638569</span>c<span class=\"hljs-string\">-0095</span><span class=\"hljs-string\">-4022</span><span class=\"hljs-string\">-9</span>a10<span class=\"hljs-string\">-31</span>b50602ad6d   10Gi       RWO            openebs-hostpath   30m<br>persistentvolumeclaim/pvc-redis-redis-cluster<span class=\"hljs-string\">-1</span>   Bound    pvc-b2f190ed<span class=\"hljs-string\">-720</span>b<span class=\"hljs-string\">-491</span>b<span class=\"hljs-string\">-8</span>d09<span class=\"hljs-string\">-7350854</span>c3f46   10Gi       RWO            openebs-hostpath   26m<br>persistentvolumeclaim/pvc-redis-redis-cluster<span class=\"hljs-string\">-2</span>   Bound    pvc<span class=\"hljs-string\">-36</span>a96ab2<span class=\"hljs-string\">-7</span>dc1<span class=\"hljs-string\">-4</span>cfd<span class=\"hljs-string\">-8</span>c7d<span class=\"hljs-string\">-7</span>f733d37e817   10Gi       RWO            openebs-hostpath   26m<br>persistentvolumeclaim/pvc-redis-redis-cluster<span class=\"hljs-string\">-3</span>   Bound    pvc<span class=\"hljs-string\">-0</span>a37fdd9<span class=\"hljs-string\">-4</span>b74<span class=\"hljs-string\">-4</span>fc0-b009-a5ed06ecac9c   10Gi       RWO            openebs-hostpath   26m<br>persistentvolumeclaim/pvc-redis-redis-cluster<span class=\"hljs-string\">-4</span>   Bound    pvc-ff8a3d3b<span class=\"hljs-string\">-2</span>ec2<span class=\"hljs-string\">-4132</span><span class=\"hljs-string\">-9</span>d09<span class=\"hljs-string\">-498</span>a25dcc506   10Gi       RWO            openebs-hostpath   26m<br>persistentvolumeclaim/pvc-redis-redis-cluster<span class=\"hljs-string\">-5</span>   Bound    pvc<span class=\"hljs-string\">-20635271</span>-fb88<span class=\"hljs-string\">-4904</span>-af26<span class=\"hljs-string\">-77754</span>bd64385   10Gi       RWO            openebs-hostpath   26m<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"三、查看ip\"><a href=\"#三、查看ip\" class=\"headerlink\" title=\"三、查看ip\"></a>三、查看ip</h1><figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\">[root@k8s-master01 kubesphere]# kubectl get pods -l app=redis-cluster -n gulimall -o jsonpath=&#x27;&#123;range.items[*]&#125;&#123;.status.podIP&#125;:<span class=\"hljs-number\">6379</span> &#x27;      <br><span class=\"hljs-number\">10.244.0.79</span>:<span class=\"hljs-number\">6379 10.244</span>.<span class=\"hljs-number\">0.81:6379</span> <span class=\"hljs-number\">10.244.0.83</span>:<span class=\"hljs-number\">6379 10.244</span>.<span class=\"hljs-number\">0.85:6379</span> <span class=\"hljs-number\">10.244.0.87</span>:<span class=\"hljs-number\">6379 10.244</span>.<span class=\"hljs-number\">0.89:6379</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"四、集群\"><a href=\"#四、集群\" class=\"headerlink\" title=\"四、集群\"></a>四、集群</h1><p>这里通过ip集群，最好通过pod.svc。例如：redis-cluster-0.redis-cluster-85pg,redis-cluster-1.redis-cluster-85pg,redis-cluster-2.redis-cluster-85pg,redis-cluster-3.redis-cluster-85pg,redis-cluster-4.redis-cluster-85pg,redis-cluster-5.redis-cluster-85pg</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\">kubectl exec -it redis-cluster-<span class=\"hljs-number\">0</span> -n gulimall -- redis-cli --cluster create --cluster-replicas <span class=\"hljs-number\">1</span> <span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> <span class=\"hljs-params\">pods</span> -<span class=\"hljs-params\">l</span> <span class=\"hljs-params\">app</span>=<span class=\"hljs-params\">redis</span>-<span class=\"hljs-params\">cluster</span> -<span class=\"hljs-params\">n</span> <span class=\"hljs-params\">gulimall</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=&#x27;&#123;<span class=\"hljs-params\">range</span>.<span class=\"hljs-params\">items</span>[<span class=\"hljs-operator\">*</span>]&#125;&#123;.<span class=\"hljs-params\">status</span>.<span class=\"hljs-params\">podIP</span>&#125;:6379 &#x27;)</span> -a <span class=\"hljs-number\">123456</span><br></code></pre></td></tr></table></figure>\n\n<p>结果打印：</p>\n<figure class=\"highlight vbnet\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs vbnet\"><span class=\"hljs-symbol\">Warning:</span> <span class=\"hljs-keyword\">Using</span> a password <span class=\"hljs-keyword\">with</span> <span class=\"hljs-comment\">&#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.</span><br>&gt;&gt;&gt; Performing hash slots allocation <span class=\"hljs-keyword\">on</span> <span class=\"hljs-number\">6</span> nodes...<br>Master[<span class=\"hljs-number\">0</span>] -&gt; Slots <span class=\"hljs-number\">0</span> - <span class=\"hljs-number\">5460</span><br>Master[<span class=\"hljs-number\">1</span>] -&gt; Slots <span class=\"hljs-number\">5461</span> - <span class=\"hljs-number\">10922</span><br>Master[<span class=\"hljs-number\">2</span>] -&gt; Slots <span class=\"hljs-number\">10923</span> - <span class=\"hljs-number\">16383</span><br>Adding replica <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.87</span>:<span class=\"hljs-number\">6379</span> <span class=\"hljs-keyword\">to</span> <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.79</span>:<span class=\"hljs-number\">6379</span><br>Adding replica <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.89</span>:<span class=\"hljs-number\">6379</span> <span class=\"hljs-keyword\">to</span> <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.81</span>:<span class=\"hljs-number\">6379</span><br>Adding replica <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.85</span>:<span class=\"hljs-number\">6379</span> <span class=\"hljs-keyword\">to</span> <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.83</span>:<span class=\"hljs-number\">6379</span><br><span class=\"hljs-symbol\">M:</span> <span class=\"hljs-number\">6</span>a8be8e3baaff7e6569484b68173f9ae929687a4 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.79</span>:<span class=\"hljs-number\">6379</span><br>   slots:[<span class=\"hljs-number\">0</span>-<span class=\"hljs-number\">5460</span>] (<span class=\"hljs-number\">5461</span> slots) master<br><span class=\"hljs-symbol\">M:</span> c902a47a859884e9d8e9e98463c998bafa8c456b <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.81</span>:<span class=\"hljs-number\">6379</span><br>   slots:[<span class=\"hljs-number\">5461</span>-<span class=\"hljs-number\">10922</span>] (<span class=\"hljs-number\">5462</span> slots) master<br><span class=\"hljs-symbol\">M:</span> edbddb2005e23a357f371fed804fc490bcabbdc0 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.83</span>:<span class=\"hljs-number\">6379</span><br>   slots:[<span class=\"hljs-number\">10923</span>-<span class=\"hljs-number\">16383</span>] (<span class=\"hljs-number\">5461</span> slots) master<br><span class=\"hljs-symbol\">S:</span> <span class=\"hljs-number\">6255</span>f444e9f53ba7d4e0c3714111820347f60ab8 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.85</span>:<span class=\"hljs-number\">6379</span><br>   replicates edbddb2005e23a357f371fed804fc490bcabbdc0<br><span class=\"hljs-symbol\">S:</span> <span class=\"hljs-number\">4563856</span>b15f4a6325c9f22dcc4f3b49b5867adc4 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.87</span>:<span class=\"hljs-number\">6379</span><br>   replicates <span class=\"hljs-number\">6</span>a8be8e3baaff7e6569484b68173f9ae929687a4<br><span class=\"hljs-symbol\">S:</span> db1d355eb2cf0ffa12240658aceadf737e00cfd3 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.89</span>:<span class=\"hljs-number\">6379</span><br>   replicates c902a47a859884e9d8e9e98463c998bafa8c456b<br>Can I <span class=\"hljs-keyword\">set</span> the above configuration? (type <span class=\"hljs-comment\">&#x27;yes&#x27; to accept): yes</span><br>&gt;&gt;&gt; Nodes configuration updated<br>&gt;&gt;&gt; Assign a different config epoch <span class=\"hljs-keyword\">to</span> <span class=\"hljs-keyword\">each</span> node<br>&gt;&gt;&gt; Sending CLUSTER MEET messages <span class=\"hljs-keyword\">to</span> <span class=\"hljs-keyword\">join</span> the cluster<br>Waiting <span class=\"hljs-keyword\">for</span> the cluster <span class=\"hljs-keyword\">to</span> <span class=\"hljs-keyword\">join</span><br>.<br>&gt;&gt;&gt; Performing Cluster Check (<span class=\"hljs-keyword\">using</span> node <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.79</span>:<span class=\"hljs-number\">6379</span>)<br><span class=\"hljs-symbol\">M:</span> <span class=\"hljs-number\">6</span>a8be8e3baaff7e6569484b68173f9ae929687a4 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.79</span>:<span class=\"hljs-number\">6379</span><br>   slots:[<span class=\"hljs-number\">0</span>-<span class=\"hljs-number\">5460</span>] (<span class=\"hljs-number\">5461</span> slots) master<br>   <span class=\"hljs-number\">1</span> additional replica(s)<br><span class=\"hljs-symbol\">S:</span> db1d355eb2cf0ffa12240658aceadf737e00cfd3 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.89</span>:<span class=\"hljs-number\">6379</span><br>   slots: (<span class=\"hljs-number\">0</span> slots) slave<br>   replicates c902a47a859884e9d8e9e98463c998bafa8c456b<br><span class=\"hljs-symbol\">S:</span> <span class=\"hljs-number\">6255</span>f444e9f53ba7d4e0c3714111820347f60ab8 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.85</span>:<span class=\"hljs-number\">6379</span><br>   slots: (<span class=\"hljs-number\">0</span> slots) slave<br>   replicates edbddb2005e23a357f371fed804fc490bcabbdc0<br><span class=\"hljs-symbol\">S:</span> <span class=\"hljs-number\">4563856</span>b15f4a6325c9f22dcc4f3b49b5867adc4 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.87</span>:<span class=\"hljs-number\">6379</span><br>   slots: (<span class=\"hljs-number\">0</span> slots) slave<br>   replicates <span class=\"hljs-number\">6</span>a8be8e3baaff7e6569484b68173f9ae929687a4<br><span class=\"hljs-symbol\">M:</span> c902a47a859884e9d8e9e98463c998bafa8c456b <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.81</span>:<span class=\"hljs-number\">6379</span><br>   slots:[<span class=\"hljs-number\">5461</span>-<span class=\"hljs-number\">10922</span>] (<span class=\"hljs-number\">5462</span> slots) master<br>   <span class=\"hljs-number\">1</span> additional replica(s)<br><span class=\"hljs-symbol\">M:</span> edbddb2005e23a357f371fed804fc490bcabbdc0 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.83</span>:<span class=\"hljs-number\">6379</span><br>   slots:[<span class=\"hljs-number\">10923</span>-<span class=\"hljs-number\">16383</span>] (<span class=\"hljs-number\">5461</span> slots) master<br>   <span class=\"hljs-number\">1</span> additional replica(s)<br>[OK] All nodes agree about slots configuration.<br>&gt;&gt;&gt; Check <span class=\"hljs-keyword\">for</span> open slots...<br>&gt;&gt;&gt; Check slots coverage...<br>[OK] All <span class=\"hljs-number\">16384</span> slots covered.<br></code></pre></td></tr></table></figure>\n\n<p>验证集群：</p>\n<figure class=\"highlight applescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs applescript\">kubectl exec -<span class=\"hljs-keyword\">it</span> redis-cluster<span class=\"hljs-number\">-0</span> -n gulimall <span class=\"hljs-comment\">-- redis-cli cluster info </span><br></code></pre></td></tr></table></figure>\n\n<p>角色查看：</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">[root@k8s-master01 src]# <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> $(seq <span class=\"hljs-number\">0</span> <span class=\"hljs-number\">5</span>); <span class=\"hljs-keyword\">do</span> echo &quot;redis-cluster-$x&quot;; kubectl exec redis-<span class=\"hljs-keyword\">cluster</span>-$x -n gulimall <span class=\"hljs-comment\">-- redis-cli -a 123456 role; echo; done </span><br>redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-0</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br>master<br><span class=\"hljs-number\">2215</span><br><span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.87</span><br><span class=\"hljs-number\">6379</span><br><span class=\"hljs-number\">2215</span><br><br>redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-1</span><br>master<br><span class=\"hljs-number\">2156</span><br><span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.89</span><br><span class=\"hljs-number\">6379</span><br><span class=\"hljs-number\">2156</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br><br>redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-2</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br>master<br><span class=\"hljs-number\">2156</span><br><span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.85</span><br><span class=\"hljs-number\">6379</span><br><span class=\"hljs-number\">2156</span><br><br>redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-3</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br>slave<br><span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.83</span><br><span class=\"hljs-number\">6379</span><br>connected<br><span class=\"hljs-number\">2156</span><br><br>redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-4</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br>slave<br><span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.79</span><br><span class=\"hljs-number\">6379</span><br>connected<br><span class=\"hljs-number\">2229</span><br><br>redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-5</span><br>slave<br><span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.81</span><br><span class=\"hljs-number\">6379</span><br>connected<br><span class=\"hljs-number\">2156</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br></code></pre></td></tr></table></figure>\n\n<p>启动集群：</p>\n<figure class=\"highlight stata\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stata\">kubectl exec -it redis-<span class=\"hljs-keyword\">cluster</span>-0 -<span class=\"hljs-keyword\">n</span> gulimall -- redis-<span class=\"hljs-keyword\">cli</span> redis-<span class=\"hljs-keyword\">cli</span> -c -p 6379<br></code></pre></td></tr></table></figure>\n\n<p>测试：</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">[root@k8s-master01 src]# kubectl exec redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-3</span> -n gulimall -it <span class=\"hljs-comment\">-- /bin/sh</span><br># redis-cli -c -a <span class=\"hljs-number\">123456</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br><span class=\"hljs-number\">127.0</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.1</span>:<span class=\"hljs-number\">6379</span>&gt; <span class=\"hljs-keyword\">get</span> aa<br>-&gt; Redirected <span class=\"hljs-keyword\">to</span> slot [<span class=\"hljs-number\">1180</span>] located at <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.79</span>:<span class=\"hljs-number\">6379</span><br>&quot;234234&quot;<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"五、整理操作\"><a href=\"#五、整理操作\" class=\"headerlink\" title=\"五、整理操作\"></a>五、整理操作</h1><p>软件版本：redis:5.0</p>\n<p>配置文件：redis-conf：redis.conf</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">cluster-enabled yes <span class=\"hljs-comment\">#开启集群</span><br>cluster-config-file nodes.conf <span class=\"hljs-comment\">#集群node</span><br>cluster-<span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-timeout</span> <span class=\"hljs-number\">5000</span> <span class=\"hljs-comment\"># 集群延迟</span><br>appendonly yes <span class=\"hljs-comment\"># aof文件开启</span><br>masterauth <span class=\"hljs-number\">123456</span> <span class=\"hljs-comment\"># 密码</span><br>requirepass <span class=\"hljs-number\">123456</span> <span class=\"hljs-comment\"># 认证密码</span><br></code></pre></td></tr></table></figure>\n\n<p>配置文件挂载：/etc/redis/redis.conf</p>\n<p>数据挂载：/data</p>\n<p>启动命令：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">redis-server <span class=\"hljs-regexp\">/etc/</span>redis/redis.conf<br></code></pre></td></tr></table></figure>\n\n<p>集群：</p>\n<figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\">kubectl exec -it redis-cluster-<span class=\"hljs-number\">0</span> -n gulimall -- redis-cli <span class=\"hljs-attr\">--cluster</span> create <span class=\"hljs-attr\">--cluster-replicas</span> <span class=\"hljs-number\">1</span> redis-cluster-<span class=\"hljs-number\">0</span><span class=\"hljs-selector-class\">.redis-cluster</span><span class=\"hljs-selector-class\">.gulimall</span>,redis-cluster-<span class=\"hljs-number\">1</span><span class=\"hljs-selector-class\">.redis-cluster</span><span class=\"hljs-selector-class\">.gulimall</span>,redis-cluster-<span class=\"hljs-number\">2</span><span class=\"hljs-selector-class\">.redis-cluster</span><span class=\"hljs-selector-class\">.gulimall</span>,redis-cluster-<span class=\"hljs-number\">3</span><span class=\"hljs-selector-class\">.redis-cluster</span><span class=\"hljs-selector-class\">.gulimall</span>,redis-cluster-<span class=\"hljs-number\">4</span><span class=\"hljs-selector-class\">.redis-cluster</span><span class=\"hljs-selector-class\">.gulimall</span>,redis-cluster-<span class=\"hljs-number\">5</span><span class=\"hljs-selector-class\">.redis-cluster</span><span class=\"hljs-selector-class\">.gulimall</span> -<span class=\"hljs-selector-tag\">a</span> <span class=\"hljs-number\">123456</span><br></code></pre></td></tr></table></figure>\n\n<p>验证集群：</p>\n<figure class=\"highlight applescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs applescript\">kubectl exec -<span class=\"hljs-keyword\">it</span> redis-cluster<span class=\"hljs-number\">-0</span> -n gulimall <span class=\"hljs-comment\">-- redis-cli cluster info </span><br></code></pre></td></tr></table></figure>\n\n<p>角色查看：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\"><span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> $(<span class=\"hljs-built_in\">seq</span> 0 5); <span class=\"hljs-keyword\">do</span> <span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;redis-cluster-<span class=\"hljs-variable\">$x</span>&quot;</span>; kubectl <span class=\"hljs-built_in\">exec</span> redis-cluster-<span class=\"hljs-variable\">$x</span> -n gulimall -- redis-cli -a 123456 role; <span class=\"hljs-built_in\">echo</span>; <span class=\"hljs-keyword\">done</span> <br></code></pre></td></tr></table></figure>\n\n<p>启动集群：</p>\n<figure class=\"highlight stata\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stata\">kubectl exec -it redis-<span class=\"hljs-keyword\">cluster</span>-0 -<span class=\"hljs-keyword\">n</span> gulimall -- redis-<span class=\"hljs-keyword\">cli</span> redis-<span class=\"hljs-keyword\">cli</span> -c -p 6379<br></code></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、配置文件创建\"><a href=\"#一、配置文件创建\" class=\"headerlink\" title=\"一、配置文件创建\"></a>一、配置文件创建</h1><p>redis-conf：redis.conf</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">cluster-enabled yes <span class=\"hljs-comment\">#开启集群</span><br>cluster-config-file nodes.conf <span class=\"hljs-comment\">#集群node</span><br>cluster-<span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-timeout</span> <span class=\"hljs-number\">5000</span> <span class=\"hljs-comment\"># 集群延迟</span><br>appendonly yes <span class=\"hljs-comment\"># aof文件开启</span><br>masterauth <span class=\"hljs-number\">123456</span> <span class=\"hljs-comment\"># 密码</span><br>requirepass <span class=\"hljs-number\">123456</span> <span class=\"hljs-comment\"># 认证密码</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"二、redis有状态服务副本集创建\"><a href=\"#二、redis有状态服务副本集创建\" class=\"headerlink\" title=\"二、redis有状态服务副本集创建\"></a>二、redis有状态服务副本集创建</h1><p>存储卷模板：</p>\n<img src=\"/2022/07/27/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2redis/1663220903688.png\" class=\"\" width=\"1663220903688\">\n\n<p>redis 容器设置即启动命令配置</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">redis-server <span class=\"hljs-regexp\">/etc/</span>redis/redis.conf<br></code></pre></td></tr></table></figure>\n\n<img src=\"/2022/07/27/kubesphere%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2redis/1663213016039.png\" class=\"\" width=\"1663213016039\">\n\n<figure class=\"highlight subunit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs subunit\">[root@k8s-master01 kubesphere]# kubectl get pod,pvc -n gulimall<br>NAME                    READY   STATUS    RESTARTS   AGE<br>pod/mysql-master-v1<span class=\"hljs-string\">-0</span>   1/1     Running   0          13h<br>pod/redis-cluster<span class=\"hljs-string\">-0</span>     1/1     Running   0          30m<br>pod/redis-cluster<span class=\"hljs-string\">-1</span>     1/1     Running   0          26m<br>pod/redis-cluster<span class=\"hljs-string\">-2</span>     1/1     Running   0          26m<br>pod/redis-cluster<span class=\"hljs-string\">-3</span>     1/1     Running   0          26m<br>pod/redis-cluster<span class=\"hljs-string\">-4</span>     1/1     Running   0          26m<br>pod/redis-cluster<span class=\"hljs-string\">-5</span>     1/1     Running   0          26m<br><br>NAME                                              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       AGE<br>persistentvolumeclaim/mysql-pvc                   Bound    pvc-c912ac48-fce5<span class=\"hljs-string\">-4</span>ced<span class=\"hljs-string\">-9763</span><span class=\"hljs-string\">-2</span>b4c31687fab   30Gi       RWO            openebs-hostpath   14h<br>persistentvolumeclaim/pvc-redis-redis-cluster<span class=\"hljs-string\">-0</span>   Bound    pvc<span class=\"hljs-string\">-9638569</span>c<span class=\"hljs-string\">-0095</span><span class=\"hljs-string\">-4022</span><span class=\"hljs-string\">-9</span>a10<span class=\"hljs-string\">-31</span>b50602ad6d   10Gi       RWO            openebs-hostpath   30m<br>persistentvolumeclaim/pvc-redis-redis-cluster<span class=\"hljs-string\">-1</span>   Bound    pvc-b2f190ed<span class=\"hljs-string\">-720</span>b<span class=\"hljs-string\">-491</span>b<span class=\"hljs-string\">-8</span>d09<span class=\"hljs-string\">-7350854</span>c3f46   10Gi       RWO            openebs-hostpath   26m<br>persistentvolumeclaim/pvc-redis-redis-cluster<span class=\"hljs-string\">-2</span>   Bound    pvc<span class=\"hljs-string\">-36</span>a96ab2<span class=\"hljs-string\">-7</span>dc1<span class=\"hljs-string\">-4</span>cfd<span class=\"hljs-string\">-8</span>c7d<span class=\"hljs-string\">-7</span>f733d37e817   10Gi       RWO            openebs-hostpath   26m<br>persistentvolumeclaim/pvc-redis-redis-cluster<span class=\"hljs-string\">-3</span>   Bound    pvc<span class=\"hljs-string\">-0</span>a37fdd9<span class=\"hljs-string\">-4</span>b74<span class=\"hljs-string\">-4</span>fc0-b009-a5ed06ecac9c   10Gi       RWO            openebs-hostpath   26m<br>persistentvolumeclaim/pvc-redis-redis-cluster<span class=\"hljs-string\">-4</span>   Bound    pvc-ff8a3d3b<span class=\"hljs-string\">-2</span>ec2<span class=\"hljs-string\">-4132</span><span class=\"hljs-string\">-9</span>d09<span class=\"hljs-string\">-498</span>a25dcc506   10Gi       RWO            openebs-hostpath   26m<br>persistentvolumeclaim/pvc-redis-redis-cluster<span class=\"hljs-string\">-5</span>   Bound    pvc<span class=\"hljs-string\">-20635271</span>-fb88<span class=\"hljs-string\">-4904</span>-af26<span class=\"hljs-string\">-77754</span>bd64385   10Gi       RWO            openebs-hostpath   26m<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"三、查看ip\"><a href=\"#三、查看ip\" class=\"headerlink\" title=\"三、查看ip\"></a>三、查看ip</h1><figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\">[root@k8s-master01 kubesphere]# kubectl get pods -l app=redis-cluster -n gulimall -o jsonpath=&#x27;&#123;range.items[*]&#125;&#123;.status.podIP&#125;:<span class=\"hljs-number\">6379</span> &#x27;      <br><span class=\"hljs-number\">10.244.0.79</span>:<span class=\"hljs-number\">6379 10.244</span>.<span class=\"hljs-number\">0.81:6379</span> <span class=\"hljs-number\">10.244.0.83</span>:<span class=\"hljs-number\">6379 10.244</span>.<span class=\"hljs-number\">0.85:6379</span> <span class=\"hljs-number\">10.244.0.87</span>:<span class=\"hljs-number\">6379 10.244</span>.<span class=\"hljs-number\">0.89:6379</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"四、集群\"><a href=\"#四、集群\" class=\"headerlink\" title=\"四、集群\"></a>四、集群</h1><p>这里通过ip集群，最好通过pod.svc。例如：redis-cluster-0.redis-cluster-85pg,redis-cluster-1.redis-cluster-85pg,redis-cluster-2.redis-cluster-85pg,redis-cluster-3.redis-cluster-85pg,redis-cluster-4.redis-cluster-85pg,redis-cluster-5.redis-cluster-85pg</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\">kubectl exec -it redis-cluster-<span class=\"hljs-number\">0</span> -n gulimall -- redis-cli --cluster create --cluster-replicas <span class=\"hljs-number\">1</span> <span class=\"hljs-constructor\">$(<span class=\"hljs-params\">kubectl</span> <span class=\"hljs-params\">get</span> <span class=\"hljs-params\">pods</span> -<span class=\"hljs-params\">l</span> <span class=\"hljs-params\">app</span>=<span class=\"hljs-params\">redis</span>-<span class=\"hljs-params\">cluster</span> -<span class=\"hljs-params\">n</span> <span class=\"hljs-params\">gulimall</span> -<span class=\"hljs-params\">o</span> <span class=\"hljs-params\">jsonpath</span>=&#x27;&#123;<span class=\"hljs-params\">range</span>.<span class=\"hljs-params\">items</span>[<span class=\"hljs-operator\">*</span>]&#125;&#123;.<span class=\"hljs-params\">status</span>.<span class=\"hljs-params\">podIP</span>&#125;:6379 &#x27;)</span> -a <span class=\"hljs-number\">123456</span><br></code></pre></td></tr></table></figure>\n\n<p>结果打印：</p>\n<figure class=\"highlight vbnet\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs vbnet\"><span class=\"hljs-symbol\">Warning:</span> <span class=\"hljs-keyword\">Using</span> a password <span class=\"hljs-keyword\">with</span> <span class=\"hljs-comment\">&#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.</span><br>&gt;&gt;&gt; Performing hash slots allocation <span class=\"hljs-keyword\">on</span> <span class=\"hljs-number\">6</span> nodes...<br>Master[<span class=\"hljs-number\">0</span>] -&gt; Slots <span class=\"hljs-number\">0</span> - <span class=\"hljs-number\">5460</span><br>Master[<span class=\"hljs-number\">1</span>] -&gt; Slots <span class=\"hljs-number\">5461</span> - <span class=\"hljs-number\">10922</span><br>Master[<span class=\"hljs-number\">2</span>] -&gt; Slots <span class=\"hljs-number\">10923</span> - <span class=\"hljs-number\">16383</span><br>Adding replica <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.87</span>:<span class=\"hljs-number\">6379</span> <span class=\"hljs-keyword\">to</span> <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.79</span>:<span class=\"hljs-number\">6379</span><br>Adding replica <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.89</span>:<span class=\"hljs-number\">6379</span> <span class=\"hljs-keyword\">to</span> <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.81</span>:<span class=\"hljs-number\">6379</span><br>Adding replica <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.85</span>:<span class=\"hljs-number\">6379</span> <span class=\"hljs-keyword\">to</span> <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.83</span>:<span class=\"hljs-number\">6379</span><br><span class=\"hljs-symbol\">M:</span> <span class=\"hljs-number\">6</span>a8be8e3baaff7e6569484b68173f9ae929687a4 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.79</span>:<span class=\"hljs-number\">6379</span><br>   slots:[<span class=\"hljs-number\">0</span>-<span class=\"hljs-number\">5460</span>] (<span class=\"hljs-number\">5461</span> slots) master<br><span class=\"hljs-symbol\">M:</span> c902a47a859884e9d8e9e98463c998bafa8c456b <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.81</span>:<span class=\"hljs-number\">6379</span><br>   slots:[<span class=\"hljs-number\">5461</span>-<span class=\"hljs-number\">10922</span>] (<span class=\"hljs-number\">5462</span> slots) master<br><span class=\"hljs-symbol\">M:</span> edbddb2005e23a357f371fed804fc490bcabbdc0 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.83</span>:<span class=\"hljs-number\">6379</span><br>   slots:[<span class=\"hljs-number\">10923</span>-<span class=\"hljs-number\">16383</span>] (<span class=\"hljs-number\">5461</span> slots) master<br><span class=\"hljs-symbol\">S:</span> <span class=\"hljs-number\">6255</span>f444e9f53ba7d4e0c3714111820347f60ab8 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.85</span>:<span class=\"hljs-number\">6379</span><br>   replicates edbddb2005e23a357f371fed804fc490bcabbdc0<br><span class=\"hljs-symbol\">S:</span> <span class=\"hljs-number\">4563856</span>b15f4a6325c9f22dcc4f3b49b5867adc4 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.87</span>:<span class=\"hljs-number\">6379</span><br>   replicates <span class=\"hljs-number\">6</span>a8be8e3baaff7e6569484b68173f9ae929687a4<br><span class=\"hljs-symbol\">S:</span> db1d355eb2cf0ffa12240658aceadf737e00cfd3 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.89</span>:<span class=\"hljs-number\">6379</span><br>   replicates c902a47a859884e9d8e9e98463c998bafa8c456b<br>Can I <span class=\"hljs-keyword\">set</span> the above configuration? (type <span class=\"hljs-comment\">&#x27;yes&#x27; to accept): yes</span><br>&gt;&gt;&gt; Nodes configuration updated<br>&gt;&gt;&gt; Assign a different config epoch <span class=\"hljs-keyword\">to</span> <span class=\"hljs-keyword\">each</span> node<br>&gt;&gt;&gt; Sending CLUSTER MEET messages <span class=\"hljs-keyword\">to</span> <span class=\"hljs-keyword\">join</span> the cluster<br>Waiting <span class=\"hljs-keyword\">for</span> the cluster <span class=\"hljs-keyword\">to</span> <span class=\"hljs-keyword\">join</span><br>.<br>&gt;&gt;&gt; Performing Cluster Check (<span class=\"hljs-keyword\">using</span> node <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.79</span>:<span class=\"hljs-number\">6379</span>)<br><span class=\"hljs-symbol\">M:</span> <span class=\"hljs-number\">6</span>a8be8e3baaff7e6569484b68173f9ae929687a4 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.79</span>:<span class=\"hljs-number\">6379</span><br>   slots:[<span class=\"hljs-number\">0</span>-<span class=\"hljs-number\">5460</span>] (<span class=\"hljs-number\">5461</span> slots) master<br>   <span class=\"hljs-number\">1</span> additional replica(s)<br><span class=\"hljs-symbol\">S:</span> db1d355eb2cf0ffa12240658aceadf737e00cfd3 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.89</span>:<span class=\"hljs-number\">6379</span><br>   slots: (<span class=\"hljs-number\">0</span> slots) slave<br>   replicates c902a47a859884e9d8e9e98463c998bafa8c456b<br><span class=\"hljs-symbol\">S:</span> <span class=\"hljs-number\">6255</span>f444e9f53ba7d4e0c3714111820347f60ab8 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.85</span>:<span class=\"hljs-number\">6379</span><br>   slots: (<span class=\"hljs-number\">0</span> slots) slave<br>   replicates edbddb2005e23a357f371fed804fc490bcabbdc0<br><span class=\"hljs-symbol\">S:</span> <span class=\"hljs-number\">4563856</span>b15f4a6325c9f22dcc4f3b49b5867adc4 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.87</span>:<span class=\"hljs-number\">6379</span><br>   slots: (<span class=\"hljs-number\">0</span> slots) slave<br>   replicates <span class=\"hljs-number\">6</span>a8be8e3baaff7e6569484b68173f9ae929687a4<br><span class=\"hljs-symbol\">M:</span> c902a47a859884e9d8e9e98463c998bafa8c456b <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.81</span>:<span class=\"hljs-number\">6379</span><br>   slots:[<span class=\"hljs-number\">5461</span>-<span class=\"hljs-number\">10922</span>] (<span class=\"hljs-number\">5462</span> slots) master<br>   <span class=\"hljs-number\">1</span> additional replica(s)<br><span class=\"hljs-symbol\">M:</span> edbddb2005e23a357f371fed804fc490bcabbdc0 <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.83</span>:<span class=\"hljs-number\">6379</span><br>   slots:[<span class=\"hljs-number\">10923</span>-<span class=\"hljs-number\">16383</span>] (<span class=\"hljs-number\">5461</span> slots) master<br>   <span class=\"hljs-number\">1</span> additional replica(s)<br>[OK] All nodes agree about slots configuration.<br>&gt;&gt;&gt; Check <span class=\"hljs-keyword\">for</span> open slots...<br>&gt;&gt;&gt; Check slots coverage...<br>[OK] All <span class=\"hljs-number\">16384</span> slots covered.<br></code></pre></td></tr></table></figure>\n\n<p>验证集群：</p>\n<figure class=\"highlight applescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs applescript\">kubectl exec -<span class=\"hljs-keyword\">it</span> redis-cluster<span class=\"hljs-number\">-0</span> -n gulimall <span class=\"hljs-comment\">-- redis-cli cluster info </span><br></code></pre></td></tr></table></figure>\n\n<p>角色查看：</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">[root@k8s-master01 src]# <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> $(seq <span class=\"hljs-number\">0</span> <span class=\"hljs-number\">5</span>); <span class=\"hljs-keyword\">do</span> echo &quot;redis-cluster-$x&quot;; kubectl exec redis-<span class=\"hljs-keyword\">cluster</span>-$x -n gulimall <span class=\"hljs-comment\">-- redis-cli -a 123456 role; echo; done </span><br>redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-0</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br>master<br><span class=\"hljs-number\">2215</span><br><span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.87</span><br><span class=\"hljs-number\">6379</span><br><span class=\"hljs-number\">2215</span><br><br>redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-1</span><br>master<br><span class=\"hljs-number\">2156</span><br><span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.89</span><br><span class=\"hljs-number\">6379</span><br><span class=\"hljs-number\">2156</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br><br>redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-2</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br>master<br><span class=\"hljs-number\">2156</span><br><span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.85</span><br><span class=\"hljs-number\">6379</span><br><span class=\"hljs-number\">2156</span><br><br>redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-3</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br>slave<br><span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.83</span><br><span class=\"hljs-number\">6379</span><br>connected<br><span class=\"hljs-number\">2156</span><br><br>redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-4</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br>slave<br><span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.79</span><br><span class=\"hljs-number\">6379</span><br>connected<br><span class=\"hljs-number\">2229</span><br><br>redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-5</span><br>slave<br><span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.81</span><br><span class=\"hljs-number\">6379</span><br>connected<br><span class=\"hljs-number\">2156</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br></code></pre></td></tr></table></figure>\n\n<p>启动集群：</p>\n<figure class=\"highlight stata\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stata\">kubectl exec -it redis-<span class=\"hljs-keyword\">cluster</span>-0 -<span class=\"hljs-keyword\">n</span> gulimall -- redis-<span class=\"hljs-keyword\">cli</span> redis-<span class=\"hljs-keyword\">cli</span> -c -p 6379<br></code></pre></td></tr></table></figure>\n\n<p>测试：</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">[root@k8s-master01 src]# kubectl exec redis-<span class=\"hljs-keyword\">cluster</span><span class=\"hljs-number\">-3</span> -n gulimall -it <span class=\"hljs-comment\">-- /bin/sh</span><br># redis-cli -c -a <span class=\"hljs-number\">123456</span><br><span class=\"hljs-built_in\">Warning</span>: <span class=\"hljs-keyword\">Using</span> a <span class=\"hljs-keyword\">password</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-string\">&#x27;-a&#x27;</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;-u&#x27;</span> <span class=\"hljs-keyword\">option</span> <span class=\"hljs-keyword\">on</span> the command <span class=\"hljs-type\">line</span> interface may <span class=\"hljs-keyword\">not</span> be safe.<br><span class=\"hljs-number\">127.0</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.1</span>:<span class=\"hljs-number\">6379</span>&gt; <span class=\"hljs-keyword\">get</span> aa<br>-&gt; Redirected <span class=\"hljs-keyword\">to</span> slot [<span class=\"hljs-number\">1180</span>] located at <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.79</span>:<span class=\"hljs-number\">6379</span><br>&quot;234234&quot;<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"五、整理操作\"><a href=\"#五、整理操作\" class=\"headerlink\" title=\"五、整理操作\"></a>五、整理操作</h1><p>软件版本：redis:5.0</p>\n<p>配置文件：redis-conf：redis.conf</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">cluster-enabled yes <span class=\"hljs-comment\">#开启集群</span><br>cluster-config-file nodes.conf <span class=\"hljs-comment\">#集群node</span><br>cluster-<span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-timeout</span> <span class=\"hljs-number\">5000</span> <span class=\"hljs-comment\"># 集群延迟</span><br>appendonly yes <span class=\"hljs-comment\"># aof文件开启</span><br>masterauth <span class=\"hljs-number\">123456</span> <span class=\"hljs-comment\"># 密码</span><br>requirepass <span class=\"hljs-number\">123456</span> <span class=\"hljs-comment\"># 认证密码</span><br></code></pre></td></tr></table></figure>\n\n<p>配置文件挂载：/etc/redis/redis.conf</p>\n<p>数据挂载：/data</p>\n<p>启动命令：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">redis-server <span class=\"hljs-regexp\">/etc/</span>redis/redis.conf<br></code></pre></td></tr></table></figure>\n\n<p>集群：</p>\n<figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\">kubectl exec -it redis-cluster-<span class=\"hljs-number\">0</span> -n gulimall -- redis-cli <span class=\"hljs-attr\">--cluster</span> create <span class=\"hljs-attr\">--cluster-replicas</span> <span class=\"hljs-number\">1</span> redis-cluster-<span class=\"hljs-number\">0</span><span class=\"hljs-selector-class\">.redis-cluster</span><span class=\"hljs-selector-class\">.gulimall</span>,redis-cluster-<span class=\"hljs-number\">1</span><span class=\"hljs-selector-class\">.redis-cluster</span><span class=\"hljs-selector-class\">.gulimall</span>,redis-cluster-<span class=\"hljs-number\">2</span><span class=\"hljs-selector-class\">.redis-cluster</span><span class=\"hljs-selector-class\">.gulimall</span>,redis-cluster-<span class=\"hljs-number\">3</span><span class=\"hljs-selector-class\">.redis-cluster</span><span class=\"hljs-selector-class\">.gulimall</span>,redis-cluster-<span class=\"hljs-number\">4</span><span class=\"hljs-selector-class\">.redis-cluster</span><span class=\"hljs-selector-class\">.gulimall</span>,redis-cluster-<span class=\"hljs-number\">5</span><span class=\"hljs-selector-class\">.redis-cluster</span><span class=\"hljs-selector-class\">.gulimall</span> -<span class=\"hljs-selector-tag\">a</span> <span class=\"hljs-number\">123456</span><br></code></pre></td></tr></table></figure>\n\n<p>验证集群：</p>\n<figure class=\"highlight applescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs applescript\">kubectl exec -<span class=\"hljs-keyword\">it</span> redis-cluster<span class=\"hljs-number\">-0</span> -n gulimall <span class=\"hljs-comment\">-- redis-cli cluster info </span><br></code></pre></td></tr></table></figure>\n\n<p>角色查看：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\"><span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> $(<span class=\"hljs-built_in\">seq</span> 0 5); <span class=\"hljs-keyword\">do</span> <span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;redis-cluster-<span class=\"hljs-variable\">$x</span>&quot;</span>; kubectl <span class=\"hljs-built_in\">exec</span> redis-cluster-<span class=\"hljs-variable\">$x</span> -n gulimall -- redis-cli -a 123456 role; <span class=\"hljs-built_in\">echo</span>; <span class=\"hljs-keyword\">done</span> <br></code></pre></td></tr></table></figure>\n\n<p>启动集群：</p>\n<figure class=\"highlight stata\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stata\">kubectl exec -it redis-<span class=\"hljs-keyword\">cluster</span>-0 -<span class=\"hljs-keyword\">n</span> gulimall -- redis-<span class=\"hljs-keyword\">cli</span> redis-<span class=\"hljs-keyword\">cli</span> -c -p 6379<br></code></pre></td></tr></table></figure>\n\n"},{"title":"k8s资源清单及常用字段","date":"2021-07-27T11:38:02.000Z","_content":"\nK8s中所有的内容都抽象为资源,资源实例化之后,叫做对象。\n\n# 名称空间级别\n\n工作负载型资源(workload ): Pod、 ReplicaSet, Deployment、 StatefulSet、DaemonSet、Job、CronJob (ReplicationController 在vl.11 版本被废弃)\n\n服务发现及负载均衡型资源( ServiceDiscovery LoadBalance )： Service, Ingress. ...\n\n配置与存储型资源： Volume(存储卷)、CSI(容器存储接口,可以扩展各种各样的第三方存储卷)\n\n特殊类型的存储卷：ConfigMap(当配置中心来使用的资源类型)、Secret(保存敏感数据)、DownwardAPI (把外部环境中的信息输出给容器)\n\n集群级资源: Namespace、 Node、 Role、 ClusterRole, RoleBinding、 ClusterRoleBinding\n\n元数据型资源: HPA、 PodTemplate、 LimitRange\n\n# 资源清单常用字段\n\nk8s 集群中对资源管理和资源对象编排部署都可以通过声明样式（YAML）文件来解决，通过kubectl 命令直接使用资源清单文件就可以实现对大量的资源对象进行编排部署了。这样的yaml文件我们一般称为资源清单。\n\n## 必须存在的属性\n\n| 参数名                 | 字段类型 | 说明                                           |\n| ---------------------- | -------- | ---------------------------------------------- |\n| version                | string   | K8S API的版本，可以通过kubectl api-version查询 |\n| kind                   | string   | 资源类型和角色                                 |\n| metadata               | object   | 元数据对象                                     |\n| metadata.name          | string   | 元数据对象的名称，比如pod的名字                |\n| metadata.namespace     | string   | 元数据对象的命名控件                           |\n| spec                   | object   | 详细定义对象                                   |\n| spec.container[]       | list     | 容器列表                                       |\n| spec.container[].name  | string   | 定义容器名称                                   |\n| spec.container[].image | string   | 定义用到镜像名称                               |\n\n## spec 主要对象\n\n| 参数名                                                       | 字段类型 | 说明                                                         |\n| ------------------------------------------------------------ | -------- | ------------------------------------------------------------ |\n| version                                                      | string   | K8S API的版本，可以通过kubectl api-version查询               |\n| kind                                                         | string   | 资源类型和角色                                               |\n| metadata                                                     | object   | 元数据对象                                                   |\n| metadata.name                                                | string   | 元数据对象的名称，比如pod的名字                              |\n| metadata.namespace                                           | string   | 元数据对象的命名控件                                         |\n| metadata.labels                                              | list     | 自定义标签列表                                               |\n| metadata.annotations                                         | list     | 自定义注解列表                                               |\n| spec                                                         | object   | 详细定义对象                                                 |\n| spec.container[]                                             | list     | 容器列表                                                     |\n| spec.container[].name                                        | string   | 定义容器名称                                                 |\n| spec.container[].image                                       | string   | 定义用到镜像名称                                             |\n| spec.container[].imagePullPolicy                             | string   | 镜像拉取策略,    Always：不管镜像是否存在都会进行一次拉取。  Never：不管镜像是否存在都不会进行拉取  IfNotPresent：只有镜像不存在时，才会进行镜像拉取。 |\n| spec.container[].command[]                                   | list     | 指定容器启动命令                                             |\n| spec.container[].args[]                                      | list     | 命令参数                                                     |\n| spec.container[].workingDir                                  | string   | 指定容器的工作目录                                           |\n| spec.container[].volumeMounts[]                              | list     | 指定容器内部的存储卷配置                                     |\n| spec.container[].volumeMounts[].name                         | string   | 指定挂载存储卷的名称                                         |\n| spec.container[].volumeMounts[].mountPath                    | string   | 指定挂载存储卷的路径                                         |\n| spec.container[].volumeMounts[].readyOnly                    | string   | true或false，读写模式                                        |\n| spec.container[].ports[]                                     | list     | 指定容器需要用到的端口列表                                   |\n| spec.container[].ports[].name                                | string   | 端口名称                                                     |\n| spec.container[].ports[].containerPort                       | string   | 指定容器要监听的端口号                                       |\n| spec.container[].ports[].hostPort                            | string   | 指定容器所在主机需要监听的端口号，默认跟containerPort相同，如果设置了hostPort同一台主机无法启动该容器的相同副本(因为主机的端口号不能相同，这样会冲突) |\n| spec.container[].ports[].protocol                            | string   | 指定端口协议，支持TCP和UDP，默认值TCP                        |\n| spec.container[].env[]                                       | list     | 指定容器运行需要的环境                                       |\n| spec.container[].env[].name                                  | string   | 环境变量名称                                                 |\n| spec.container[].env[].value                                 | string   | 环境变量值                                                   |\n| spec.container[].resources                                   | object   | 指定资源限制和资源请求的值                                   |\n| spec.container[].resources.limits                            | object   | 指定设置容器运行时资源的运行上限                             |\n| spec.container[].resources.limits.cpu                        | string   | 指定cpu的限制，单位core数，将用于docker run --cpu-shares 参数 |\n| spec.container[].resources.limits.memory                     | string   | 指定MEM内存的限制，单位MIB ,GIB                              |\n| spec.container[].resources.requests                          | object   | 指定容器启动和调度的限制设置                                 |\n| spec.container[].resources.requests.cpu                      | string   | cpu请求，单位core数，容器启动时初始化可用数量                |\n| spec.container[].resources.requests.memory                   | string   | 内存请求，单位MIB,GIB 容器启动的初始化可用数量               |\n| spec.container[].livenessProbe                               | object   | 对Pod内各容器健康检查的设置，当探测无响应几次之后，系统将自动重启该容器。可以设置的方法包括：exec、httpGet和tcpSocket。对一个容器仅需设置一种健康检查方法 |\n| spec.container[].livenessProbe.exec                          | object   | 对Pod内各容器健康检查的设置                                  |\n| spec.container[].livenessProbe.exec.command[]                | list     | exec方式需要指定的命令或者脚本                               |\n| spec.container[].livenessProbe.httpGet                       | object   | 对Pod内各容器健康检查的设置，httpget方式。需指定path、port   |\n| spec.container[].livenessProbe.httpGet.path                  | string   |                                                              |\n| spec.container[].livenessProbe.httpGet.port                  | string   |                                                              |\n| spec.container[].livenessProbe.httpGet.host                  | string   |                                                              |\n| spec.container[].livenessProbe.httpGet.scheme                | string   |                                                              |\n| spec.container[].livenessProbe.httpGet .httpHeaders[]        | list     |                                                              |\n| spec.container[].livenessProbe.httpGet .httpHeaders[] .name  | string   |                                                              |\n| spec.container[].livenessProbe.httpGet .httpHeaders[] .value | string   |                                                              |\n| spec.container[].livenessProbe.tcpSocket                     | object   |                                                              |\n| spec.container[].livenessProbe.tcpSocket.port                | string   |                                                              |\n| spec.container[].livenessProbe.initialDelaySeconds           | string   | 容器启动完成后首次探测的时间，单位为s                        |\n| spec.container[].livenessProbe.timeoutSeconds                | string   | 探测等待响应的超时时间，单位为s,默认1s                       |\n| spec.container[].livenessProbe.periodSeconds                 | string   | 定期探测时间设置，单位s,默认10s探测一次                      |\n| spec.container[].livenessProbe.successThreshold              | string   | 失败后检查成功的最小连续成功次数。默认为1.活跃度必须为1。最小值为1。 |\n| spec.container[].livenessProbe.failureThreshold              | string   | 当Pod成功启动且检查失败时，Kubernetes将在放弃之前尝试failureThreshold次。放弃生存检查意味着重新启动Pod。而放弃就绪检查，Pod将被标记为未就绪。默认为3.最小值为1。 |\n| spec.container[].livenessProbe.securityContext               | object   |                                                              |\n| spec.container[].livenessProbe.securityContext .privileged   | string   |                                                              |\n| spec.restartPolicy                                           | string   | 定义pod重启策略，默认值Always                   Always：Pod一旦终止运行，则无论容器是如何终止的kubelet服务都将重启它                    OnFailure：只有Pod以非零退出码终止时，kubelet才会重启该容器，如果容器正常结束（退出码为0），则kubelet将不会重启它      Never：Pod终止后，kubelet将退出码报告给Master，不会重启该Pod |\n| spec.nodeSelector                                            | object   | 定义node的label过滤标签，以key：value格式指定                |\n| spec.imagePullSecrets                                        | Object   | 定义pull镜像secret名称，以name:secretKey格式指定             |\n| spec.hostNetwork                                             | Boolean  | 定义是否使用主机网络模式，默认值false，设置true表示使用宿主网路，不适用docker网桥，同时设置true将无法在同一台宿主机上启动第二个副本。 |\n| spec.volumes[]                                               | list     | 在该pod上定义的共享存储卷列表                                |\n| spec.volumes[].name                                          | string   | 共享存储卷的名称，在一个pod中每个存储卷定义一个名称，容器定义部分的containers[].volumeMounts[].name将引用该共享存储卷的名称。可以定义多个volume，每个volume的name保持唯一。 |\n| spec.volumes[].emptyDir                                      | string   | 类型为emptyDir的存储卷，表示与Pod同生命周期的一个临时目录，其值为一个空对象：emptyDir:{} |\n| spec.volumes[].hostPath                                      | object   | 类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录，通过volume[].hostPath.path指定 |\n| spec.volumes[].hostPath.path                                 | string   | Pod所在主机的目录，将被用于容器中mount的目录                 |\n| spec.volumes[].secret                                        | object   | 类型为secret的存储卷，表示挂载集群预定义的secret对象到容器内部 |\n| spec.volumes[].secret.secretName                             | string   |                                                              |\n| spec.volumes[].secret.items[]                                | list     |                                                              |\n| spec.volumes[].secret.items[].key                            | string   |                                                              |\n| spec.volumes[].secret.items[].path                           | string   |                                                              |\n| spec.volumes[].configMap                                     | object   | 类型为configMap的存储卷，表示挂载集群预定义的configMap对象到容器内部 |\n| spec.volumes[].configMap.name                                | string   |                                                              |\n| spec.volumes[].configMap.items[]                             | list     |                                                              |\n| spec.volumes[].configMap.items[].key                         | string   |                                                              |\n| spec.volumes[].configMap.items[].path                        | string   |                                                              |\n\n# 资源清单格式\n\n```\napiVersion: group/apiversion #如果没有给定group名称,那么默认为core,可以使用kubectl api-versions #获取当前k8s版本上所有的 apiVersion版本信息(每个版本可能不同)\nkind:#资源类别\nmetadata:#资源元数据\n  name\n  namespace\n  1ables\n  annotations #主要目的是方便用户阅读查找\nspec: #期望的状态(disired state)\nstatus: #当前状态,本字段有Kubernetes 自身维护,用户不能去定义\n\n```\n\n","source":"_posts/k8s资源清单及常用字段.md","raw":"---\ntitle: k8s资源清单及常用字段\ndate: 2021-07-27 19:38:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n---\n\nK8s中所有的内容都抽象为资源,资源实例化之后,叫做对象。\n\n# 名称空间级别\n\n工作负载型资源(workload ): Pod、 ReplicaSet, Deployment、 StatefulSet、DaemonSet、Job、CronJob (ReplicationController 在vl.11 版本被废弃)\n\n服务发现及负载均衡型资源( ServiceDiscovery LoadBalance )： Service, Ingress. ...\n\n配置与存储型资源： Volume(存储卷)、CSI(容器存储接口,可以扩展各种各样的第三方存储卷)\n\n特殊类型的存储卷：ConfigMap(当配置中心来使用的资源类型)、Secret(保存敏感数据)、DownwardAPI (把外部环境中的信息输出给容器)\n\n集群级资源: Namespace、 Node、 Role、 ClusterRole, RoleBinding、 ClusterRoleBinding\n\n元数据型资源: HPA、 PodTemplate、 LimitRange\n\n# 资源清单常用字段\n\nk8s 集群中对资源管理和资源对象编排部署都可以通过声明样式（YAML）文件来解决，通过kubectl 命令直接使用资源清单文件就可以实现对大量的资源对象进行编排部署了。这样的yaml文件我们一般称为资源清单。\n\n## 必须存在的属性\n\n| 参数名                 | 字段类型 | 说明                                           |\n| ---------------------- | -------- | ---------------------------------------------- |\n| version                | string   | K8S API的版本，可以通过kubectl api-version查询 |\n| kind                   | string   | 资源类型和角色                                 |\n| metadata               | object   | 元数据对象                                     |\n| metadata.name          | string   | 元数据对象的名称，比如pod的名字                |\n| metadata.namespace     | string   | 元数据对象的命名控件                           |\n| spec                   | object   | 详细定义对象                                   |\n| spec.container[]       | list     | 容器列表                                       |\n| spec.container[].name  | string   | 定义容器名称                                   |\n| spec.container[].image | string   | 定义用到镜像名称                               |\n\n## spec 主要对象\n\n| 参数名                                                       | 字段类型 | 说明                                                         |\n| ------------------------------------------------------------ | -------- | ------------------------------------------------------------ |\n| version                                                      | string   | K8S API的版本，可以通过kubectl api-version查询               |\n| kind                                                         | string   | 资源类型和角色                                               |\n| metadata                                                     | object   | 元数据对象                                                   |\n| metadata.name                                                | string   | 元数据对象的名称，比如pod的名字                              |\n| metadata.namespace                                           | string   | 元数据对象的命名控件                                         |\n| metadata.labels                                              | list     | 自定义标签列表                                               |\n| metadata.annotations                                         | list     | 自定义注解列表                                               |\n| spec                                                         | object   | 详细定义对象                                                 |\n| spec.container[]                                             | list     | 容器列表                                                     |\n| spec.container[].name                                        | string   | 定义容器名称                                                 |\n| spec.container[].image                                       | string   | 定义用到镜像名称                                             |\n| spec.container[].imagePullPolicy                             | string   | 镜像拉取策略,    Always：不管镜像是否存在都会进行一次拉取。  Never：不管镜像是否存在都不会进行拉取  IfNotPresent：只有镜像不存在时，才会进行镜像拉取。 |\n| spec.container[].command[]                                   | list     | 指定容器启动命令                                             |\n| spec.container[].args[]                                      | list     | 命令参数                                                     |\n| spec.container[].workingDir                                  | string   | 指定容器的工作目录                                           |\n| spec.container[].volumeMounts[]                              | list     | 指定容器内部的存储卷配置                                     |\n| spec.container[].volumeMounts[].name                         | string   | 指定挂载存储卷的名称                                         |\n| spec.container[].volumeMounts[].mountPath                    | string   | 指定挂载存储卷的路径                                         |\n| spec.container[].volumeMounts[].readyOnly                    | string   | true或false，读写模式                                        |\n| spec.container[].ports[]                                     | list     | 指定容器需要用到的端口列表                                   |\n| spec.container[].ports[].name                                | string   | 端口名称                                                     |\n| spec.container[].ports[].containerPort                       | string   | 指定容器要监听的端口号                                       |\n| spec.container[].ports[].hostPort                            | string   | 指定容器所在主机需要监听的端口号，默认跟containerPort相同，如果设置了hostPort同一台主机无法启动该容器的相同副本(因为主机的端口号不能相同，这样会冲突) |\n| spec.container[].ports[].protocol                            | string   | 指定端口协议，支持TCP和UDP，默认值TCP                        |\n| spec.container[].env[]                                       | list     | 指定容器运行需要的环境                                       |\n| spec.container[].env[].name                                  | string   | 环境变量名称                                                 |\n| spec.container[].env[].value                                 | string   | 环境变量值                                                   |\n| spec.container[].resources                                   | object   | 指定资源限制和资源请求的值                                   |\n| spec.container[].resources.limits                            | object   | 指定设置容器运行时资源的运行上限                             |\n| spec.container[].resources.limits.cpu                        | string   | 指定cpu的限制，单位core数，将用于docker run --cpu-shares 参数 |\n| spec.container[].resources.limits.memory                     | string   | 指定MEM内存的限制，单位MIB ,GIB                              |\n| spec.container[].resources.requests                          | object   | 指定容器启动和调度的限制设置                                 |\n| spec.container[].resources.requests.cpu                      | string   | cpu请求，单位core数，容器启动时初始化可用数量                |\n| spec.container[].resources.requests.memory                   | string   | 内存请求，单位MIB,GIB 容器启动的初始化可用数量               |\n| spec.container[].livenessProbe                               | object   | 对Pod内各容器健康检查的设置，当探测无响应几次之后，系统将自动重启该容器。可以设置的方法包括：exec、httpGet和tcpSocket。对一个容器仅需设置一种健康检查方法 |\n| spec.container[].livenessProbe.exec                          | object   | 对Pod内各容器健康检查的设置                                  |\n| spec.container[].livenessProbe.exec.command[]                | list     | exec方式需要指定的命令或者脚本                               |\n| spec.container[].livenessProbe.httpGet                       | object   | 对Pod内各容器健康检查的设置，httpget方式。需指定path、port   |\n| spec.container[].livenessProbe.httpGet.path                  | string   |                                                              |\n| spec.container[].livenessProbe.httpGet.port                  | string   |                                                              |\n| spec.container[].livenessProbe.httpGet.host                  | string   |                                                              |\n| spec.container[].livenessProbe.httpGet.scheme                | string   |                                                              |\n| spec.container[].livenessProbe.httpGet .httpHeaders[]        | list     |                                                              |\n| spec.container[].livenessProbe.httpGet .httpHeaders[] .name  | string   |                                                              |\n| spec.container[].livenessProbe.httpGet .httpHeaders[] .value | string   |                                                              |\n| spec.container[].livenessProbe.tcpSocket                     | object   |                                                              |\n| spec.container[].livenessProbe.tcpSocket.port                | string   |                                                              |\n| spec.container[].livenessProbe.initialDelaySeconds           | string   | 容器启动完成后首次探测的时间，单位为s                        |\n| spec.container[].livenessProbe.timeoutSeconds                | string   | 探测等待响应的超时时间，单位为s,默认1s                       |\n| spec.container[].livenessProbe.periodSeconds                 | string   | 定期探测时间设置，单位s,默认10s探测一次                      |\n| spec.container[].livenessProbe.successThreshold              | string   | 失败后检查成功的最小连续成功次数。默认为1.活跃度必须为1。最小值为1。 |\n| spec.container[].livenessProbe.failureThreshold              | string   | 当Pod成功启动且检查失败时，Kubernetes将在放弃之前尝试failureThreshold次。放弃生存检查意味着重新启动Pod。而放弃就绪检查，Pod将被标记为未就绪。默认为3.最小值为1。 |\n| spec.container[].livenessProbe.securityContext               | object   |                                                              |\n| spec.container[].livenessProbe.securityContext .privileged   | string   |                                                              |\n| spec.restartPolicy                                           | string   | 定义pod重启策略，默认值Always                   Always：Pod一旦终止运行，则无论容器是如何终止的kubelet服务都将重启它                    OnFailure：只有Pod以非零退出码终止时，kubelet才会重启该容器，如果容器正常结束（退出码为0），则kubelet将不会重启它      Never：Pod终止后，kubelet将退出码报告给Master，不会重启该Pod |\n| spec.nodeSelector                                            | object   | 定义node的label过滤标签，以key：value格式指定                |\n| spec.imagePullSecrets                                        | Object   | 定义pull镜像secret名称，以name:secretKey格式指定             |\n| spec.hostNetwork                                             | Boolean  | 定义是否使用主机网络模式，默认值false，设置true表示使用宿主网路，不适用docker网桥，同时设置true将无法在同一台宿主机上启动第二个副本。 |\n| spec.volumes[]                                               | list     | 在该pod上定义的共享存储卷列表                                |\n| spec.volumes[].name                                          | string   | 共享存储卷的名称，在一个pod中每个存储卷定义一个名称，容器定义部分的containers[].volumeMounts[].name将引用该共享存储卷的名称。可以定义多个volume，每个volume的name保持唯一。 |\n| spec.volumes[].emptyDir                                      | string   | 类型为emptyDir的存储卷，表示与Pod同生命周期的一个临时目录，其值为一个空对象：emptyDir:{} |\n| spec.volumes[].hostPath                                      | object   | 类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录，通过volume[].hostPath.path指定 |\n| spec.volumes[].hostPath.path                                 | string   | Pod所在主机的目录，将被用于容器中mount的目录                 |\n| spec.volumes[].secret                                        | object   | 类型为secret的存储卷，表示挂载集群预定义的secret对象到容器内部 |\n| spec.volumes[].secret.secretName                             | string   |                                                              |\n| spec.volumes[].secret.items[]                                | list     |                                                              |\n| spec.volumes[].secret.items[].key                            | string   |                                                              |\n| spec.volumes[].secret.items[].path                           | string   |                                                              |\n| spec.volumes[].configMap                                     | object   | 类型为configMap的存储卷，表示挂载集群预定义的configMap对象到容器内部 |\n| spec.volumes[].configMap.name                                | string   |                                                              |\n| spec.volumes[].configMap.items[]                             | list     |                                                              |\n| spec.volumes[].configMap.items[].key                         | string   |                                                              |\n| spec.volumes[].configMap.items[].path                        | string   |                                                              |\n\n# 资源清单格式\n\n```\napiVersion: group/apiversion #如果没有给定group名称,那么默认为core,可以使用kubectl api-versions #获取当前k8s版本上所有的 apiVersion版本信息(每个版本可能不同)\nkind:#资源类别\nmetadata:#资源元数据\n  name\n  namespace\n  1ables\n  annotations #主要目的是方便用户阅读查找\nspec: #期望的状态(disired state)\nstatus: #当前状态,本字段有Kubernetes 自身维护,用户不能去定义\n\n```\n\n","slug":"k8s资源清单及常用字段","published":1,"updated":"2022-09-23T16:39:06.839Z","_id":"cl8epi5n20000v4vjg8938wzp","comments":1,"layout":"post","photos":[],"link":"","content":"<p>K8s中所有的内容都抽象为资源,资源实例化之后,叫做对象。</p>\n<h1 id=\"名称空间级别\"><a href=\"#名称空间级别\" class=\"headerlink\" title=\"名称空间级别\"></a>名称空间级别</h1><p>工作负载型资源(workload ): Pod、 ReplicaSet, Deployment、 StatefulSet、DaemonSet、Job、CronJob (ReplicationController 在vl.11 版本被废弃)</p>\n<p>服务发现及负载均衡型资源( ServiceDiscovery LoadBalance )： Service, Ingress. …</p>\n<p>配置与存储型资源： Volume(存储卷)、CSI(容器存储接口,可以扩展各种各样的第三方存储卷)</p>\n<p>特殊类型的存储卷：ConfigMap(当配置中心来使用的资源类型)、Secret(保存敏感数据)、DownwardAPI (把外部环境中的信息输出给容器)</p>\n<p>集群级资源: Namespace、 Node、 Role、 ClusterRole, RoleBinding、 ClusterRoleBinding</p>\n<p>元数据型资源: HPA、 PodTemplate、 LimitRange</p>\n<h1 id=\"资源清单常用字段\"><a href=\"#资源清单常用字段\" class=\"headerlink\" title=\"资源清单常用字段\"></a>资源清单常用字段</h1><p>k8s 集群中对资源管理和资源对象编排部署都可以通过声明样式（YAML）文件来解决，通过kubectl 命令直接使用资源清单文件就可以实现对大量的资源对象进行编排部署了。这样的yaml文件我们一般称为资源清单。</p>\n<h2 id=\"必须存在的属性\"><a href=\"#必须存在的属性\" class=\"headerlink\" title=\"必须存在的属性\"></a>必须存在的属性</h2><table>\n<thead>\n<tr>\n<th>参数名</th>\n<th>字段类型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>version</td>\n<td>string</td>\n<td>K8S API的版本，可以通过kubectl api-version查询</td>\n</tr>\n<tr>\n<td>kind</td>\n<td>string</td>\n<td>资源类型和角色</td>\n</tr>\n<tr>\n<td>metadata</td>\n<td>object</td>\n<td>元数据对象</td>\n</tr>\n<tr>\n<td>metadata.name</td>\n<td>string</td>\n<td>元数据对象的名称，比如pod的名字</td>\n</tr>\n<tr>\n<td>metadata.namespace</td>\n<td>string</td>\n<td>元数据对象的命名控件</td>\n</tr>\n<tr>\n<td>spec</td>\n<td>object</td>\n<td>详细定义对象</td>\n</tr>\n<tr>\n<td>spec.container[]</td>\n<td>list</td>\n<td>容器列表</td>\n</tr>\n<tr>\n<td>spec.container[].name</td>\n<td>string</td>\n<td>定义容器名称</td>\n</tr>\n<tr>\n<td>spec.container[].image</td>\n<td>string</td>\n<td>定义用到镜像名称</td>\n</tr>\n</tbody></table>\n<h2 id=\"spec-主要对象\"><a href=\"#spec-主要对象\" class=\"headerlink\" title=\"spec 主要对象\"></a>spec 主要对象</h2><table>\n<thead>\n<tr>\n<th>参数名</th>\n<th>字段类型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>version</td>\n<td>string</td>\n<td>K8S API的版本，可以通过kubectl api-version查询</td>\n</tr>\n<tr>\n<td>kind</td>\n<td>string</td>\n<td>资源类型和角色</td>\n</tr>\n<tr>\n<td>metadata</td>\n<td>object</td>\n<td>元数据对象</td>\n</tr>\n<tr>\n<td>metadata.name</td>\n<td>string</td>\n<td>元数据对象的名称，比如pod的名字</td>\n</tr>\n<tr>\n<td>metadata.namespace</td>\n<td>string</td>\n<td>元数据对象的命名控件</td>\n</tr>\n<tr>\n<td>metadata.labels</td>\n<td>list</td>\n<td>自定义标签列表</td>\n</tr>\n<tr>\n<td>metadata.annotations</td>\n<td>list</td>\n<td>自定义注解列表</td>\n</tr>\n<tr>\n<td>spec</td>\n<td>object</td>\n<td>详细定义对象</td>\n</tr>\n<tr>\n<td>spec.container[]</td>\n<td>list</td>\n<td>容器列表</td>\n</tr>\n<tr>\n<td>spec.container[].name</td>\n<td>string</td>\n<td>定义容器名称</td>\n</tr>\n<tr>\n<td>spec.container[].image</td>\n<td>string</td>\n<td>定义用到镜像名称</td>\n</tr>\n<tr>\n<td>spec.container[].imagePullPolicy</td>\n<td>string</td>\n<td>镜像拉取策略,    Always：不管镜像是否存在都会进行一次拉取。  Never：不管镜像是否存在都不会进行拉取  IfNotPresent：只有镜像不存在时，才会进行镜像拉取。</td>\n</tr>\n<tr>\n<td>spec.container[].command[]</td>\n<td>list</td>\n<td>指定容器启动命令</td>\n</tr>\n<tr>\n<td>spec.container[].args[]</td>\n<td>list</td>\n<td>命令参数</td>\n</tr>\n<tr>\n<td>spec.container[].workingDir</td>\n<td>string</td>\n<td>指定容器的工作目录</td>\n</tr>\n<tr>\n<td>spec.container[].volumeMounts[]</td>\n<td>list</td>\n<td>指定容器内部的存储卷配置</td>\n</tr>\n<tr>\n<td>spec.container[].volumeMounts[].name</td>\n<td>string</td>\n<td>指定挂载存储卷的名称</td>\n</tr>\n<tr>\n<td>spec.container[].volumeMounts[].mountPath</td>\n<td>string</td>\n<td>指定挂载存储卷的路径</td>\n</tr>\n<tr>\n<td>spec.container[].volumeMounts[].readyOnly</td>\n<td>string</td>\n<td>true或false，读写模式</td>\n</tr>\n<tr>\n<td>spec.container[].ports[]</td>\n<td>list</td>\n<td>指定容器需要用到的端口列表</td>\n</tr>\n<tr>\n<td>spec.container[].ports[].name</td>\n<td>string</td>\n<td>端口名称</td>\n</tr>\n<tr>\n<td>spec.container[].ports[].containerPort</td>\n<td>string</td>\n<td>指定容器要监听的端口号</td>\n</tr>\n<tr>\n<td>spec.container[].ports[].hostPort</td>\n<td>string</td>\n<td>指定容器所在主机需要监听的端口号，默认跟containerPort相同，如果设置了hostPort同一台主机无法启动该容器的相同副本(因为主机的端口号不能相同，这样会冲突)</td>\n</tr>\n<tr>\n<td>spec.container[].ports[].protocol</td>\n<td>string</td>\n<td>指定端口协议，支持TCP和UDP，默认值TCP</td>\n</tr>\n<tr>\n<td>spec.container[].env[]</td>\n<td>list</td>\n<td>指定容器运行需要的环境</td>\n</tr>\n<tr>\n<td>spec.container[].env[].name</td>\n<td>string</td>\n<td>环境变量名称</td>\n</tr>\n<tr>\n<td>spec.container[].env[].value</td>\n<td>string</td>\n<td>环境变量值</td>\n</tr>\n<tr>\n<td>spec.container[].resources</td>\n<td>object</td>\n<td>指定资源限制和资源请求的值</td>\n</tr>\n<tr>\n<td>spec.container[].resources.limits</td>\n<td>object</td>\n<td>指定设置容器运行时资源的运行上限</td>\n</tr>\n<tr>\n<td>spec.container[].resources.limits.cpu</td>\n<td>string</td>\n<td>指定cpu的限制，单位core数，将用于docker run –cpu-shares 参数</td>\n</tr>\n<tr>\n<td>spec.container[].resources.limits.memory</td>\n<td>string</td>\n<td>指定MEM内存的限制，单位MIB ,GIB</td>\n</tr>\n<tr>\n<td>spec.container[].resources.requests</td>\n<td>object</td>\n<td>指定容器启动和调度的限制设置</td>\n</tr>\n<tr>\n<td>spec.container[].resources.requests.cpu</td>\n<td>string</td>\n<td>cpu请求，单位core数，容器启动时初始化可用数量</td>\n</tr>\n<tr>\n<td>spec.container[].resources.requests.memory</td>\n<td>string</td>\n<td>内存请求，单位MIB,GIB 容器启动的初始化可用数量</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe</td>\n<td>object</td>\n<td>对Pod内各容器健康检查的设置，当探测无响应几次之后，系统将自动重启该容器。可以设置的方法包括：exec、httpGet和tcpSocket。对一个容器仅需设置一种健康检查方法</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.exec</td>\n<td>object</td>\n<td>对Pod内各容器健康检查的设置</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.exec.command[]</td>\n<td>list</td>\n<td>exec方式需要指定的命令或者脚本</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet</td>\n<td>object</td>\n<td>对Pod内各容器健康检查的设置，httpget方式。需指定path、port</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet.path</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet.port</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet.host</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet.scheme</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet .httpHeaders[]</td>\n<td>list</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet .httpHeaders[] .name</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet .httpHeaders[] .value</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.tcpSocket</td>\n<td>object</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.tcpSocket.port</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.initialDelaySeconds</td>\n<td>string</td>\n<td>容器启动完成后首次探测的时间，单位为s</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.timeoutSeconds</td>\n<td>string</td>\n<td>探测等待响应的超时时间，单位为s,默认1s</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.periodSeconds</td>\n<td>string</td>\n<td>定期探测时间设置，单位s,默认10s探测一次</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.successThreshold</td>\n<td>string</td>\n<td>失败后检查成功的最小连续成功次数。默认为1.活跃度必须为1。最小值为1。</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.failureThreshold</td>\n<td>string</td>\n<td>当Pod成功启动且检查失败时，Kubernetes将在放弃之前尝试failureThreshold次。放弃生存检查意味着重新启动Pod。而放弃就绪检查，Pod将被标记为未就绪。默认为3.最小值为1。</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.securityContext</td>\n<td>object</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.securityContext .privileged</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.restartPolicy</td>\n<td>string</td>\n<td>定义pod重启策略，默认值Always                   Always：Pod一旦终止运行，则无论容器是如何终止的kubelet服务都将重启它                    OnFailure：只有Pod以非零退出码终止时，kubelet才会重启该容器，如果容器正常结束（退出码为0），则kubelet将不会重启它      Never：Pod终止后，kubelet将退出码报告给Master，不会重启该Pod</td>\n</tr>\n<tr>\n<td>spec.nodeSelector</td>\n<td>object</td>\n<td>定义node的label过滤标签，以key：value格式指定</td>\n</tr>\n<tr>\n<td>spec.imagePullSecrets</td>\n<td>Object</td>\n<td>定义pull镜像secret名称，以name:secretKey格式指定</td>\n</tr>\n<tr>\n<td>spec.hostNetwork</td>\n<td>Boolean</td>\n<td>定义是否使用主机网络模式，默认值false，设置true表示使用宿主网路，不适用docker网桥，同时设置true将无法在同一台宿主机上启动第二个副本。</td>\n</tr>\n<tr>\n<td>spec.volumes[]</td>\n<td>list</td>\n<td>在该pod上定义的共享存储卷列表</td>\n</tr>\n<tr>\n<td>spec.volumes[].name</td>\n<td>string</td>\n<td>共享存储卷的名称，在一个pod中每个存储卷定义一个名称，容器定义部分的containers[].volumeMounts[].name将引用该共享存储卷的名称。可以定义多个volume，每个volume的name保持唯一。</td>\n</tr>\n<tr>\n<td>spec.volumes[].emptyDir</td>\n<td>string</td>\n<td>类型为emptyDir的存储卷，表示与Pod同生命周期的一个临时目录，其值为一个空对象：emptyDir:{}</td>\n</tr>\n<tr>\n<td>spec.volumes[].hostPath</td>\n<td>object</td>\n<td>类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录，通过volume[].hostPath.path指定</td>\n</tr>\n<tr>\n<td>spec.volumes[].hostPath.path</td>\n<td>string</td>\n<td>Pod所在主机的目录，将被用于容器中mount的目录</td>\n</tr>\n<tr>\n<td>spec.volumes[].secret</td>\n<td>object</td>\n<td>类型为secret的存储卷，表示挂载集群预定义的secret对象到容器内部</td>\n</tr>\n<tr>\n<td>spec.volumes[].secret.secretName</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].secret.items[]</td>\n<td>list</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].secret.items[].key</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].secret.items[].path</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].configMap</td>\n<td>object</td>\n<td>类型为configMap的存储卷，表示挂载集群预定义的configMap对象到容器内部</td>\n</tr>\n<tr>\n<td>spec.volumes[].configMap.name</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].configMap.items[]</td>\n<td>list</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].configMap.items[].key</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].configMap.items[].path</td>\n<td>string</td>\n<td></td>\n</tr>\n</tbody></table>\n<h1 id=\"资源清单格式\"><a href=\"#资源清单格式\" class=\"headerlink\" title=\"资源清单格式\"></a>资源清单格式</h1><figure class=\"highlight avrasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs avrasm\"><span class=\"hljs-symbol\">apiVersion:</span> group/apiversion <span class=\"hljs-meta\">#如果没有给定group名称,那么默认为core,可以使用kubectl api-versions #获取当前k8s版本上所有的 apiVersion版本信息(每个版本可能不同)</span><br><span class=\"hljs-symbol\">kind:</span><span class=\"hljs-meta\">#资源类别</span><br><span class=\"hljs-symbol\">metadata:</span><span class=\"hljs-meta\">#资源元数据</span><br>  name<br>  namespace<br>  <span class=\"hljs-number\">1</span>ables<br>  annotations <span class=\"hljs-meta\">#主要目的是方便用户阅读查找</span><br><span class=\"hljs-symbol\">spec:</span> <span class=\"hljs-meta\">#期望的状态(disired state)</span><br><span class=\"hljs-symbol\">status:</span> <span class=\"hljs-meta\">#当前状态,本字段有Kubernetes 自身维护,用户不能去定义</span><br><br></code></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<p>K8s中所有的内容都抽象为资源,资源实例化之后,叫做对象。</p>\n<h1 id=\"名称空间级别\"><a href=\"#名称空间级别\" class=\"headerlink\" title=\"名称空间级别\"></a>名称空间级别</h1><p>工作负载型资源(workload ): Pod、 ReplicaSet, Deployment、 StatefulSet、DaemonSet、Job、CronJob (ReplicationController 在vl.11 版本被废弃)</p>\n<p>服务发现及负载均衡型资源( ServiceDiscovery LoadBalance )： Service, Ingress. …</p>\n<p>配置与存储型资源： Volume(存储卷)、CSI(容器存储接口,可以扩展各种各样的第三方存储卷)</p>\n<p>特殊类型的存储卷：ConfigMap(当配置中心来使用的资源类型)、Secret(保存敏感数据)、DownwardAPI (把外部环境中的信息输出给容器)</p>\n<p>集群级资源: Namespace、 Node、 Role、 ClusterRole, RoleBinding、 ClusterRoleBinding</p>\n<p>元数据型资源: HPA、 PodTemplate、 LimitRange</p>\n<h1 id=\"资源清单常用字段\"><a href=\"#资源清单常用字段\" class=\"headerlink\" title=\"资源清单常用字段\"></a>资源清单常用字段</h1><p>k8s 集群中对资源管理和资源对象编排部署都可以通过声明样式（YAML）文件来解决，通过kubectl 命令直接使用资源清单文件就可以实现对大量的资源对象进行编排部署了。这样的yaml文件我们一般称为资源清单。</p>\n<h2 id=\"必须存在的属性\"><a href=\"#必须存在的属性\" class=\"headerlink\" title=\"必须存在的属性\"></a>必须存在的属性</h2><table>\n<thead>\n<tr>\n<th>参数名</th>\n<th>字段类型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>version</td>\n<td>string</td>\n<td>K8S API的版本，可以通过kubectl api-version查询</td>\n</tr>\n<tr>\n<td>kind</td>\n<td>string</td>\n<td>资源类型和角色</td>\n</tr>\n<tr>\n<td>metadata</td>\n<td>object</td>\n<td>元数据对象</td>\n</tr>\n<tr>\n<td>metadata.name</td>\n<td>string</td>\n<td>元数据对象的名称，比如pod的名字</td>\n</tr>\n<tr>\n<td>metadata.namespace</td>\n<td>string</td>\n<td>元数据对象的命名控件</td>\n</tr>\n<tr>\n<td>spec</td>\n<td>object</td>\n<td>详细定义对象</td>\n</tr>\n<tr>\n<td>spec.container[]</td>\n<td>list</td>\n<td>容器列表</td>\n</tr>\n<tr>\n<td>spec.container[].name</td>\n<td>string</td>\n<td>定义容器名称</td>\n</tr>\n<tr>\n<td>spec.container[].image</td>\n<td>string</td>\n<td>定义用到镜像名称</td>\n</tr>\n</tbody></table>\n<h2 id=\"spec-主要对象\"><a href=\"#spec-主要对象\" class=\"headerlink\" title=\"spec 主要对象\"></a>spec 主要对象</h2><table>\n<thead>\n<tr>\n<th>参数名</th>\n<th>字段类型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>version</td>\n<td>string</td>\n<td>K8S API的版本，可以通过kubectl api-version查询</td>\n</tr>\n<tr>\n<td>kind</td>\n<td>string</td>\n<td>资源类型和角色</td>\n</tr>\n<tr>\n<td>metadata</td>\n<td>object</td>\n<td>元数据对象</td>\n</tr>\n<tr>\n<td>metadata.name</td>\n<td>string</td>\n<td>元数据对象的名称，比如pod的名字</td>\n</tr>\n<tr>\n<td>metadata.namespace</td>\n<td>string</td>\n<td>元数据对象的命名控件</td>\n</tr>\n<tr>\n<td>metadata.labels</td>\n<td>list</td>\n<td>自定义标签列表</td>\n</tr>\n<tr>\n<td>metadata.annotations</td>\n<td>list</td>\n<td>自定义注解列表</td>\n</tr>\n<tr>\n<td>spec</td>\n<td>object</td>\n<td>详细定义对象</td>\n</tr>\n<tr>\n<td>spec.container[]</td>\n<td>list</td>\n<td>容器列表</td>\n</tr>\n<tr>\n<td>spec.container[].name</td>\n<td>string</td>\n<td>定义容器名称</td>\n</tr>\n<tr>\n<td>spec.container[].image</td>\n<td>string</td>\n<td>定义用到镜像名称</td>\n</tr>\n<tr>\n<td>spec.container[].imagePullPolicy</td>\n<td>string</td>\n<td>镜像拉取策略,    Always：不管镜像是否存在都会进行一次拉取。  Never：不管镜像是否存在都不会进行拉取  IfNotPresent：只有镜像不存在时，才会进行镜像拉取。</td>\n</tr>\n<tr>\n<td>spec.container[].command[]</td>\n<td>list</td>\n<td>指定容器启动命令</td>\n</tr>\n<tr>\n<td>spec.container[].args[]</td>\n<td>list</td>\n<td>命令参数</td>\n</tr>\n<tr>\n<td>spec.container[].workingDir</td>\n<td>string</td>\n<td>指定容器的工作目录</td>\n</tr>\n<tr>\n<td>spec.container[].volumeMounts[]</td>\n<td>list</td>\n<td>指定容器内部的存储卷配置</td>\n</tr>\n<tr>\n<td>spec.container[].volumeMounts[].name</td>\n<td>string</td>\n<td>指定挂载存储卷的名称</td>\n</tr>\n<tr>\n<td>spec.container[].volumeMounts[].mountPath</td>\n<td>string</td>\n<td>指定挂载存储卷的路径</td>\n</tr>\n<tr>\n<td>spec.container[].volumeMounts[].readyOnly</td>\n<td>string</td>\n<td>true或false，读写模式</td>\n</tr>\n<tr>\n<td>spec.container[].ports[]</td>\n<td>list</td>\n<td>指定容器需要用到的端口列表</td>\n</tr>\n<tr>\n<td>spec.container[].ports[].name</td>\n<td>string</td>\n<td>端口名称</td>\n</tr>\n<tr>\n<td>spec.container[].ports[].containerPort</td>\n<td>string</td>\n<td>指定容器要监听的端口号</td>\n</tr>\n<tr>\n<td>spec.container[].ports[].hostPort</td>\n<td>string</td>\n<td>指定容器所在主机需要监听的端口号，默认跟containerPort相同，如果设置了hostPort同一台主机无法启动该容器的相同副本(因为主机的端口号不能相同，这样会冲突)</td>\n</tr>\n<tr>\n<td>spec.container[].ports[].protocol</td>\n<td>string</td>\n<td>指定端口协议，支持TCP和UDP，默认值TCP</td>\n</tr>\n<tr>\n<td>spec.container[].env[]</td>\n<td>list</td>\n<td>指定容器运行需要的环境</td>\n</tr>\n<tr>\n<td>spec.container[].env[].name</td>\n<td>string</td>\n<td>环境变量名称</td>\n</tr>\n<tr>\n<td>spec.container[].env[].value</td>\n<td>string</td>\n<td>环境变量值</td>\n</tr>\n<tr>\n<td>spec.container[].resources</td>\n<td>object</td>\n<td>指定资源限制和资源请求的值</td>\n</tr>\n<tr>\n<td>spec.container[].resources.limits</td>\n<td>object</td>\n<td>指定设置容器运行时资源的运行上限</td>\n</tr>\n<tr>\n<td>spec.container[].resources.limits.cpu</td>\n<td>string</td>\n<td>指定cpu的限制，单位core数，将用于docker run –cpu-shares 参数</td>\n</tr>\n<tr>\n<td>spec.container[].resources.limits.memory</td>\n<td>string</td>\n<td>指定MEM内存的限制，单位MIB ,GIB</td>\n</tr>\n<tr>\n<td>spec.container[].resources.requests</td>\n<td>object</td>\n<td>指定容器启动和调度的限制设置</td>\n</tr>\n<tr>\n<td>spec.container[].resources.requests.cpu</td>\n<td>string</td>\n<td>cpu请求，单位core数，容器启动时初始化可用数量</td>\n</tr>\n<tr>\n<td>spec.container[].resources.requests.memory</td>\n<td>string</td>\n<td>内存请求，单位MIB,GIB 容器启动的初始化可用数量</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe</td>\n<td>object</td>\n<td>对Pod内各容器健康检查的设置，当探测无响应几次之后，系统将自动重启该容器。可以设置的方法包括：exec、httpGet和tcpSocket。对一个容器仅需设置一种健康检查方法</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.exec</td>\n<td>object</td>\n<td>对Pod内各容器健康检查的设置</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.exec.command[]</td>\n<td>list</td>\n<td>exec方式需要指定的命令或者脚本</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet</td>\n<td>object</td>\n<td>对Pod内各容器健康检查的设置，httpget方式。需指定path、port</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet.path</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet.port</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet.host</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet.scheme</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet .httpHeaders[]</td>\n<td>list</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet .httpHeaders[] .name</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.httpGet .httpHeaders[] .value</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.tcpSocket</td>\n<td>object</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.tcpSocket.port</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.initialDelaySeconds</td>\n<td>string</td>\n<td>容器启动完成后首次探测的时间，单位为s</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.timeoutSeconds</td>\n<td>string</td>\n<td>探测等待响应的超时时间，单位为s,默认1s</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.periodSeconds</td>\n<td>string</td>\n<td>定期探测时间设置，单位s,默认10s探测一次</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.successThreshold</td>\n<td>string</td>\n<td>失败后检查成功的最小连续成功次数。默认为1.活跃度必须为1。最小值为1。</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.failureThreshold</td>\n<td>string</td>\n<td>当Pod成功启动且检查失败时，Kubernetes将在放弃之前尝试failureThreshold次。放弃生存检查意味着重新启动Pod。而放弃就绪检查，Pod将被标记为未就绪。默认为3.最小值为1。</td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.securityContext</td>\n<td>object</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.container[].livenessProbe.securityContext .privileged</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.restartPolicy</td>\n<td>string</td>\n<td>定义pod重启策略，默认值Always                   Always：Pod一旦终止运行，则无论容器是如何终止的kubelet服务都将重启它                    OnFailure：只有Pod以非零退出码终止时，kubelet才会重启该容器，如果容器正常结束（退出码为0），则kubelet将不会重启它      Never：Pod终止后，kubelet将退出码报告给Master，不会重启该Pod</td>\n</tr>\n<tr>\n<td>spec.nodeSelector</td>\n<td>object</td>\n<td>定义node的label过滤标签，以key：value格式指定</td>\n</tr>\n<tr>\n<td>spec.imagePullSecrets</td>\n<td>Object</td>\n<td>定义pull镜像secret名称，以name:secretKey格式指定</td>\n</tr>\n<tr>\n<td>spec.hostNetwork</td>\n<td>Boolean</td>\n<td>定义是否使用主机网络模式，默认值false，设置true表示使用宿主网路，不适用docker网桥，同时设置true将无法在同一台宿主机上启动第二个副本。</td>\n</tr>\n<tr>\n<td>spec.volumes[]</td>\n<td>list</td>\n<td>在该pod上定义的共享存储卷列表</td>\n</tr>\n<tr>\n<td>spec.volumes[].name</td>\n<td>string</td>\n<td>共享存储卷的名称，在一个pod中每个存储卷定义一个名称，容器定义部分的containers[].volumeMounts[].name将引用该共享存储卷的名称。可以定义多个volume，每个volume的name保持唯一。</td>\n</tr>\n<tr>\n<td>spec.volumes[].emptyDir</td>\n<td>string</td>\n<td>类型为emptyDir的存储卷，表示与Pod同生命周期的一个临时目录，其值为一个空对象：emptyDir:{}</td>\n</tr>\n<tr>\n<td>spec.volumes[].hostPath</td>\n<td>object</td>\n<td>类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录，通过volume[].hostPath.path指定</td>\n</tr>\n<tr>\n<td>spec.volumes[].hostPath.path</td>\n<td>string</td>\n<td>Pod所在主机的目录，将被用于容器中mount的目录</td>\n</tr>\n<tr>\n<td>spec.volumes[].secret</td>\n<td>object</td>\n<td>类型为secret的存储卷，表示挂载集群预定义的secret对象到容器内部</td>\n</tr>\n<tr>\n<td>spec.volumes[].secret.secretName</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].secret.items[]</td>\n<td>list</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].secret.items[].key</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].secret.items[].path</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].configMap</td>\n<td>object</td>\n<td>类型为configMap的存储卷，表示挂载集群预定义的configMap对象到容器内部</td>\n</tr>\n<tr>\n<td>spec.volumes[].configMap.name</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].configMap.items[]</td>\n<td>list</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].configMap.items[].key</td>\n<td>string</td>\n<td></td>\n</tr>\n<tr>\n<td>spec.volumes[].configMap.items[].path</td>\n<td>string</td>\n<td></td>\n</tr>\n</tbody></table>\n<h1 id=\"资源清单格式\"><a href=\"#资源清单格式\" class=\"headerlink\" title=\"资源清单格式\"></a>资源清单格式</h1><figure class=\"highlight avrasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs avrasm\"><span class=\"hljs-symbol\">apiVersion:</span> group/apiversion <span class=\"hljs-meta\">#如果没有给定group名称,那么默认为core,可以使用kubectl api-versions #获取当前k8s版本上所有的 apiVersion版本信息(每个版本可能不同)</span><br><span class=\"hljs-symbol\">kind:</span><span class=\"hljs-meta\">#资源类别</span><br><span class=\"hljs-symbol\">metadata:</span><span class=\"hljs-meta\">#资源元数据</span><br>  name<br>  namespace<br>  <span class=\"hljs-number\">1</span>ables<br>  annotations <span class=\"hljs-meta\">#主要目的是方便用户阅读查找</span><br><span class=\"hljs-symbol\">spec:</span> <span class=\"hljs-meta\">#期望的状态(disired state)</span><br><span class=\"hljs-symbol\">status:</span> <span class=\"hljs-meta\">#当前状态,本字段有Kubernetes 自身维护,用户不能去定义</span><br><br></code></pre></td></tr></table></figure>\n\n"},{"title":"k8s资源清单及常用字段","date":"2021-07-29T11:38:02.000Z","_content":"\n# kubernetes组件\n\n一个 Kubernetes 集群是由一组被称作节点（node）的机器组成， 这些节点上会运行由 Kubernetes 所管理的容器化应用。 且每个集群至少有一个工作节点。\n\n工作节点会托管所谓的 Pods，而 Pod 就是作为应用负载的组件。 控制平面管理集群中的工作节点和 Pods。 为集群提供故障转移和高可用性， 这些控制平面一般跨多主机运行，而集群也会跨多个节点运行。\n\n![img](kubernetes组件介绍/image-1-1024x478.png)Kubernetes 集群的组件\n\n**控制平面组件（Control Plane Components）**\n\n控制平面组件会为集群做出全局决策，比如资源的调度。 以及检测和响应集群事件，例如当不满足部署的 `replicas` 字段时， 要启动新的 pod）。\n\n**kube-apiserver**\n\nAPI 服务器是 Kubernetes 控制平面的组件， 该组件负责公开了 Kubernetes API，负责处理接受请求的工作。 API 服务器是 Kubernetes 控制平面的前端。集群统一入口,以restful方式,交给etcd存储.\n\n**etcd**\n\n`etcd` 是兼顾一致性与高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。存储系统,用于保存集群相关的数据。\netcd的官方将它定位成一个可信赖的分布式键值存储服务,它能够为整个分布式集群存储一些关键数据,协助分布式集群的正常运转。[etcd运行原理](http://t.zoukankan.com/liujunjun-p-12186354.html)\n\n**kube-scheduler**\n\n`kube-scheduler` 是控制平面的组件， 负责监视新创建的、未指定运行节点（node）的 Pods， 并选择节点来让 Pod 在上面运行。负责介绍任务，选择合适的节点进行分配任务。\n\n调度决策考虑的因素包括单个 Pod 及 Pods 集合的资源需求、软硬件及策略约束、 亲和性及反亲和性规范、数据位置、工作负载间的干扰及最后时限。\n\n节点调度,选择node节点应用部署。\n\n**kube-controller-manager**\n\nkube-controller-manager 是控制平面的组件， 负责运行控制器进程。\n\n为了降低复杂性，控制器都被编译到同一个可执行文件，并在同一个进程中运行。\n\n控制器：\n\n- 节点控制器（Node Controller）：负责在节点出现故障时进行通知和响应\n- 任务控制器（Job Controller）：监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成\n- 端点控制器（Endpoints Controller）：填充端点（Endpoints）对象（即加入 Service 与 Pod）\n- 服务帐户和令牌控制器（Service Account & Token Controllers）：为新的命名空间创建默认帐户和 API 访问令牌\n- 副本管理器（ReplicationController）：确保特定数量的 Pod 副本处于运⾏状态且总是可用。\n- Deployment管理器（DeploymentController）：可以拥有 ReplicaSet 并使⽤声明式⽅式在服务器端完成对 Pods 滚动更新的对象。\n- 状态管理器（StatefulSetController）：管理有状态应⽤的⼯作负载 API 对象。\n- DaemonSetController：确保全部（或者某些）节点上运⾏⼀个 Pod 的副本。 当有节点加⼊集群时， 也会为他们新增⼀个 Pod 。 当有节点从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。\n- JobController：创建一个或者多个Pods,并将继续重试Pods的执行,直到指定数量的Pods成功终止。\n- CronJobController：创建基于时隔重复调度的 Jobs。\n- TTLController\n- EndpointController\n- PodGCController\n- ResourceQuotaController\n- NamespaceController\n- ServiceAccountController\n- GarbageCollectorController\n- HPAController\n- DisruptionController\n- CSRSigningController\n- CSRApprovingController\n- TokenController\n- NodeController\n- ServiceController\n- RouteController\n- PVBinderController\n- AttachDetachController\n- BootstrapSignerController\n- TokenCleanerController\n\n**cloud-controller-manager**\n\n`cloud-controller-manager` 是指嵌入特定云的控制逻辑之 控制平面组件。 `cloud-controller-manager` 允许你将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。\n\n下面的控制器都包含对云平台驱动的依赖：\n\n- 节点控制器（Node Controller）：用于在节点终止响应后检查云提供商以确定节点是否已被删除\n- 路由控制器（Route Controller）：用于在底层云基础架构中设置路由\n- 服务控制器（Service Controller）：用于创建、更新和删除云提供商负载均衡器\n\n**Node 组件**\n\n**kubelet**\n\n直接跟容器引擎交互实现容器的生命周期管理。\n\nmaster排到node节点代表,管理本机容器。\n\nkubelet 会在集群中每个节点（node）上运行。 它保证容器（containers）都运行在 Pod 中。\nkubelet 接收一组通过各类机制提供给它的 PodSpecs， 确保这些 PodSpecs 中描述的容器处于运行状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容器。\n\n**kube-proxy**\n\n负责写入规则至 IPTABLES、IPVS 实现服务映射访问的。\n\nkube-proxy 是集群中每个节点（node）所上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。\nkube-proxy 维护节点上的一些网络规则， 这些网络规则会允许从集群内部或外部的网络会话与 Pod 进行网络通信。\n如果操作系统提供了可用的数据包过滤层，则 kube-proxy 会通过它来实现网络规则。 否则，kube-proxy 仅做流量转发。\n\n**k8s核心概念**\n\nPod\n\n- 最小部署单元\n- 一组容器的集合\n- 共享网络\n- 生命周期是短暂的\n\ncontroller\n\n- 确保预期的pod副本数量\n- 无状态应用部署\n- 有状态应用部署\n- 确保所有的node运行同一个pod一次性任务和定时任务\n\nService\n\n- 定义一组pod的访问规则\n\n","source":"_posts/kubernetes组件介绍.md","raw":"---\ntitle: k8s资源清单及常用字段\ndate: 2021-07-29 19:38:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - 组件\n---\n\n# kubernetes组件\n\n一个 Kubernetes 集群是由一组被称作节点（node）的机器组成， 这些节点上会运行由 Kubernetes 所管理的容器化应用。 且每个集群至少有一个工作节点。\n\n工作节点会托管所谓的 Pods，而 Pod 就是作为应用负载的组件。 控制平面管理集群中的工作节点和 Pods。 为集群提供故障转移和高可用性， 这些控制平面一般跨多主机运行，而集群也会跨多个节点运行。\n\n![img](kubernetes组件介绍/image-1-1024x478.png)Kubernetes 集群的组件\n\n**控制平面组件（Control Plane Components）**\n\n控制平面组件会为集群做出全局决策，比如资源的调度。 以及检测和响应集群事件，例如当不满足部署的 `replicas` 字段时， 要启动新的 pod）。\n\n**kube-apiserver**\n\nAPI 服务器是 Kubernetes 控制平面的组件， 该组件负责公开了 Kubernetes API，负责处理接受请求的工作。 API 服务器是 Kubernetes 控制平面的前端。集群统一入口,以restful方式,交给etcd存储.\n\n**etcd**\n\n`etcd` 是兼顾一致性与高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。存储系统,用于保存集群相关的数据。\netcd的官方将它定位成一个可信赖的分布式键值存储服务,它能够为整个分布式集群存储一些关键数据,协助分布式集群的正常运转。[etcd运行原理](http://t.zoukankan.com/liujunjun-p-12186354.html)\n\n**kube-scheduler**\n\n`kube-scheduler` 是控制平面的组件， 负责监视新创建的、未指定运行节点（node）的 Pods， 并选择节点来让 Pod 在上面运行。负责介绍任务，选择合适的节点进行分配任务。\n\n调度决策考虑的因素包括单个 Pod 及 Pods 集合的资源需求、软硬件及策略约束、 亲和性及反亲和性规范、数据位置、工作负载间的干扰及最后时限。\n\n节点调度,选择node节点应用部署。\n\n**kube-controller-manager**\n\nkube-controller-manager 是控制平面的组件， 负责运行控制器进程。\n\n为了降低复杂性，控制器都被编译到同一个可执行文件，并在同一个进程中运行。\n\n控制器：\n\n- 节点控制器（Node Controller）：负责在节点出现故障时进行通知和响应\n- 任务控制器（Job Controller）：监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成\n- 端点控制器（Endpoints Controller）：填充端点（Endpoints）对象（即加入 Service 与 Pod）\n- 服务帐户和令牌控制器（Service Account & Token Controllers）：为新的命名空间创建默认帐户和 API 访问令牌\n- 副本管理器（ReplicationController）：确保特定数量的 Pod 副本处于运⾏状态且总是可用。\n- Deployment管理器（DeploymentController）：可以拥有 ReplicaSet 并使⽤声明式⽅式在服务器端完成对 Pods 滚动更新的对象。\n- 状态管理器（StatefulSetController）：管理有状态应⽤的⼯作负载 API 对象。\n- DaemonSetController：确保全部（或者某些）节点上运⾏⼀个 Pod 的副本。 当有节点加⼊集群时， 也会为他们新增⼀个 Pod 。 当有节点从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。\n- JobController：创建一个或者多个Pods,并将继续重试Pods的执行,直到指定数量的Pods成功终止。\n- CronJobController：创建基于时隔重复调度的 Jobs。\n- TTLController\n- EndpointController\n- PodGCController\n- ResourceQuotaController\n- NamespaceController\n- ServiceAccountController\n- GarbageCollectorController\n- HPAController\n- DisruptionController\n- CSRSigningController\n- CSRApprovingController\n- TokenController\n- NodeController\n- ServiceController\n- RouteController\n- PVBinderController\n- AttachDetachController\n- BootstrapSignerController\n- TokenCleanerController\n\n**cloud-controller-manager**\n\n`cloud-controller-manager` 是指嵌入特定云的控制逻辑之 控制平面组件。 `cloud-controller-manager` 允许你将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。\n\n下面的控制器都包含对云平台驱动的依赖：\n\n- 节点控制器（Node Controller）：用于在节点终止响应后检查云提供商以确定节点是否已被删除\n- 路由控制器（Route Controller）：用于在底层云基础架构中设置路由\n- 服务控制器（Service Controller）：用于创建、更新和删除云提供商负载均衡器\n\n**Node 组件**\n\n**kubelet**\n\n直接跟容器引擎交互实现容器的生命周期管理。\n\nmaster排到node节点代表,管理本机容器。\n\nkubelet 会在集群中每个节点（node）上运行。 它保证容器（containers）都运行在 Pod 中。\nkubelet 接收一组通过各类机制提供给它的 PodSpecs， 确保这些 PodSpecs 中描述的容器处于运行状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容器。\n\n**kube-proxy**\n\n负责写入规则至 IPTABLES、IPVS 实现服务映射访问的。\n\nkube-proxy 是集群中每个节点（node）所上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。\nkube-proxy 维护节点上的一些网络规则， 这些网络规则会允许从集群内部或外部的网络会话与 Pod 进行网络通信。\n如果操作系统提供了可用的数据包过滤层，则 kube-proxy 会通过它来实现网络规则。 否则，kube-proxy 仅做流量转发。\n\n**k8s核心概念**\n\nPod\n\n- 最小部署单元\n- 一组容器的集合\n- 共享网络\n- 生命周期是短暂的\n\ncontroller\n\n- 确保预期的pod副本数量\n- 无状态应用部署\n- 有状态应用部署\n- 确保所有的node运行同一个pod一次性任务和定时任务\n\nService\n\n- 定义一组pod的访问规则\n\n","slug":"kubernetes组件介绍","published":1,"updated":"2022-09-23T16:41:53.594Z","_id":"cl8epkzh10007v4vjfd21hfkd","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"kubernetes组件\"><a href=\"#kubernetes组件\" class=\"headerlink\" title=\"kubernetes组件\"></a>kubernetes组件</h1><p>一个 Kubernetes 集群是由一组被称作节点（node）的机器组成， 这些节点上会运行由 Kubernetes 所管理的容器化应用。 且每个集群至少有一个工作节点。</p>\n<p>工作节点会托管所谓的 Pods，而 Pod 就是作为应用负载的组件。 控制平面管理集群中的工作节点和 Pods。 为集群提供故障转移和高可用性， 这些控制平面一般跨多主机运行，而集群也会跨多个节点运行。</p>\n<img src=\"/2021/07/29/kubernetes%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/image-1-1024x478.png\" class=\"\" title=\"img\">Kubernetes 集群的组件\n\n<p><strong>控制平面组件（Control Plane Components）</strong></p>\n<p>控制平面组件会为集群做出全局决策，比如资源的调度。 以及检测和响应集群事件，例如当不满足部署的 <code>replicas</code> 字段时， 要启动新的 pod）。</p>\n<p><strong>kube-apiserver</strong></p>\n<p>API 服务器是 Kubernetes 控制平面的组件， 该组件负责公开了 Kubernetes API，负责处理接受请求的工作。 API 服务器是 Kubernetes 控制平面的前端。集群统一入口,以restful方式,交给etcd存储.</p>\n<p><strong>etcd</strong></p>\n<p><code>etcd</code> 是兼顾一致性与高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。存储系统,用于保存集群相关的数据。<br>etcd的官方将它定位成一个可信赖的分布式键值存储服务,它能够为整个分布式集群存储一些关键数据,协助分布式集群的正常运转。<a href=\"http://t.zoukankan.com/liujunjun-p-12186354.html\">etcd运行原理</a></p>\n<p><strong>kube-scheduler</strong></p>\n<p><code>kube-scheduler</code> 是控制平面的组件， 负责监视新创建的、未指定运行节点（node）的 Pods， 并选择节点来让 Pod 在上面运行。负责介绍任务，选择合适的节点进行分配任务。</p>\n<p>调度决策考虑的因素包括单个 Pod 及 Pods 集合的资源需求、软硬件及策略约束、 亲和性及反亲和性规范、数据位置、工作负载间的干扰及最后时限。</p>\n<p>节点调度,选择node节点应用部署。</p>\n<p><strong>kube-controller-manager</strong></p>\n<p>kube-controller-manager 是控制平面的组件， 负责运行控制器进程。</p>\n<p>为了降低复杂性，控制器都被编译到同一个可执行文件，并在同一个进程中运行。</p>\n<p>控制器：</p>\n<ul>\n<li>节点控制器（Node Controller）：负责在节点出现故障时进行通知和响应</li>\n<li>任务控制器（Job Controller）：监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成</li>\n<li>端点控制器（Endpoints Controller）：填充端点（Endpoints）对象（即加入 Service 与 Pod）</li>\n<li>服务帐户和令牌控制器（Service Account &amp; Token Controllers）：为新的命名空间创建默认帐户和 API 访问令牌</li>\n<li>副本管理器（ReplicationController）：确保特定数量的 Pod 副本处于运⾏状态且总是可用。</li>\n<li>Deployment管理器（DeploymentController）：可以拥有 ReplicaSet 并使⽤声明式⽅式在服务器端完成对 Pods 滚动更新的对象。</li>\n<li>状态管理器（StatefulSetController）：管理有状态应⽤的⼯作负载 API 对象。</li>\n<li>DaemonSetController：确保全部（或者某些）节点上运⾏⼀个 Pod 的副本。 当有节点加⼊集群时， 也会为他们新增⼀个 Pod 。 当有节点从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。</li>\n<li>JobController：创建一个或者多个Pods,并将继续重试Pods的执行,直到指定数量的Pods成功终止。</li>\n<li>CronJobController：创建基于时隔重复调度的 Jobs。</li>\n<li>TTLController</li>\n<li>EndpointController</li>\n<li>PodGCController</li>\n<li>ResourceQuotaController</li>\n<li>NamespaceController</li>\n<li>ServiceAccountController</li>\n<li>GarbageCollectorController</li>\n<li>HPAController</li>\n<li>DisruptionController</li>\n<li>CSRSigningController</li>\n<li>CSRApprovingController</li>\n<li>TokenController</li>\n<li>NodeController</li>\n<li>ServiceController</li>\n<li>RouteController</li>\n<li>PVBinderController</li>\n<li>AttachDetachController</li>\n<li>BootstrapSignerController</li>\n<li>TokenCleanerController</li>\n</ul>\n<p><strong>cloud-controller-manager</strong></p>\n<p><code>cloud-controller-manager</code> 是指嵌入特定云的控制逻辑之 控制平面组件。 <code>cloud-controller-manager</code> 允许你将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。</p>\n<p>下面的控制器都包含对云平台驱动的依赖：</p>\n<ul>\n<li>节点控制器（Node Controller）：用于在节点终止响应后检查云提供商以确定节点是否已被删除</li>\n<li>路由控制器（Route Controller）：用于在底层云基础架构中设置路由</li>\n<li>服务控制器（Service Controller）：用于创建、更新和删除云提供商负载均衡器</li>\n</ul>\n<p><strong>Node 组件</strong></p>\n<p><strong>kubelet</strong></p>\n<p>直接跟容器引擎交互实现容器的生命周期管理。</p>\n<p>master排到node节点代表,管理本机容器。</p>\n<p>kubelet 会在集群中每个节点（node）上运行。 它保证容器（containers）都运行在 Pod 中。<br>kubelet 接收一组通过各类机制提供给它的 PodSpecs， 确保这些 PodSpecs 中描述的容器处于运行状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容器。</p>\n<p><strong>kube-proxy</strong></p>\n<p>负责写入规则至 IPTABLES、IPVS 实现服务映射访问的。</p>\n<p>kube-proxy 是集群中每个节点（node）所上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。<br>kube-proxy 维护节点上的一些网络规则， 这些网络规则会允许从集群内部或外部的网络会话与 Pod 进行网络通信。<br>如果操作系统提供了可用的数据包过滤层，则 kube-proxy 会通过它来实现网络规则。 否则，kube-proxy 仅做流量转发。</p>\n<p><strong>k8s核心概念</strong></p>\n<p>Pod</p>\n<ul>\n<li>最小部署单元</li>\n<li>一组容器的集合</li>\n<li>共享网络</li>\n<li>生命周期是短暂的</li>\n</ul>\n<p>controller</p>\n<ul>\n<li>确保预期的pod副本数量</li>\n<li>无状态应用部署</li>\n<li>有状态应用部署</li>\n<li>确保所有的node运行同一个pod一次性任务和定时任务</li>\n</ul>\n<p>Service</p>\n<ul>\n<li>定义一组pod的访问规则</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"kubernetes组件\"><a href=\"#kubernetes组件\" class=\"headerlink\" title=\"kubernetes组件\"></a>kubernetes组件</h1><p>一个 Kubernetes 集群是由一组被称作节点（node）的机器组成， 这些节点上会运行由 Kubernetes 所管理的容器化应用。 且每个集群至少有一个工作节点。</p>\n<p>工作节点会托管所谓的 Pods，而 Pod 就是作为应用负载的组件。 控制平面管理集群中的工作节点和 Pods。 为集群提供故障转移和高可用性， 这些控制平面一般跨多主机运行，而集群也会跨多个节点运行。</p>\n<img src=\"/2021/07/29/kubernetes%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/image-1-1024x478.png\" class=\"\" title=\"img\">Kubernetes 集群的组件\n\n<p><strong>控制平面组件（Control Plane Components）</strong></p>\n<p>控制平面组件会为集群做出全局决策，比如资源的调度。 以及检测和响应集群事件，例如当不满足部署的 <code>replicas</code> 字段时， 要启动新的 pod）。</p>\n<p><strong>kube-apiserver</strong></p>\n<p>API 服务器是 Kubernetes 控制平面的组件， 该组件负责公开了 Kubernetes API，负责处理接受请求的工作。 API 服务器是 Kubernetes 控制平面的前端。集群统一入口,以restful方式,交给etcd存储.</p>\n<p><strong>etcd</strong></p>\n<p><code>etcd</code> 是兼顾一致性与高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。存储系统,用于保存集群相关的数据。<br>etcd的官方将它定位成一个可信赖的分布式键值存储服务,它能够为整个分布式集群存储一些关键数据,协助分布式集群的正常运转。<a href=\"http://t.zoukankan.com/liujunjun-p-12186354.html\">etcd运行原理</a></p>\n<p><strong>kube-scheduler</strong></p>\n<p><code>kube-scheduler</code> 是控制平面的组件， 负责监视新创建的、未指定运行节点（node）的 Pods， 并选择节点来让 Pod 在上面运行。负责介绍任务，选择合适的节点进行分配任务。</p>\n<p>调度决策考虑的因素包括单个 Pod 及 Pods 集合的资源需求、软硬件及策略约束、 亲和性及反亲和性规范、数据位置、工作负载间的干扰及最后时限。</p>\n<p>节点调度,选择node节点应用部署。</p>\n<p><strong>kube-controller-manager</strong></p>\n<p>kube-controller-manager 是控制平面的组件， 负责运行控制器进程。</p>\n<p>为了降低复杂性，控制器都被编译到同一个可执行文件，并在同一个进程中运行。</p>\n<p>控制器：</p>\n<ul>\n<li>节点控制器（Node Controller）：负责在节点出现故障时进行通知和响应</li>\n<li>任务控制器（Job Controller）：监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成</li>\n<li>端点控制器（Endpoints Controller）：填充端点（Endpoints）对象（即加入 Service 与 Pod）</li>\n<li>服务帐户和令牌控制器（Service Account &amp; Token Controllers）：为新的命名空间创建默认帐户和 API 访问令牌</li>\n<li>副本管理器（ReplicationController）：确保特定数量的 Pod 副本处于运⾏状态且总是可用。</li>\n<li>Deployment管理器（DeploymentController）：可以拥有 ReplicaSet 并使⽤声明式⽅式在服务器端完成对 Pods 滚动更新的对象。</li>\n<li>状态管理器（StatefulSetController）：管理有状态应⽤的⼯作负载 API 对象。</li>\n<li>DaemonSetController：确保全部（或者某些）节点上运⾏⼀个 Pod 的副本。 当有节点加⼊集群时， 也会为他们新增⼀个 Pod 。 当有节点从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。</li>\n<li>JobController：创建一个或者多个Pods,并将继续重试Pods的执行,直到指定数量的Pods成功终止。</li>\n<li>CronJobController：创建基于时隔重复调度的 Jobs。</li>\n<li>TTLController</li>\n<li>EndpointController</li>\n<li>PodGCController</li>\n<li>ResourceQuotaController</li>\n<li>NamespaceController</li>\n<li>ServiceAccountController</li>\n<li>GarbageCollectorController</li>\n<li>HPAController</li>\n<li>DisruptionController</li>\n<li>CSRSigningController</li>\n<li>CSRApprovingController</li>\n<li>TokenController</li>\n<li>NodeController</li>\n<li>ServiceController</li>\n<li>RouteController</li>\n<li>PVBinderController</li>\n<li>AttachDetachController</li>\n<li>BootstrapSignerController</li>\n<li>TokenCleanerController</li>\n</ul>\n<p><strong>cloud-controller-manager</strong></p>\n<p><code>cloud-controller-manager</code> 是指嵌入特定云的控制逻辑之 控制平面组件。 <code>cloud-controller-manager</code> 允许你将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。</p>\n<p>下面的控制器都包含对云平台驱动的依赖：</p>\n<ul>\n<li>节点控制器（Node Controller）：用于在节点终止响应后检查云提供商以确定节点是否已被删除</li>\n<li>路由控制器（Route Controller）：用于在底层云基础架构中设置路由</li>\n<li>服务控制器（Service Controller）：用于创建、更新和删除云提供商负载均衡器</li>\n</ul>\n<p><strong>Node 组件</strong></p>\n<p><strong>kubelet</strong></p>\n<p>直接跟容器引擎交互实现容器的生命周期管理。</p>\n<p>master排到node节点代表,管理本机容器。</p>\n<p>kubelet 会在集群中每个节点（node）上运行。 它保证容器（containers）都运行在 Pod 中。<br>kubelet 接收一组通过各类机制提供给它的 PodSpecs， 确保这些 PodSpecs 中描述的容器处于运行状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容器。</p>\n<p><strong>kube-proxy</strong></p>\n<p>负责写入规则至 IPTABLES、IPVS 实现服务映射访问的。</p>\n<p>kube-proxy 是集群中每个节点（node）所上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。<br>kube-proxy 维护节点上的一些网络规则， 这些网络规则会允许从集群内部或外部的网络会话与 Pod 进行网络通信。<br>如果操作系统提供了可用的数据包过滤层，则 kube-proxy 会通过它来实现网络规则。 否则，kube-proxy 仅做流量转发。</p>\n<p><strong>k8s核心概念</strong></p>\n<p>Pod</p>\n<ul>\n<li>最小部署单元</li>\n<li>一组容器的集合</li>\n<li>共享网络</li>\n<li>生命周期是短暂的</li>\n</ul>\n<p>controller</p>\n<ul>\n<li>确保预期的pod副本数量</li>\n<li>无状态应用部署</li>\n<li>有状态应用部署</li>\n<li>确保所有的node运行同一个pod一次性任务和定时任务</li>\n</ul>\n<p>Service</p>\n<ul>\n<li>定义一组pod的访问规则</li>\n</ul>\n"},{"title":"k8s资源清单及常用字段","date":"2021-07-24T04:38:02.000Z","_content":"\n## **kubernetes发展史**\n\nCNCF(云计算基金会) Borg google内部使用borg，后来发现dockerswarm使用广泛，所以让go开发工程师重写brog，成了k8s，1.0版本的时候捐给了CNCF。\n\n> 一开始docker和另外一家coreos公司，技术基本是共享的，docker火起来后，coreos也研发了一个类似docker的技术，最后coreos加入k8s生态构建，etcd就是coreos提供的捐赠给CNCF的\n\n## 其它容器管理引擎：\n\n- podman 红帽RedHat开发的容器管理引擎\n- docker docker公司研发的docker，另外他还研发了container捐给CNCF\n- CNCF container，docker公司研发捐给CNCF的\n\n## **docker和contaniner的关系：**\n\n- docker用到的运行接口是CRI，CRI是一种容器运行时的标准，可以把CRI想象成一个数据线接口，Python等调用docker是需要调用这个接口，遵循这个规范，这个规范就是CRI\n- container用到的接口是O-CRI，他是CRI做了些改动，O即OPEN\n\n> k8s加入CNCF后，kubectl用的是O-CRI接口，无法直接调用docker的CRI接口，CNCF是国际公司，不可能直接去迁就docker，所以在中间加了个垫片，类似于螺丝与螺母之间的垫片，后来k8s壮大超过docker后，不再迁就docker，在1.19版本中，移除了垫片。k8s调用docker的O-CRI接口，如果没有就不调了，docker忍气吞声发了声明，说支持O_CRI，反过来支持k8s。\n\n## **k8s基本介绍**\n\nkubernetes，简称K8s。k8s 这个缩写是因为 k 和 s 之间有八个字符的关系。 Google 在 2014 年开源了 Kubernetes 项目。\n\nKubernetes 建立在Google 大规模运行生产工作负载十几年经验的基础上， 结合了社区中最优秀的想法和实践。\n\n是一个可移植的，可扩展的开源平台，用于管理云平台中多个主机上的容器化的应用，Kubernetes 的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes 提供了应用部署，规划，更新，维护的一种机制。\n\nKubernetes 是Google 开源的一个**容器编排引擎**，它支持**自动化部署、大规模可伸缩、应用容器化管理**。\n\n在Kubernetes 中，可以创建多个容器，每个容器里面运行一个应用实例，然后通过内置的负载均衡策略，实现对这一组应用实例的管理、发现、访问，而这些细节都不需要人为的手工配置和处理。\n\n## **应用部署发展**\n\n![img](kubernetes的历史与介绍/image-1024x388.png)\n\n**传统部署**\n\n各个组织机构在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。\n\n**虚拟化部署时代**\n\n允许在单个物理服务器的 CPU 上运行多个虚拟机（VM）。 虚拟化允许应用程序在 VM 之间隔离，并提供一定程度的安全，因为一个应用程序的信息 不能被另一应用程序随意访问。\n\n**容器部署时代**\n\n轻量级，容器类似于 VM，但是它们具有被放宽的隔离属性，可以在应用程序之间共享操作系统（OS）。 与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。 由于与基础架构分离，因此可以跨云和 OS 发行版本进行移植。\n\n*好处：*\n\n- 敏捷应用程序的创建和部署\n- 持续开发、集成和部署\n- 关注开发与运维的分离\n- 可观察性\n- 跨开发、测试和生产的环境一致性\n- 跨云和操作系统发行版本的可移植性\n- 以应用程序为中心的管理\n- 松散耦合、分布式、弹性、解放的微服务\n- 资源隔离\n- 资源利用\n\n## **k8s的优势**\n\n- 开源\n- 轻量级\n- 弹性伸缩\n- 负载均衡\n\n## **K8s 功能**\n\n**自动装箱**\n\n基于容器对应用运行环境的资源配置要求自动部署应用容器\n\n**自我修复(自愈能力)**\n\n当容器失败时，会对容器进行重启当所部署的Node 节点有问题时，会对容器进行重新部署和重新调度当容器未通过监控检查时，会关闭此容器直到容器正常运行时，才会对外提供服务\n\n**水平扩展**\n\n通过简单的命令、用户UI 界面或基于CPU 等资源使用情况，对应用容器进行规模扩大或规模剪裁\n\n**服务发现和负载均衡**\n\nKubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。\n\n**滚动更新**\n\n可以根据应用的变化，对应用容器运行的应用，进行一次性或批量式更新\n\n**版本回退**\n\n可以根据应用部署情况，对应用容器运行的应用，进行历史版本即时回退\n\n**密钥和配置管理**\n\n在不需要重新构建镜像的情况下，可以部署和更新密钥和应用配置，类似热部署。\n\n**存储编排**\n\n自动实现存储系统挂载及应用，特别对有状态应用实现数据持久化非常重要存储系统可以来自于本地目录、网络存储(NFS、Gluster、Ceph 等)、公共云存储服务\n\n**批处理**\n\n提供一次性任务，定时任务；满足批量数据处理和分析的场景","source":"_posts/kubernetes的历史与介绍.md","raw":"---\ntitle: k8s资源清单及常用字段\ndate: 2021-07-24 12:38:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n---\n\n## **kubernetes发展史**\n\nCNCF(云计算基金会) Borg google内部使用borg，后来发现dockerswarm使用广泛，所以让go开发工程师重写brog，成了k8s，1.0版本的时候捐给了CNCF。\n\n> 一开始docker和另外一家coreos公司，技术基本是共享的，docker火起来后，coreos也研发了一个类似docker的技术，最后coreos加入k8s生态构建，etcd就是coreos提供的捐赠给CNCF的\n\n## 其它容器管理引擎：\n\n- podman 红帽RedHat开发的容器管理引擎\n- docker docker公司研发的docker，另外他还研发了container捐给CNCF\n- CNCF container，docker公司研发捐给CNCF的\n\n## **docker和contaniner的关系：**\n\n- docker用到的运行接口是CRI，CRI是一种容器运行时的标准，可以把CRI想象成一个数据线接口，Python等调用docker是需要调用这个接口，遵循这个规范，这个规范就是CRI\n- container用到的接口是O-CRI，他是CRI做了些改动，O即OPEN\n\n> k8s加入CNCF后，kubectl用的是O-CRI接口，无法直接调用docker的CRI接口，CNCF是国际公司，不可能直接去迁就docker，所以在中间加了个垫片，类似于螺丝与螺母之间的垫片，后来k8s壮大超过docker后，不再迁就docker，在1.19版本中，移除了垫片。k8s调用docker的O-CRI接口，如果没有就不调了，docker忍气吞声发了声明，说支持O_CRI，反过来支持k8s。\n\n## **k8s基本介绍**\n\nkubernetes，简称K8s。k8s 这个缩写是因为 k 和 s 之间有八个字符的关系。 Google 在 2014 年开源了 Kubernetes 项目。\n\nKubernetes 建立在Google 大规模运行生产工作负载十几年经验的基础上， 结合了社区中最优秀的想法和实践。\n\n是一个可移植的，可扩展的开源平台，用于管理云平台中多个主机上的容器化的应用，Kubernetes 的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes 提供了应用部署，规划，更新，维护的一种机制。\n\nKubernetes 是Google 开源的一个**容器编排引擎**，它支持**自动化部署、大规模可伸缩、应用容器化管理**。\n\n在Kubernetes 中，可以创建多个容器，每个容器里面运行一个应用实例，然后通过内置的负载均衡策略，实现对这一组应用实例的管理、发现、访问，而这些细节都不需要人为的手工配置和处理。\n\n## **应用部署发展**\n\n![img](kubernetes的历史与介绍/image-1024x388.png)\n\n**传统部署**\n\n各个组织机构在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。\n\n**虚拟化部署时代**\n\n允许在单个物理服务器的 CPU 上运行多个虚拟机（VM）。 虚拟化允许应用程序在 VM 之间隔离，并提供一定程度的安全，因为一个应用程序的信息 不能被另一应用程序随意访问。\n\n**容器部署时代**\n\n轻量级，容器类似于 VM，但是它们具有被放宽的隔离属性，可以在应用程序之间共享操作系统（OS）。 与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。 由于与基础架构分离，因此可以跨云和 OS 发行版本进行移植。\n\n*好处：*\n\n- 敏捷应用程序的创建和部署\n- 持续开发、集成和部署\n- 关注开发与运维的分离\n- 可观察性\n- 跨开发、测试和生产的环境一致性\n- 跨云和操作系统发行版本的可移植性\n- 以应用程序为中心的管理\n- 松散耦合、分布式、弹性、解放的微服务\n- 资源隔离\n- 资源利用\n\n## **k8s的优势**\n\n- 开源\n- 轻量级\n- 弹性伸缩\n- 负载均衡\n\n## **K8s 功能**\n\n**自动装箱**\n\n基于容器对应用运行环境的资源配置要求自动部署应用容器\n\n**自我修复(自愈能力)**\n\n当容器失败时，会对容器进行重启当所部署的Node 节点有问题时，会对容器进行重新部署和重新调度当容器未通过监控检查时，会关闭此容器直到容器正常运行时，才会对外提供服务\n\n**水平扩展**\n\n通过简单的命令、用户UI 界面或基于CPU 等资源使用情况，对应用容器进行规模扩大或规模剪裁\n\n**服务发现和负载均衡**\n\nKubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。\n\n**滚动更新**\n\n可以根据应用的变化，对应用容器运行的应用，进行一次性或批量式更新\n\n**版本回退**\n\n可以根据应用部署情况，对应用容器运行的应用，进行历史版本即时回退\n\n**密钥和配置管理**\n\n在不需要重新构建镜像的情况下，可以部署和更新密钥和应用配置，类似热部署。\n\n**存储编排**\n\n自动实现存储系统挂载及应用，特别对有状态应用实现数据持久化非常重要存储系统可以来自于本地目录、网络存储(NFS、Gluster、Ceph 等)、公共云存储服务\n\n**批处理**\n\n提供一次性任务，定时任务；满足批量数据处理和分析的场景","slug":"kubernetes的历史与介绍","published":1,"updated":"2022-09-23T16:43:38.513Z","_id":"cl8epnweg000dv4vjclra4b10","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"kubernetes发展史\"><a href=\"#kubernetes发展史\" class=\"headerlink\" title=\"kubernetes发展史\"></a><strong>kubernetes发展史</strong></h2><p>CNCF(云计算基金会) Borg google内部使用borg，后来发现dockerswarm使用广泛，所以让go开发工程师重写brog，成了k8s，1.0版本的时候捐给了CNCF。</p>\n<blockquote>\n<p>一开始docker和另外一家coreos公司，技术基本是共享的，docker火起来后，coreos也研发了一个类似docker的技术，最后coreos加入k8s生态构建，etcd就是coreos提供的捐赠给CNCF的</p>\n</blockquote>\n<h2 id=\"其它容器管理引擎：\"><a href=\"#其它容器管理引擎：\" class=\"headerlink\" title=\"其它容器管理引擎：\"></a>其它容器管理引擎：</h2><ul>\n<li>podman 红帽RedHat开发的容器管理引擎</li>\n<li>docker docker公司研发的docker，另外他还研发了container捐给CNCF</li>\n<li>CNCF container，docker公司研发捐给CNCF的</li>\n</ul>\n<h2 id=\"docker和contaniner的关系：\"><a href=\"#docker和contaniner的关系：\" class=\"headerlink\" title=\"docker和contaniner的关系：\"></a><strong>docker和contaniner的关系：</strong></h2><ul>\n<li>docker用到的运行接口是CRI，CRI是一种容器运行时的标准，可以把CRI想象成一个数据线接口，Python等调用docker是需要调用这个接口，遵循这个规范，这个规范就是CRI</li>\n<li>container用到的接口是O-CRI，他是CRI做了些改动，O即OPEN</li>\n</ul>\n<blockquote>\n<p>k8s加入CNCF后，kubectl用的是O-CRI接口，无法直接调用docker的CRI接口，CNCF是国际公司，不可能直接去迁就docker，所以在中间加了个垫片，类似于螺丝与螺母之间的垫片，后来k8s壮大超过docker后，不再迁就docker，在1.19版本中，移除了垫片。k8s调用docker的O-CRI接口，如果没有就不调了，docker忍气吞声发了声明，说支持O_CRI，反过来支持k8s。</p>\n</blockquote>\n<h2 id=\"k8s基本介绍\"><a href=\"#k8s基本介绍\" class=\"headerlink\" title=\"k8s基本介绍\"></a><strong>k8s基本介绍</strong></h2><p>kubernetes，简称K8s。k8s 这个缩写是因为 k 和 s 之间有八个字符的关系。 Google 在 2014 年开源了 Kubernetes 项目。</p>\n<p>Kubernetes 建立在Google 大规模运行生产工作负载十几年经验的基础上， 结合了社区中最优秀的想法和实践。</p>\n<p>是一个可移植的，可扩展的开源平台，用于管理云平台中多个主机上的容器化的应用，Kubernetes 的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes 提供了应用部署，规划，更新，维护的一种机制。</p>\n<p>Kubernetes 是Google 开源的一个<strong>容器编排引擎</strong>，它支持<strong>自动化部署、大规模可伸缩、应用容器化管理</strong>。</p>\n<p>在Kubernetes 中，可以创建多个容器，每个容器里面运行一个应用实例，然后通过内置的负载均衡策略，实现对这一组应用实例的管理、发现、访问，而这些细节都不需要人为的手工配置和处理。</p>\n<h2 id=\"应用部署发展\"><a href=\"#应用部署发展\" class=\"headerlink\" title=\"应用部署发展\"></a><strong>应用部署发展</strong></h2><img src=\"/2021/07/24/kubernetes%E7%9A%84%E5%8E%86%E5%8F%B2%E4%B8%8E%E4%BB%8B%E7%BB%8D/image-1024x388.png\" class=\"\" title=\"img\">\n\n<p><strong>传统部署</strong></p>\n<p>各个组织机构在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。</p>\n<p><strong>虚拟化部署时代</strong></p>\n<p>允许在单个物理服务器的 CPU 上运行多个虚拟机（VM）。 虚拟化允许应用程序在 VM 之间隔离，并提供一定程度的安全，因为一个应用程序的信息 不能被另一应用程序随意访问。</p>\n<p><strong>容器部署时代</strong></p>\n<p>轻量级，容器类似于 VM，但是它们具有被放宽的隔离属性，可以在应用程序之间共享操作系统（OS）。 与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。 由于与基础架构分离，因此可以跨云和 OS 发行版本进行移植。</p>\n<p><em>好处：</em></p>\n<ul>\n<li>敏捷应用程序的创建和部署</li>\n<li>持续开发、集成和部署</li>\n<li>关注开发与运维的分离</li>\n<li>可观察性</li>\n<li>跨开发、测试和生产的环境一致性</li>\n<li>跨云和操作系统发行版本的可移植性</li>\n<li>以应用程序为中心的管理</li>\n<li>松散耦合、分布式、弹性、解放的微服务</li>\n<li>资源隔离</li>\n<li>资源利用</li>\n</ul>\n<h2 id=\"k8s的优势\"><a href=\"#k8s的优势\" class=\"headerlink\" title=\"k8s的优势\"></a><strong>k8s的优势</strong></h2><ul>\n<li>开源</li>\n<li>轻量级</li>\n<li>弹性伸缩</li>\n<li>负载均衡</li>\n</ul>\n<h2 id=\"K8s-功能\"><a href=\"#K8s-功能\" class=\"headerlink\" title=\"K8s 功能\"></a><strong>K8s 功能</strong></h2><p><strong>自动装箱</strong></p>\n<p>基于容器对应用运行环境的资源配置要求自动部署应用容器</p>\n<p><strong>自我修复(自愈能力)</strong></p>\n<p>当容器失败时，会对容器进行重启当所部署的Node 节点有问题时，会对容器进行重新部署和重新调度当容器未通过监控检查时，会关闭此容器直到容器正常运行时，才会对外提供服务</p>\n<p><strong>水平扩展</strong></p>\n<p>通过简单的命令、用户UI 界面或基于CPU 等资源使用情况，对应用容器进行规模扩大或规模剪裁</p>\n<p><strong>服务发现和负载均衡</strong></p>\n<p>Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。</p>\n<p><strong>滚动更新</strong></p>\n<p>可以根据应用的变化，对应用容器运行的应用，进行一次性或批量式更新</p>\n<p><strong>版本回退</strong></p>\n<p>可以根据应用部署情况，对应用容器运行的应用，进行历史版本即时回退</p>\n<p><strong>密钥和配置管理</strong></p>\n<p>在不需要重新构建镜像的情况下，可以部署和更新密钥和应用配置，类似热部署。</p>\n<p><strong>存储编排</strong></p>\n<p>自动实现存储系统挂载及应用，特别对有状态应用实现数据持久化非常重要存储系统可以来自于本地目录、网络存储(NFS、Gluster、Ceph 等)、公共云存储服务</p>\n<p><strong>批处理</strong></p>\n<p>提供一次性任务，定时任务；满足批量数据处理和分析的场景</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"kubernetes发展史\"><a href=\"#kubernetes发展史\" class=\"headerlink\" title=\"kubernetes发展史\"></a><strong>kubernetes发展史</strong></h2><p>CNCF(云计算基金会) Borg google内部使用borg，后来发现dockerswarm使用广泛，所以让go开发工程师重写brog，成了k8s，1.0版本的时候捐给了CNCF。</p>\n<blockquote>\n<p>一开始docker和另外一家coreos公司，技术基本是共享的，docker火起来后，coreos也研发了一个类似docker的技术，最后coreos加入k8s生态构建，etcd就是coreos提供的捐赠给CNCF的</p>\n</blockquote>\n<h2 id=\"其它容器管理引擎：\"><a href=\"#其它容器管理引擎：\" class=\"headerlink\" title=\"其它容器管理引擎：\"></a>其它容器管理引擎：</h2><ul>\n<li>podman 红帽RedHat开发的容器管理引擎</li>\n<li>docker docker公司研发的docker，另外他还研发了container捐给CNCF</li>\n<li>CNCF container，docker公司研发捐给CNCF的</li>\n</ul>\n<h2 id=\"docker和contaniner的关系：\"><a href=\"#docker和contaniner的关系：\" class=\"headerlink\" title=\"docker和contaniner的关系：\"></a><strong>docker和contaniner的关系：</strong></h2><ul>\n<li>docker用到的运行接口是CRI，CRI是一种容器运行时的标准，可以把CRI想象成一个数据线接口，Python等调用docker是需要调用这个接口，遵循这个规范，这个规范就是CRI</li>\n<li>container用到的接口是O-CRI，他是CRI做了些改动，O即OPEN</li>\n</ul>\n<blockquote>\n<p>k8s加入CNCF后，kubectl用的是O-CRI接口，无法直接调用docker的CRI接口，CNCF是国际公司，不可能直接去迁就docker，所以在中间加了个垫片，类似于螺丝与螺母之间的垫片，后来k8s壮大超过docker后，不再迁就docker，在1.19版本中，移除了垫片。k8s调用docker的O-CRI接口，如果没有就不调了，docker忍气吞声发了声明，说支持O_CRI，反过来支持k8s。</p>\n</blockquote>\n<h2 id=\"k8s基本介绍\"><a href=\"#k8s基本介绍\" class=\"headerlink\" title=\"k8s基本介绍\"></a><strong>k8s基本介绍</strong></h2><p>kubernetes，简称K8s。k8s 这个缩写是因为 k 和 s 之间有八个字符的关系。 Google 在 2014 年开源了 Kubernetes 项目。</p>\n<p>Kubernetes 建立在Google 大规模运行生产工作负载十几年经验的基础上， 结合了社区中最优秀的想法和实践。</p>\n<p>是一个可移植的，可扩展的开源平台，用于管理云平台中多个主机上的容器化的应用，Kubernetes 的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes 提供了应用部署，规划，更新，维护的一种机制。</p>\n<p>Kubernetes 是Google 开源的一个<strong>容器编排引擎</strong>，它支持<strong>自动化部署、大规模可伸缩、应用容器化管理</strong>。</p>\n<p>在Kubernetes 中，可以创建多个容器，每个容器里面运行一个应用实例，然后通过内置的负载均衡策略，实现对这一组应用实例的管理、发现、访问，而这些细节都不需要人为的手工配置和处理。</p>\n<h2 id=\"应用部署发展\"><a href=\"#应用部署发展\" class=\"headerlink\" title=\"应用部署发展\"></a><strong>应用部署发展</strong></h2><img src=\"/2021/07/24/kubernetes%E7%9A%84%E5%8E%86%E5%8F%B2%E4%B8%8E%E4%BB%8B%E7%BB%8D/image-1024x388.png\" class=\"\" title=\"img\">\n\n<p><strong>传统部署</strong></p>\n<p>各个组织机构在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。</p>\n<p><strong>虚拟化部署时代</strong></p>\n<p>允许在单个物理服务器的 CPU 上运行多个虚拟机（VM）。 虚拟化允许应用程序在 VM 之间隔离，并提供一定程度的安全，因为一个应用程序的信息 不能被另一应用程序随意访问。</p>\n<p><strong>容器部署时代</strong></p>\n<p>轻量级，容器类似于 VM，但是它们具有被放宽的隔离属性，可以在应用程序之间共享操作系统（OS）。 与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。 由于与基础架构分离，因此可以跨云和 OS 发行版本进行移植。</p>\n<p><em>好处：</em></p>\n<ul>\n<li>敏捷应用程序的创建和部署</li>\n<li>持续开发、集成和部署</li>\n<li>关注开发与运维的分离</li>\n<li>可观察性</li>\n<li>跨开发、测试和生产的环境一致性</li>\n<li>跨云和操作系统发行版本的可移植性</li>\n<li>以应用程序为中心的管理</li>\n<li>松散耦合、分布式、弹性、解放的微服务</li>\n<li>资源隔离</li>\n<li>资源利用</li>\n</ul>\n<h2 id=\"k8s的优势\"><a href=\"#k8s的优势\" class=\"headerlink\" title=\"k8s的优势\"></a><strong>k8s的优势</strong></h2><ul>\n<li>开源</li>\n<li>轻量级</li>\n<li>弹性伸缩</li>\n<li>负载均衡</li>\n</ul>\n<h2 id=\"K8s-功能\"><a href=\"#K8s-功能\" class=\"headerlink\" title=\"K8s 功能\"></a><strong>K8s 功能</strong></h2><p><strong>自动装箱</strong></p>\n<p>基于容器对应用运行环境的资源配置要求自动部署应用容器</p>\n<p><strong>自我修复(自愈能力)</strong></p>\n<p>当容器失败时，会对容器进行重启当所部署的Node 节点有问题时，会对容器进行重新部署和重新调度当容器未通过监控检查时，会关闭此容器直到容器正常运行时，才会对外提供服务</p>\n<p><strong>水平扩展</strong></p>\n<p>通过简单的命令、用户UI 界面或基于CPU 等资源使用情况，对应用容器进行规模扩大或规模剪裁</p>\n<p><strong>服务发现和负载均衡</strong></p>\n<p>Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。</p>\n<p><strong>滚动更新</strong></p>\n<p>可以根据应用的变化，对应用容器运行的应用，进行一次性或批量式更新</p>\n<p><strong>版本回退</strong></p>\n<p>可以根据应用部署情况，对应用容器运行的应用，进行历史版本即时回退</p>\n<p><strong>密钥和配置管理</strong></p>\n<p>在不需要重新构建镜像的情况下，可以部署和更新密钥和应用配置，类似热部署。</p>\n<p><strong>存储编排</strong></p>\n<p>自动实现存储系统挂载及应用，特别对有状态应用实现数据持久化非常重要存储系统可以来自于本地目录、网络存储(NFS、Gluster、Ceph 等)、公共云存储服务</p>\n<p><strong>批处理</strong></p>\n<p>提供一次性任务，定时任务；满足批量数据处理和分析的场景</p>\n"},{"title":"kubernetes  kubectl常用命令","date":"2021-07-25T14:38:02.000Z","_content":"\n# 1 kubectl 概述\n\nkubectl 是Kubernetes 集群的命令行工具，通过kubectl 能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署。\n\n[kubectl 概述 | Kubernetes](https://kubernetes.io/zh/docs/reference/kubectl/overview/) \n\n# 2 kubectl 命令的语法\n\n```\nkubectl [command] [TYPE] [NAME] [flags]\n```\n\n- `command`：指定要对一个或多个资源执行的操作，例如 `create`、`get`、`describe`、`delete`。\n- `TYPE`：指定[资源类型](https://kubernetes.io/zh/docs/reference/kubectl/overview/#%E8%B5%84%E6%BA%90%E7%B1%BB%E5%9E%8B)。资源类型不区分大小写， 可以指定单数、复数或缩写形式。 \n- `NAME`：指定资源的名称。名称区分大小写。 如果省略名称，则显示所有资源的详细信息 `kubectl get pods`。 \n- `flags`: 指定可选的参数。例如，可以使用 `-s` 或 `-server` 参数指定 Kubernetes API 服务器的地址和端口。\n\n# 3 常用命令\n\n[kubectl | Kubernetes](https://kubernetes.io/zh/docs/reference/kubectl/kubectl/) \n\n[常用命令](http://docs.kubernetes.org.cn/475.html)\n\n## 3.1 基础命令\n\n| create  | 从文件或 stdin 创建一个或多个资源。                          |\n| ------- | ------------------------------------------------------------ |\n| expose  | 将副本控制器、服务或 pod 作为新的 Kubernetes 服务暴露。      |\n| run     | 在集群上运行指定的镜像。                                     |\n| get     | 列出一个或多个资源。                                         |\n| delete  | 从文件、标准输入或指定标签选择器、名称、资源选择器或资源中删除资源。 |\n| set     | 为对象设置功能特性                                           |\n| explain | 获取多种资源的文档。例如 pod, node, service 等。             |\n| edit    | 使用默认编辑器编辑和更新服务器上一个或多个资源的定义。       |\n\n## 3.2 部署命令\n\n| rollout   | 管理资源的部署。                     |\n| --------- | ------------------------------------ |\n| scale     | 更新指定副本控制器的大小。           |\n| autoscale | 自动伸缩由副本控制器管理的一组 pod。 |\n\n## 3.3 集群管理命令\n\n| certificate  | 修改证书资源                          |\n| ------------ | ------------------------------------- |\n| cluster-info | 显示集群信息                          |\n| top          | 显示资源（CPU/内存/存储）的使用情况。 |\n| cordon       | 将节点标记为不可调度。                |\n| uncordon     | 将节点标记为可调度。                  |\n| drain        | 腾空节点以准备维护。                  |\n| taint        | 更新一个或多个节点上的污点。          |\n\n## 3.4 故障诊断命令\n\n| describe     | 显示一个或多个资源的详细状态                          |\n| ------------ | ----------------------------------------------------- |\n| logs         | 在 pod 中打印容器的日志。                             |\n| attach       | 附加到正在运行的容器，查看输出流或与容器（stdin）交互 |\n| exec         | 执行命令到容器                                        |\n| port-forward | 转发一个或多个本地端口到一个pod                       |\n| proxy        | 运行 Kubernetes API 服务器的代理                      |\n| cp           | 拷贝文件或目录到容器中                                |\n| auth         | 检查授权                                              |\n\n## 3.5 其它命令\n\n| convert      | 在不同的 API 版本之间转换配置文件。配置文件可以是 YAML 或 JSON 格式。 |\n| ------------ | ------------------------------------------------------------ |\n| replace      | 从文件或标准输入中替换资源                                   |\n| apply        | 从文件或 stdin 对资源应用配置更改。                          |\n| patch        | 使用策略合并 patch 程序更新资源的一个或多个字段。            |\n| label        | 添加或更新一个或多个资源的标签。                             |\n| annotate     | 添加或更新一个或多个资源的注解。                             |\n| completion   | 为指定的 shell （bash 或 zsh）输出 shell 补齐代码。          |\n| api-versions | 列出可用的 API 版本。                                        |\n| config       | 修改 kubeconfig 文件。有关详细信息，请参阅各个子命令。       |\n| plugin       | 提供用于与插件交互的实用程序。                               |\n| version      | 显示运行在客户端和服务器上的 Kubernetes 版本。               |\n\n## 3.6 kubectl create 与kubectl apply区别\n\n| **kubectl create**                                           | **kubectl apply**                                      |\n| ------------------------------------------------------------ | ------------------------------------------------------ |\n| 它首先删除资源，然后从提供的文件中创建资源                   | 只更新文件中给出的属性                                 |\n| 在create中使用的文件应该是完整的                             | apply中使用的文件可能是一个不完整的规范                |\n| Create工作于资源的每个属性                                   | Apply仅对资源的某些属性有效                            |\n| 如果您将使用同一个文件的替换命令，该命令将失败，因为缺少信息 | 您可以应用只更改注释的文件，而不指定资源的任何其他属性 |\n\n# 4 常用命令使用案例\n\n```\n//获取所有可用的api 版本\nkubectl api-versions\n//给Node加上标签\nkubectl label nodes <your-node-name> disktype=ssd\n```\n\n快速创建pod及查看运行状态\n\n```shell\n// 创建deployment \nkubectl create deployment nginx --image=nginx\n// 将资源暴露为新的Kubernetes Service\nkubectl expose deployment nginx --port=80 --type=NodePort\n//查看pod\nkubectl get pod/po <Pod_name>\nkubectl get pod/po <Pod_name> -o wide\n//显示所有pod\nkubectl get pods\n//删除pod\nkubectl delete -f pod pod_name.yaml\nkubectl delete pod --all/[pod_name]\n```\n\n通过yaml创建deployment \n\n```\nkubectl apply -f nginx-create.yaml\n```\n\n获取所有的node\n\n```\nkubectl get nodes\n```\n\n获取指定node信息\n\n```\nkubectl get nodes node_name\n```\n\n帮助命令\n\n```\nkubectl --help\n//查看某个操作\nkubectl get -help\n```\n\n快速获取yaml\n\n```\nkubectl create deployment nginx --image=nginx -o yaml --dry-run > nginx-create.yaml\n# 或者\nkubectl get deploy nginx -o yaml ---export > nginx-test.yaml\n```\n\n# 5 练习操作\n\n## 5.1 删除操作\n\n**删除deplyment**\n\n```\n//删除myapp\nkubectl delete deployment myapp\n//删除所有\nkubectl delete deployment --all\n```\n\n**删除pod**\n\n```\n//删除myapp\nkubectl delete pod myapp\n//删除所有\nkubectl delete pod --all\n```\n\n**删除svc**\n\n```\n//删除nginx svc\nkubectl delete svc nginx\n```\n\n## 5.2 通过yaml创建资源\n\ncreate和apply的区别在**3.2 常用命令**有说明\n\n```\nkubectl create -f  init.yaml\n或\nkubectl apply -f  init.yaml\n```\n\n## 5.3 查看k8s可用的apiVersion\n\n```\nkubectl api-versions\n```\n\n## 5.4 查看所有api资源\n\n通过配置清单创建资源时，会出现error: unable to recognize \"init.yaml\": no matches for kind \"Pod\" in version \"V1\"，说明对应apiVersion 版本没有指定资源的定义，可以通过如下命令来查看对应资源的版本。\n\n```\nkubectl api-resources\n```\n\n## 5.5 查看资源\n\n查看pod资源\n\n```yaml\nkubectl get pod\n```\n\n## 5.6 分析资源\n\n查看pod的描述\n\n```\nkubectl describe pod myapp-pod\n```\n\n## 5.7 资源日志查看\n\n查看pod的指定容器的日志\n\n```\nkubectl logs myapp-pod -c  init-myservice\n```\n\n## 5.8 编辑资源清单\n\n```\nkubectl edit pod myapp-pod\n```\n\n## 5.9 获取资源的api版本\n\n```\nkubectl explain pod\n```\n\n## 5.10 获取已创建pod的yaml\n\n```\nkubectl get pod lifecycle-demo -o yaml\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/kubernetes kubectl常用命令.md","raw":"---\ntitle: kubernetes  kubectl常用命令\ndate: 2021-07-25 22:38:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - kubectl \n---\n\n# 1 kubectl 概述\n\nkubectl 是Kubernetes 集群的命令行工具，通过kubectl 能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署。\n\n[kubectl 概述 | Kubernetes](https://kubernetes.io/zh/docs/reference/kubectl/overview/) \n\n# 2 kubectl 命令的语法\n\n```\nkubectl [command] [TYPE] [NAME] [flags]\n```\n\n- `command`：指定要对一个或多个资源执行的操作，例如 `create`、`get`、`describe`、`delete`。\n- `TYPE`：指定[资源类型](https://kubernetes.io/zh/docs/reference/kubectl/overview/#%E8%B5%84%E6%BA%90%E7%B1%BB%E5%9E%8B)。资源类型不区分大小写， 可以指定单数、复数或缩写形式。 \n- `NAME`：指定资源的名称。名称区分大小写。 如果省略名称，则显示所有资源的详细信息 `kubectl get pods`。 \n- `flags`: 指定可选的参数。例如，可以使用 `-s` 或 `-server` 参数指定 Kubernetes API 服务器的地址和端口。\n\n# 3 常用命令\n\n[kubectl | Kubernetes](https://kubernetes.io/zh/docs/reference/kubectl/kubectl/) \n\n[常用命令](http://docs.kubernetes.org.cn/475.html)\n\n## 3.1 基础命令\n\n| create  | 从文件或 stdin 创建一个或多个资源。                          |\n| ------- | ------------------------------------------------------------ |\n| expose  | 将副本控制器、服务或 pod 作为新的 Kubernetes 服务暴露。      |\n| run     | 在集群上运行指定的镜像。                                     |\n| get     | 列出一个或多个资源。                                         |\n| delete  | 从文件、标准输入或指定标签选择器、名称、资源选择器或资源中删除资源。 |\n| set     | 为对象设置功能特性                                           |\n| explain | 获取多种资源的文档。例如 pod, node, service 等。             |\n| edit    | 使用默认编辑器编辑和更新服务器上一个或多个资源的定义。       |\n\n## 3.2 部署命令\n\n| rollout   | 管理资源的部署。                     |\n| --------- | ------------------------------------ |\n| scale     | 更新指定副本控制器的大小。           |\n| autoscale | 自动伸缩由副本控制器管理的一组 pod。 |\n\n## 3.3 集群管理命令\n\n| certificate  | 修改证书资源                          |\n| ------------ | ------------------------------------- |\n| cluster-info | 显示集群信息                          |\n| top          | 显示资源（CPU/内存/存储）的使用情况。 |\n| cordon       | 将节点标记为不可调度。                |\n| uncordon     | 将节点标记为可调度。                  |\n| drain        | 腾空节点以准备维护。                  |\n| taint        | 更新一个或多个节点上的污点。          |\n\n## 3.4 故障诊断命令\n\n| describe     | 显示一个或多个资源的详细状态                          |\n| ------------ | ----------------------------------------------------- |\n| logs         | 在 pod 中打印容器的日志。                             |\n| attach       | 附加到正在运行的容器，查看输出流或与容器（stdin）交互 |\n| exec         | 执行命令到容器                                        |\n| port-forward | 转发一个或多个本地端口到一个pod                       |\n| proxy        | 运行 Kubernetes API 服务器的代理                      |\n| cp           | 拷贝文件或目录到容器中                                |\n| auth         | 检查授权                                              |\n\n## 3.5 其它命令\n\n| convert      | 在不同的 API 版本之间转换配置文件。配置文件可以是 YAML 或 JSON 格式。 |\n| ------------ | ------------------------------------------------------------ |\n| replace      | 从文件或标准输入中替换资源                                   |\n| apply        | 从文件或 stdin 对资源应用配置更改。                          |\n| patch        | 使用策略合并 patch 程序更新资源的一个或多个字段。            |\n| label        | 添加或更新一个或多个资源的标签。                             |\n| annotate     | 添加或更新一个或多个资源的注解。                             |\n| completion   | 为指定的 shell （bash 或 zsh）输出 shell 补齐代码。          |\n| api-versions | 列出可用的 API 版本。                                        |\n| config       | 修改 kubeconfig 文件。有关详细信息，请参阅各个子命令。       |\n| plugin       | 提供用于与插件交互的实用程序。                               |\n| version      | 显示运行在客户端和服务器上的 Kubernetes 版本。               |\n\n## 3.6 kubectl create 与kubectl apply区别\n\n| **kubectl create**                                           | **kubectl apply**                                      |\n| ------------------------------------------------------------ | ------------------------------------------------------ |\n| 它首先删除资源，然后从提供的文件中创建资源                   | 只更新文件中给出的属性                                 |\n| 在create中使用的文件应该是完整的                             | apply中使用的文件可能是一个不完整的规范                |\n| Create工作于资源的每个属性                                   | Apply仅对资源的某些属性有效                            |\n| 如果您将使用同一个文件的替换命令，该命令将失败，因为缺少信息 | 您可以应用只更改注释的文件，而不指定资源的任何其他属性 |\n\n# 4 常用命令使用案例\n\n```\n//获取所有可用的api 版本\nkubectl api-versions\n//给Node加上标签\nkubectl label nodes <your-node-name> disktype=ssd\n```\n\n快速创建pod及查看运行状态\n\n```shell\n// 创建deployment \nkubectl create deployment nginx --image=nginx\n// 将资源暴露为新的Kubernetes Service\nkubectl expose deployment nginx --port=80 --type=NodePort\n//查看pod\nkubectl get pod/po <Pod_name>\nkubectl get pod/po <Pod_name> -o wide\n//显示所有pod\nkubectl get pods\n//删除pod\nkubectl delete -f pod pod_name.yaml\nkubectl delete pod --all/[pod_name]\n```\n\n通过yaml创建deployment \n\n```\nkubectl apply -f nginx-create.yaml\n```\n\n获取所有的node\n\n```\nkubectl get nodes\n```\n\n获取指定node信息\n\n```\nkubectl get nodes node_name\n```\n\n帮助命令\n\n```\nkubectl --help\n//查看某个操作\nkubectl get -help\n```\n\n快速获取yaml\n\n```\nkubectl create deployment nginx --image=nginx -o yaml --dry-run > nginx-create.yaml\n# 或者\nkubectl get deploy nginx -o yaml ---export > nginx-test.yaml\n```\n\n# 5 练习操作\n\n## 5.1 删除操作\n\n**删除deplyment**\n\n```\n//删除myapp\nkubectl delete deployment myapp\n//删除所有\nkubectl delete deployment --all\n```\n\n**删除pod**\n\n```\n//删除myapp\nkubectl delete pod myapp\n//删除所有\nkubectl delete pod --all\n```\n\n**删除svc**\n\n```\n//删除nginx svc\nkubectl delete svc nginx\n```\n\n## 5.2 通过yaml创建资源\n\ncreate和apply的区别在**3.2 常用命令**有说明\n\n```\nkubectl create -f  init.yaml\n或\nkubectl apply -f  init.yaml\n```\n\n## 5.3 查看k8s可用的apiVersion\n\n```\nkubectl api-versions\n```\n\n## 5.4 查看所有api资源\n\n通过配置清单创建资源时，会出现error: unable to recognize \"init.yaml\": no matches for kind \"Pod\" in version \"V1\"，说明对应apiVersion 版本没有指定资源的定义，可以通过如下命令来查看对应资源的版本。\n\n```\nkubectl api-resources\n```\n\n## 5.5 查看资源\n\n查看pod资源\n\n```yaml\nkubectl get pod\n```\n\n## 5.6 分析资源\n\n查看pod的描述\n\n```\nkubectl describe pod myapp-pod\n```\n\n## 5.7 资源日志查看\n\n查看pod的指定容器的日志\n\n```\nkubectl logs myapp-pod -c  init-myservice\n```\n\n## 5.8 编辑资源清单\n\n```\nkubectl edit pod myapp-pod\n```\n\n## 5.9 获取资源的api版本\n\n```\nkubectl explain pod\n```\n\n## 5.10 获取已创建pod的yaml\n\n```\nkubectl get pod lifecycle-demo -o yaml\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"kubernetes kubectl常用命令","published":1,"updated":"2022-09-23T16:46:08.890Z","_id":"cl8epr3d7000hv4vjg0su48e1","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"1-kubectl-概述\"><a href=\"#1-kubectl-概述\" class=\"headerlink\" title=\"1 kubectl 概述\"></a>1 kubectl 概述</h1><p>kubectl 是Kubernetes 集群的命令行工具，通过kubectl 能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署。</p>\n<p><a href=\"https://kubernetes.io/zh/docs/reference/kubectl/overview/\">kubectl 概述 | Kubernetes</a> </p>\n<h1 id=\"2-kubectl-命令的语法\"><a href=\"#2-kubectl-命令的语法\" class=\"headerlink\" title=\"2 kubectl 命令的语法\"></a>2 kubectl 命令的语法</h1><figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\">kubectl <span class=\"hljs-selector-attr\">[command]</span> <span class=\"hljs-selector-attr\">[TYPE]</span> <span class=\"hljs-selector-attr\">[NAME]</span> <span class=\"hljs-selector-attr\">[flags]</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><code>command</code>：指定要对一个或多个资源执行的操作，例如 <code>create</code>、<code>get</code>、<code>describe</code>、<code>delete</code>。</li>\n<li><code>TYPE</code>：指定<a href=\"https://kubernetes.io/zh/docs/reference/kubectl/overview/#%E8%B5%84%E6%BA%90%E7%B1%BB%E5%9E%8B\">资源类型</a>。资源类型不区分大小写， 可以指定单数、复数或缩写形式。 </li>\n<li><code>NAME</code>：指定资源的名称。名称区分大小写。 如果省略名称，则显示所有资源的详细信息 <code>kubectl get pods</code>。 </li>\n<li><code>flags</code>: 指定可选的参数。例如，可以使用 <code>-s</code> 或 <code>-server</code> 参数指定 Kubernetes API 服务器的地址和端口。</li>\n</ul>\n<h1 id=\"3-常用命令\"><a href=\"#3-常用命令\" class=\"headerlink\" title=\"3 常用命令\"></a>3 常用命令</h1><p><a href=\"https://kubernetes.io/zh/docs/reference/kubectl/kubectl/\">kubectl | Kubernetes</a> </p>\n<p><a href=\"http://docs.kubernetes.org.cn/475.html\">常用命令</a></p>\n<h2 id=\"3-1-基础命令\"><a href=\"#3-1-基础命令\" class=\"headerlink\" title=\"3.1 基础命令\"></a>3.1 基础命令</h2><table>\n<thead>\n<tr>\n<th>create</th>\n<th>从文件或 stdin 创建一个或多个资源。</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>expose</td>\n<td>将副本控制器、服务或 pod 作为新的 Kubernetes 服务暴露。</td>\n</tr>\n<tr>\n<td>run</td>\n<td>在集群上运行指定的镜像。</td>\n</tr>\n<tr>\n<td>get</td>\n<td>列出一个或多个资源。</td>\n</tr>\n<tr>\n<td>delete</td>\n<td>从文件、标准输入或指定标签选择器、名称、资源选择器或资源中删除资源。</td>\n</tr>\n<tr>\n<td>set</td>\n<td>为对象设置功能特性</td>\n</tr>\n<tr>\n<td>explain</td>\n<td>获取多种资源的文档。例如 pod, node, service 等。</td>\n</tr>\n<tr>\n<td>edit</td>\n<td>使用默认编辑器编辑和更新服务器上一个或多个资源的定义。</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-2-部署命令\"><a href=\"#3-2-部署命令\" class=\"headerlink\" title=\"3.2 部署命令\"></a>3.2 部署命令</h2><table>\n<thead>\n<tr>\n<th>rollout</th>\n<th>管理资源的部署。</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>scale</td>\n<td>更新指定副本控制器的大小。</td>\n</tr>\n<tr>\n<td>autoscale</td>\n<td>自动伸缩由副本控制器管理的一组 pod。</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-3-集群管理命令\"><a href=\"#3-3-集群管理命令\" class=\"headerlink\" title=\"3.3 集群管理命令\"></a>3.3 集群管理命令</h2><table>\n<thead>\n<tr>\n<th>certificate</th>\n<th>修改证书资源</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>cluster-info</td>\n<td>显示集群信息</td>\n</tr>\n<tr>\n<td>top</td>\n<td>显示资源（CPU/内存/存储）的使用情况。</td>\n</tr>\n<tr>\n<td>cordon</td>\n<td>将节点标记为不可调度。</td>\n</tr>\n<tr>\n<td>uncordon</td>\n<td>将节点标记为可调度。</td>\n</tr>\n<tr>\n<td>drain</td>\n<td>腾空节点以准备维护。</td>\n</tr>\n<tr>\n<td>taint</td>\n<td>更新一个或多个节点上的污点。</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-4-故障诊断命令\"><a href=\"#3-4-故障诊断命令\" class=\"headerlink\" title=\"3.4 故障诊断命令\"></a>3.4 故障诊断命令</h2><table>\n<thead>\n<tr>\n<th>describe</th>\n<th>显示一个或多个资源的详细状态</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>logs</td>\n<td>在 pod 中打印容器的日志。</td>\n</tr>\n<tr>\n<td>attach</td>\n<td>附加到正在运行的容器，查看输出流或与容器（stdin）交互</td>\n</tr>\n<tr>\n<td>exec</td>\n<td>执行命令到容器</td>\n</tr>\n<tr>\n<td>port-forward</td>\n<td>转发一个或多个本地端口到一个pod</td>\n</tr>\n<tr>\n<td>proxy</td>\n<td>运行 Kubernetes API 服务器的代理</td>\n</tr>\n<tr>\n<td>cp</td>\n<td>拷贝文件或目录到容器中</td>\n</tr>\n<tr>\n<td>auth</td>\n<td>检查授权</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-5-其它命令\"><a href=\"#3-5-其它命令\" class=\"headerlink\" title=\"3.5 其它命令\"></a>3.5 其它命令</h2><table>\n<thead>\n<tr>\n<th>convert</th>\n<th>在不同的 API 版本之间转换配置文件。配置文件可以是 YAML 或 JSON 格式。</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>replace</td>\n<td>从文件或标准输入中替换资源</td>\n</tr>\n<tr>\n<td>apply</td>\n<td>从文件或 stdin 对资源应用配置更改。</td>\n</tr>\n<tr>\n<td>patch</td>\n<td>使用策略合并 patch 程序更新资源的一个或多个字段。</td>\n</tr>\n<tr>\n<td>label</td>\n<td>添加或更新一个或多个资源的标签。</td>\n</tr>\n<tr>\n<td>annotate</td>\n<td>添加或更新一个或多个资源的注解。</td>\n</tr>\n<tr>\n<td>completion</td>\n<td>为指定的 shell （bash 或 zsh）输出 shell 补齐代码。</td>\n</tr>\n<tr>\n<td>api-versions</td>\n<td>列出可用的 API 版本。</td>\n</tr>\n<tr>\n<td>config</td>\n<td>修改 kubeconfig 文件。有关详细信息，请参阅各个子命令。</td>\n</tr>\n<tr>\n<td>plugin</td>\n<td>提供用于与插件交互的实用程序。</td>\n</tr>\n<tr>\n<td>version</td>\n<td>显示运行在客户端和服务器上的 Kubernetes 版本。</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-6-kubectl-create-与kubectl-apply区别\"><a href=\"#3-6-kubectl-create-与kubectl-apply区别\" class=\"headerlink\" title=\"3.6 kubectl create 与kubectl apply区别\"></a>3.6 kubectl create 与kubectl apply区别</h2><table>\n<thead>\n<tr>\n<th><strong>kubectl create</strong></th>\n<th><strong>kubectl apply</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>它首先删除资源，然后从提供的文件中创建资源</td>\n<td>只更新文件中给出的属性</td>\n</tr>\n<tr>\n<td>在create中使用的文件应该是完整的</td>\n<td>apply中使用的文件可能是一个不完整的规范</td>\n</tr>\n<tr>\n<td>Create工作于资源的每个属性</td>\n<td>Apply仅对资源的某些属性有效</td>\n</tr>\n<tr>\n<td>如果您将使用同一个文件的替换命令，该命令将失败，因为缺少信息</td>\n<td>您可以应用只更改注释的文件，而不指定资源的任何其他属性</td>\n</tr>\n</tbody></table>\n<h1 id=\"4-常用命令使用案例\"><a href=\"#4-常用命令使用案例\" class=\"headerlink\" title=\"4 常用命令使用案例\"></a>4 常用命令使用案例</h1><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">//</span>获取所有可用的api 版本<br>kubectl api-versions<br><span class=\"hljs-regexp\">//</span>给Node加上标签<br>kubectl label nodes &lt;your-node-name&gt; disktype=ssd<br></code></pre></td></tr></table></figure>\n\n<p>快速创建pod及查看运行状态</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">// 创建deployment <br>kubectl create deployment nginx --image=nginx<br>// 将资源暴露为新的Kubernetes Service<br>kubectl expose deployment nginx --port=80 --type=NodePort<br>//查看pod<br>kubectl get pod/po &lt;Pod_name&gt;<br>kubectl get pod/po &lt;Pod_name&gt; -o wide<br>//显示所有pod<br>kubectl get pods<br>//删除pod<br>kubectl delete -f pod pod_name.yaml<br>kubectl delete pod --all/[pod_name]<br></code></pre></td></tr></table></figure>\n\n<p>通过yaml创建deployment </p>\n<figure class=\"highlight coq\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs coq\">kubectl <span class=\"hljs-built_in\">apply</span> -f nginx-create.yaml<br></code></pre></td></tr></table></figure>\n\n<p>获取所有的node</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl <span class=\"hljs-built_in\">get</span> nodes<br></code></pre></td></tr></table></figure>\n\n<p>获取指定node信息</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl <span class=\"hljs-built_in\">get</span> nodes node_name<br></code></pre></td></tr></table></figure>\n\n<p>帮助命令</p>\n<figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs livecodeserver\">kubectl <span class=\"hljs-comment\">--help</span><span class=\"hljs-comment\"></span><br><span class=\"hljs-comment\">//查看某个操作</span><br>kubectl <span class=\"hljs-built_in\">get</span> -help<br></code></pre></td></tr></table></figure>\n\n<p>快速获取yaml</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl create deployment nginx <span class=\"hljs-attribute\">--image</span>=nginx -o yaml --dry-<span class=\"hljs-built_in\">run</span> &gt; nginx-create.yaml<br><span class=\"hljs-comment\"># 或者</span><br>kubectl <span class=\"hljs-built_in\">get</span> deploy nginx -o yaml ---<span class=\"hljs-built_in\">export</span> &gt; nginx-test.yaml<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"5-练习操作\"><a href=\"#5-练习操作\" class=\"headerlink\" title=\"5 练习操作\"></a>5 练习操作</h1><h2 id=\"5-1-删除操作\"><a href=\"#5-1-删除操作\" class=\"headerlink\" title=\"5.1 删除操作\"></a>5.1 删除操作</h2><p><strong>删除deplyment</strong></p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">//</span>删除myapp<br>kubectl <span class=\"hljs-keyword\">delete</span> deployment myapp<br><span class=\"hljs-regexp\">//</span>删除所有<br>kubectl <span class=\"hljs-keyword\">delete</span> deployment --all<br></code></pre></td></tr></table></figure>\n\n<p><strong>删除pod</strong></p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">//</span>删除myapp<br>kubectl <span class=\"hljs-keyword\">delete</span> pod myapp<br><span class=\"hljs-regexp\">//</span>删除所有<br>kubectl <span class=\"hljs-keyword\">delete</span> pod --all<br></code></pre></td></tr></table></figure>\n\n<p><strong>删除svc</strong></p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">//</span>删除nginx svc<br>kubectl <span class=\"hljs-keyword\">delete</span> svc nginx<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-2-通过yaml创建资源\"><a href=\"#5-2-通过yaml创建资源\" class=\"headerlink\" title=\"5.2 通过yaml创建资源\"></a>5.2 通过yaml创建资源</h2><p>create和apply的区别在<strong>3.2 常用命令</strong>有说明</p>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs csharp\">kubectl create -f  <span class=\"hljs-keyword\">init</span>.yaml<br>或<br>kubectl apply -f  <span class=\"hljs-keyword\">init</span>.yaml<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-3-查看k8s可用的apiVersion\"><a href=\"#5-3-查看k8s可用的apiVersion\" class=\"headerlink\" title=\"5.3 查看k8s可用的apiVersion\"></a>5.3 查看k8s可用的apiVersion</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">kubectl api-versions</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-4-查看所有api资源\"><a href=\"#5-4-查看所有api资源\" class=\"headerlink\" title=\"5.4 查看所有api资源\"></a>5.4 查看所有api资源</h2><p>通过配置清单创建资源时，会出现error: unable to recognize “init.yaml”: no matches for kind “Pod” in version “V1”，说明对应apiVersion 版本没有指定资源的定义，可以通过如下命令来查看对应资源的版本。</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">kubectl api-resources</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-5-查看资源\"><a href=\"#5-5-查看资源\" class=\"headerlink\" title=\"5.5 查看资源\"></a>5.5 查看资源</h2><p>查看pod资源</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-string\">kubectl</span> <span class=\"hljs-string\">get</span> <span class=\"hljs-string\">pod</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-6-分析资源\"><a href=\"#5-6-分析资源\" class=\"headerlink\" title=\"5.6 分析资源\"></a>5.6 分析资源</h2><p>查看pod的描述</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">kubectl describe pod myapp-pod</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-7-资源日志查看\"><a href=\"#5-7-资源日志查看\" class=\"headerlink\" title=\"5.7 资源日志查看\"></a>5.7 资源日志查看</h2><p>查看pod的指定容器的日志</p>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs csharp\">kubectl logs myapp-pod -c  <span class=\"hljs-keyword\">init</span>-myservice<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-8-编辑资源清单\"><a href=\"#5-8-编辑资源清单\" class=\"headerlink\" title=\"5.8 编辑资源清单\"></a>5.8 编辑资源清单</h2><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl <span class=\"hljs-built_in\">edit</span> pod myapp-pod<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-9-获取资源的api版本\"><a href=\"#5-9-获取资源的api版本\" class=\"headerlink\" title=\"5.9 获取资源的api版本\"></a>5.9 获取资源的api版本</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">kubectl explain pod</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-10-获取已创建pod的yaml\"><a href=\"#5-10-获取已创建pod的yaml\" class=\"headerlink\" title=\"5.10 获取已创建pod的yaml\"></a>5.10 获取已创建pod的yaml</h2><figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">kubectl <span class=\"hljs-built_in\">get</span> pod lifecycle-<span class=\"hljs-built_in\">demo</span> -o yaml<br></code></pre></td></tr></table></figure>\n\n\n\n\n\n\n\n\n\n\n\n\n\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-kubectl-概述\"><a href=\"#1-kubectl-概述\" class=\"headerlink\" title=\"1 kubectl 概述\"></a>1 kubectl 概述</h1><p>kubectl 是Kubernetes 集群的命令行工具，通过kubectl 能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署。</p>\n<p><a href=\"https://kubernetes.io/zh/docs/reference/kubectl/overview/\">kubectl 概述 | Kubernetes</a> </p>\n<h1 id=\"2-kubectl-命令的语法\"><a href=\"#2-kubectl-命令的语法\" class=\"headerlink\" title=\"2 kubectl 命令的语法\"></a>2 kubectl 命令的语法</h1><figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\">kubectl <span class=\"hljs-selector-attr\">[command]</span> <span class=\"hljs-selector-attr\">[TYPE]</span> <span class=\"hljs-selector-attr\">[NAME]</span> <span class=\"hljs-selector-attr\">[flags]</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><code>command</code>：指定要对一个或多个资源执行的操作，例如 <code>create</code>、<code>get</code>、<code>describe</code>、<code>delete</code>。</li>\n<li><code>TYPE</code>：指定<a href=\"https://kubernetes.io/zh/docs/reference/kubectl/overview/#%E8%B5%84%E6%BA%90%E7%B1%BB%E5%9E%8B\">资源类型</a>。资源类型不区分大小写， 可以指定单数、复数或缩写形式。 </li>\n<li><code>NAME</code>：指定资源的名称。名称区分大小写。 如果省略名称，则显示所有资源的详细信息 <code>kubectl get pods</code>。 </li>\n<li><code>flags</code>: 指定可选的参数。例如，可以使用 <code>-s</code> 或 <code>-server</code> 参数指定 Kubernetes API 服务器的地址和端口。</li>\n</ul>\n<h1 id=\"3-常用命令\"><a href=\"#3-常用命令\" class=\"headerlink\" title=\"3 常用命令\"></a>3 常用命令</h1><p><a href=\"https://kubernetes.io/zh/docs/reference/kubectl/kubectl/\">kubectl | Kubernetes</a> </p>\n<p><a href=\"http://docs.kubernetes.org.cn/475.html\">常用命令</a></p>\n<h2 id=\"3-1-基础命令\"><a href=\"#3-1-基础命令\" class=\"headerlink\" title=\"3.1 基础命令\"></a>3.1 基础命令</h2><table>\n<thead>\n<tr>\n<th>create</th>\n<th>从文件或 stdin 创建一个或多个资源。</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>expose</td>\n<td>将副本控制器、服务或 pod 作为新的 Kubernetes 服务暴露。</td>\n</tr>\n<tr>\n<td>run</td>\n<td>在集群上运行指定的镜像。</td>\n</tr>\n<tr>\n<td>get</td>\n<td>列出一个或多个资源。</td>\n</tr>\n<tr>\n<td>delete</td>\n<td>从文件、标准输入或指定标签选择器、名称、资源选择器或资源中删除资源。</td>\n</tr>\n<tr>\n<td>set</td>\n<td>为对象设置功能特性</td>\n</tr>\n<tr>\n<td>explain</td>\n<td>获取多种资源的文档。例如 pod, node, service 等。</td>\n</tr>\n<tr>\n<td>edit</td>\n<td>使用默认编辑器编辑和更新服务器上一个或多个资源的定义。</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-2-部署命令\"><a href=\"#3-2-部署命令\" class=\"headerlink\" title=\"3.2 部署命令\"></a>3.2 部署命令</h2><table>\n<thead>\n<tr>\n<th>rollout</th>\n<th>管理资源的部署。</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>scale</td>\n<td>更新指定副本控制器的大小。</td>\n</tr>\n<tr>\n<td>autoscale</td>\n<td>自动伸缩由副本控制器管理的一组 pod。</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-3-集群管理命令\"><a href=\"#3-3-集群管理命令\" class=\"headerlink\" title=\"3.3 集群管理命令\"></a>3.3 集群管理命令</h2><table>\n<thead>\n<tr>\n<th>certificate</th>\n<th>修改证书资源</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>cluster-info</td>\n<td>显示集群信息</td>\n</tr>\n<tr>\n<td>top</td>\n<td>显示资源（CPU/内存/存储）的使用情况。</td>\n</tr>\n<tr>\n<td>cordon</td>\n<td>将节点标记为不可调度。</td>\n</tr>\n<tr>\n<td>uncordon</td>\n<td>将节点标记为可调度。</td>\n</tr>\n<tr>\n<td>drain</td>\n<td>腾空节点以准备维护。</td>\n</tr>\n<tr>\n<td>taint</td>\n<td>更新一个或多个节点上的污点。</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-4-故障诊断命令\"><a href=\"#3-4-故障诊断命令\" class=\"headerlink\" title=\"3.4 故障诊断命令\"></a>3.4 故障诊断命令</h2><table>\n<thead>\n<tr>\n<th>describe</th>\n<th>显示一个或多个资源的详细状态</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>logs</td>\n<td>在 pod 中打印容器的日志。</td>\n</tr>\n<tr>\n<td>attach</td>\n<td>附加到正在运行的容器，查看输出流或与容器（stdin）交互</td>\n</tr>\n<tr>\n<td>exec</td>\n<td>执行命令到容器</td>\n</tr>\n<tr>\n<td>port-forward</td>\n<td>转发一个或多个本地端口到一个pod</td>\n</tr>\n<tr>\n<td>proxy</td>\n<td>运行 Kubernetes API 服务器的代理</td>\n</tr>\n<tr>\n<td>cp</td>\n<td>拷贝文件或目录到容器中</td>\n</tr>\n<tr>\n<td>auth</td>\n<td>检查授权</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-5-其它命令\"><a href=\"#3-5-其它命令\" class=\"headerlink\" title=\"3.5 其它命令\"></a>3.5 其它命令</h2><table>\n<thead>\n<tr>\n<th>convert</th>\n<th>在不同的 API 版本之间转换配置文件。配置文件可以是 YAML 或 JSON 格式。</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>replace</td>\n<td>从文件或标准输入中替换资源</td>\n</tr>\n<tr>\n<td>apply</td>\n<td>从文件或 stdin 对资源应用配置更改。</td>\n</tr>\n<tr>\n<td>patch</td>\n<td>使用策略合并 patch 程序更新资源的一个或多个字段。</td>\n</tr>\n<tr>\n<td>label</td>\n<td>添加或更新一个或多个资源的标签。</td>\n</tr>\n<tr>\n<td>annotate</td>\n<td>添加或更新一个或多个资源的注解。</td>\n</tr>\n<tr>\n<td>completion</td>\n<td>为指定的 shell （bash 或 zsh）输出 shell 补齐代码。</td>\n</tr>\n<tr>\n<td>api-versions</td>\n<td>列出可用的 API 版本。</td>\n</tr>\n<tr>\n<td>config</td>\n<td>修改 kubeconfig 文件。有关详细信息，请参阅各个子命令。</td>\n</tr>\n<tr>\n<td>plugin</td>\n<td>提供用于与插件交互的实用程序。</td>\n</tr>\n<tr>\n<td>version</td>\n<td>显示运行在客户端和服务器上的 Kubernetes 版本。</td>\n</tr>\n</tbody></table>\n<h2 id=\"3-6-kubectl-create-与kubectl-apply区别\"><a href=\"#3-6-kubectl-create-与kubectl-apply区别\" class=\"headerlink\" title=\"3.6 kubectl create 与kubectl apply区别\"></a>3.6 kubectl create 与kubectl apply区别</h2><table>\n<thead>\n<tr>\n<th><strong>kubectl create</strong></th>\n<th><strong>kubectl apply</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>它首先删除资源，然后从提供的文件中创建资源</td>\n<td>只更新文件中给出的属性</td>\n</tr>\n<tr>\n<td>在create中使用的文件应该是完整的</td>\n<td>apply中使用的文件可能是一个不完整的规范</td>\n</tr>\n<tr>\n<td>Create工作于资源的每个属性</td>\n<td>Apply仅对资源的某些属性有效</td>\n</tr>\n<tr>\n<td>如果您将使用同一个文件的替换命令，该命令将失败，因为缺少信息</td>\n<td>您可以应用只更改注释的文件，而不指定资源的任何其他属性</td>\n</tr>\n</tbody></table>\n<h1 id=\"4-常用命令使用案例\"><a href=\"#4-常用命令使用案例\" class=\"headerlink\" title=\"4 常用命令使用案例\"></a>4 常用命令使用案例</h1><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">//</span>获取所有可用的api 版本<br>kubectl api-versions<br><span class=\"hljs-regexp\">//</span>给Node加上标签<br>kubectl label nodes &lt;your-node-name&gt; disktype=ssd<br></code></pre></td></tr></table></figure>\n\n<p>快速创建pod及查看运行状态</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">// 创建deployment <br>kubectl create deployment nginx --image=nginx<br>// 将资源暴露为新的Kubernetes Service<br>kubectl expose deployment nginx --port=80 --type=NodePort<br>//查看pod<br>kubectl get pod/po &lt;Pod_name&gt;<br>kubectl get pod/po &lt;Pod_name&gt; -o wide<br>//显示所有pod<br>kubectl get pods<br>//删除pod<br>kubectl delete -f pod pod_name.yaml<br>kubectl delete pod --all/[pod_name]<br></code></pre></td></tr></table></figure>\n\n<p>通过yaml创建deployment </p>\n<figure class=\"highlight coq\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs coq\">kubectl <span class=\"hljs-built_in\">apply</span> -f nginx-create.yaml<br></code></pre></td></tr></table></figure>\n\n<p>获取所有的node</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl <span class=\"hljs-built_in\">get</span> nodes<br></code></pre></td></tr></table></figure>\n\n<p>获取指定node信息</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl <span class=\"hljs-built_in\">get</span> nodes node_name<br></code></pre></td></tr></table></figure>\n\n<p>帮助命令</p>\n<figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs livecodeserver\">kubectl <span class=\"hljs-comment\">--help</span><span class=\"hljs-comment\"></span><br><span class=\"hljs-comment\">//查看某个操作</span><br>kubectl <span class=\"hljs-built_in\">get</span> -help<br></code></pre></td></tr></table></figure>\n\n<p>快速获取yaml</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl create deployment nginx <span class=\"hljs-attribute\">--image</span>=nginx -o yaml --dry-<span class=\"hljs-built_in\">run</span> &gt; nginx-create.yaml<br><span class=\"hljs-comment\"># 或者</span><br>kubectl <span class=\"hljs-built_in\">get</span> deploy nginx -o yaml ---<span class=\"hljs-built_in\">export</span> &gt; nginx-test.yaml<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"5-练习操作\"><a href=\"#5-练习操作\" class=\"headerlink\" title=\"5 练习操作\"></a>5 练习操作</h1><h2 id=\"5-1-删除操作\"><a href=\"#5-1-删除操作\" class=\"headerlink\" title=\"5.1 删除操作\"></a>5.1 删除操作</h2><p><strong>删除deplyment</strong></p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">//</span>删除myapp<br>kubectl <span class=\"hljs-keyword\">delete</span> deployment myapp<br><span class=\"hljs-regexp\">//</span>删除所有<br>kubectl <span class=\"hljs-keyword\">delete</span> deployment --all<br></code></pre></td></tr></table></figure>\n\n<p><strong>删除pod</strong></p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">//</span>删除myapp<br>kubectl <span class=\"hljs-keyword\">delete</span> pod myapp<br><span class=\"hljs-regexp\">//</span>删除所有<br>kubectl <span class=\"hljs-keyword\">delete</span> pod --all<br></code></pre></td></tr></table></figure>\n\n<p><strong>删除svc</strong></p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">//</span>删除nginx svc<br>kubectl <span class=\"hljs-keyword\">delete</span> svc nginx<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-2-通过yaml创建资源\"><a href=\"#5-2-通过yaml创建资源\" class=\"headerlink\" title=\"5.2 通过yaml创建资源\"></a>5.2 通过yaml创建资源</h2><p>create和apply的区别在<strong>3.2 常用命令</strong>有说明</p>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs csharp\">kubectl create -f  <span class=\"hljs-keyword\">init</span>.yaml<br>或<br>kubectl apply -f  <span class=\"hljs-keyword\">init</span>.yaml<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-3-查看k8s可用的apiVersion\"><a href=\"#5-3-查看k8s可用的apiVersion\" class=\"headerlink\" title=\"5.3 查看k8s可用的apiVersion\"></a>5.3 查看k8s可用的apiVersion</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">kubectl api-versions</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-4-查看所有api资源\"><a href=\"#5-4-查看所有api资源\" class=\"headerlink\" title=\"5.4 查看所有api资源\"></a>5.4 查看所有api资源</h2><p>通过配置清单创建资源时，会出现error: unable to recognize “init.yaml”: no matches for kind “Pod” in version “V1”，说明对应apiVersion 版本没有指定资源的定义，可以通过如下命令来查看对应资源的版本。</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">kubectl api-resources</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-5-查看资源\"><a href=\"#5-5-查看资源\" class=\"headerlink\" title=\"5.5 查看资源\"></a>5.5 查看资源</h2><p>查看pod资源</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-string\">kubectl</span> <span class=\"hljs-string\">get</span> <span class=\"hljs-string\">pod</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-6-分析资源\"><a href=\"#5-6-分析资源\" class=\"headerlink\" title=\"5.6 分析资源\"></a>5.6 分析资源</h2><p>查看pod的描述</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">kubectl describe pod myapp-pod</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-7-资源日志查看\"><a href=\"#5-7-资源日志查看\" class=\"headerlink\" title=\"5.7 资源日志查看\"></a>5.7 资源日志查看</h2><p>查看pod的指定容器的日志</p>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs csharp\">kubectl logs myapp-pod -c  <span class=\"hljs-keyword\">init</span>-myservice<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-8-编辑资源清单\"><a href=\"#5-8-编辑资源清单\" class=\"headerlink\" title=\"5.8 编辑资源清单\"></a>5.8 编辑资源清单</h2><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl <span class=\"hljs-built_in\">edit</span> pod myapp-pod<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-9-获取资源的api版本\"><a href=\"#5-9-获取资源的api版本\" class=\"headerlink\" title=\"5.9 获取资源的api版本\"></a>5.9 获取资源的api版本</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">kubectl explain pod</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5-10-获取已创建pod的yaml\"><a href=\"#5-10-获取已创建pod的yaml\" class=\"headerlink\" title=\"5.10 获取已创建pod的yaml\"></a>5.10 获取已创建pod的yaml</h2><figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">kubectl <span class=\"hljs-built_in\">get</span> pod lifecycle-<span class=\"hljs-built_in\">demo</span> -o yaml<br></code></pre></td></tr></table></figure>\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"title":"k8s网络通讯方式","date":"2021-07-30T06:38:02.000Z","_content":"\n# **k8s组网要求**\n\n- 所有的Pods之间可以在不使用NAT网络地址转换的情况下相互通信。\n- 所有的Nodes之间可以在不使用NAT网络地址转换的情况下相互通信。\n- 每个Pod自己看到的自己的ip和其他Pod看到的一致。即所有Pod对象都处于同一平面网络中，而且可以使用Pod自身的地址直接通信。\n\n# **k8s网络模型设计基础原则**\n\n- 每个Pod都拥有一个独立的IP地址，假定所有 Pod 都在一个可以直接连通的、扁平的网络空间中 。\n- 不管Pod是否运行在同一个 Node中，都要求它们可以直接通过对方的 IP 进行访问。\n- 用户不需要额外考虑如何建立 Pod 之间的连接，也不需要考虑将容器端口映射到主机端口等问题。\n\nk8s使用的网络插件必须能为Pod提供满足以上要求的网络，它需要为每个Pod配置至少一个特定的地址，即Pod IP。Pod IP地址实际存在于某个网卡（可以是虚拟设备）上，而service的地址却是一个虚拟IP地址，没有任何网络接口配置此地址，它由kube-proxy借助iptables规则或者IPVS规则重新定向到本地端口，在将其调度至后端Pod对象。Service的IP地址是集群提供服务的接口，也称为ClusterIP。\n\nPod网络及其IP由k8s的网络插件负责配置和管理，具体使用的网络地址可在管理配置网络插件时指定，如10.244.0.0/16网络。而Cluster网络和IP则是由k8s集群负责管理和配置，如10.96.0.0/12网络。\n\n# k8s集群网络\n\n- 主机之间通信(如master和node)，不归k8s管，管理员自行构建。\n- pod资源对象之间通信，是一个虚拟网络。用于为各Pod对象设定IP地址等网络参数，其地址配置于Pod中容器的网络接口上，Pod网络需要借助k8s插件或者CNI插件实现，该插件可独立不属于k8s集群，亦可托管于k8s之上，他需要在构建k8s集群时由管理员定义，而后创建Pod对象时由其自动完成网络参数的动态配置。\n- Service资源的对象的网络，也是一个虚拟网络，用于k8s集群之中的Service配置IP地址，但此地址并不配置于任何主机或容器的网络接口之上，而是通过Node之上的kube-proxy配置为iptables或ipvs规则，从而将发往此地址的所有流量调度至其后端的各个Pod对象之上。Service网络在k8s集群创建时予以指定，而各Service的地址则在用户创建Service时予以动态配置。\n\n![img](k8s网络通讯方式/image-4.png)k8s网络环境\n\n**容器和容器之间的网络**\n\n- 在k8s中每个Pod中管理着一组Docker容器，这些Docker容器共享同一个网络命名空间。\n- Pod中的每个Docker容器拥有与Pod相同的IP和port地址空间，并且由于他们在同一个网络命名空间，他们之间可以通过localhost相互访问。\n\ncontainer模式指定新创建的Docker容器和已经存在的一个容器共享一个网络命名空间，而不是和宿主机共享。新创建的Docker容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等\n\n每个Pod容器有有一个pause容器其有独立的网络命名空间，在Pod内启动Docker容器时候使用 –net=container就可以让当前Docker容器加入到Pod容器拥有的网络命名空间（pause容器），同一个Pod内的多个docker容器相互通信机制。\n\n![img](k8s网络通讯方式/image-5.png)\n\n**Pod与Pod之间的网络**\n\n![img](k8s网络通讯方式/image-6.png)pod和pod通信\n\n- k8s中，每个Pod拥有一个ip地址，不同的Pod之间可以直接使用ip通讯\n- 在同一个Node上，从Pod的视角看，它存在于自己的网络命名空间中，并且需要与该Node上的其他网络命名空间上的Pod进行通信。\n\n原理：\n\n使用linux虚拟以太网设备或者说是由两个虚拟接口组成的veth对使不同的网络命名空间链接起来，这些虚拟接口分布在多个网络命名空间上（这里是指多个Pod上）\n\n为了让多个Pod的网络命名空间链接起来，可以让veth对的一端链接到root网络命名空间（宿主机的），另一端链接到Pod的网络命名空间。这里需要用到一个Linux以太网桥，它是一个虚拟的二层网络设备，目的就是把多个以太网段连接起来，它维护一个转发表，通过查看每个设备mac地址决定转发，还是丢弃数据。\n\n同一台node节点上pod1和pod2通信：\n\npod1通过自身eth0网卡发送数据，eth0连接着veth0，网桥把veth0和veth1组成了一个以太网，然后数据到达veth0之后，网桥通过转发表，发送给veth1，veth1直接把数据传给pod2的eth0。\n\n每对Veth就像一根接插电缆，连接两侧并允许流量在它们之间流动；这种veth对可以推广到同一个Node上任意多的Pod上，如上图这里展示使用veth对链接每个Pod到虚拟机的root网络命名空间。不同node节点上pod和pod通信：**CIDR**CIDR（无类域间路由选择）它消除了传统的A类、B类和C类地址以及划分子网的概念，因而可以更加有效地分配IPv4的地址空间。它可以将好几个IP网络结合在一起，使用一种无类别的域际路由选择算法，使它们合并成一条路由从而较少路由表中的路由条目减轻Internet路由器的负担。k8s集群中，每个node节点都会被分配一个CIDR块，（把网络前缀都相同的连续地址组成的地址组称为CIDR地址块）用来给node上的pod分配IP地址，另外还需要把pod的ip和所在nodeip进行关联.比如node1上pod1和node2上的pod4进行通信首先pod1上网卡eth0将数据发送给已经管理到root命名空间的veth0上，被虚拟网桥收到，查看自己转发表之后，并没有pod4的mac地址。就会把包转发到默认路由，（root命名空间的eth0上，也就是已经到了node节点的网卡上）通过eth0，发送到网络中。寻址转发后包来到了node2，首先被root命名空间的eth0设备接受，查看目标地址是发往pod4的，交给虚拟网桥路由到veth1，最终传给pod4的eth0上。\n\n![img](k8s网络通讯方式/1411165-20210604153215333-1022736403-990x1024.png)不同node节点上\n\npod和pod通信**pod与service之间的网络**pod的ip地址是不持久的，当集群中pod的规模缩减或者pod故障或者node故障重启后，新的pod的ip就可能与之前的不一样的。所以k8s中衍生出来Service来解决这个问题。Service管理了多个Pods，每个Service有一个虚拟的ip,要访问service管理的Pod上的服务只需要访问你这个虚拟ip就可以了，这个虚拟ip是固定的，当service下的pod规模改变、故障重启、node重启时候，对使用service的用户来说是无感知的，因为他们使用的service的ip没有变。当数据包到达Service虚拟ip后，数据包会被通过k8s给该servcie自动创建的负载均衡器路由到背后的pod容器。在k8s里，iptables规则是由kube-proxy配置，kube-proxy监视APIserver的更改，因为集群中所有service（iptables）更改都会发送到APIServer上，所以每台kubelet-proxy监视APIServer，当对service或pod虚拟IP进行修改时，kube-proxy就会在本地更新，以便正确发送给后端pod.![img](k8s网络通讯方式/1411165-20210604153302687-2143265992.png)\n\n数据包从pod1的eth0离开，通过veth0传给网桥cbr0，网桥找不到service的ip对应的mac，交给了默认路由，到达了root命名空间的eth0root命名空间的eth0接受数据包之前会经过iptables进行过滤，iptables接受数据包后使用kube-proxy在node上配置的规则响应service，然后数据包的目的ip重写为service后端指定的pod的ip了。service到pod包的流转：收到包的pod会回应数据包到源pod，源ip是发送方ip，目标IP是接收方，数据包进行回复时经过iptables，iptables使用内核机制conntrack记住它之前做的选择，又将数据包源ip重新为service的ip，目标ip不变，然后原路返回至pod1的eth0**Internet与service之间的网络**node到internet包的流转\n\n![img](k8s网络通讯方式/1411165-20210604153732180-730315756.png)\n\n数据包源自pod1网络命名空间，通过veth对连接到root网络命名空间，紧接着，转发表里没有IP对应的mac，会发送到默认路由，到达root网络命名空间的eth0那么在到达root网络明明空间之前，iptables会修改数据包，现在数据包源ip是pod1的，继续传输会被Internet网关拒绝掉，因为网关NAT仅转发node的ip，解决方案：使iptables执行源NAT更改数据包源ip，让数据包看起来是来自于node而不是podiptables修改完源ip之后，数据包离开node，根据转发规则发给Internet网关，Internet网关执行另一个NAT，内网ip转为公网ip，在Internet上传输。数据包回应时，也是按照：Internet网关需要将公网IP转换为私有ip，到达目标node节点，再通过iptables修改目标ip并且最终传送到pod的eth0虚拟网桥。Internet到k8s的流量：让Internet流量进入k8s集群，这特定于配置的网络，可以在网络堆栈的不同层来实现：（1） NodePort（2）Service LoadBalancer（3）Ingress控制器。**Flannel**Flannel是CoreOS团队针对Kubernetes设计的一个网络规划服务,简单来说,它的功能是让集群中的不同节点主机创建的Docker容器都具有全集群唯一的虚拟IP地址。而且它还能在这些IP地址之间建立一个覆盖网络(Overlay Network),通过这个覆盖网络,将数据包原封不动地传递到目标容器内\n\n![img](k8s网络通讯方式/image-2.png)ETCD 之Flannel提供说明:\n\n存储管理Flannel可分配的IP地址段资源 监控ETCD中每个Pod的实际地址,并在内存中建立维护Pod节点路由表同一个Pod内部通讯:同一个Pod共享同一个网络命名空间,共享同一个Linux协议栈 **Pod1至Pod2**Pod1与Pod2不在同一台主机,Pod的地址是与docker0在同一个网段的,但docker0网段与宿主机网卡是两个完全不同的IP网段，并且不同Node之间的通信只能通过宿主机的物理网卡进行。将Pod的IP和所在Node的IP关联起来,通过这个关联让Pod可以互相访问Pod1与Pod2在同一台机器,由Docker0网桥直接转发请求至Pod2,不需要经过Flannel**Pod至Service的网络**目前基于性能考虑,全部为iptables维护和转发**Pod到外网**Pod向外网发送请求,查找路由表,转发数据包到宿主机的网卡,宿主网卡完成路由选择后，iptables执行Masquerade，把源IP 更改为宿主网卡的IP,然后向外网服务器发送请求。外网访问PodService\n\n参考文章： \n\nhttps://blog.csdn.net/iqifenxia/article/details/121226087\n\nhttp://t.zoukankan.com/fat-girl-spring-p-14849880.html","source":"_posts/k8s网络通讯方式.md","raw":"---\ntitle: k8s网络通讯方式\ndate: 2021-07-30 14:38:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - 网络通讯\n---\n\n# **k8s组网要求**\n\n- 所有的Pods之间可以在不使用NAT网络地址转换的情况下相互通信。\n- 所有的Nodes之间可以在不使用NAT网络地址转换的情况下相互通信。\n- 每个Pod自己看到的自己的ip和其他Pod看到的一致。即所有Pod对象都处于同一平面网络中，而且可以使用Pod自身的地址直接通信。\n\n# **k8s网络模型设计基础原则**\n\n- 每个Pod都拥有一个独立的IP地址，假定所有 Pod 都在一个可以直接连通的、扁平的网络空间中 。\n- 不管Pod是否运行在同一个 Node中，都要求它们可以直接通过对方的 IP 进行访问。\n- 用户不需要额外考虑如何建立 Pod 之间的连接，也不需要考虑将容器端口映射到主机端口等问题。\n\nk8s使用的网络插件必须能为Pod提供满足以上要求的网络，它需要为每个Pod配置至少一个特定的地址，即Pod IP。Pod IP地址实际存在于某个网卡（可以是虚拟设备）上，而service的地址却是一个虚拟IP地址，没有任何网络接口配置此地址，它由kube-proxy借助iptables规则或者IPVS规则重新定向到本地端口，在将其调度至后端Pod对象。Service的IP地址是集群提供服务的接口，也称为ClusterIP。\n\nPod网络及其IP由k8s的网络插件负责配置和管理，具体使用的网络地址可在管理配置网络插件时指定，如10.244.0.0/16网络。而Cluster网络和IP则是由k8s集群负责管理和配置，如10.96.0.0/12网络。\n\n# k8s集群网络\n\n- 主机之间通信(如master和node)，不归k8s管，管理员自行构建。\n- pod资源对象之间通信，是一个虚拟网络。用于为各Pod对象设定IP地址等网络参数，其地址配置于Pod中容器的网络接口上，Pod网络需要借助k8s插件或者CNI插件实现，该插件可独立不属于k8s集群，亦可托管于k8s之上，他需要在构建k8s集群时由管理员定义，而后创建Pod对象时由其自动完成网络参数的动态配置。\n- Service资源的对象的网络，也是一个虚拟网络，用于k8s集群之中的Service配置IP地址，但此地址并不配置于任何主机或容器的网络接口之上，而是通过Node之上的kube-proxy配置为iptables或ipvs规则，从而将发往此地址的所有流量调度至其后端的各个Pod对象之上。Service网络在k8s集群创建时予以指定，而各Service的地址则在用户创建Service时予以动态配置。\n\n![img](k8s网络通讯方式/image-4.png)k8s网络环境\n\n**容器和容器之间的网络**\n\n- 在k8s中每个Pod中管理着一组Docker容器，这些Docker容器共享同一个网络命名空间。\n- Pod中的每个Docker容器拥有与Pod相同的IP和port地址空间，并且由于他们在同一个网络命名空间，他们之间可以通过localhost相互访问。\n\ncontainer模式指定新创建的Docker容器和已经存在的一个容器共享一个网络命名空间，而不是和宿主机共享。新创建的Docker容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等\n\n每个Pod容器有有一个pause容器其有独立的网络命名空间，在Pod内启动Docker容器时候使用 –net=container就可以让当前Docker容器加入到Pod容器拥有的网络命名空间（pause容器），同一个Pod内的多个docker容器相互通信机制。\n\n![img](k8s网络通讯方式/image-5.png)\n\n**Pod与Pod之间的网络**\n\n![img](k8s网络通讯方式/image-6.png)pod和pod通信\n\n- k8s中，每个Pod拥有一个ip地址，不同的Pod之间可以直接使用ip通讯\n- 在同一个Node上，从Pod的视角看，它存在于自己的网络命名空间中，并且需要与该Node上的其他网络命名空间上的Pod进行通信。\n\n原理：\n\n使用linux虚拟以太网设备或者说是由两个虚拟接口组成的veth对使不同的网络命名空间链接起来，这些虚拟接口分布在多个网络命名空间上（这里是指多个Pod上）\n\n为了让多个Pod的网络命名空间链接起来，可以让veth对的一端链接到root网络命名空间（宿主机的），另一端链接到Pod的网络命名空间。这里需要用到一个Linux以太网桥，它是一个虚拟的二层网络设备，目的就是把多个以太网段连接起来，它维护一个转发表，通过查看每个设备mac地址决定转发，还是丢弃数据。\n\n同一台node节点上pod1和pod2通信：\n\npod1通过自身eth0网卡发送数据，eth0连接着veth0，网桥把veth0和veth1组成了一个以太网，然后数据到达veth0之后，网桥通过转发表，发送给veth1，veth1直接把数据传给pod2的eth0。\n\n每对Veth就像一根接插电缆，连接两侧并允许流量在它们之间流动；这种veth对可以推广到同一个Node上任意多的Pod上，如上图这里展示使用veth对链接每个Pod到虚拟机的root网络命名空间。不同node节点上pod和pod通信：**CIDR**CIDR（无类域间路由选择）它消除了传统的A类、B类和C类地址以及划分子网的概念，因而可以更加有效地分配IPv4的地址空间。它可以将好几个IP网络结合在一起，使用一种无类别的域际路由选择算法，使它们合并成一条路由从而较少路由表中的路由条目减轻Internet路由器的负担。k8s集群中，每个node节点都会被分配一个CIDR块，（把网络前缀都相同的连续地址组成的地址组称为CIDR地址块）用来给node上的pod分配IP地址，另外还需要把pod的ip和所在nodeip进行关联.比如node1上pod1和node2上的pod4进行通信首先pod1上网卡eth0将数据发送给已经管理到root命名空间的veth0上，被虚拟网桥收到，查看自己转发表之后，并没有pod4的mac地址。就会把包转发到默认路由，（root命名空间的eth0上，也就是已经到了node节点的网卡上）通过eth0，发送到网络中。寻址转发后包来到了node2，首先被root命名空间的eth0设备接受，查看目标地址是发往pod4的，交给虚拟网桥路由到veth1，最终传给pod4的eth0上。\n\n![img](k8s网络通讯方式/1411165-20210604153215333-1022736403-990x1024.png)不同node节点上\n\npod和pod通信**pod与service之间的网络**pod的ip地址是不持久的，当集群中pod的规模缩减或者pod故障或者node故障重启后，新的pod的ip就可能与之前的不一样的。所以k8s中衍生出来Service来解决这个问题。Service管理了多个Pods，每个Service有一个虚拟的ip,要访问service管理的Pod上的服务只需要访问你这个虚拟ip就可以了，这个虚拟ip是固定的，当service下的pod规模改变、故障重启、node重启时候，对使用service的用户来说是无感知的，因为他们使用的service的ip没有变。当数据包到达Service虚拟ip后，数据包会被通过k8s给该servcie自动创建的负载均衡器路由到背后的pod容器。在k8s里，iptables规则是由kube-proxy配置，kube-proxy监视APIserver的更改，因为集群中所有service（iptables）更改都会发送到APIServer上，所以每台kubelet-proxy监视APIServer，当对service或pod虚拟IP进行修改时，kube-proxy就会在本地更新，以便正确发送给后端pod.![img](k8s网络通讯方式/1411165-20210604153302687-2143265992.png)\n\n数据包从pod1的eth0离开，通过veth0传给网桥cbr0，网桥找不到service的ip对应的mac，交给了默认路由，到达了root命名空间的eth0root命名空间的eth0接受数据包之前会经过iptables进行过滤，iptables接受数据包后使用kube-proxy在node上配置的规则响应service，然后数据包的目的ip重写为service后端指定的pod的ip了。service到pod包的流转：收到包的pod会回应数据包到源pod，源ip是发送方ip，目标IP是接收方，数据包进行回复时经过iptables，iptables使用内核机制conntrack记住它之前做的选择，又将数据包源ip重新为service的ip，目标ip不变，然后原路返回至pod1的eth0**Internet与service之间的网络**node到internet包的流转\n\n![img](k8s网络通讯方式/1411165-20210604153732180-730315756.png)\n\n数据包源自pod1网络命名空间，通过veth对连接到root网络命名空间，紧接着，转发表里没有IP对应的mac，会发送到默认路由，到达root网络命名空间的eth0那么在到达root网络明明空间之前，iptables会修改数据包，现在数据包源ip是pod1的，继续传输会被Internet网关拒绝掉，因为网关NAT仅转发node的ip，解决方案：使iptables执行源NAT更改数据包源ip，让数据包看起来是来自于node而不是podiptables修改完源ip之后，数据包离开node，根据转发规则发给Internet网关，Internet网关执行另一个NAT，内网ip转为公网ip，在Internet上传输。数据包回应时，也是按照：Internet网关需要将公网IP转换为私有ip，到达目标node节点，再通过iptables修改目标ip并且最终传送到pod的eth0虚拟网桥。Internet到k8s的流量：让Internet流量进入k8s集群，这特定于配置的网络，可以在网络堆栈的不同层来实现：（1） NodePort（2）Service LoadBalancer（3）Ingress控制器。**Flannel**Flannel是CoreOS团队针对Kubernetes设计的一个网络规划服务,简单来说,它的功能是让集群中的不同节点主机创建的Docker容器都具有全集群唯一的虚拟IP地址。而且它还能在这些IP地址之间建立一个覆盖网络(Overlay Network),通过这个覆盖网络,将数据包原封不动地传递到目标容器内\n\n![img](k8s网络通讯方式/image-2.png)ETCD 之Flannel提供说明:\n\n存储管理Flannel可分配的IP地址段资源 监控ETCD中每个Pod的实际地址,并在内存中建立维护Pod节点路由表同一个Pod内部通讯:同一个Pod共享同一个网络命名空间,共享同一个Linux协议栈 **Pod1至Pod2**Pod1与Pod2不在同一台主机,Pod的地址是与docker0在同一个网段的,但docker0网段与宿主机网卡是两个完全不同的IP网段，并且不同Node之间的通信只能通过宿主机的物理网卡进行。将Pod的IP和所在Node的IP关联起来,通过这个关联让Pod可以互相访问Pod1与Pod2在同一台机器,由Docker0网桥直接转发请求至Pod2,不需要经过Flannel**Pod至Service的网络**目前基于性能考虑,全部为iptables维护和转发**Pod到外网**Pod向外网发送请求,查找路由表,转发数据包到宿主机的网卡,宿主网卡完成路由选择后，iptables执行Masquerade，把源IP 更改为宿主网卡的IP,然后向外网服务器发送请求。外网访问PodService\n\n参考文章： \n\nhttps://blog.csdn.net/iqifenxia/article/details/121226087\n\nhttp://t.zoukankan.com/fat-girl-spring-p-14849880.html","slug":"k8s网络通讯方式","published":1,"updated":"2022-09-23T16:50:17.248Z","_id":"cl8eptfvl000nv4vj8ukgfs4i","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"k8s组网要求\"><a href=\"#k8s组网要求\" class=\"headerlink\" title=\"k8s组网要求\"></a><strong>k8s组网要求</strong></h1><ul>\n<li>所有的Pods之间可以在不使用NAT网络地址转换的情况下相互通信。</li>\n<li>所有的Nodes之间可以在不使用NAT网络地址转换的情况下相互通信。</li>\n<li>每个Pod自己看到的自己的ip和其他Pod看到的一致。即所有Pod对象都处于同一平面网络中，而且可以使用Pod自身的地址直接通信。</li>\n</ul>\n<h1 id=\"k8s网络模型设计基础原则\"><a href=\"#k8s网络模型设计基础原则\" class=\"headerlink\" title=\"k8s网络模型设计基础原则\"></a><strong>k8s网络模型设计基础原则</strong></h1><ul>\n<li>每个Pod都拥有一个独立的IP地址，假定所有 Pod 都在一个可以直接连通的、扁平的网络空间中 。</li>\n<li>不管Pod是否运行在同一个 Node中，都要求它们可以直接通过对方的 IP 进行访问。</li>\n<li>用户不需要额外考虑如何建立 Pod 之间的连接，也不需要考虑将容器端口映射到主机端口等问题。</li>\n</ul>\n<p>k8s使用的网络插件必须能为Pod提供满足以上要求的网络，它需要为每个Pod配置至少一个特定的地址，即Pod IP。Pod IP地址实际存在于某个网卡（可以是虚拟设备）上，而service的地址却是一个虚拟IP地址，没有任何网络接口配置此地址，它由kube-proxy借助iptables规则或者IPVS规则重新定向到本地端口，在将其调度至后端Pod对象。Service的IP地址是集群提供服务的接口，也称为ClusterIP。</p>\n<p>Pod网络及其IP由k8s的网络插件负责配置和管理，具体使用的网络地址可在管理配置网络插件时指定，如10.244.0.0/16网络。而Cluster网络和IP则是由k8s集群负责管理和配置，如10.96.0.0/12网络。</p>\n<h1 id=\"k8s集群网络\"><a href=\"#k8s集群网络\" class=\"headerlink\" title=\"k8s集群网络\"></a>k8s集群网络</h1><ul>\n<li>主机之间通信(如master和node)，不归k8s管，管理员自行构建。</li>\n<li>pod资源对象之间通信，是一个虚拟网络。用于为各Pod对象设定IP地址等网络参数，其地址配置于Pod中容器的网络接口上，Pod网络需要借助k8s插件或者CNI插件实现，该插件可独立不属于k8s集群，亦可托管于k8s之上，他需要在构建k8s集群时由管理员定义，而后创建Pod对象时由其自动完成网络参数的动态配置。</li>\n<li>Service资源的对象的网络，也是一个虚拟网络，用于k8s集群之中的Service配置IP地址，但此地址并不配置于任何主机或容器的网络接口之上，而是通过Node之上的kube-proxy配置为iptables或ipvs规则，从而将发往此地址的所有流量调度至其后端的各个Pod对象之上。Service网络在k8s集群创建时予以指定，而各Service的地址则在用户创建Service时予以动态配置。</li>\n</ul>\n<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/image-4.png\" class=\"\" title=\"img\">k8s网络环境\n\n<p><strong>容器和容器之间的网络</strong></p>\n<ul>\n<li>在k8s中每个Pod中管理着一组Docker容器，这些Docker容器共享同一个网络命名空间。</li>\n<li>Pod中的每个Docker容器拥有与Pod相同的IP和port地址空间，并且由于他们在同一个网络命名空间，他们之间可以通过localhost相互访问。</li>\n</ul>\n<p>container模式指定新创建的Docker容器和已经存在的一个容器共享一个网络命名空间，而不是和宿主机共享。新创建的Docker容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等</p>\n<p>每个Pod容器有有一个pause容器其有独立的网络命名空间，在Pod内启动Docker容器时候使用 –net=container就可以让当前Docker容器加入到Pod容器拥有的网络命名空间（pause容器），同一个Pod内的多个docker容器相互通信机制。</p>\n<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/image-5.png\" class=\"\" title=\"img\">\n\n<p><strong>Pod与Pod之间的网络</strong></p>\n<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/image-6.png\" class=\"\" title=\"img\">pod和pod通信\n\n<ul>\n<li>k8s中，每个Pod拥有一个ip地址，不同的Pod之间可以直接使用ip通讯</li>\n<li>在同一个Node上，从Pod的视角看，它存在于自己的网络命名空间中，并且需要与该Node上的其他网络命名空间上的Pod进行通信。</li>\n</ul>\n<p>原理：</p>\n<p>使用linux虚拟以太网设备或者说是由两个虚拟接口组成的veth对使不同的网络命名空间链接起来，这些虚拟接口分布在多个网络命名空间上（这里是指多个Pod上）</p>\n<p>为了让多个Pod的网络命名空间链接起来，可以让veth对的一端链接到root网络命名空间（宿主机的），另一端链接到Pod的网络命名空间。这里需要用到一个Linux以太网桥，它是一个虚拟的二层网络设备，目的就是把多个以太网段连接起来，它维护一个转发表，通过查看每个设备mac地址决定转发，还是丢弃数据。</p>\n<p>同一台node节点上pod1和pod2通信：</p>\n<p>pod1通过自身eth0网卡发送数据，eth0连接着veth0，网桥把veth0和veth1组成了一个以太网，然后数据到达veth0之后，网桥通过转发表，发送给veth1，veth1直接把数据传给pod2的eth0。</p>\n<p>每对Veth就像一根接插电缆，连接两侧并允许流量在它们之间流动；这种veth对可以推广到同一个Node上任意多的Pod上，如上图这里展示使用veth对链接每个Pod到虚拟机的root网络命名空间。不同node节点上pod和pod通信：<strong>CIDR</strong>CIDR（无类域间路由选择）它消除了传统的A类、B类和C类地址以及划分子网的概念，因而可以更加有效地分配IPv4的地址空间。它可以将好几个IP网络结合在一起，使用一种无类别的域际路由选择算法，使它们合并成一条路由从而较少路由表中的路由条目减轻Internet路由器的负担。k8s集群中，每个node节点都会被分配一个CIDR块，（把网络前缀都相同的连续地址组成的地址组称为CIDR地址块）用来给node上的pod分配IP地址，另外还需要把pod的ip和所在nodeip进行关联.比如node1上pod1和node2上的pod4进行通信首先pod1上网卡eth0将数据发送给已经管理到root命名空间的veth0上，被虚拟网桥收到，查看自己转发表之后，并没有pod4的mac地址。就会把包转发到默认路由，（root命名空间的eth0上，也就是已经到了node节点的网卡上）通过eth0，发送到网络中。寻址转发后包来到了node2，首先被root命名空间的eth0设备接受，查看目标地址是发往pod4的，交给虚拟网桥路由到veth1，最终传给pod4的eth0上。</p>\n<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/1411165-20210604153215333-1022736403-990x1024.png\" class=\"\" title=\"img\">不同node节点上\n\n<p>pod和pod通信<strong>pod与service之间的网络</strong>pod的ip地址是不持久的，当集群中pod的规模缩减或者pod故障或者node故障重启后，新的pod的ip就可能与之前的不一样的。所以k8s中衍生出来Service来解决这个问题。Service管理了多个Pods，每个Service有一个虚拟的ip,要访问service管理的Pod上的服务只需要访问你这个虚拟ip就可以了，这个虚拟ip是固定的，当service下的pod规模改变、故障重启、node重启时候，对使用service的用户来说是无感知的，因为他们使用的service的ip没有变。当数据包到达Service虚拟ip后，数据包会被通过k8s给该servcie自动创建的负载均衡器路由到背后的pod容器。在k8s里，iptables规则是由kube-proxy配置，kube-proxy监视APIserver的更改，因为集群中所有service（iptables）更改都会发送到APIServer上，所以每台kubelet-proxy监视APIServer，当对service或pod虚拟IP进行修改时，kube-proxy就会在本地更新，以便正确发送给后端pod.<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/1411165-20210604153302687-2143265992.png\" class=\"\" title=\"img\"></p>\n<p>数据包从pod1的eth0离开，通过veth0传给网桥cbr0，网桥找不到service的ip对应的mac，交给了默认路由，到达了root命名空间的eth0root命名空间的eth0接受数据包之前会经过iptables进行过滤，iptables接受数据包后使用kube-proxy在node上配置的规则响应service，然后数据包的目的ip重写为service后端指定的pod的ip了。service到pod包的流转：收到包的pod会回应数据包到源pod，源ip是发送方ip，目标IP是接收方，数据包进行回复时经过iptables，iptables使用内核机制conntrack记住它之前做的选择，又将数据包源ip重新为service的ip，目标ip不变，然后原路返回至pod1的eth0<strong>Internet与service之间的网络</strong>node到internet包的流转</p>\n<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/1411165-20210604153732180-730315756.png\" class=\"\" title=\"img\">\n\n<p>数据包源自pod1网络命名空间，通过veth对连接到root网络命名空间，紧接着，转发表里没有IP对应的mac，会发送到默认路由，到达root网络命名空间的eth0那么在到达root网络明明空间之前，iptables会修改数据包，现在数据包源ip是pod1的，继续传输会被Internet网关拒绝掉，因为网关NAT仅转发node的ip，解决方案：使iptables执行源NAT更改数据包源ip，让数据包看起来是来自于node而不是podiptables修改完源ip之后，数据包离开node，根据转发规则发给Internet网关，Internet网关执行另一个NAT，内网ip转为公网ip，在Internet上传输。数据包回应时，也是按照：Internet网关需要将公网IP转换为私有ip，到达目标node节点，再通过iptables修改目标ip并且最终传送到pod的eth0虚拟网桥。Internet到k8s的流量：让Internet流量进入k8s集群，这特定于配置的网络，可以在网络堆栈的不同层来实现：（1） NodePort（2）Service LoadBalancer（3）Ingress控制器。<strong>Flannel</strong>Flannel是CoreOS团队针对Kubernetes设计的一个网络规划服务,简单来说,它的功能是让集群中的不同节点主机创建的Docker容器都具有全集群唯一的虚拟IP地址。而且它还能在这些IP地址之间建立一个覆盖网络(Overlay Network),通过这个覆盖网络,将数据包原封不动地传递到目标容器内</p>\n<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/image-2.png\" class=\"\" title=\"img\">ETCD 之Flannel提供说明:\n\n<p>存储管理Flannel可分配的IP地址段资源 监控ETCD中每个Pod的实际地址,并在内存中建立维护Pod节点路由表同一个Pod内部通讯:同一个Pod共享同一个网络命名空间,共享同一个Linux协议栈 <strong>Pod1至Pod2</strong>Pod1与Pod2不在同一台主机,Pod的地址是与docker0在同一个网段的,但docker0网段与宿主机网卡是两个完全不同的IP网段，并且不同Node之间的通信只能通过宿主机的物理网卡进行。将Pod的IP和所在Node的IP关联起来,通过这个关联让Pod可以互相访问Pod1与Pod2在同一台机器,由Docker0网桥直接转发请求至Pod2,不需要经过Flannel<strong>Pod至Service的网络</strong>目前基于性能考虑,全部为iptables维护和转发<strong>Pod到外网</strong>Pod向外网发送请求,查找路由表,转发数据包到宿主机的网卡,宿主网卡完成路由选择后，iptables执行Masquerade，把源IP 更改为宿主网卡的IP,然后向外网服务器发送请求。外网访问PodService</p>\n<p>参考文章： </p>\n<p><a href=\"https://blog.csdn.net/iqifenxia/article/details/121226087\">https://blog.csdn.net/iqifenxia/article/details/121226087</a></p>\n<p><a href=\"http://t.zoukankan.com/fat-girl-spring-p-14849880.html\">http://t.zoukankan.com/fat-girl-spring-p-14849880.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"k8s组网要求\"><a href=\"#k8s组网要求\" class=\"headerlink\" title=\"k8s组网要求\"></a><strong>k8s组网要求</strong></h1><ul>\n<li>所有的Pods之间可以在不使用NAT网络地址转换的情况下相互通信。</li>\n<li>所有的Nodes之间可以在不使用NAT网络地址转换的情况下相互通信。</li>\n<li>每个Pod自己看到的自己的ip和其他Pod看到的一致。即所有Pod对象都处于同一平面网络中，而且可以使用Pod自身的地址直接通信。</li>\n</ul>\n<h1 id=\"k8s网络模型设计基础原则\"><a href=\"#k8s网络模型设计基础原则\" class=\"headerlink\" title=\"k8s网络模型设计基础原则\"></a><strong>k8s网络模型设计基础原则</strong></h1><ul>\n<li>每个Pod都拥有一个独立的IP地址，假定所有 Pod 都在一个可以直接连通的、扁平的网络空间中 。</li>\n<li>不管Pod是否运行在同一个 Node中，都要求它们可以直接通过对方的 IP 进行访问。</li>\n<li>用户不需要额外考虑如何建立 Pod 之间的连接，也不需要考虑将容器端口映射到主机端口等问题。</li>\n</ul>\n<p>k8s使用的网络插件必须能为Pod提供满足以上要求的网络，它需要为每个Pod配置至少一个特定的地址，即Pod IP。Pod IP地址实际存在于某个网卡（可以是虚拟设备）上，而service的地址却是一个虚拟IP地址，没有任何网络接口配置此地址，它由kube-proxy借助iptables规则或者IPVS规则重新定向到本地端口，在将其调度至后端Pod对象。Service的IP地址是集群提供服务的接口，也称为ClusterIP。</p>\n<p>Pod网络及其IP由k8s的网络插件负责配置和管理，具体使用的网络地址可在管理配置网络插件时指定，如10.244.0.0/16网络。而Cluster网络和IP则是由k8s集群负责管理和配置，如10.96.0.0/12网络。</p>\n<h1 id=\"k8s集群网络\"><a href=\"#k8s集群网络\" class=\"headerlink\" title=\"k8s集群网络\"></a>k8s集群网络</h1><ul>\n<li>主机之间通信(如master和node)，不归k8s管，管理员自行构建。</li>\n<li>pod资源对象之间通信，是一个虚拟网络。用于为各Pod对象设定IP地址等网络参数，其地址配置于Pod中容器的网络接口上，Pod网络需要借助k8s插件或者CNI插件实现，该插件可独立不属于k8s集群，亦可托管于k8s之上，他需要在构建k8s集群时由管理员定义，而后创建Pod对象时由其自动完成网络参数的动态配置。</li>\n<li>Service资源的对象的网络，也是一个虚拟网络，用于k8s集群之中的Service配置IP地址，但此地址并不配置于任何主机或容器的网络接口之上，而是通过Node之上的kube-proxy配置为iptables或ipvs规则，从而将发往此地址的所有流量调度至其后端的各个Pod对象之上。Service网络在k8s集群创建时予以指定，而各Service的地址则在用户创建Service时予以动态配置。</li>\n</ul>\n<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/image-4.png\" class=\"\" title=\"img\">k8s网络环境\n\n<p><strong>容器和容器之间的网络</strong></p>\n<ul>\n<li>在k8s中每个Pod中管理着一组Docker容器，这些Docker容器共享同一个网络命名空间。</li>\n<li>Pod中的每个Docker容器拥有与Pod相同的IP和port地址空间，并且由于他们在同一个网络命名空间，他们之间可以通过localhost相互访问。</li>\n</ul>\n<p>container模式指定新创建的Docker容器和已经存在的一个容器共享一个网络命名空间，而不是和宿主机共享。新创建的Docker容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等</p>\n<p>每个Pod容器有有一个pause容器其有独立的网络命名空间，在Pod内启动Docker容器时候使用 –net=container就可以让当前Docker容器加入到Pod容器拥有的网络命名空间（pause容器），同一个Pod内的多个docker容器相互通信机制。</p>\n<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/image-5.png\" class=\"\" title=\"img\">\n\n<p><strong>Pod与Pod之间的网络</strong></p>\n<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/image-6.png\" class=\"\" title=\"img\">pod和pod通信\n\n<ul>\n<li>k8s中，每个Pod拥有一个ip地址，不同的Pod之间可以直接使用ip通讯</li>\n<li>在同一个Node上，从Pod的视角看，它存在于自己的网络命名空间中，并且需要与该Node上的其他网络命名空间上的Pod进行通信。</li>\n</ul>\n<p>原理：</p>\n<p>使用linux虚拟以太网设备或者说是由两个虚拟接口组成的veth对使不同的网络命名空间链接起来，这些虚拟接口分布在多个网络命名空间上（这里是指多个Pod上）</p>\n<p>为了让多个Pod的网络命名空间链接起来，可以让veth对的一端链接到root网络命名空间（宿主机的），另一端链接到Pod的网络命名空间。这里需要用到一个Linux以太网桥，它是一个虚拟的二层网络设备，目的就是把多个以太网段连接起来，它维护一个转发表，通过查看每个设备mac地址决定转发，还是丢弃数据。</p>\n<p>同一台node节点上pod1和pod2通信：</p>\n<p>pod1通过自身eth0网卡发送数据，eth0连接着veth0，网桥把veth0和veth1组成了一个以太网，然后数据到达veth0之后，网桥通过转发表，发送给veth1，veth1直接把数据传给pod2的eth0。</p>\n<p>每对Veth就像一根接插电缆，连接两侧并允许流量在它们之间流动；这种veth对可以推广到同一个Node上任意多的Pod上，如上图这里展示使用veth对链接每个Pod到虚拟机的root网络命名空间。不同node节点上pod和pod通信：<strong>CIDR</strong>CIDR（无类域间路由选择）它消除了传统的A类、B类和C类地址以及划分子网的概念，因而可以更加有效地分配IPv4的地址空间。它可以将好几个IP网络结合在一起，使用一种无类别的域际路由选择算法，使它们合并成一条路由从而较少路由表中的路由条目减轻Internet路由器的负担。k8s集群中，每个node节点都会被分配一个CIDR块，（把网络前缀都相同的连续地址组成的地址组称为CIDR地址块）用来给node上的pod分配IP地址，另外还需要把pod的ip和所在nodeip进行关联.比如node1上pod1和node2上的pod4进行通信首先pod1上网卡eth0将数据发送给已经管理到root命名空间的veth0上，被虚拟网桥收到，查看自己转发表之后，并没有pod4的mac地址。就会把包转发到默认路由，（root命名空间的eth0上，也就是已经到了node节点的网卡上）通过eth0，发送到网络中。寻址转发后包来到了node2，首先被root命名空间的eth0设备接受，查看目标地址是发往pod4的，交给虚拟网桥路由到veth1，最终传给pod4的eth0上。</p>\n<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/1411165-20210604153215333-1022736403-990x1024.png\" class=\"\" title=\"img\">不同node节点上\n\n<p>pod和pod通信<strong>pod与service之间的网络</strong>pod的ip地址是不持久的，当集群中pod的规模缩减或者pod故障或者node故障重启后，新的pod的ip就可能与之前的不一样的。所以k8s中衍生出来Service来解决这个问题。Service管理了多个Pods，每个Service有一个虚拟的ip,要访问service管理的Pod上的服务只需要访问你这个虚拟ip就可以了，这个虚拟ip是固定的，当service下的pod规模改变、故障重启、node重启时候，对使用service的用户来说是无感知的，因为他们使用的service的ip没有变。当数据包到达Service虚拟ip后，数据包会被通过k8s给该servcie自动创建的负载均衡器路由到背后的pod容器。在k8s里，iptables规则是由kube-proxy配置，kube-proxy监视APIserver的更改，因为集群中所有service（iptables）更改都会发送到APIServer上，所以每台kubelet-proxy监视APIServer，当对service或pod虚拟IP进行修改时，kube-proxy就会在本地更新，以便正确发送给后端pod.<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/1411165-20210604153302687-2143265992.png\" class=\"\" title=\"img\"></p>\n<p>数据包从pod1的eth0离开，通过veth0传给网桥cbr0，网桥找不到service的ip对应的mac，交给了默认路由，到达了root命名空间的eth0root命名空间的eth0接受数据包之前会经过iptables进行过滤，iptables接受数据包后使用kube-proxy在node上配置的规则响应service，然后数据包的目的ip重写为service后端指定的pod的ip了。service到pod包的流转：收到包的pod会回应数据包到源pod，源ip是发送方ip，目标IP是接收方，数据包进行回复时经过iptables，iptables使用内核机制conntrack记住它之前做的选择，又将数据包源ip重新为service的ip，目标ip不变，然后原路返回至pod1的eth0<strong>Internet与service之间的网络</strong>node到internet包的流转</p>\n<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/1411165-20210604153732180-730315756.png\" class=\"\" title=\"img\">\n\n<p>数据包源自pod1网络命名空间，通过veth对连接到root网络命名空间，紧接着，转发表里没有IP对应的mac，会发送到默认路由，到达root网络命名空间的eth0那么在到达root网络明明空间之前，iptables会修改数据包，现在数据包源ip是pod1的，继续传输会被Internet网关拒绝掉，因为网关NAT仅转发node的ip，解决方案：使iptables执行源NAT更改数据包源ip，让数据包看起来是来自于node而不是podiptables修改完源ip之后，数据包离开node，根据转发规则发给Internet网关，Internet网关执行另一个NAT，内网ip转为公网ip，在Internet上传输。数据包回应时，也是按照：Internet网关需要将公网IP转换为私有ip，到达目标node节点，再通过iptables修改目标ip并且最终传送到pod的eth0虚拟网桥。Internet到k8s的流量：让Internet流量进入k8s集群，这特定于配置的网络，可以在网络堆栈的不同层来实现：（1） NodePort（2）Service LoadBalancer（3）Ingress控制器。<strong>Flannel</strong>Flannel是CoreOS团队针对Kubernetes设计的一个网络规划服务,简单来说,它的功能是让集群中的不同节点主机创建的Docker容器都具有全集群唯一的虚拟IP地址。而且它还能在这些IP地址之间建立一个覆盖网络(Overlay Network),通过这个覆盖网络,将数据包原封不动地传递到目标容器内</p>\n<img src=\"/2021/07/30/k8s%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F/image-2.png\" class=\"\" title=\"img\">ETCD 之Flannel提供说明:\n\n<p>存储管理Flannel可分配的IP地址段资源 监控ETCD中每个Pod的实际地址,并在内存中建立维护Pod节点路由表同一个Pod内部通讯:同一个Pod共享同一个网络命名空间,共享同一个Linux协议栈 <strong>Pod1至Pod2</strong>Pod1与Pod2不在同一台主机,Pod的地址是与docker0在同一个网段的,但docker0网段与宿主机网卡是两个完全不同的IP网段，并且不同Node之间的通信只能通过宿主机的物理网卡进行。将Pod的IP和所在Node的IP关联起来,通过这个关联让Pod可以互相访问Pod1与Pod2在同一台机器,由Docker0网桥直接转发请求至Pod2,不需要经过Flannel<strong>Pod至Service的网络</strong>目前基于性能考虑,全部为iptables维护和转发<strong>Pod到外网</strong>Pod向外网发送请求,查找路由表,转发数据包到宿主机的网卡,宿主网卡完成路由选择后，iptables执行Masquerade，把源IP 更改为宿主网卡的IP,然后向外网服务器发送请求。外网访问PodService</p>\n<p>参考文章： </p>\n<p><a href=\"https://blog.csdn.net/iqifenxia/article/details/121226087\">https://blog.csdn.net/iqifenxia/article/details/121226087</a></p>\n<p><a href=\"http://t.zoukankan.com/fat-girl-spring-p-14849880.html\">http://t.zoukankan.com/fat-girl-spring-p-14849880.html</a></p>\n"},{"title":"k8s集群开启firewalld防火墙","date":"2021-08-02T11:18:02.000Z","_content":"\n# 一、基础设置\n\n```\n# 关闭selinux\nsed -i 's/enforcing/disabled/' /etc/selinux/config  # 永久\nsetenforce 0  # 临时\n\n# 关闭swap\nswapoff -a  # 临时\nsed -ri 's/.*swap.*/#&/' /etc/fstab    # 永久\n\n#将桥接的IPv4流量传递到iptables的链\ncat > /etc/sysctl.d/k8s.conf << EOF\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nEOF\nsysctl --system  # 生效\n```\n\n# 二、假设k8s部署情况如下：\n\n| 主机名       | 主机IP    |\n| ------------ | --------- |\n| k8s-master01 | 10.0.0.10 |\n| k8s-node01   | 10.0.0.11 |\n| k8s-node02   | 10.0.0.21 |\n| k8s-node03   | 10.0.0.22 |\n\n# 三、所有机器上执行如下命令：\n\n```\n# 确保开启防火墙服务\nsystemctl restart firewalld\n\n# 将集群内所有的节点IP配置到防火墙可信区中\nfirewall-cmd --permanent --zone=trusted --add-source=10.0.0.10\nfirewall-cmd --permanent --zone=trusted --add-source=10.0.0.11\nfirewall-cmd --permanent --zone=trusted --add-source=10.0.0.21\nfirewall-cmd --permanent --zone=trusted --add-source=10.0.0.22\n\n# 增加防火墙规则\nfirewall-cmd --permanent --direct --add-rule ipv4 filter INPUT 1 -j ACCEPT -m comment --comment \"kube-proxy redirects\"\nfirewall-cmd --permanent --direct --add-rule ipv4 filter FORWARD 1  -j ACCEPT -m comment --comment \"docker subnet\"\n\n# 设置防火墙伪装ip, 打开NAT，默认是关闭状态\nfirewall-cmd --add-masquerade --permanent\n\n# 所有k8s的NodePort端口添加到例外\nfirewall-cmd --permanent --zone=public --add-port=30000-32767/tcp\n\n# 重新加载配置\nfirewall-cmd --reload\n```\n\n","source":"_posts/k8s集群开启firewalld防火墙.md","raw":"---\ntitle: k8s集群开启firewalld防火墙\ndate: 2021-08-02 19:18:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - firewalld\n  - 防火墙\n---\n\n# 一、基础设置\n\n```\n# 关闭selinux\nsed -i 's/enforcing/disabled/' /etc/selinux/config  # 永久\nsetenforce 0  # 临时\n\n# 关闭swap\nswapoff -a  # 临时\nsed -ri 's/.*swap.*/#&/' /etc/fstab    # 永久\n\n#将桥接的IPv4流量传递到iptables的链\ncat > /etc/sysctl.d/k8s.conf << EOF\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nEOF\nsysctl --system  # 生效\n```\n\n# 二、假设k8s部署情况如下：\n\n| 主机名       | 主机IP    |\n| ------------ | --------- |\n| k8s-master01 | 10.0.0.10 |\n| k8s-node01   | 10.0.0.11 |\n| k8s-node02   | 10.0.0.21 |\n| k8s-node03   | 10.0.0.22 |\n\n# 三、所有机器上执行如下命令：\n\n```\n# 确保开启防火墙服务\nsystemctl restart firewalld\n\n# 将集群内所有的节点IP配置到防火墙可信区中\nfirewall-cmd --permanent --zone=trusted --add-source=10.0.0.10\nfirewall-cmd --permanent --zone=trusted --add-source=10.0.0.11\nfirewall-cmd --permanent --zone=trusted --add-source=10.0.0.21\nfirewall-cmd --permanent --zone=trusted --add-source=10.0.0.22\n\n# 增加防火墙规则\nfirewall-cmd --permanent --direct --add-rule ipv4 filter INPUT 1 -j ACCEPT -m comment --comment \"kube-proxy redirects\"\nfirewall-cmd --permanent --direct --add-rule ipv4 filter FORWARD 1  -j ACCEPT -m comment --comment \"docker subnet\"\n\n# 设置防火墙伪装ip, 打开NAT，默认是关闭状态\nfirewall-cmd --add-masquerade --permanent\n\n# 所有k8s的NodePort端口添加到例外\nfirewall-cmd --permanent --zone=public --add-port=30000-32767/tcp\n\n# 重新加载配置\nfirewall-cmd --reload\n```\n\n","slug":"k8s集群开启firewalld防火墙","published":1,"updated":"2022-09-23T16:51:41.423Z","_id":"cl8epy0rf000uv4vj5bwc0xqj","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、基础设置\"><a href=\"#一、基础设置\" class=\"headerlink\" title=\"一、基础设置\"></a>一、基础设置</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\"><span class=\"hljs-comment\"># 关闭selinux</span><br>sed -i <span class=\"hljs-string\">&#x27;s/enforcing/disabled/&#x27;</span> /etc/selinux/config  <span class=\"hljs-comment\"># 永久</span><br>setenforce 0  <span class=\"hljs-comment\"># 临时</span><br><br><span class=\"hljs-comment\"># 关闭swap</span><br>swapoff -a  <span class=\"hljs-comment\"># 临时</span><br>sed -ri <span class=\"hljs-string\">&#x27;s/.*swap.*/#&amp;/&#x27;</span> /etc/fstab    <span class=\"hljs-comment\"># 永久</span><br><br><span class=\"hljs-comment\">#将桥接的IPv4流量传递到iptables的链</span><br><span class=\"hljs-built_in\">cat</span> &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class=\"hljs-string\">EOF</span><br><span class=\"hljs-string\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"hljs-string\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"hljs-string\">EOF</span><br>sysctl --system  <span class=\"hljs-comment\"># 生效</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"二、假设k8s部署情况如下：\"><a href=\"#二、假设k8s部署情况如下：\" class=\"headerlink\" title=\"二、假设k8s部署情况如下：\"></a>二、假设k8s部署情况如下：</h1><table>\n<thead>\n<tr>\n<th>主机名</th>\n<th>主机IP</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>k8s-master01</td>\n<td>10.0.0.10</td>\n</tr>\n<tr>\n<td>k8s-node01</td>\n<td>10.0.0.11</td>\n</tr>\n<tr>\n<td>k8s-node02</td>\n<td>10.0.0.21</td>\n</tr>\n<tr>\n<td>k8s-node03</td>\n<td>10.0.0.22</td>\n</tr>\n</tbody></table>\n<h1 id=\"三、所有机器上执行如下命令：\"><a href=\"#三、所有机器上执行如下命令：\" class=\"headerlink\" title=\"三、所有机器上执行如下命令：\"></a>三、所有机器上执行如下命令：</h1><figure class=\"highlight jboss-cli\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs jboss-cli\"><span class=\"hljs-comment\"># 确保开启防火墙服务</span><br>systemctl restart firewalld<br><br><span class=\"hljs-comment\"># 将集群内所有的节点IP配置到防火墙可信区中</span><br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--zone=trusted</span> <span class=\"hljs-params\">--add-source=10</span>.0.0.10<br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--zone=trusted</span> <span class=\"hljs-params\">--add-source=10</span>.0.0.11<br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--zone=trusted</span> <span class=\"hljs-params\">--add-source=10</span>.0.0.21<br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--zone=trusted</span> <span class=\"hljs-params\">--add-source=10</span>.0.0.22<br><br><span class=\"hljs-comment\"># 增加防火墙规则</span><br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--direct</span> <span class=\"hljs-params\">--add-rule</span> ipv4 filter INPUT 1 -j ACCEPT -m comment <span class=\"hljs-params\">--comment</span> <span class=\"hljs-string\">&quot;kube-proxy redirects&quot;</span><br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--direct</span> <span class=\"hljs-params\">--add-rule</span> ipv4 filter FORWARD 1  -j ACCEPT -m comment <span class=\"hljs-params\">--comment</span> <span class=\"hljs-string\">&quot;docker subnet&quot;</span><br><br><span class=\"hljs-comment\"># 设置防火墙伪装ip, 打开NAT，默认是关闭状态</span><br>firewall-cmd <span class=\"hljs-params\">--add-masquerade</span> <span class=\"hljs-params\">--permanent</span><br><br><span class=\"hljs-comment\"># 所有k8s的NodePort端口添加到例外</span><br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--zone=public</span> <span class=\"hljs-params\">--add-port=30000-32767/tcp</span><br><br><span class=\"hljs-comment\"># 重新加载配置</span><br>firewall-cmd <span class=\"hljs-params\">--reload</span><br></code></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、基础设置\"><a href=\"#一、基础设置\" class=\"headerlink\" title=\"一、基础设置\"></a>一、基础设置</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\"><span class=\"hljs-comment\"># 关闭selinux</span><br>sed -i <span class=\"hljs-string\">&#x27;s/enforcing/disabled/&#x27;</span> /etc/selinux/config  <span class=\"hljs-comment\"># 永久</span><br>setenforce 0  <span class=\"hljs-comment\"># 临时</span><br><br><span class=\"hljs-comment\"># 关闭swap</span><br>swapoff -a  <span class=\"hljs-comment\"># 临时</span><br>sed -ri <span class=\"hljs-string\">&#x27;s/.*swap.*/#&amp;/&#x27;</span> /etc/fstab    <span class=\"hljs-comment\"># 永久</span><br><br><span class=\"hljs-comment\">#将桥接的IPv4流量传递到iptables的链</span><br><span class=\"hljs-built_in\">cat</span> &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class=\"hljs-string\">EOF</span><br><span class=\"hljs-string\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"hljs-string\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"hljs-string\">EOF</span><br>sysctl --system  <span class=\"hljs-comment\"># 生效</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"二、假设k8s部署情况如下：\"><a href=\"#二、假设k8s部署情况如下：\" class=\"headerlink\" title=\"二、假设k8s部署情况如下：\"></a>二、假设k8s部署情况如下：</h1><table>\n<thead>\n<tr>\n<th>主机名</th>\n<th>主机IP</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>k8s-master01</td>\n<td>10.0.0.10</td>\n</tr>\n<tr>\n<td>k8s-node01</td>\n<td>10.0.0.11</td>\n</tr>\n<tr>\n<td>k8s-node02</td>\n<td>10.0.0.21</td>\n</tr>\n<tr>\n<td>k8s-node03</td>\n<td>10.0.0.22</td>\n</tr>\n</tbody></table>\n<h1 id=\"三、所有机器上执行如下命令：\"><a href=\"#三、所有机器上执行如下命令：\" class=\"headerlink\" title=\"三、所有机器上执行如下命令：\"></a>三、所有机器上执行如下命令：</h1><figure class=\"highlight jboss-cli\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs jboss-cli\"><span class=\"hljs-comment\"># 确保开启防火墙服务</span><br>systemctl restart firewalld<br><br><span class=\"hljs-comment\"># 将集群内所有的节点IP配置到防火墙可信区中</span><br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--zone=trusted</span> <span class=\"hljs-params\">--add-source=10</span>.0.0.10<br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--zone=trusted</span> <span class=\"hljs-params\">--add-source=10</span>.0.0.11<br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--zone=trusted</span> <span class=\"hljs-params\">--add-source=10</span>.0.0.21<br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--zone=trusted</span> <span class=\"hljs-params\">--add-source=10</span>.0.0.22<br><br><span class=\"hljs-comment\"># 增加防火墙规则</span><br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--direct</span> <span class=\"hljs-params\">--add-rule</span> ipv4 filter INPUT 1 -j ACCEPT -m comment <span class=\"hljs-params\">--comment</span> <span class=\"hljs-string\">&quot;kube-proxy redirects&quot;</span><br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--direct</span> <span class=\"hljs-params\">--add-rule</span> ipv4 filter FORWARD 1  -j ACCEPT -m comment <span class=\"hljs-params\">--comment</span> <span class=\"hljs-string\">&quot;docker subnet&quot;</span><br><br><span class=\"hljs-comment\"># 设置防火墙伪装ip, 打开NAT，默认是关闭状态</span><br>firewall-cmd <span class=\"hljs-params\">--add-masquerade</span> <span class=\"hljs-params\">--permanent</span><br><br><span class=\"hljs-comment\"># 所有k8s的NodePort端口添加到例外</span><br>firewall-cmd <span class=\"hljs-params\">--permanent</span> <span class=\"hljs-params\">--zone=public</span> <span class=\"hljs-params\">--add-port=30000-32767/tcp</span><br><br><span class=\"hljs-comment\"># 重新加载配置</span><br>firewall-cmd <span class=\"hljs-params\">--reload</span><br></code></pre></td></tr></table></figure>\n\n"},{"title":"kubernetes调度器scheduler","date":"2021-08-02T11:18:02.000Z","_content":"\n# 一、简介\nScheduler 是kubernetes 的调度器,主要的任务是把定义的pod分配到集群的节点上。听起来非常简单,但有很多要考虑的问题:\n\n- 公平：如何保证每个节点都能被分配资源\n- 资源高效利用：集群所有资源最大化被使用\n- 效率：调度的性能要好,能够尽快地对大批量的pod完成调度工作\n- 灵活：允许用户根据自己的需求控制调度的逻辑\n\nSheduler 是作为单独的程序运行的，启动之后会一直坚挺API Server，获取PodSpec.NodeName为空的 pod,对每个pod都会创建一个binding,表明该pod应该放到哪个节点上\n\n# 二、调度过程\n\n调度分为几个部分：首先是过滤掉不满足条件的节点，这个过程称为predicate；然后对通过的节点按照优先级排序,这个是priority;最后从中选择优先级最高的节点。如果中间任何一步骤有错误,就直接返回错误。\n\nPredicate 有一系列的算法可以使用:\n\nPredicate 有一系列的算法可以使用:\n\n- PodFitsResources：节点上剩余的资源是否大于 pod请求的资源\n- PodFitsHost：如果pod指定了NodeName,检查节点名称是否和NodeName匹配\n- PodFitsHostPorts：节点上已经使用的port 是否和 pod申请的port冲突\n- PodSelectorMatches：过滤掉和pod指定的label 不匹配的节点\n- NoDiskConflict：已经mount 的volume 和 pod指定的volume 不冲突,除非它们都是只读\n\n如果在predicate过程中没有合适的节点，pod会一直在pending状态，不断重试调度，直到有节点满足条件。\n经过这个步骤，如果有多个节点满足条件，就继续priorities过程:按照优先级大小对节点排序\n\n优先级由一系列键值对组成,键是该优先级项的名称,值是它的权重(该项的重要性)。这些优先级选项包括:\n\n- LeastRequestedPriority :通过计算 CPU 和Memory 的使用率来决定权重,使用率越低权重越高。换句话说,这个优先级指标倾向于资源使用比例更低的节点\n- BalancedResourceAllocation :节点上CPU 和Memory 使用率越接近,权重越高。这个应该和上面的一起使用,不应该单独使用\n- ImageLocalityPriority :倾向于已经有要使用镜像的节点,镜像总大小值越大,权重越高\n\n通过算法对所有的优先级项目和权重进行计算,得出最终的结果。\n\n# 三、自定义调度器\n\n除了kubernetes 自带的调度器,也可以编写自己的调度器。通过spec:schedulername参数指定调度器的名字,可以为pod选择某个调度器进行调度。比如下面的pod选择my-scheduler进行调度,而不是默认的default-scheduler。\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: annotation-second-scheduler\n  labels:\n    name: multischeduler-example\nspec:\n  schedulerName: my-schedulen\n  containers:\n  - name: pod-with-second-annotation-container\n    image: gcr.io/google_containers/pause:2.0\n```\n\n# 四、节点亲和性\n\npod.spec.nodeAffinity\n\n- preferredDuringSchedulinglgnoredDuringExecution：软策略\n- requiredDuringSchedulinglgnoredDuringExecution：硬策略\n\nrequiredDuringSchedulinglgnoredDuringExecution\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: affinity\n  labels:\n    app: node-affinity-pod\nspec:\n  containers:\n  - name: with-node-affinity\n    image: harborcloud.com/library/nginx:1.9.1\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: kubernetes.io/hostname\n            operator: NotIn\n            values:\n            - k8s-node02\n```\n\nrequiredDuringSchedulinglgnoredDuringExecution\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: affinity\n  labels:\n    app: node-affinity-pod\nspec:\n  containers:\n  - name: with-node-affinity\n    image: harborcloud.com/library/nginx:1.9.1\n  affinity:\n    nodeAffinity:\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 1\n        preference:\n          matchExpressions:\n          - key: kubernetes.io/hostname\n            operator: In\n            values:\n            - k8s-node02222\n```\n\n综合\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: affinity\n  labels:\n    app: node-affinity-pod\nspec:\n  containers:\n  - name: with-node-affinity\n    image: harborcloud.com/library/nginx:1.9.1\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: kubernetes.io/hostname\n            operator: NotIn\n            values:\n            - k8s-node02\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 1\n        preference:\n          matchExpressions:\n          - key: source\n            operator: In\n            values:\n            - qikqiak\n```\n\n## 4.1 键值运算关系\n\n- In: label的值在某个列表中\n- Notln: label的值不在某个列表中\n- Gt: label的值大于某个值\n- Lt: label的值小于某个值\n- Exists:某个label 存在\n- DoesNotExist:某 label 不存在\n\n# 五、Pod亲和性\n\npod.spec.affinity.podAffinity/podAntiAffinity\n\n- preferredDuringSchedulinglgnoredDuringExecution: 软策略\n- requiredDuringSchedulinglgnoredDuringExecution:硬策略\n\n```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  affinity:\n    podAffinity: #亲和力\n      requiredDuringSchedulingIgnoredDuringExecution:\n      - labelSelector:\n          matchLabels:\n            service.cpaas.io/name: deployment-nginx\n        topologyKey: kubernetes.io/hostname # pod同node\n    podAntiAffinity: #反亲和力\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 100\n        podAffinityTerm:\n          labelSelector:\n            matchExpressions:\n            - key: a\n              operator: In\n              values:\n              - b\n          topologyKey: kubernetes.io/hostname\n  containers:\n - name: test-pod\n    image: nginx:1.18\n```\n\n# 六、亲和性/反亲和性调度策略比较如下:\n\n| 调度策略        | 匹配标签 | 操作符                                        | 拓扑域支持 | 调度目标                                |\n| --------------- | -------- | --------------------------------------------- | ---------- | --------------------------------------- |\n| nodeAffinity    | 主机     | In, Notln, Exists,DoesNotExist, Gt, Lt <br /> | 否         | 指定主机                                |\n| podAffinity     | POD      | In, Notln, Exists,DoesNotExist                | 是         | POD与指定POD同一拓扑域 （同一个node上） |\n| podAnitAffinity | POD      | In, Notln, Exists,DoesNotExist                | 是         | POD与指定POD不在同一拓扑域              |\n\n# 七、污点(Taint) 和容忍(Toleration)\n\n节点亲和性，是pod的一种属性(偏好或硬性要求),它使pod被吸引到一类特定的节点。Taint则相反,它使节点能够排斥一类特定的pod。Taint 和toleration 相互配合,可以用来避免 pod 被分配到不合适的节点上。每个节点上都可以应用一个或多个taint,这表示对于那些不能容忍这些taint的pod,是不会被该节点接受的。如果将toleration应用于pod上,则表示这些pod可以(但不要求)被调度到具有匹配taint的节点上\n\n## 7.1 污点(Taint)\n\n1、污点(Taint)的组成\n使用kubectl taint命令可以给某个Node节点设置污点, Node被设置上污点之后就和Pod之间存在了一种相斥的关系,可以让Node拒绝Pod的调度执行,甚至将Node已经存在的Pod驱逐出去。\n\n每个污点的组成如下:\n\n```\nkey=value:effect\n```\n\n每个污点有一个key和value作为污点的标签,其中value 可以为空, effect描述污点的作用。\n\n当前taint effect 支持如下三个选项:\n\n- NoSchedule ：表示k8s将不会将Pod调度到具有该污点的Node上\n- PreferNoSchedule：表示k8s将尽量避免将Pod调度到具有该污点的Node上\n- NoExecute ：表示k8s将不会将Pod调度到具有该污点的Node上,同时会将Node 上已经存在的Pod驱逐出去\n\n1、污点的设置、查看和去除\n\n```\n#设置污点\nkubectl taint nodes node1 key1=value1: NoSchedule\n#节点说明中,查找Taints字段\nkubectl describe pod pod - name\n#去除污点\nkubectl taint nodes node1 key1: NoSchedule-\n# master 节点的添加Taint\nkubectl taint nodes k8s-master01 node-role.kubernetes.io/master=:NoSchedule\n# master去除污点\nkubectl taint nodes k8s-master01 node-role.kubernetes.io/master=:NoSchedule-\n```\n\n2 例如：\n\n```\n[root@k8s-master01 scheduler]# kubectl get pod -o wide\nNAME    READY   STATUS    RESTARTS   AGE     IP             NODE         NOMINATED NODE   READINESS GATES\npod-1   1/1     Running   0          8m28s   10.244.2.205   k8s-node02   <none>           <none>\npod-3   1/1     Running   0          7m27s   10.244.2.207   k8s-node02   <none>           <none>\n[root@k8s-master01 scheduler]# kubectl taint node  k8s-node02 checkstatus=k8s:NoExecute\nnode/k8s-node02 tainted\n[root@k8s-master01 scheduler]# kubectl get pod -o wide\nNo resources found in default namespace.\n```\n\n将k8s-node02设置污点NoExecute ，pod将从k8s-node02移除。\n\n## 7.2 容忍(Tolerations)\n\n设置了污点的Node将根据taint 的 effect: NoSchedule, PreferNoSchedule, NoExecute 和Pod 之间产生互斥的关系, Pod将在一定程度上不会被调度到Node上。但我们可以在Pod上设置容忍(Toleration),意思是设置了容忍的Pod将可以容忍污点的存在,可以被调度到存在污点的Node上。\n\npod.spec.tolerations\n\n```yaml\ntolerations:\n- key: \"key1\"\n  operator: \"Equal\"\n  value: \"value1\"\n  effect: \"NoExecute\"\n  tolerationSeconds: 3600\n- key: \"key1\"\n  operator: \"Equal\"\n  value: \"value1\"\n  effect: \"NoExecute\"\n  key: \"key2\"\n  operator: \"Exists\"\n  effect: \"NoSchedule\"\n```\n\n完整yaml：\n\n将在60s过后才会被node移除pod\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-1\n  labels:\n    app: pod-1\nspec:\n  containers:\n  - name: with-node-affinity\n    image: harborcloud.com/library/nginx:1.9.1\n  tolerations:\n  - key: \"checkstatus\"\n    operator: \"Equal\"\n    value: \"k8s\"\n    effect: \"NoExecute\"\n    tolerationSeconds: 60\n```\n\n其中key, vaule, effect 要与Node上设置的taint保持一致\noperator 的值为Exists 将会忽略value值\ntolerationSeconds 用于描述当Pod需要被驱逐时可以在Pod上继续保留运行的时间.。\n\n1 当不指定key值时,表示容忍所有的污点key\n\n```yaml\ntolerations:\n- operator: \"Exists\"\n```\n\n2 当不指定effect值时,表示容忍所有的污点作用\n\n```yaml\ntolerations:\n- key: \"key\"\n  operator: \"Exists\"\n```\n\n3 有多个Master存在时,防止资源浪费,可以如下设置\n\n```\nkubectl taint nodes Node-Name node-role.kubernetes.io/master=:PreferNoSchedule\n```\n\n# 八、指定调度节点\n\n1 Pod.spec.nodeName 将 Pod 直接调度到指定的Node 节点上,会跳过Scheduler的调度策略,该匹配规则是强制匹配\n\n```yaml\napiVersion: extensions/vlbeta1\nkind: Deployment\nmetadata:\n  name: myweb\nspec:\n  replicas: 7\n  template:\n    metadata:\n      labels:\n        app: myweb\n    spec:\n      nodeName: k8s-node01 #将pod调度到k8s-node01\n      containers:\n      - name: myweb\n        image: hub.atguigu.com/library/myapp:v1\n        ports:\n        - containerPort: 80\n```\n\n2 Pod.spec.nodeSelector:通过 kubernetes 的label-selector 机制选择节点,由调度器调度策略匹配label,而后调度Pod到目标节点,该匹配规则属于强制约束\n\n```yaml\napiVersion: extensions/vlbeta1\nkind: Deployment\nmetadata:\n  name: myweb\nspec:\n  replicas: 2\n  template:\n  metadata:\n    labels:\n      app: myweb\n  spec:\n    nodeSelector: # 未来Kubernetes会将nodeSelector废除\n      type: backEndNode1 #自定义节点调度器\n    containers:\n    - name: myweb\n      image: harbor/tomcat:8.5-jre8\n      ports:\n      - containerPort: 80\n```\n\n","source":"_posts/kubernetes调度器scheduler.md","raw":"---\ntitle: kubernetes调度器scheduler\ndate: 2021-08-02 19:18:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - scheduler\n  - 调度器\n---\n\n# 一、简介\nScheduler 是kubernetes 的调度器,主要的任务是把定义的pod分配到集群的节点上。听起来非常简单,但有很多要考虑的问题:\n\n- 公平：如何保证每个节点都能被分配资源\n- 资源高效利用：集群所有资源最大化被使用\n- 效率：调度的性能要好,能够尽快地对大批量的pod完成调度工作\n- 灵活：允许用户根据自己的需求控制调度的逻辑\n\nSheduler 是作为单独的程序运行的，启动之后会一直坚挺API Server，获取PodSpec.NodeName为空的 pod,对每个pod都会创建一个binding,表明该pod应该放到哪个节点上\n\n# 二、调度过程\n\n调度分为几个部分：首先是过滤掉不满足条件的节点，这个过程称为predicate；然后对通过的节点按照优先级排序,这个是priority;最后从中选择优先级最高的节点。如果中间任何一步骤有错误,就直接返回错误。\n\nPredicate 有一系列的算法可以使用:\n\nPredicate 有一系列的算法可以使用:\n\n- PodFitsResources：节点上剩余的资源是否大于 pod请求的资源\n- PodFitsHost：如果pod指定了NodeName,检查节点名称是否和NodeName匹配\n- PodFitsHostPorts：节点上已经使用的port 是否和 pod申请的port冲突\n- PodSelectorMatches：过滤掉和pod指定的label 不匹配的节点\n- NoDiskConflict：已经mount 的volume 和 pod指定的volume 不冲突,除非它们都是只读\n\n如果在predicate过程中没有合适的节点，pod会一直在pending状态，不断重试调度，直到有节点满足条件。\n经过这个步骤，如果有多个节点满足条件，就继续priorities过程:按照优先级大小对节点排序\n\n优先级由一系列键值对组成,键是该优先级项的名称,值是它的权重(该项的重要性)。这些优先级选项包括:\n\n- LeastRequestedPriority :通过计算 CPU 和Memory 的使用率来决定权重,使用率越低权重越高。换句话说,这个优先级指标倾向于资源使用比例更低的节点\n- BalancedResourceAllocation :节点上CPU 和Memory 使用率越接近,权重越高。这个应该和上面的一起使用,不应该单独使用\n- ImageLocalityPriority :倾向于已经有要使用镜像的节点,镜像总大小值越大,权重越高\n\n通过算法对所有的优先级项目和权重进行计算,得出最终的结果。\n\n# 三、自定义调度器\n\n除了kubernetes 自带的调度器,也可以编写自己的调度器。通过spec:schedulername参数指定调度器的名字,可以为pod选择某个调度器进行调度。比如下面的pod选择my-scheduler进行调度,而不是默认的default-scheduler。\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: annotation-second-scheduler\n  labels:\n    name: multischeduler-example\nspec:\n  schedulerName: my-schedulen\n  containers:\n  - name: pod-with-second-annotation-container\n    image: gcr.io/google_containers/pause:2.0\n```\n\n# 四、节点亲和性\n\npod.spec.nodeAffinity\n\n- preferredDuringSchedulinglgnoredDuringExecution：软策略\n- requiredDuringSchedulinglgnoredDuringExecution：硬策略\n\nrequiredDuringSchedulinglgnoredDuringExecution\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: affinity\n  labels:\n    app: node-affinity-pod\nspec:\n  containers:\n  - name: with-node-affinity\n    image: harborcloud.com/library/nginx:1.9.1\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: kubernetes.io/hostname\n            operator: NotIn\n            values:\n            - k8s-node02\n```\n\nrequiredDuringSchedulinglgnoredDuringExecution\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: affinity\n  labels:\n    app: node-affinity-pod\nspec:\n  containers:\n  - name: with-node-affinity\n    image: harborcloud.com/library/nginx:1.9.1\n  affinity:\n    nodeAffinity:\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 1\n        preference:\n          matchExpressions:\n          - key: kubernetes.io/hostname\n            operator: In\n            values:\n            - k8s-node02222\n```\n\n综合\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: affinity\n  labels:\n    app: node-affinity-pod\nspec:\n  containers:\n  - name: with-node-affinity\n    image: harborcloud.com/library/nginx:1.9.1\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: kubernetes.io/hostname\n            operator: NotIn\n            values:\n            - k8s-node02\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 1\n        preference:\n          matchExpressions:\n          - key: source\n            operator: In\n            values:\n            - qikqiak\n```\n\n## 4.1 键值运算关系\n\n- In: label的值在某个列表中\n- Notln: label的值不在某个列表中\n- Gt: label的值大于某个值\n- Lt: label的值小于某个值\n- Exists:某个label 存在\n- DoesNotExist:某 label 不存在\n\n# 五、Pod亲和性\n\npod.spec.affinity.podAffinity/podAntiAffinity\n\n- preferredDuringSchedulinglgnoredDuringExecution: 软策略\n- requiredDuringSchedulinglgnoredDuringExecution:硬策略\n\n```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  affinity:\n    podAffinity: #亲和力\n      requiredDuringSchedulingIgnoredDuringExecution:\n      - labelSelector:\n          matchLabels:\n            service.cpaas.io/name: deployment-nginx\n        topologyKey: kubernetes.io/hostname # pod同node\n    podAntiAffinity: #反亲和力\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 100\n        podAffinityTerm:\n          labelSelector:\n            matchExpressions:\n            - key: a\n              operator: In\n              values:\n              - b\n          topologyKey: kubernetes.io/hostname\n  containers:\n - name: test-pod\n    image: nginx:1.18\n```\n\n# 六、亲和性/反亲和性调度策略比较如下:\n\n| 调度策略        | 匹配标签 | 操作符                                        | 拓扑域支持 | 调度目标                                |\n| --------------- | -------- | --------------------------------------------- | ---------- | --------------------------------------- |\n| nodeAffinity    | 主机     | In, Notln, Exists,DoesNotExist, Gt, Lt <br /> | 否         | 指定主机                                |\n| podAffinity     | POD      | In, Notln, Exists,DoesNotExist                | 是         | POD与指定POD同一拓扑域 （同一个node上） |\n| podAnitAffinity | POD      | In, Notln, Exists,DoesNotExist                | 是         | POD与指定POD不在同一拓扑域              |\n\n# 七、污点(Taint) 和容忍(Toleration)\n\n节点亲和性，是pod的一种属性(偏好或硬性要求),它使pod被吸引到一类特定的节点。Taint则相反,它使节点能够排斥一类特定的pod。Taint 和toleration 相互配合,可以用来避免 pod 被分配到不合适的节点上。每个节点上都可以应用一个或多个taint,这表示对于那些不能容忍这些taint的pod,是不会被该节点接受的。如果将toleration应用于pod上,则表示这些pod可以(但不要求)被调度到具有匹配taint的节点上\n\n## 7.1 污点(Taint)\n\n1、污点(Taint)的组成\n使用kubectl taint命令可以给某个Node节点设置污点, Node被设置上污点之后就和Pod之间存在了一种相斥的关系,可以让Node拒绝Pod的调度执行,甚至将Node已经存在的Pod驱逐出去。\n\n每个污点的组成如下:\n\n```\nkey=value:effect\n```\n\n每个污点有一个key和value作为污点的标签,其中value 可以为空, effect描述污点的作用。\n\n当前taint effect 支持如下三个选项:\n\n- NoSchedule ：表示k8s将不会将Pod调度到具有该污点的Node上\n- PreferNoSchedule：表示k8s将尽量避免将Pod调度到具有该污点的Node上\n- NoExecute ：表示k8s将不会将Pod调度到具有该污点的Node上,同时会将Node 上已经存在的Pod驱逐出去\n\n1、污点的设置、查看和去除\n\n```\n#设置污点\nkubectl taint nodes node1 key1=value1: NoSchedule\n#节点说明中,查找Taints字段\nkubectl describe pod pod - name\n#去除污点\nkubectl taint nodes node1 key1: NoSchedule-\n# master 节点的添加Taint\nkubectl taint nodes k8s-master01 node-role.kubernetes.io/master=:NoSchedule\n# master去除污点\nkubectl taint nodes k8s-master01 node-role.kubernetes.io/master=:NoSchedule-\n```\n\n2 例如：\n\n```\n[root@k8s-master01 scheduler]# kubectl get pod -o wide\nNAME    READY   STATUS    RESTARTS   AGE     IP             NODE         NOMINATED NODE   READINESS GATES\npod-1   1/1     Running   0          8m28s   10.244.2.205   k8s-node02   <none>           <none>\npod-3   1/1     Running   0          7m27s   10.244.2.207   k8s-node02   <none>           <none>\n[root@k8s-master01 scheduler]# kubectl taint node  k8s-node02 checkstatus=k8s:NoExecute\nnode/k8s-node02 tainted\n[root@k8s-master01 scheduler]# kubectl get pod -o wide\nNo resources found in default namespace.\n```\n\n将k8s-node02设置污点NoExecute ，pod将从k8s-node02移除。\n\n## 7.2 容忍(Tolerations)\n\n设置了污点的Node将根据taint 的 effect: NoSchedule, PreferNoSchedule, NoExecute 和Pod 之间产生互斥的关系, Pod将在一定程度上不会被调度到Node上。但我们可以在Pod上设置容忍(Toleration),意思是设置了容忍的Pod将可以容忍污点的存在,可以被调度到存在污点的Node上。\n\npod.spec.tolerations\n\n```yaml\ntolerations:\n- key: \"key1\"\n  operator: \"Equal\"\n  value: \"value1\"\n  effect: \"NoExecute\"\n  tolerationSeconds: 3600\n- key: \"key1\"\n  operator: \"Equal\"\n  value: \"value1\"\n  effect: \"NoExecute\"\n  key: \"key2\"\n  operator: \"Exists\"\n  effect: \"NoSchedule\"\n```\n\n完整yaml：\n\n将在60s过后才会被node移除pod\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-1\n  labels:\n    app: pod-1\nspec:\n  containers:\n  - name: with-node-affinity\n    image: harborcloud.com/library/nginx:1.9.1\n  tolerations:\n  - key: \"checkstatus\"\n    operator: \"Equal\"\n    value: \"k8s\"\n    effect: \"NoExecute\"\n    tolerationSeconds: 60\n```\n\n其中key, vaule, effect 要与Node上设置的taint保持一致\noperator 的值为Exists 将会忽略value值\ntolerationSeconds 用于描述当Pod需要被驱逐时可以在Pod上继续保留运行的时间.。\n\n1 当不指定key值时,表示容忍所有的污点key\n\n```yaml\ntolerations:\n- operator: \"Exists\"\n```\n\n2 当不指定effect值时,表示容忍所有的污点作用\n\n```yaml\ntolerations:\n- key: \"key\"\n  operator: \"Exists\"\n```\n\n3 有多个Master存在时,防止资源浪费,可以如下设置\n\n```\nkubectl taint nodes Node-Name node-role.kubernetes.io/master=:PreferNoSchedule\n```\n\n# 八、指定调度节点\n\n1 Pod.spec.nodeName 将 Pod 直接调度到指定的Node 节点上,会跳过Scheduler的调度策略,该匹配规则是强制匹配\n\n```yaml\napiVersion: extensions/vlbeta1\nkind: Deployment\nmetadata:\n  name: myweb\nspec:\n  replicas: 7\n  template:\n    metadata:\n      labels:\n        app: myweb\n    spec:\n      nodeName: k8s-node01 #将pod调度到k8s-node01\n      containers:\n      - name: myweb\n        image: hub.atguigu.com/library/myapp:v1\n        ports:\n        - containerPort: 80\n```\n\n2 Pod.spec.nodeSelector:通过 kubernetes 的label-selector 机制选择节点,由调度器调度策略匹配label,而后调度Pod到目标节点,该匹配规则属于强制约束\n\n```yaml\napiVersion: extensions/vlbeta1\nkind: Deployment\nmetadata:\n  name: myweb\nspec:\n  replicas: 2\n  template:\n  metadata:\n    labels:\n      app: myweb\n  spec:\n    nodeSelector: # 未来Kubernetes会将nodeSelector废除\n      type: backEndNode1 #自定义节点调度器\n    containers:\n    - name: myweb\n      image: harbor/tomcat:8.5-jre8\n      ports:\n      - containerPort: 80\n```\n\n","slug":"kubernetes调度器scheduler","published":1,"updated":"2022-09-23T16:55:26.724Z","_id":"cl8eq0sz70012v4vjf9oibiju","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、简介\"><a href=\"#一、简介\" class=\"headerlink\" title=\"一、简介\"></a>一、简介</h1><p>Scheduler 是kubernetes 的调度器,主要的任务是把定义的pod分配到集群的节点上。听起来非常简单,但有很多要考虑的问题:</p>\n<ul>\n<li>公平：如何保证每个节点都能被分配资源</li>\n<li>资源高效利用：集群所有资源最大化被使用</li>\n<li>效率：调度的性能要好,能够尽快地对大批量的pod完成调度工作</li>\n<li>灵活：允许用户根据自己的需求控制调度的逻辑</li>\n</ul>\n<p>Sheduler 是作为单独的程序运行的，启动之后会一直坚挺API Server，获取PodSpec.NodeName为空的 pod,对每个pod都会创建一个binding,表明该pod应该放到哪个节点上</p>\n<h1 id=\"二、调度过程\"><a href=\"#二、调度过程\" class=\"headerlink\" title=\"二、调度过程\"></a>二、调度过程</h1><p>调度分为几个部分：首先是过滤掉不满足条件的节点，这个过程称为predicate；然后对通过的节点按照优先级排序,这个是priority;最后从中选择优先级最高的节点。如果中间任何一步骤有错误,就直接返回错误。</p>\n<p>Predicate 有一系列的算法可以使用:</p>\n<p>Predicate 有一系列的算法可以使用:</p>\n<ul>\n<li>PodFitsResources：节点上剩余的资源是否大于 pod请求的资源</li>\n<li>PodFitsHost：如果pod指定了NodeName,检查节点名称是否和NodeName匹配</li>\n<li>PodFitsHostPorts：节点上已经使用的port 是否和 pod申请的port冲突</li>\n<li>PodSelectorMatches：过滤掉和pod指定的label 不匹配的节点</li>\n<li>NoDiskConflict：已经mount 的volume 和 pod指定的volume 不冲突,除非它们都是只读</li>\n</ul>\n<p>如果在predicate过程中没有合适的节点，pod会一直在pending状态，不断重试调度，直到有节点满足条件。<br>经过这个步骤，如果有多个节点满足条件，就继续priorities过程:按照优先级大小对节点排序</p>\n<p>优先级由一系列键值对组成,键是该优先级项的名称,值是它的权重(该项的重要性)。这些优先级选项包括:</p>\n<ul>\n<li>LeastRequestedPriority :通过计算 CPU 和Memory 的使用率来决定权重,使用率越低权重越高。换句话说,这个优先级指标倾向于资源使用比例更低的节点</li>\n<li>BalancedResourceAllocation :节点上CPU 和Memory 使用率越接近,权重越高。这个应该和上面的一起使用,不应该单独使用</li>\n<li>ImageLocalityPriority :倾向于已经有要使用镜像的节点,镜像总大小值越大,权重越高</li>\n</ul>\n<p>通过算法对所有的优先级项目和权重进行计算,得出最终的结果。</p>\n<h1 id=\"三、自定义调度器\"><a href=\"#三、自定义调度器\" class=\"headerlink\" title=\"三、自定义调度器\"></a>三、自定义调度器</h1><p>除了kubernetes 自带的调度器,也可以编写自己的调度器。通过spec:schedulername参数指定调度器的名字,可以为pod选择某个调度器进行调度。比如下面的pod选择my-scheduler进行调度,而不是默认的default-scheduler。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">annotation-second-scheduler</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">multischeduler-example</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">schedulerName:</span> <span class=\"hljs-string\">my-schedulen</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">pod-with-second-annotation-container</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">gcr.io/google_containers/pause:2.0</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"四、节点亲和性\"><a href=\"#四、节点亲和性\" class=\"headerlink\" title=\"四、节点亲和性\"></a>四、节点亲和性</h1><p>pod.spec.nodeAffinity</p>\n<ul>\n<li>preferredDuringSchedulinglgnoredDuringExecution：软策略</li>\n<li>requiredDuringSchedulinglgnoredDuringExecution：硬策略</li>\n</ul>\n<p>requiredDuringSchedulinglgnoredDuringExecution</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">affinity</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">node-affinity-pod</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">with-node-affinity</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.9.1</span><br>  <span class=\"hljs-attr\">affinity:</span><br>    <span class=\"hljs-attr\">nodeAffinity:</span><br>      <span class=\"hljs-attr\">requiredDuringSchedulingIgnoredDuringExecution:</span><br>        <span class=\"hljs-attr\">nodeSelectorTerms:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">matchExpressions:</span><br>          <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">kubernetes.io/hostname</span><br>            <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">NotIn</span><br>            <span class=\"hljs-attr\">values:</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">k8s-node02</span><br></code></pre></td></tr></table></figure>\n\n<p>requiredDuringSchedulinglgnoredDuringExecution</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">affinity</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">node-affinity-pod</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">with-node-affinity</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.9.1</span><br>  <span class=\"hljs-attr\">affinity:</span><br>    <span class=\"hljs-attr\">nodeAffinity:</span><br>      <span class=\"hljs-attr\">preferredDuringSchedulingIgnoredDuringExecution:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">weight:</span> <span class=\"hljs-number\">1</span><br>        <span class=\"hljs-attr\">preference:</span><br>          <span class=\"hljs-attr\">matchExpressions:</span><br>          <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">kubernetes.io/hostname</span><br>            <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">In</span><br>            <span class=\"hljs-attr\">values:</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">k8s-node02222</span><br></code></pre></td></tr></table></figure>\n\n<p>综合</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">affinity</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">node-affinity-pod</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">with-node-affinity</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.9.1</span><br>  <span class=\"hljs-attr\">affinity:</span><br>    <span class=\"hljs-attr\">nodeAffinity:</span><br>      <span class=\"hljs-attr\">requiredDuringSchedulingIgnoredDuringExecution:</span><br>        <span class=\"hljs-attr\">nodeSelectorTerms:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">matchExpressions:</span><br>          <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">kubernetes.io/hostname</span><br>            <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">NotIn</span><br>            <span class=\"hljs-attr\">values:</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">k8s-node02</span><br>      <span class=\"hljs-attr\">preferredDuringSchedulingIgnoredDuringExecution:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">weight:</span> <span class=\"hljs-number\">1</span><br>        <span class=\"hljs-attr\">preference:</span><br>          <span class=\"hljs-attr\">matchExpressions:</span><br>          <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">source</span><br>            <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">In</span><br>            <span class=\"hljs-attr\">values:</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">qikqiak</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"4-1-键值运算关系\"><a href=\"#4-1-键值运算关系\" class=\"headerlink\" title=\"4.1 键值运算关系\"></a>4.1 键值运算关系</h2><ul>\n<li>In: label的值在某个列表中</li>\n<li>Notln: label的值不在某个列表中</li>\n<li>Gt: label的值大于某个值</li>\n<li>Lt: label的值小于某个值</li>\n<li>Exists:某个label 存在</li>\n<li>DoesNotExist:某 label 不存在</li>\n</ul>\n<h1 id=\"五、Pod亲和性\"><a href=\"#五、Pod亲和性\" class=\"headerlink\" title=\"五、Pod亲和性\"></a>五、Pod亲和性</h1><p>pod.spec.affinity.podAffinity/podAntiAffinity</p>\n<ul>\n<li>preferredDuringSchedulinglgnoredDuringExecution: 软策略</li>\n<li>requiredDuringSchedulinglgnoredDuringExecution:硬策略</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">test-pod</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">affinity:</span><br>    <span class=\"hljs-attr\">podAffinity:</span> <span class=\"hljs-comment\">#亲和力</span><br>      <span class=\"hljs-attr\">requiredDuringSchedulingIgnoredDuringExecution:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">labelSelector:</span><br>          <span class=\"hljs-attr\">matchLabels:</span><br>            <span class=\"hljs-attr\">service.cpaas.io/name:</span> <span class=\"hljs-string\">deployment-nginx</span><br>        <span class=\"hljs-attr\">topologyKey:</span> <span class=\"hljs-string\">kubernetes.io/hostname</span> <span class=\"hljs-comment\"># pod同node</span><br>    <span class=\"hljs-attr\">podAntiAffinity:</span> <span class=\"hljs-comment\">#反亲和力</span><br>      <span class=\"hljs-attr\">preferredDuringSchedulingIgnoredDuringExecution:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">weight:</span> <span class=\"hljs-number\">100</span><br>        <span class=\"hljs-attr\">podAffinityTerm:</span><br>          <span class=\"hljs-attr\">labelSelector:</span><br>            <span class=\"hljs-attr\">matchExpressions:</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">a</span><br>              <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">In</span><br>              <span class=\"hljs-attr\">values:</span><br>              <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">b</span><br>          <span class=\"hljs-attr\">topologyKey:</span> <span class=\"hljs-string\">kubernetes.io/hostname</span><br>  <span class=\"hljs-attr\">containers:</span><br> <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">test-pod</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">nginx:1.18</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"六、亲和性-反亲和性调度策略比较如下\"><a href=\"#六、亲和性-反亲和性调度策略比较如下\" class=\"headerlink\" title=\"六、亲和性/反亲和性调度策略比较如下:\"></a>六、亲和性/反亲和性调度策略比较如下:</h1><table>\n<thead>\n<tr>\n<th>调度策略</th>\n<th>匹配标签</th>\n<th>操作符</th>\n<th>拓扑域支持</th>\n<th>调度目标</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>nodeAffinity</td>\n<td>主机</td>\n<td>In, Notln, Exists,DoesNotExist, Gt, Lt <br /></td>\n<td>否</td>\n<td>指定主机</td>\n</tr>\n<tr>\n<td>podAffinity</td>\n<td>POD</td>\n<td>In, Notln, Exists,DoesNotExist</td>\n<td>是</td>\n<td>POD与指定POD同一拓扑域 （同一个node上）</td>\n</tr>\n<tr>\n<td>podAnitAffinity</td>\n<td>POD</td>\n<td>In, Notln, Exists,DoesNotExist</td>\n<td>是</td>\n<td>POD与指定POD不在同一拓扑域</td>\n</tr>\n</tbody></table>\n<h1 id=\"七、污点-Taint-和容忍-Toleration\"><a href=\"#七、污点-Taint-和容忍-Toleration\" class=\"headerlink\" title=\"七、污点(Taint) 和容忍(Toleration)\"></a>七、污点(Taint) 和容忍(Toleration)</h1><p>节点亲和性，是pod的一种属性(偏好或硬性要求),它使pod被吸引到一类特定的节点。Taint则相反,它使节点能够排斥一类特定的pod。Taint 和toleration 相互配合,可以用来避免 pod 被分配到不合适的节点上。每个节点上都可以应用一个或多个taint,这表示对于那些不能容忍这些taint的pod,是不会被该节点接受的。如果将toleration应用于pod上,则表示这些pod可以(但不要求)被调度到具有匹配taint的节点上</p>\n<h2 id=\"7-1-污点-Taint\"><a href=\"#7-1-污点-Taint\" class=\"headerlink\" title=\"7.1 污点(Taint)\"></a>7.1 污点(Taint)</h2><p>1、污点(Taint)的组成<br>使用kubectl taint命令可以给某个Node节点设置污点, Node被设置上污点之后就和Pod之间存在了一种相斥的关系,可以让Node拒绝Pod的调度执行,甚至将Node已经存在的Pod驱逐出去。</p>\n<p>每个污点的组成如下:</p>\n<figure class=\"highlight ini\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ini\"><span class=\"hljs-attr\">key</span>=value:effect<br></code></pre></td></tr></table></figure>\n\n<p>每个污点有一个key和value作为污点的标签,其中value 可以为空, effect描述污点的作用。</p>\n<p>当前taint effect 支持如下三个选项:</p>\n<ul>\n<li>NoSchedule ：表示k8s将不会将Pod调度到具有该污点的Node上</li>\n<li>PreferNoSchedule：表示k8s将尽量避免将Pod调度到具有该污点的Node上</li>\n<li>NoExecute ：表示k8s将不会将Pod调度到具有该污点的Node上,同时会将Node 上已经存在的Pod驱逐出去</li>\n</ul>\n<p>1、污点的设置、查看和去除</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\"><span class=\"hljs-comment\">#设置污点</span><br>kubectl taint nodes node1 <span class=\"hljs-attr\">key1=</span>value1: NoSchedule<br><span class=\"hljs-comment\">#节点说明中,查找Taints字段</span><br>kubectl describe pod pod - name<br><span class=\"hljs-comment\">#去除污点</span><br>kubectl taint nodes node1 key1: NoSchedule-<br><span class=\"hljs-comment\"># master 节点的添加Taint</span><br>kubectl taint nodes k8s-master01 <span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-role</span>.kubernetes.io/<span class=\"hljs-attr\">master=</span>:NoSchedule<br><span class=\"hljs-comment\"># master去除污点</span><br>kubectl taint nodes k8s-master01 <span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-role</span>.kubernetes.io/<span class=\"hljs-attr\">master=</span>:NoSchedule-<br></code></pre></td></tr></table></figure>\n\n<p>2 例如：</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">[root@k8s-master01 scheduler]<span class=\"hljs-comment\"># kubectl get pod -o wide</span><br>NAME    READY   STATUS    RESTARTS   AGE     IP             <span class=\"hljs-keyword\">NODE</span>         <span class=\"hljs-title\">NOMINATED</span> <span class=\"hljs-keyword\">NODE</span>   <span class=\"hljs-title\">READINESS</span> GATES<br>pod-<span class=\"hljs-number\">1</span>   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">8m</span>28s   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">2.205</span>   k8s-node02   <span class=\"hljs-tag\">&lt;none&gt;</span>           <span class=\"hljs-tag\">&lt;none&gt;</span><br>pod-<span class=\"hljs-number\">3</span>   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">7m</span>27s   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">2.207</span>   k8s-node02   <span class=\"hljs-tag\">&lt;none&gt;</span>           <span class=\"hljs-tag\">&lt;none&gt;</span><br>[root@k8s-master01 scheduler]<span class=\"hljs-comment\"># kubectl taint node  k8s-node02 checkstatus=k8s:NoExecute</span><br><span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">/k8s-node02</span> tainted<br>[root@k8s-master01 scheduler]<span class=\"hljs-comment\"># kubectl get pod -o wide</span><br>No resources found <span class=\"hljs-keyword\">in</span> default namespace.<br></code></pre></td></tr></table></figure>\n\n<p>将k8s-node02设置污点NoExecute ，pod将从k8s-node02移除。</p>\n<h2 id=\"7-2-容忍-Tolerations\"><a href=\"#7-2-容忍-Tolerations\" class=\"headerlink\" title=\"7.2 容忍(Tolerations)\"></a>7.2 容忍(Tolerations)</h2><p>设置了污点的Node将根据taint 的 effect: NoSchedule, PreferNoSchedule, NoExecute 和Pod 之间产生互斥的关系, Pod将在一定程度上不会被调度到Node上。但我们可以在Pod上设置容忍(Toleration),意思是设置了容忍的Pod将可以容忍污点的存在,可以被调度到存在污点的Node上。</p>\n<p>pod.spec.tolerations</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">tolerations:</span><br><span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">&quot;key1&quot;</span><br>  <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">&quot;Equal&quot;</span><br>  <span class=\"hljs-attr\">value:</span> <span class=\"hljs-string\">&quot;value1&quot;</span><br>  <span class=\"hljs-attr\">effect:</span> <span class=\"hljs-string\">&quot;NoExecute&quot;</span><br>  <span class=\"hljs-attr\">tolerationSeconds:</span> <span class=\"hljs-number\">3600</span><br><span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">&quot;key1&quot;</span><br>  <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">&quot;Equal&quot;</span><br>  <span class=\"hljs-attr\">value:</span> <span class=\"hljs-string\">&quot;value1&quot;</span><br>  <span class=\"hljs-attr\">effect:</span> <span class=\"hljs-string\">&quot;NoExecute&quot;</span><br>  <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">&quot;key2&quot;</span><br>  <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">&quot;Exists&quot;</span><br>  <span class=\"hljs-attr\">effect:</span> <span class=\"hljs-string\">&quot;NoSchedule&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>完整yaml：</p>\n<p>将在60s过后才会被node移除pod</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">pod-1</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">pod-1</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">with-node-affinity</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.9.1</span><br>  <span class=\"hljs-attr\">tolerations:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">&quot;checkstatus&quot;</span><br>    <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">&quot;Equal&quot;</span><br>    <span class=\"hljs-attr\">value:</span> <span class=\"hljs-string\">&quot;k8s&quot;</span><br>    <span class=\"hljs-attr\">effect:</span> <span class=\"hljs-string\">&quot;NoExecute&quot;</span><br>    <span class=\"hljs-attr\">tolerationSeconds:</span> <span class=\"hljs-number\">60</span><br></code></pre></td></tr></table></figure>\n\n<p>其中key, vaule, effect 要与Node上设置的taint保持一致<br>operator 的值为Exists 将会忽略value值<br>tolerationSeconds 用于描述当Pod需要被驱逐时可以在Pod上继续保留运行的时间.。</p>\n<p>1 当不指定key值时,表示容忍所有的污点key</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">tolerations:</span><br><span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">&quot;Exists&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>2 当不指定effect值时,表示容忍所有的污点作用</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">tolerations:</span><br><span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">&quot;key&quot;</span><br>  <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">&quot;Exists&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>3 有多个Master存在时,防止资源浪费,可以如下设置</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">kubectl taint nodes <span class=\"hljs-keyword\">Node</span><span class=\"hljs-title\">-Name</span> <span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-role</span>.kubernetes.io/<span class=\"hljs-attr\">master=</span>:PreferNoSchedule<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"八、指定调度节点\"><a href=\"#八、指定调度节点\" class=\"headerlink\" title=\"八、指定调度节点\"></a>八、指定调度节点</h1><p>1 Pod.spec.nodeName 将 Pod 直接调度到指定的Node 节点上,会跳过Scheduler的调度策略,该匹配规则是强制匹配</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">extensions/vlbeta1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Deployment</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myweb</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-number\">7</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">labels:</span><br>        <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myweb</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">nodeName:</span> <span class=\"hljs-string\">k8s-node01</span> <span class=\"hljs-comment\">#将pod调度到k8s-node01</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myweb</span><br>        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">hub.atguigu.com/library/myapp:v1</span><br>        <span class=\"hljs-attr\">ports:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n<p>2 Pod.spec.nodeSelector:通过 kubernetes 的label-selector 机制选择节点,由调度器调度策略匹配label,而后调度Pod到目标节点,该匹配规则属于强制约束</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">extensions/vlbeta1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Deployment</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myweb</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-number\">2</span><br>  <span class=\"hljs-attr\">template:</span><br>  <span class=\"hljs-attr\">metadata:</span><br>    <span class=\"hljs-attr\">labels:</span><br>      <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myweb</span><br>  <span class=\"hljs-attr\">spec:</span><br>    <span class=\"hljs-attr\">nodeSelector:</span> <span class=\"hljs-comment\"># 未来Kubernetes会将nodeSelector废除</span><br>      <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">backEndNode1</span> <span class=\"hljs-comment\">#自定义节点调度器</span><br>    <span class=\"hljs-attr\">containers:</span><br>    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myweb</span><br>      <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harbor/tomcat:8.5-jre8</span><br>      <span class=\"hljs-attr\">ports:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、简介\"><a href=\"#一、简介\" class=\"headerlink\" title=\"一、简介\"></a>一、简介</h1><p>Scheduler 是kubernetes 的调度器,主要的任务是把定义的pod分配到集群的节点上。听起来非常简单,但有很多要考虑的问题:</p>\n<ul>\n<li>公平：如何保证每个节点都能被分配资源</li>\n<li>资源高效利用：集群所有资源最大化被使用</li>\n<li>效率：调度的性能要好,能够尽快地对大批量的pod完成调度工作</li>\n<li>灵活：允许用户根据自己的需求控制调度的逻辑</li>\n</ul>\n<p>Sheduler 是作为单独的程序运行的，启动之后会一直坚挺API Server，获取PodSpec.NodeName为空的 pod,对每个pod都会创建一个binding,表明该pod应该放到哪个节点上</p>\n<h1 id=\"二、调度过程\"><a href=\"#二、调度过程\" class=\"headerlink\" title=\"二、调度过程\"></a>二、调度过程</h1><p>调度分为几个部分：首先是过滤掉不满足条件的节点，这个过程称为predicate；然后对通过的节点按照优先级排序,这个是priority;最后从中选择优先级最高的节点。如果中间任何一步骤有错误,就直接返回错误。</p>\n<p>Predicate 有一系列的算法可以使用:</p>\n<p>Predicate 有一系列的算法可以使用:</p>\n<ul>\n<li>PodFitsResources：节点上剩余的资源是否大于 pod请求的资源</li>\n<li>PodFitsHost：如果pod指定了NodeName,检查节点名称是否和NodeName匹配</li>\n<li>PodFitsHostPorts：节点上已经使用的port 是否和 pod申请的port冲突</li>\n<li>PodSelectorMatches：过滤掉和pod指定的label 不匹配的节点</li>\n<li>NoDiskConflict：已经mount 的volume 和 pod指定的volume 不冲突,除非它们都是只读</li>\n</ul>\n<p>如果在predicate过程中没有合适的节点，pod会一直在pending状态，不断重试调度，直到有节点满足条件。<br>经过这个步骤，如果有多个节点满足条件，就继续priorities过程:按照优先级大小对节点排序</p>\n<p>优先级由一系列键值对组成,键是该优先级项的名称,值是它的权重(该项的重要性)。这些优先级选项包括:</p>\n<ul>\n<li>LeastRequestedPriority :通过计算 CPU 和Memory 的使用率来决定权重,使用率越低权重越高。换句话说,这个优先级指标倾向于资源使用比例更低的节点</li>\n<li>BalancedResourceAllocation :节点上CPU 和Memory 使用率越接近,权重越高。这个应该和上面的一起使用,不应该单独使用</li>\n<li>ImageLocalityPriority :倾向于已经有要使用镜像的节点,镜像总大小值越大,权重越高</li>\n</ul>\n<p>通过算法对所有的优先级项目和权重进行计算,得出最终的结果。</p>\n<h1 id=\"三、自定义调度器\"><a href=\"#三、自定义调度器\" class=\"headerlink\" title=\"三、自定义调度器\"></a>三、自定义调度器</h1><p>除了kubernetes 自带的调度器,也可以编写自己的调度器。通过spec:schedulername参数指定调度器的名字,可以为pod选择某个调度器进行调度。比如下面的pod选择my-scheduler进行调度,而不是默认的default-scheduler。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">annotation-second-scheduler</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">multischeduler-example</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">schedulerName:</span> <span class=\"hljs-string\">my-schedulen</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">pod-with-second-annotation-container</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">gcr.io/google_containers/pause:2.0</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"四、节点亲和性\"><a href=\"#四、节点亲和性\" class=\"headerlink\" title=\"四、节点亲和性\"></a>四、节点亲和性</h1><p>pod.spec.nodeAffinity</p>\n<ul>\n<li>preferredDuringSchedulinglgnoredDuringExecution：软策略</li>\n<li>requiredDuringSchedulinglgnoredDuringExecution：硬策略</li>\n</ul>\n<p>requiredDuringSchedulinglgnoredDuringExecution</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">affinity</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">node-affinity-pod</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">with-node-affinity</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.9.1</span><br>  <span class=\"hljs-attr\">affinity:</span><br>    <span class=\"hljs-attr\">nodeAffinity:</span><br>      <span class=\"hljs-attr\">requiredDuringSchedulingIgnoredDuringExecution:</span><br>        <span class=\"hljs-attr\">nodeSelectorTerms:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">matchExpressions:</span><br>          <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">kubernetes.io/hostname</span><br>            <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">NotIn</span><br>            <span class=\"hljs-attr\">values:</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">k8s-node02</span><br></code></pre></td></tr></table></figure>\n\n<p>requiredDuringSchedulinglgnoredDuringExecution</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">affinity</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">node-affinity-pod</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">with-node-affinity</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.9.1</span><br>  <span class=\"hljs-attr\">affinity:</span><br>    <span class=\"hljs-attr\">nodeAffinity:</span><br>      <span class=\"hljs-attr\">preferredDuringSchedulingIgnoredDuringExecution:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">weight:</span> <span class=\"hljs-number\">1</span><br>        <span class=\"hljs-attr\">preference:</span><br>          <span class=\"hljs-attr\">matchExpressions:</span><br>          <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">kubernetes.io/hostname</span><br>            <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">In</span><br>            <span class=\"hljs-attr\">values:</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">k8s-node02222</span><br></code></pre></td></tr></table></figure>\n\n<p>综合</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">affinity</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">node-affinity-pod</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">with-node-affinity</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.9.1</span><br>  <span class=\"hljs-attr\">affinity:</span><br>    <span class=\"hljs-attr\">nodeAffinity:</span><br>      <span class=\"hljs-attr\">requiredDuringSchedulingIgnoredDuringExecution:</span><br>        <span class=\"hljs-attr\">nodeSelectorTerms:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">matchExpressions:</span><br>          <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">kubernetes.io/hostname</span><br>            <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">NotIn</span><br>            <span class=\"hljs-attr\">values:</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">k8s-node02</span><br>      <span class=\"hljs-attr\">preferredDuringSchedulingIgnoredDuringExecution:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">weight:</span> <span class=\"hljs-number\">1</span><br>        <span class=\"hljs-attr\">preference:</span><br>          <span class=\"hljs-attr\">matchExpressions:</span><br>          <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">source</span><br>            <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">In</span><br>            <span class=\"hljs-attr\">values:</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">qikqiak</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"4-1-键值运算关系\"><a href=\"#4-1-键值运算关系\" class=\"headerlink\" title=\"4.1 键值运算关系\"></a>4.1 键值运算关系</h2><ul>\n<li>In: label的值在某个列表中</li>\n<li>Notln: label的值不在某个列表中</li>\n<li>Gt: label的值大于某个值</li>\n<li>Lt: label的值小于某个值</li>\n<li>Exists:某个label 存在</li>\n<li>DoesNotExist:某 label 不存在</li>\n</ul>\n<h1 id=\"五、Pod亲和性\"><a href=\"#五、Pod亲和性\" class=\"headerlink\" title=\"五、Pod亲和性\"></a>五、Pod亲和性</h1><p>pod.spec.affinity.podAffinity/podAntiAffinity</p>\n<ul>\n<li>preferredDuringSchedulinglgnoredDuringExecution: 软策略</li>\n<li>requiredDuringSchedulinglgnoredDuringExecution:硬策略</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">test-pod</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">affinity:</span><br>    <span class=\"hljs-attr\">podAffinity:</span> <span class=\"hljs-comment\">#亲和力</span><br>      <span class=\"hljs-attr\">requiredDuringSchedulingIgnoredDuringExecution:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">labelSelector:</span><br>          <span class=\"hljs-attr\">matchLabels:</span><br>            <span class=\"hljs-attr\">service.cpaas.io/name:</span> <span class=\"hljs-string\">deployment-nginx</span><br>        <span class=\"hljs-attr\">topologyKey:</span> <span class=\"hljs-string\">kubernetes.io/hostname</span> <span class=\"hljs-comment\"># pod同node</span><br>    <span class=\"hljs-attr\">podAntiAffinity:</span> <span class=\"hljs-comment\">#反亲和力</span><br>      <span class=\"hljs-attr\">preferredDuringSchedulingIgnoredDuringExecution:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">weight:</span> <span class=\"hljs-number\">100</span><br>        <span class=\"hljs-attr\">podAffinityTerm:</span><br>          <span class=\"hljs-attr\">labelSelector:</span><br>            <span class=\"hljs-attr\">matchExpressions:</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">a</span><br>              <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">In</span><br>              <span class=\"hljs-attr\">values:</span><br>              <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">b</span><br>          <span class=\"hljs-attr\">topologyKey:</span> <span class=\"hljs-string\">kubernetes.io/hostname</span><br>  <span class=\"hljs-attr\">containers:</span><br> <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">test-pod</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">nginx:1.18</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"六、亲和性-反亲和性调度策略比较如下\"><a href=\"#六、亲和性-反亲和性调度策略比较如下\" class=\"headerlink\" title=\"六、亲和性/反亲和性调度策略比较如下:\"></a>六、亲和性/反亲和性调度策略比较如下:</h1><table>\n<thead>\n<tr>\n<th>调度策略</th>\n<th>匹配标签</th>\n<th>操作符</th>\n<th>拓扑域支持</th>\n<th>调度目标</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>nodeAffinity</td>\n<td>主机</td>\n<td>In, Notln, Exists,DoesNotExist, Gt, Lt <br /></td>\n<td>否</td>\n<td>指定主机</td>\n</tr>\n<tr>\n<td>podAffinity</td>\n<td>POD</td>\n<td>In, Notln, Exists,DoesNotExist</td>\n<td>是</td>\n<td>POD与指定POD同一拓扑域 （同一个node上）</td>\n</tr>\n<tr>\n<td>podAnitAffinity</td>\n<td>POD</td>\n<td>In, Notln, Exists,DoesNotExist</td>\n<td>是</td>\n<td>POD与指定POD不在同一拓扑域</td>\n</tr>\n</tbody></table>\n<h1 id=\"七、污点-Taint-和容忍-Toleration\"><a href=\"#七、污点-Taint-和容忍-Toleration\" class=\"headerlink\" title=\"七、污点(Taint) 和容忍(Toleration)\"></a>七、污点(Taint) 和容忍(Toleration)</h1><p>节点亲和性，是pod的一种属性(偏好或硬性要求),它使pod被吸引到一类特定的节点。Taint则相反,它使节点能够排斥一类特定的pod。Taint 和toleration 相互配合,可以用来避免 pod 被分配到不合适的节点上。每个节点上都可以应用一个或多个taint,这表示对于那些不能容忍这些taint的pod,是不会被该节点接受的。如果将toleration应用于pod上,则表示这些pod可以(但不要求)被调度到具有匹配taint的节点上</p>\n<h2 id=\"7-1-污点-Taint\"><a href=\"#7-1-污点-Taint\" class=\"headerlink\" title=\"7.1 污点(Taint)\"></a>7.1 污点(Taint)</h2><p>1、污点(Taint)的组成<br>使用kubectl taint命令可以给某个Node节点设置污点, Node被设置上污点之后就和Pod之间存在了一种相斥的关系,可以让Node拒绝Pod的调度执行,甚至将Node已经存在的Pod驱逐出去。</p>\n<p>每个污点的组成如下:</p>\n<figure class=\"highlight ini\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ini\"><span class=\"hljs-attr\">key</span>=value:effect<br></code></pre></td></tr></table></figure>\n\n<p>每个污点有一个key和value作为污点的标签,其中value 可以为空, effect描述污点的作用。</p>\n<p>当前taint effect 支持如下三个选项:</p>\n<ul>\n<li>NoSchedule ：表示k8s将不会将Pod调度到具有该污点的Node上</li>\n<li>PreferNoSchedule：表示k8s将尽量避免将Pod调度到具有该污点的Node上</li>\n<li>NoExecute ：表示k8s将不会将Pod调度到具有该污点的Node上,同时会将Node 上已经存在的Pod驱逐出去</li>\n</ul>\n<p>1、污点的设置、查看和去除</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\"><span class=\"hljs-comment\">#设置污点</span><br>kubectl taint nodes node1 <span class=\"hljs-attr\">key1=</span>value1: NoSchedule<br><span class=\"hljs-comment\">#节点说明中,查找Taints字段</span><br>kubectl describe pod pod - name<br><span class=\"hljs-comment\">#去除污点</span><br>kubectl taint nodes node1 key1: NoSchedule-<br><span class=\"hljs-comment\"># master 节点的添加Taint</span><br>kubectl taint nodes k8s-master01 <span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-role</span>.kubernetes.io/<span class=\"hljs-attr\">master=</span>:NoSchedule<br><span class=\"hljs-comment\"># master去除污点</span><br>kubectl taint nodes k8s-master01 <span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-role</span>.kubernetes.io/<span class=\"hljs-attr\">master=</span>:NoSchedule-<br></code></pre></td></tr></table></figure>\n\n<p>2 例如：</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">[root@k8s-master01 scheduler]<span class=\"hljs-comment\"># kubectl get pod -o wide</span><br>NAME    READY   STATUS    RESTARTS   AGE     IP             <span class=\"hljs-keyword\">NODE</span>         <span class=\"hljs-title\">NOMINATED</span> <span class=\"hljs-keyword\">NODE</span>   <span class=\"hljs-title\">READINESS</span> GATES<br>pod-<span class=\"hljs-number\">1</span>   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">8m</span>28s   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">2.205</span>   k8s-node02   <span class=\"hljs-tag\">&lt;none&gt;</span>           <span class=\"hljs-tag\">&lt;none&gt;</span><br>pod-<span class=\"hljs-number\">3</span>   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">7m</span>27s   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">2.207</span>   k8s-node02   <span class=\"hljs-tag\">&lt;none&gt;</span>           <span class=\"hljs-tag\">&lt;none&gt;</span><br>[root@k8s-master01 scheduler]<span class=\"hljs-comment\"># kubectl taint node  k8s-node02 checkstatus=k8s:NoExecute</span><br><span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">/k8s-node02</span> tainted<br>[root@k8s-master01 scheduler]<span class=\"hljs-comment\"># kubectl get pod -o wide</span><br>No resources found <span class=\"hljs-keyword\">in</span> default namespace.<br></code></pre></td></tr></table></figure>\n\n<p>将k8s-node02设置污点NoExecute ，pod将从k8s-node02移除。</p>\n<h2 id=\"7-2-容忍-Tolerations\"><a href=\"#7-2-容忍-Tolerations\" class=\"headerlink\" title=\"7.2 容忍(Tolerations)\"></a>7.2 容忍(Tolerations)</h2><p>设置了污点的Node将根据taint 的 effect: NoSchedule, PreferNoSchedule, NoExecute 和Pod 之间产生互斥的关系, Pod将在一定程度上不会被调度到Node上。但我们可以在Pod上设置容忍(Toleration),意思是设置了容忍的Pod将可以容忍污点的存在,可以被调度到存在污点的Node上。</p>\n<p>pod.spec.tolerations</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">tolerations:</span><br><span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">&quot;key1&quot;</span><br>  <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">&quot;Equal&quot;</span><br>  <span class=\"hljs-attr\">value:</span> <span class=\"hljs-string\">&quot;value1&quot;</span><br>  <span class=\"hljs-attr\">effect:</span> <span class=\"hljs-string\">&quot;NoExecute&quot;</span><br>  <span class=\"hljs-attr\">tolerationSeconds:</span> <span class=\"hljs-number\">3600</span><br><span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">&quot;key1&quot;</span><br>  <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">&quot;Equal&quot;</span><br>  <span class=\"hljs-attr\">value:</span> <span class=\"hljs-string\">&quot;value1&quot;</span><br>  <span class=\"hljs-attr\">effect:</span> <span class=\"hljs-string\">&quot;NoExecute&quot;</span><br>  <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">&quot;key2&quot;</span><br>  <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">&quot;Exists&quot;</span><br>  <span class=\"hljs-attr\">effect:</span> <span class=\"hljs-string\">&quot;NoSchedule&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>完整yaml：</p>\n<p>将在60s过后才会被node移除pod</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">pod-1</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">pod-1</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">with-node-affinity</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.9.1</span><br>  <span class=\"hljs-attr\">tolerations:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">&quot;checkstatus&quot;</span><br>    <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">&quot;Equal&quot;</span><br>    <span class=\"hljs-attr\">value:</span> <span class=\"hljs-string\">&quot;k8s&quot;</span><br>    <span class=\"hljs-attr\">effect:</span> <span class=\"hljs-string\">&quot;NoExecute&quot;</span><br>    <span class=\"hljs-attr\">tolerationSeconds:</span> <span class=\"hljs-number\">60</span><br></code></pre></td></tr></table></figure>\n\n<p>其中key, vaule, effect 要与Node上设置的taint保持一致<br>operator 的值为Exists 将会忽略value值<br>tolerationSeconds 用于描述当Pod需要被驱逐时可以在Pod上继续保留运行的时间.。</p>\n<p>1 当不指定key值时,表示容忍所有的污点key</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">tolerations:</span><br><span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">&quot;Exists&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>2 当不指定effect值时,表示容忍所有的污点作用</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">tolerations:</span><br><span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">&quot;key&quot;</span><br>  <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">&quot;Exists&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>3 有多个Master存在时,防止资源浪费,可以如下设置</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">kubectl taint nodes <span class=\"hljs-keyword\">Node</span><span class=\"hljs-title\">-Name</span> <span class=\"hljs-keyword\">node</span><span class=\"hljs-title\">-role</span>.kubernetes.io/<span class=\"hljs-attr\">master=</span>:PreferNoSchedule<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"八、指定调度节点\"><a href=\"#八、指定调度节点\" class=\"headerlink\" title=\"八、指定调度节点\"></a>八、指定调度节点</h1><p>1 Pod.spec.nodeName 将 Pod 直接调度到指定的Node 节点上,会跳过Scheduler的调度策略,该匹配规则是强制匹配</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">extensions/vlbeta1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Deployment</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myweb</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-number\">7</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">labels:</span><br>        <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myweb</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">nodeName:</span> <span class=\"hljs-string\">k8s-node01</span> <span class=\"hljs-comment\">#将pod调度到k8s-node01</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myweb</span><br>        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">hub.atguigu.com/library/myapp:v1</span><br>        <span class=\"hljs-attr\">ports:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n<p>2 Pod.spec.nodeSelector:通过 kubernetes 的label-selector 机制选择节点,由调度器调度策略匹配label,而后调度Pod到目标节点,该匹配规则属于强制约束</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">extensions/vlbeta1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Deployment</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myweb</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-number\">2</span><br>  <span class=\"hljs-attr\">template:</span><br>  <span class=\"hljs-attr\">metadata:</span><br>    <span class=\"hljs-attr\">labels:</span><br>      <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myweb</span><br>  <span class=\"hljs-attr\">spec:</span><br>    <span class=\"hljs-attr\">nodeSelector:</span> <span class=\"hljs-comment\"># 未来Kubernetes会将nodeSelector废除</span><br>      <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">backEndNode1</span> <span class=\"hljs-comment\">#自定义节点调度器</span><br>    <span class=\"hljs-attr\">containers:</span><br>    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myweb</span><br>      <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harbor/tomcat:8.5-jre8</span><br>      <span class=\"hljs-attr\">ports:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n"},{"title":"kubernetes 入门学习 dashboard","date":"2021-08-02T11:18:02.000Z","_content":"\n\n\n# 1 dashboard安装\n\n```shell\n$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml\n```\n\n结果：\n\n```shell\nnamespace/kubernetes-dashboard created  # 命名空间kubernetes-dashboard\nserviceaccount/kubernetes-dashboard created # 服务账号kubernetes-dashboard\nservice/kubernetes-dashboard created # 服务kubernetes-dashboard\nsecret/kubernetes-dashboard-certs created #  secret创建\nsecret/kubernetes-dashboard-csrf created\nsecret/kubernetes-dashboard-key-holder created \nconfigmap/kubernetes-dashboard-settings created # 配置\nrole.rbac.authorization.k8s.io/kubernetes-dashboard created # 角色和角色绑定\nclusterrole.rbac.authorization.k8s.io/kubernetes-dashboard configured\nrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created\nclusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard unchanged\ndeployment.apps/kubernetes-dashboard created\nservice/dashboard-metrics-scraper created\ndeployment.apps/dashboard-metrics-scraper created\n```\n\n查看校验资源的安装情况\n\n```shell\n$ kubectl get deployments -n kubernetes-dashboard\n$ kubectl get services -n kubernetes-dashboard\n$ kubectl get pods -n kubernetes-dashboard\n$ kubectl get secrets -n kubernetes-dashboard\n$ kubectl get configMap -n kubernetes-dashboard\n$ kubectl  get services -n kubernetes-dashboard\n```\n\n# 2 开放外部访问端口\n\nkubernetes-dashbaord安装完毕后，kubernetes-dashboard默认service的类型为ClusterIP，为了从外部访问控制面板，开放为NodePort类型\n\n过程：编辑之前——编辑——编辑之后\n\n```shell\n[root@k8smaster influxdb]# kubectl get svc -n kubernetes-dashboard\nNAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE\ndashboard-metrics-scraper   ClusterIP   10.104.64.108   <none>        8000/TCP   2m33s\nkubernetes-dashboard        ClusterIP   10.102.42.206   <none>        443/TCP    2m33s\n[root@k8smaster influxdb]# kubectl edit svc/kubernetes-dashboard -n kubernetes-dashboard\nservice/kubernetes-dashboard edited\n[root@k8smaster influxdb]# kubectl get svc -n kubernetes-dashboard\nNAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE\ndashboard-metrics-scraper   ClusterIP   10.104.64.108   <none>        8000/TCP        10m\nkubernetes-dashboard        NodePort    10.102.42.206   <none>        443:30367/TCP   10m\n```\n\n# 3 授权用户访问集群\n\ndashboard-rbac.yaml定义\n\n```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: happycloudlab \n  namespace: kubernetes-dashboard\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: happycloudlab\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: happycloudlab\n  namespace: kubernetes-dashboard\n```\n\n操作：\n\n```shell\n[root@k8smaster influxdb]# vi dashboard-rbac.yaml\n[root@k8smaster influxdb]# kubectl create -f dashboard-rbac.yaml \nserviceaccount/happycloudlab created\nclusterrolebinding.rbac.authorization.k8s.io/happycloudlab created\n```\n\n# 4 获取token\n\n通过token字段来登陆，token通过base64加密,这里的happycloudlab-token-*须通过命令查看，具体是哪一个。\n\n## 4.1 获取具体secret并且提取yaml信息\n\n```shell\n[root@k8smaster influxdb]# kubectl get secret -n kubernetes-dashboard\nNAME                               TYPE                                  DATA   AGE\ndefault-token-vzxqv                kubernetes.io/service-account-token   3      14m\nhappycloudlab-token-5dxhd          kubernetes.io/service-account-token   3      44s\nkubernetes-dashboard-certs         Opaque                                0      14m\nkubernetes-dashboard-csrf          Opaque                                1      14m\nkubernetes-dashboard-key-holder    Opaque                                2      14m\nkubernetes-dashboard-token-fqtcx   kubernetes.io/service-account-token   3      14m\n[root@k8smaster influxdb]# kubectl get secrets -n kubernetes-dashboard happycloudlab-token-5dxhd -o yaml\n```\n\n![1630834989795](.\\k8s dashboard\\1630834989795.png)\n\n## 4.2 通过echo获取base64编码token\n\n```shell\n[root@k8smaster influxdb]# echo 'ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklrWmtSVE5UYVhOT2RrUlFWRU5vV2xOeE5FSkJjMGQxTURkM2JETkJOa2Q2TFZaNVdWbzFhV3hOV0ZFaWZRLmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbGNtNWxkR1Z6TFdSaGMyaGliMkZ5WkNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKb1lYQndlV05zYjNWa2JHRmlMWFJ2YTJWdUxUVmtlR2hrSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW1oaGNIQjVZMnh2ZFdSc1lXSWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzUxYVdRaU9pSm1NemM1TkdOak5TMHhNMk5pTFRRMVpEQXRPRFJpWWkxaU5UVmtNRFF3TkdVMU9Ea2lMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2YTNWaVpYSnVaWFJsY3kxa1lYTm9ZbTloY21RNmFHRndjSGxqYkc5MVpHeGhZaUo5LkpBZVFBRS1CT1RGZDhXOGp3cEFpa0lTQlF4N2N6bmhySmZneDFxLXA5OTRLSUI5aXRfeFZ3bUlEaEI4bVlZQTJQLXRBNWp4d2d6NDZHamdSZTlfc1dYdFRrTHYwT3dpYmtNeDU3Q0RFVzkxV09CNzkyeTZiOWNWX1BhV3hPVkRyZFFvSVo3S3A0OVFITFNkN1lhREl1eE15UDlzX3pQaTI3dmc0YUZwLUFLS1ZWV0NqcDFvaURFM213Y3FJd2xha3JySW5ZUmg0THNKTFc5TTBVc3BCRklZUFhGNEh5QWxvX2NGX29qNVlHMUFJWUJGTGtlQUZyaEYwalFzQmhseHVYVVRubC01TmN2WjlDRXJJbGJ4VEpfMWtLcVc2UjBwOXFsZ1dpZzFPamhFNzg4NWs0dnVzeDM5S004d2U1ZHBJbjV6WDdIMzBFSjgwOGRpOGVyTFFQUQ==' | base64 -d\n```\n\n得到结果：\n\n```\neyJhbGciOiJSUzI1NiIsImtpZCI6IkZkRTNTaXNOdkRQVENoWlNxNEJBc0d1MDd3bDNBNkd6LVZ5WVo1aWxNWFEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJoYXBweWNsb3VkbGFiLXRva2VuLTVkeGhkIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImhhcHB5Y2xvdWRsYWIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJmMzc5NGNjNS0xM2NiLTQ1ZDAtODRiYi1iNTVkMDQwNGU1ODkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6aGFwcHljbG91ZGxhYiJ9.JAeQAE-BOTFd8W8jwpAikISBQx7cznhrJfgx1q-p994KIB9it_xVwmIDhB8mYYA2P-tA5jxwgz46GjgRe9_sWXtTkLv0OwibkMx57CDEW91WOB792y6b9cV_PaWxOVDrdQoIZ7Kp49QHLSd7YaDIuxMyP9s_zPi27vg4aFp-AKKVVWCjp1oiDE3mwcqIwlakrrInYRh4LsJLW9M0UspBFIYPXF4HyAlo_cF_oj5YG1AIYBFLkeAFrhF0jQsBhlxuXUTnl-5NcvZ9CErIlbxTJ_1kKqW6R0p9qlgWig1OjhE7885k4vusx39KM8we5dpIn5zX7H30EJ808di8erLQPQ\n```\n\n# 5 登录dashboard\n\n获取外网访问端口\n\n```\n[root@k8smaster influxdb]# kubectl get svc -n kubernetes-dashboard\nNAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE\ndashboard-metrics-scraper   ClusterIP   10.104.64.108   <none>        8000/TCP        10m\nkubernetes-dashboard        NodePort    10.102.42.206   <none>        443:30367/TCP   10m\n```\n\n填写token并登录\n\n![1630835361904](.\\k8s dashboard\\1630835361904.png)\n\n![1630835709026](.\\1630835709026.png)","source":"_posts/k8s dashboard.md","raw":"---\ntitle: kubernetes 入门学习 dashboard\ndate: 2021-08-02 19:18:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - dashboard\n---\n\n\n\n# 1 dashboard安装\n\n```shell\n$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml\n```\n\n结果：\n\n```shell\nnamespace/kubernetes-dashboard created  # 命名空间kubernetes-dashboard\nserviceaccount/kubernetes-dashboard created # 服务账号kubernetes-dashboard\nservice/kubernetes-dashboard created # 服务kubernetes-dashboard\nsecret/kubernetes-dashboard-certs created #  secret创建\nsecret/kubernetes-dashboard-csrf created\nsecret/kubernetes-dashboard-key-holder created \nconfigmap/kubernetes-dashboard-settings created # 配置\nrole.rbac.authorization.k8s.io/kubernetes-dashboard created # 角色和角色绑定\nclusterrole.rbac.authorization.k8s.io/kubernetes-dashboard configured\nrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created\nclusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard unchanged\ndeployment.apps/kubernetes-dashboard created\nservice/dashboard-metrics-scraper created\ndeployment.apps/dashboard-metrics-scraper created\n```\n\n查看校验资源的安装情况\n\n```shell\n$ kubectl get deployments -n kubernetes-dashboard\n$ kubectl get services -n kubernetes-dashboard\n$ kubectl get pods -n kubernetes-dashboard\n$ kubectl get secrets -n kubernetes-dashboard\n$ kubectl get configMap -n kubernetes-dashboard\n$ kubectl  get services -n kubernetes-dashboard\n```\n\n# 2 开放外部访问端口\n\nkubernetes-dashbaord安装完毕后，kubernetes-dashboard默认service的类型为ClusterIP，为了从外部访问控制面板，开放为NodePort类型\n\n过程：编辑之前——编辑——编辑之后\n\n```shell\n[root@k8smaster influxdb]# kubectl get svc -n kubernetes-dashboard\nNAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE\ndashboard-metrics-scraper   ClusterIP   10.104.64.108   <none>        8000/TCP   2m33s\nkubernetes-dashboard        ClusterIP   10.102.42.206   <none>        443/TCP    2m33s\n[root@k8smaster influxdb]# kubectl edit svc/kubernetes-dashboard -n kubernetes-dashboard\nservice/kubernetes-dashboard edited\n[root@k8smaster influxdb]# kubectl get svc -n kubernetes-dashboard\nNAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE\ndashboard-metrics-scraper   ClusterIP   10.104.64.108   <none>        8000/TCP        10m\nkubernetes-dashboard        NodePort    10.102.42.206   <none>        443:30367/TCP   10m\n```\n\n# 3 授权用户访问集群\n\ndashboard-rbac.yaml定义\n\n```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: happycloudlab \n  namespace: kubernetes-dashboard\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: happycloudlab\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: happycloudlab\n  namespace: kubernetes-dashboard\n```\n\n操作：\n\n```shell\n[root@k8smaster influxdb]# vi dashboard-rbac.yaml\n[root@k8smaster influxdb]# kubectl create -f dashboard-rbac.yaml \nserviceaccount/happycloudlab created\nclusterrolebinding.rbac.authorization.k8s.io/happycloudlab created\n```\n\n# 4 获取token\n\n通过token字段来登陆，token通过base64加密,这里的happycloudlab-token-*须通过命令查看，具体是哪一个。\n\n## 4.1 获取具体secret并且提取yaml信息\n\n```shell\n[root@k8smaster influxdb]# kubectl get secret -n kubernetes-dashboard\nNAME                               TYPE                                  DATA   AGE\ndefault-token-vzxqv                kubernetes.io/service-account-token   3      14m\nhappycloudlab-token-5dxhd          kubernetes.io/service-account-token   3      44s\nkubernetes-dashboard-certs         Opaque                                0      14m\nkubernetes-dashboard-csrf          Opaque                                1      14m\nkubernetes-dashboard-key-holder    Opaque                                2      14m\nkubernetes-dashboard-token-fqtcx   kubernetes.io/service-account-token   3      14m\n[root@k8smaster influxdb]# kubectl get secrets -n kubernetes-dashboard happycloudlab-token-5dxhd -o yaml\n```\n\n![1630834989795](.\\k8s dashboard\\1630834989795.png)\n\n## 4.2 通过echo获取base64编码token\n\n```shell\n[root@k8smaster influxdb]# echo 'ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklrWmtSVE5UYVhOT2RrUlFWRU5vV2xOeE5FSkJjMGQxTURkM2JETkJOa2Q2TFZaNVdWbzFhV3hOV0ZFaWZRLmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbGNtNWxkR1Z6TFdSaGMyaGliMkZ5WkNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKb1lYQndlV05zYjNWa2JHRmlMWFJ2YTJWdUxUVmtlR2hrSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW1oaGNIQjVZMnh2ZFdSc1lXSWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzUxYVdRaU9pSm1NemM1TkdOak5TMHhNMk5pTFRRMVpEQXRPRFJpWWkxaU5UVmtNRFF3TkdVMU9Ea2lMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2YTNWaVpYSnVaWFJsY3kxa1lYTm9ZbTloY21RNmFHRndjSGxqYkc5MVpHeGhZaUo5LkpBZVFBRS1CT1RGZDhXOGp3cEFpa0lTQlF4N2N6bmhySmZneDFxLXA5OTRLSUI5aXRfeFZ3bUlEaEI4bVlZQTJQLXRBNWp4d2d6NDZHamdSZTlfc1dYdFRrTHYwT3dpYmtNeDU3Q0RFVzkxV09CNzkyeTZiOWNWX1BhV3hPVkRyZFFvSVo3S3A0OVFITFNkN1lhREl1eE15UDlzX3pQaTI3dmc0YUZwLUFLS1ZWV0NqcDFvaURFM213Y3FJd2xha3JySW5ZUmg0THNKTFc5TTBVc3BCRklZUFhGNEh5QWxvX2NGX29qNVlHMUFJWUJGTGtlQUZyaEYwalFzQmhseHVYVVRubC01TmN2WjlDRXJJbGJ4VEpfMWtLcVc2UjBwOXFsZ1dpZzFPamhFNzg4NWs0dnVzeDM5S004d2U1ZHBJbjV6WDdIMzBFSjgwOGRpOGVyTFFQUQ==' | base64 -d\n```\n\n得到结果：\n\n```\neyJhbGciOiJSUzI1NiIsImtpZCI6IkZkRTNTaXNOdkRQVENoWlNxNEJBc0d1MDd3bDNBNkd6LVZ5WVo1aWxNWFEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJoYXBweWNsb3VkbGFiLXRva2VuLTVkeGhkIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImhhcHB5Y2xvdWRsYWIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJmMzc5NGNjNS0xM2NiLTQ1ZDAtODRiYi1iNTVkMDQwNGU1ODkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6aGFwcHljbG91ZGxhYiJ9.JAeQAE-BOTFd8W8jwpAikISBQx7cznhrJfgx1q-p994KIB9it_xVwmIDhB8mYYA2P-tA5jxwgz46GjgRe9_sWXtTkLv0OwibkMx57CDEW91WOB792y6b9cV_PaWxOVDrdQoIZ7Kp49QHLSd7YaDIuxMyP9s_zPi27vg4aFp-AKKVVWCjp1oiDE3mwcqIwlakrrInYRh4LsJLW9M0UspBFIYPXF4HyAlo_cF_oj5YG1AIYBFLkeAFrhF0jQsBhlxuXUTnl-5NcvZ9CErIlbxTJ_1kKqW6R0p9qlgWig1OjhE7885k4vusx39KM8we5dpIn5zX7H30EJ808di8erLQPQ\n```\n\n# 5 登录dashboard\n\n获取外网访问端口\n\n```\n[root@k8smaster influxdb]# kubectl get svc -n kubernetes-dashboard\nNAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE\ndashboard-metrics-scraper   ClusterIP   10.104.64.108   <none>        8000/TCP        10m\nkubernetes-dashboard        NodePort    10.102.42.206   <none>        443:30367/TCP   10m\n```\n\n填写token并登录\n\n![1630835361904](.\\k8s dashboard\\1630835361904.png)\n\n![1630835709026](.\\1630835709026.png)","slug":"k8s dashboard","published":1,"updated":"2022-09-23T17:02:35.624Z","_id":"cl8eqccz80000d4vjd3w15j4r","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"1-dashboard安装\"><a href=\"#1-dashboard安装\" class=\"headerlink\" title=\"1 dashboard安装\"></a>1 dashboard安装</h1><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml</span><br></code></pre></td></tr></table></figure>\n\n<p>结果：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">namespace/kubernetes-dashboard created  # 命名空间kubernetes-dashboard<br>serviceaccount/kubernetes-dashboard created # 服务账号kubernetes-dashboard<br>service/kubernetes-dashboard created # 服务kubernetes-dashboard<br>secret/kubernetes-dashboard-certs created #  secret创建<br>secret/kubernetes-dashboard-csrf created<br>secret/kubernetes-dashboard-key-holder created <br>configmap/kubernetes-dashboard-settings created # 配置<br>role.rbac.authorization.k8s.io/kubernetes-dashboard created # 角色和角色绑定<br>clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard configured<br>rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created<br>clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard unchanged<br>deployment.apps/kubernetes-dashboard created<br>service/dashboard-metrics-scraper created<br>deployment.apps/dashboard-metrics-scraper created<br></code></pre></td></tr></table></figure>\n\n<p>查看校验资源的安装情况</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl get deployments -n kubernetes-dashboard</span><br><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl get services -n kubernetes-dashboard</span><br><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl get pods -n kubernetes-dashboard</span><br><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl get secrets -n kubernetes-dashboard</span><br><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl get configMap -n kubernetes-dashboard</span><br><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl  get services -n kubernetes-dashboard</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"2-开放外部访问端口\"><a href=\"#2-开放外部访问端口\" class=\"headerlink\" title=\"2 开放外部访问端口\"></a>2 开放外部访问端口</h1><p>kubernetes-dashbaord安装完毕后，kubernetes-dashboard默认service的类型为ClusterIP，为了从外部访问控制面板，开放为NodePort类型</p>\n<p>过程：编辑之前——编辑——编辑之后</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[root@k8smaster influxdb]# kubectl get svc -n kubernetes-dashboard<br>NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE<br>dashboard-metrics-scraper   ClusterIP   10.104.64.108   &lt;none&gt;        8000/TCP   2m33s<br>kubernetes-dashboard        ClusterIP   10.102.42.206   &lt;none&gt;        443/TCP    2m33s<br>[root@k8smaster influxdb]# kubectl edit svc/kubernetes-dashboard -n kubernetes-dashboard<br>service/kubernetes-dashboard edited<br>[root@k8smaster influxdb]# kubectl get svc -n kubernetes-dashboard<br>NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE<br>dashboard-metrics-scraper   ClusterIP   10.104.64.108   &lt;none&gt;        8000/TCP        10m<br>kubernetes-dashboard        NodePort    10.102.42.206   &lt;none&gt;        443:30367/TCP   10m<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"3-授权用户访问集群\"><a href=\"#3-授权用户访问集群\" class=\"headerlink\" title=\"3 授权用户访问集群\"></a>3 授权用户访问集群</h1><p>dashboard-rbac.yaml定义</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">ServiceAccount</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">happycloudlab</span> <br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">kubernetes-dashboard</span><br><span class=\"hljs-meta\">---</span><br><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">rbac.authorization.k8s.io/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">ClusterRoleBinding</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">happycloudlab</span><br><span class=\"hljs-attr\">roleRef:</span><br>  <span class=\"hljs-attr\">apiGroup:</span> <span class=\"hljs-string\">rbac.authorization.k8s.io</span><br>  <span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">ClusterRole</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">cluster-admin</span><br><span class=\"hljs-attr\">subjects:</span><br><span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">ServiceAccount</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">happycloudlab</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">kubernetes-dashboard</span><br></code></pre></td></tr></table></figure>\n\n<p>操作：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[root@k8smaster influxdb]# vi dashboard-rbac.yaml<br>[root@k8smaster influxdb]# kubectl create -f dashboard-rbac.yaml <br>serviceaccount/happycloudlab created<br>clusterrolebinding.rbac.authorization.k8s.io/happycloudlab created<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"4-获取token\"><a href=\"#4-获取token\" class=\"headerlink\" title=\"4 获取token\"></a>4 获取token</h1><p>通过token字段来登陆，token通过base64加密,这里的happycloudlab-token-*须通过命令查看，具体是哪一个。</p>\n<h2 id=\"4-1-获取具体secret并且提取yaml信息\"><a href=\"#4-1-获取具体secret并且提取yaml信息\" class=\"headerlink\" title=\"4.1 获取具体secret并且提取yaml信息\"></a>4.1 获取具体secret并且提取yaml信息</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[root@k8smaster influxdb]# kubectl get secret -n kubernetes-dashboard<br>NAME                               TYPE                                  DATA   AGE<br>default-token-vzxqv                kubernetes.io/service-account-token   3      14m<br>happycloudlab-token-5dxhd          kubernetes.io/service-account-token   3      44s<br>kubernetes-dashboard-certs         Opaque                                0      14m<br>kubernetes-dashboard-csrf          Opaque                                1      14m<br>kubernetes-dashboard-key-holder    Opaque                                2      14m<br>kubernetes-dashboard-token-fqtcx   kubernetes.io/service-account-token   3      14m<br>[root@k8smaster influxdb]# kubectl get secrets -n kubernetes-dashboard happycloudlab-token-5dxhd -o yaml<br></code></pre></td></tr></table></figure>\n\n<p>![1630834989795](.\\k8s dashboard\\1630834989795.png)</p>\n<h2 id=\"4-2-通过echo获取base64编码token\"><a href=\"#4-2-通过echo获取base64编码token\" class=\"headerlink\" title=\"4.2 通过echo获取base64编码token\"></a>4.2 通过echo获取base64编码token</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[root@k8smaster influxdb]# echo &#x27;ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklrWmtSVE5UYVhOT2RrUlFWRU5vV2xOeE5FSkJjMGQxTURkM2JETkJOa2Q2TFZaNVdWbzFhV3hOV0ZFaWZRLmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbGNtNWxkR1Z6TFdSaGMyaGliMkZ5WkNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKb1lYQndlV05zYjNWa2JHRmlMWFJ2YTJWdUxUVmtlR2hrSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW1oaGNIQjVZMnh2ZFdSc1lXSWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzUxYVdRaU9pSm1NemM1TkdOak5TMHhNMk5pTFRRMVpEQXRPRFJpWWkxaU5UVmtNRFF3TkdVMU9Ea2lMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2YTNWaVpYSnVaWFJsY3kxa1lYTm9ZbTloY21RNmFHRndjSGxqYkc5MVpHeGhZaUo5LkpBZVFBRS1CT1RGZDhXOGp3cEFpa0lTQlF4N2N6bmhySmZneDFxLXA5OTRLSUI5aXRfeFZ3bUlEaEI4bVlZQTJQLXRBNWp4d2d6NDZHamdSZTlfc1dYdFRrTHYwT3dpYmtNeDU3Q0RFVzkxV09CNzkyeTZiOWNWX1BhV3hPVkRyZFFvSVo3S3A0OVFITFNkN1lhREl1eE15UDlzX3pQaTI3dmc0YUZwLUFLS1ZWV0NqcDFvaURFM213Y3FJd2xha3JySW5ZUmg0THNKTFc5TTBVc3BCRklZUFhGNEh5QWxvX2NGX29qNVlHMUFJWUJGTGtlQUZyaEYwalFzQmhseHVYVVRubC01TmN2WjlDRXJJbGJ4VEpfMWtLcVc2UjBwOXFsZ1dpZzFPamhFNzg4NWs0dnVzeDM5S004d2U1ZHBJbjV6WDdIMzBFSjgwOGRpOGVyTFFQUQ==&#x27; | base64 -d<br></code></pre></td></tr></table></figure>\n\n<p>得到结果：</p>\n<figure class=\"highlight smali\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs smali\">eyJhbGciOiJSUzI1NiIsImtpZCI6IkZkRTNTaXNOdkRQVENoWlNxNEJBc0d1MDd3bDNBNkd6LVZ5WVo1aWxNWFEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJoYXBweWNsb3VkbGFiLXRva2VuLTVkeGhkIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImhhcHB5Y2xvdWRsYWIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJmMzc5NGNjNS0xM2NiLTQ1ZDAtODRiYi1iNTVkMDQwNGU1ODkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6aGFwcHljbG91ZGxhYiJ9.JAeQAE-BOTFd8W8jwpAikISBQx7cznhrJfgx1q-p994KIB9it_xVwmIDhB8mYYA2P-tA5jxwgz46GjgRe9_sWXtTkLv0OwibkMx57CDEW91WOB792y6b9cV_PaWxOVDrdQoIZ7Kp49QHLSd7YaDIuxMyP9s_zPi27vg4aFp-AKKVVWCjp1oiDE3mwcqIwlakrrInYRh4LsJLW9M0UspBFIYPXF4HyAlo_cF_oj5YG1AIYBFLkeAFrhF0jQsBhlxuXUTnl-5NcvZ9CErIlbxTJ_1kKqW6R0p9qlgWig1OjhE7885k4vusx39KM8we5dpIn5zX7H30EJ808di8erLQPQ<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"5-登录dashboard\"><a href=\"#5-登录dashboard\" class=\"headerlink\" title=\"5 登录dashboard\"></a>5 登录dashboard</h1><p>获取外网访问端口</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">[root@k8smaster influxdb]# kubectl <span class=\"hljs-keyword\">get</span> svc -n kubernetes-dashboard<br><span class=\"hljs-type\">NAME</span>                        <span class=\"hljs-keyword\">TYPE</span>        <span class=\"hljs-keyword\">CLUSTER</span>-IP      <span class=\"hljs-keyword\">EXTERNAL</span>-IP   PORT(S)         AGE<br>dashboard-metrics-scraper   ClusterIP   <span class=\"hljs-number\">10.104</span><span class=\"hljs-number\">.64</span><span class=\"hljs-number\">.108</span>   &lt;<span class=\"hljs-keyword\">none</span>&gt;        <span class=\"hljs-number\">8000</span>/TCP        <span class=\"hljs-number\">10</span>m<br>kubernetes-dashboard        NodePort    <span class=\"hljs-number\">10.102</span><span class=\"hljs-number\">.42</span><span class=\"hljs-number\">.206</span>   &lt;<span class=\"hljs-keyword\">none</span>&gt;        <span class=\"hljs-number\">443</span>:<span class=\"hljs-number\">30367</span>/TCP   <span class=\"hljs-number\">10</span>m<br></code></pre></td></tr></table></figure>\n\n<p>填写token并登录</p>\n<p>![1630835361904](.\\k8s dashboard\\1630835361904.png)</p>\n<p><img src=\".%5C1630835709026.png\" alt=\"1630835709026\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-dashboard安装\"><a href=\"#1-dashboard安装\" class=\"headerlink\" title=\"1 dashboard安装\"></a>1 dashboard安装</h1><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml</span><br></code></pre></td></tr></table></figure>\n\n<p>结果：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">namespace/kubernetes-dashboard created  # 命名空间kubernetes-dashboard<br>serviceaccount/kubernetes-dashboard created # 服务账号kubernetes-dashboard<br>service/kubernetes-dashboard created # 服务kubernetes-dashboard<br>secret/kubernetes-dashboard-certs created #  secret创建<br>secret/kubernetes-dashboard-csrf created<br>secret/kubernetes-dashboard-key-holder created <br>configmap/kubernetes-dashboard-settings created # 配置<br>role.rbac.authorization.k8s.io/kubernetes-dashboard created # 角色和角色绑定<br>clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard configured<br>rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created<br>clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard unchanged<br>deployment.apps/kubernetes-dashboard created<br>service/dashboard-metrics-scraper created<br>deployment.apps/dashboard-metrics-scraper created<br></code></pre></td></tr></table></figure>\n\n<p>查看校验资源的安装情况</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl get deployments -n kubernetes-dashboard</span><br><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl get services -n kubernetes-dashboard</span><br><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl get pods -n kubernetes-dashboard</span><br><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl get secrets -n kubernetes-dashboard</span><br><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl get configMap -n kubernetes-dashboard</span><br><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl  get services -n kubernetes-dashboard</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"2-开放外部访问端口\"><a href=\"#2-开放外部访问端口\" class=\"headerlink\" title=\"2 开放外部访问端口\"></a>2 开放外部访问端口</h1><p>kubernetes-dashbaord安装完毕后，kubernetes-dashboard默认service的类型为ClusterIP，为了从外部访问控制面板，开放为NodePort类型</p>\n<p>过程：编辑之前——编辑——编辑之后</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[root@k8smaster influxdb]# kubectl get svc -n kubernetes-dashboard<br>NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE<br>dashboard-metrics-scraper   ClusterIP   10.104.64.108   &lt;none&gt;        8000/TCP   2m33s<br>kubernetes-dashboard        ClusterIP   10.102.42.206   &lt;none&gt;        443/TCP    2m33s<br>[root@k8smaster influxdb]# kubectl edit svc/kubernetes-dashboard -n kubernetes-dashboard<br>service/kubernetes-dashboard edited<br>[root@k8smaster influxdb]# kubectl get svc -n kubernetes-dashboard<br>NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE<br>dashboard-metrics-scraper   ClusterIP   10.104.64.108   &lt;none&gt;        8000/TCP        10m<br>kubernetes-dashboard        NodePort    10.102.42.206   &lt;none&gt;        443:30367/TCP   10m<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"3-授权用户访问集群\"><a href=\"#3-授权用户访问集群\" class=\"headerlink\" title=\"3 授权用户访问集群\"></a>3 授权用户访问集群</h1><p>dashboard-rbac.yaml定义</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">ServiceAccount</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">happycloudlab</span> <br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">kubernetes-dashboard</span><br><span class=\"hljs-meta\">---</span><br><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">rbac.authorization.k8s.io/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">ClusterRoleBinding</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">happycloudlab</span><br><span class=\"hljs-attr\">roleRef:</span><br>  <span class=\"hljs-attr\">apiGroup:</span> <span class=\"hljs-string\">rbac.authorization.k8s.io</span><br>  <span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">ClusterRole</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">cluster-admin</span><br><span class=\"hljs-attr\">subjects:</span><br><span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">ServiceAccount</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">happycloudlab</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">kubernetes-dashboard</span><br></code></pre></td></tr></table></figure>\n\n<p>操作：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[root@k8smaster influxdb]# vi dashboard-rbac.yaml<br>[root@k8smaster influxdb]# kubectl create -f dashboard-rbac.yaml <br>serviceaccount/happycloudlab created<br>clusterrolebinding.rbac.authorization.k8s.io/happycloudlab created<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"4-获取token\"><a href=\"#4-获取token\" class=\"headerlink\" title=\"4 获取token\"></a>4 获取token</h1><p>通过token字段来登陆，token通过base64加密,这里的happycloudlab-token-*须通过命令查看，具体是哪一个。</p>\n<h2 id=\"4-1-获取具体secret并且提取yaml信息\"><a href=\"#4-1-获取具体secret并且提取yaml信息\" class=\"headerlink\" title=\"4.1 获取具体secret并且提取yaml信息\"></a>4.1 获取具体secret并且提取yaml信息</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[root@k8smaster influxdb]# kubectl get secret -n kubernetes-dashboard<br>NAME                               TYPE                                  DATA   AGE<br>default-token-vzxqv                kubernetes.io/service-account-token   3      14m<br>happycloudlab-token-5dxhd          kubernetes.io/service-account-token   3      44s<br>kubernetes-dashboard-certs         Opaque                                0      14m<br>kubernetes-dashboard-csrf          Opaque                                1      14m<br>kubernetes-dashboard-key-holder    Opaque                                2      14m<br>kubernetes-dashboard-token-fqtcx   kubernetes.io/service-account-token   3      14m<br>[root@k8smaster influxdb]# kubectl get secrets -n kubernetes-dashboard happycloudlab-token-5dxhd -o yaml<br></code></pre></td></tr></table></figure>\n\n<p>![1630834989795](.\\k8s dashboard\\1630834989795.png)</p>\n<h2 id=\"4-2-通过echo获取base64编码token\"><a href=\"#4-2-通过echo获取base64编码token\" class=\"headerlink\" title=\"4.2 通过echo获取base64编码token\"></a>4.2 通过echo获取base64编码token</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[root@k8smaster influxdb]# echo &#x27;ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklrWmtSVE5UYVhOT2RrUlFWRU5vV2xOeE5FSkJjMGQxTURkM2JETkJOa2Q2TFZaNVdWbzFhV3hOV0ZFaWZRLmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUpyZFdKbGNtNWxkR1Z6TFdSaGMyaGliMkZ5WkNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZqY21WMExtNWhiV1VpT2lKb1lYQndlV05zYjNWa2JHRmlMWFJ2YTJWdUxUVmtlR2hrSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW1oaGNIQjVZMnh2ZFdSc1lXSWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzUxYVdRaU9pSm1NemM1TkdOak5TMHhNMk5pTFRRMVpEQXRPRFJpWWkxaU5UVmtNRFF3TkdVMU9Ea2lMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2YTNWaVpYSnVaWFJsY3kxa1lYTm9ZbTloY21RNmFHRndjSGxqYkc5MVpHeGhZaUo5LkpBZVFBRS1CT1RGZDhXOGp3cEFpa0lTQlF4N2N6bmhySmZneDFxLXA5OTRLSUI5aXRfeFZ3bUlEaEI4bVlZQTJQLXRBNWp4d2d6NDZHamdSZTlfc1dYdFRrTHYwT3dpYmtNeDU3Q0RFVzkxV09CNzkyeTZiOWNWX1BhV3hPVkRyZFFvSVo3S3A0OVFITFNkN1lhREl1eE15UDlzX3pQaTI3dmc0YUZwLUFLS1ZWV0NqcDFvaURFM213Y3FJd2xha3JySW5ZUmg0THNKTFc5TTBVc3BCRklZUFhGNEh5QWxvX2NGX29qNVlHMUFJWUJGTGtlQUZyaEYwalFzQmhseHVYVVRubC01TmN2WjlDRXJJbGJ4VEpfMWtLcVc2UjBwOXFsZ1dpZzFPamhFNzg4NWs0dnVzeDM5S004d2U1ZHBJbjV6WDdIMzBFSjgwOGRpOGVyTFFQUQ==&#x27; | base64 -d<br></code></pre></td></tr></table></figure>\n\n<p>得到结果：</p>\n<figure class=\"highlight smali\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs smali\">eyJhbGciOiJSUzI1NiIsImtpZCI6IkZkRTNTaXNOdkRQVENoWlNxNEJBc0d1MDd3bDNBNkd6LVZ5WVo1aWxNWFEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJoYXBweWNsb3VkbGFiLXRva2VuLTVkeGhkIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImhhcHB5Y2xvdWRsYWIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJmMzc5NGNjNS0xM2NiLTQ1ZDAtODRiYi1iNTVkMDQwNGU1ODkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6aGFwcHljbG91ZGxhYiJ9.JAeQAE-BOTFd8W8jwpAikISBQx7cznhrJfgx1q-p994KIB9it_xVwmIDhB8mYYA2P-tA5jxwgz46GjgRe9_sWXtTkLv0OwibkMx57CDEW91WOB792y6b9cV_PaWxOVDrdQoIZ7Kp49QHLSd7YaDIuxMyP9s_zPi27vg4aFp-AKKVVWCjp1oiDE3mwcqIwlakrrInYRh4LsJLW9M0UspBFIYPXF4HyAlo_cF_oj5YG1AIYBFLkeAFrhF0jQsBhlxuXUTnl-5NcvZ9CErIlbxTJ_1kKqW6R0p9qlgWig1OjhE7885k4vusx39KM8we5dpIn5zX7H30EJ808di8erLQPQ<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"5-登录dashboard\"><a href=\"#5-登录dashboard\" class=\"headerlink\" title=\"5 登录dashboard\"></a>5 登录dashboard</h1><p>获取外网访问端口</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">[root@k8smaster influxdb]# kubectl <span class=\"hljs-keyword\">get</span> svc -n kubernetes-dashboard<br><span class=\"hljs-type\">NAME</span>                        <span class=\"hljs-keyword\">TYPE</span>        <span class=\"hljs-keyword\">CLUSTER</span>-IP      <span class=\"hljs-keyword\">EXTERNAL</span>-IP   PORT(S)         AGE<br>dashboard-metrics-scraper   ClusterIP   <span class=\"hljs-number\">10.104</span><span class=\"hljs-number\">.64</span><span class=\"hljs-number\">.108</span>   &lt;<span class=\"hljs-keyword\">none</span>&gt;        <span class=\"hljs-number\">8000</span>/TCP        <span class=\"hljs-number\">10</span>m<br>kubernetes-dashboard        NodePort    <span class=\"hljs-number\">10.102</span><span class=\"hljs-number\">.42</span><span class=\"hljs-number\">.206</span>   &lt;<span class=\"hljs-keyword\">none</span>&gt;        <span class=\"hljs-number\">443</span>:<span class=\"hljs-number\">30367</span>/TCP   <span class=\"hljs-number\">10</span>m<br></code></pre></td></tr></table></figure>\n\n<p>填写token并登录</p>\n<p>![1630835361904](.\\k8s dashboard\\1630835361904.png)</p>\n<p><img src=\".%5C1630835709026.png\" alt=\"1630835709026\"></p>\n"},{"title":"kubernetes调度器scheduler","date":"2021-08-04T10:11:02.000Z","_content":"\n# kubeadm快速部署kubernetes集群\n\n# 1 安装要求\n\n- 一台或多台机器，操作系统 CentOS7.x-86_x64\n- 硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多(master必须2cpu,node可以不用)\n- 可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点\n- 禁止swap分区\n\n[安装 kubeadm | Kubernetes](https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)\n\n# 2 准备环境\n\n| 角色   | IP            |\n| ------ | ------------- |\n| master | 192.168.66.11 |\n| node1  | 192.168.66.21 |\n| node2  | 192.168.66.22 |\n\n```\nyum update -y\nyum install -y firewalld ntpdate net-tools ipvsadm wget\n```\n\n## 2.1 关闭防火墙及selinux\n\n所有节点执行一下命令\n\n```\n# 关闭防火墙\nsystemctl stop firewalld\nsystemctl disable firewalld\n\n# 关闭selinux\n# 永久\nsed -i 's/enforcing/disabled/' /etc/selinux/config  \n# 临时\nsetenforce 0  \n```\n\n## 2.2 关闭swap\n\n所有节点执行一下命令\n\n```\n# 关闭swap\n# 临时\nswapoff -a  \n# 永久\nsed -ri 's/.*swap.*/#&/' /etc/fstab    \n```\n\n## 2.3 根据规划设置主机名及hosts\n\n所有节点执行hostnamectl set-hostname <hostname>命令\n\n```\n# k8smaster节点执行\nhostnamectl set-hostname k8s-master01\n# k8snode1节点执行\nhostnamectl set-hostname k8s-node01\n# k8snode2节点执行\nhostnamectl set-hostname k8s-node02\n```\n\nk8smaster主节点执行\n\n```\ncat >> /etc/hosts << EOF\n192.168.66.11 k8s-master01\n192.168.66.21 k8s-node01\n192.168.66.22 k8s-node02\nEOF\n```\n\n## 2.4 将桥接的IPv4流量传递到iptables的链\n\n确保 `br_netfilter` 模块被加载。这一操作可以通过运行 `lsmod | grep br_netfilter` 来完成。若要显式加载该模块，可执行 `sudo modprobe br_netfilter`。 \n\n确保在你的 `sysctl` 配置中将 `net.bridge.bridge-nf-call-iptables` 设置为 1。 \n\n```\ncat <<EOF | sudo tee /etc/modules-load.d/k8s.conf\nbr_netfilter\nEOF\n\n#将桥接的IPv4流量传递到iptables的链\ncat > /etc/sysctl.d/k8s.conf << EOF\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nEOF\n# 生效\nsysctl --system  \n```\n\n## 2.5 时间同步\n\n所有节点执行一下命令\n\n```\nyum install ntpdate -y\nntpdate time.windows.com\n# 强制把系统时间写入CMOS\nclock -w\n```\n\n# 3 所有节点安装Docker/kubeadm/kubelet\n\n## 3.1 安装Docker\n\nk8snode1和k8snode2下安装docker\n\n```\nwget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo\nyum -y install docker-ce-18.06.1.ce-3.el7\nsystemctl enable docker && systemctl start docker\ndocker --version\n```\n\n## 3.2 配置docker镜像加速\n\n![img](kubeadm快速部署kubernetes集群/1629031322356.png)\n\n```\ncat > /etc/docker/daemon.json << EOF\n{\n  \"registry-mirrors\": [\"https://onozxvpe.mirror.aliyuncs.com\",\"http://hub-mirror.c.163.com\", \"https://registry.docker-cn.com\"],\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"]\n}\nEOF\n```\n\n添加镜像加入和本地搭建harbor后：\n\n```\n{\n  \"registry-mirrors\": [\"https://onozxvpe.mirror.aliyuncs.com\"],\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"],\n  \"insecure-registries\": [\"harborcloud.com\"]\n}\n```\n\n\n\n## 3.3 添加阿里云YUM软件源\n\n```\ncat > /etc/yum.repos.d/kubernetes.repo << EOF\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=0\nrepo_gpgcheck=0\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n```\n\n## 3.4 安装kubeadm，kubelet和kubectl\n\n```\nyum install -y kubeadm-1.22.0 kubectl-1.22.0 kubelet-1.22.0\nsystemctl enable kubelet\n```\n\n# 4 部署Kubernetes Master\n\nhttps://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/kubeadm-init/\n\n在192.168.66.10（k8smaster）执行。\n\n由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址\n\n**–pod-network-cidr**\n\n指定pod网络的IP地址范围。 设置后，控制平面将自动为每个节点分配cidr。\n\n**–service-cidr**\n\n集群内部虚拟网络，Pod统一访问入口\n\n```\nkubeadm init \\\n--apiserver-advertise-address=192.168.66.10 \\\n--image-repository registry.aliyuncs.com/google_containers \\\n--kubernetes-version v1.22.0 \\\n--service-cidr=10.96.0.0/12 \\\n--pod-network-cidr=10.244.0.0/16\n```\n\n执行结果\n\n```\n[init] Using Kubernetes version: v1.22.0\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [k8s-master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.66.11]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [k8s-master01 localhost] and IPs [192.168.66.11 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [k8s-master01 localhost] and IPs [192.168.66.11 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Starting the kubelet\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 12.003757 seconds\n[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.22\" in namespace kube-system with the configuration for the kubelets in the cluster\n[upload-certs] Skipping phase. Please see --upload-certs\n[mark-control-plane] Marking the node k8s-master01 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]\n[mark-control-plane] Marking the node k8s-master01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[bootstrap-token] Using token: ii3pse.bfxj9fqc9tvz6yrr\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.66.11:6443 --token ii3pse.bfxj9fqc9tvz6yrr \\\n        --discovery-token-ca-cert-hash sha256:643b48706d97589356e2a4be7294a898ac9a909baa56fecca277b7b4e5634e0e \n```\n\n- preflight，系统前置检查\n- certs 各种证书的文件生成\n- kubeconfig生成kubeconfig文件，主要是kubenetes的几大组件的配置文件。\n- kubelet-start 启动kubelet\n- control-plane 生成所有静态pod的manifest文件，这些静态pod组成了kubenetes的控制面板，apiserver，controller，scheduler，生成这个文件后，kubelet会自动依据此文件描述的信息拉起镜像\n- etcd 生成etcd的manifest\n- upload-config 上传kubeadm和kubelet的配置文件到configmap中\n- upload-certs 上传配置证书文件\n- mark-control-plane mark一个node作为控制台\n- bootstrap-token 生成bootstrap tokens用于把node节点加入到集群。\n- kubelet-finalize 更新kubelet的设置\n- addon 安装其他的相关组件。主要是网络组件dns和kube-proxy\n\n所有node执行：\n\n注：`kubectl` 在 `$HOME/.kube` 目录中查找一个名为 `config` 的配置文件。 你可以通过设置 KUBECONFIG 环境变量或设置 [`--kubeconfig`](https://kubernetes.io/zh/docs/concepts/configuration/organize-cluster-access-kubeconfig/) 参数来指定其它 [kubeconfig](https://kubernetes.io/zh/docs/concepts/configuration/organize-cluster-access-kubeconfig/) 文件。\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n$ kubectl get nodes\n```\n\n如果出现错误通过一下命令重置\n\n```\nkubeadm reset\n```\n\n# 5 加入Kubernetes Node\n\n执行上面kubeadm init后显示的信息提示，加入kubernates\n\n```\nkubeadm join 192.168.66.11:6443 --token ii3pse.bfxj9fqc9tvz6yrr \\\n        --discovery-token-ca-cert-hash sha256:643b48706d97589356e2a4be7294a898ac9a909baa56fecca277b7b4e5634e0e\n```\n\n默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，操作如下：\n\n```\nkubeadm token create --print-join-command\n```\n\n# 6 部署CNI网络插件\n\n![img](kubeadm快速部署kubernetes集群/image-25.png)\n\n这里可能需要代理下载，可以先下载下来\n\n```\n$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n$ kubectl get pods -n kube-system\nNAME                          READY   STATUS    RESTARTS   AGE\nkube-flannel-ds-amd64-2pc95   1/1     Running   0          72s\n```\n\n![img](kubeadm快速部署kubernetes集群/image-26.png)\n\n**Flannel工作原理**\n\nk8s网络通讯方式：[k8s网络通讯方式 – 青叶水间 (youhang.site)](http://jishu.youhang.site/25.html)\n\n每个主机配置一个ip段和子网个数。 例如，可以配置一个覆盖网络使用 10.244.0.0/16段，每个主机/24个子网。因此主机a可以接受10.244.1.0/24，主机B可以接受10.244.2.0/24的包。flannel使用etcd来维护分配的子网到实际的ip地址之间的映射。\n\nmaster IP信息：\n\n```\n[root@k8s-master01 ~]# ip addr\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: eno16777736: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 00:0c:29:6b:de:b6 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.66.11/24 brd 10.0.0.255 scope global noprefixroute eno16777736\n       valid_lft forever preferred_lft forever\n    inet6 fd56:a9ae:cb0f::a49/128 scope global noprefixroute dynamic \n       valid_lft 29570sec preferred_lft 29570sec\n    inet6 fd56:a9ae:cb0f:0:20c:29ff:fe6b:deb6/64 scope global noprefixroute \n       valid_lft forever preferred_lft forever\n    inet6 fe80::20c:29ff:fe6b:deb6/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n    link/ether 02:42:f0:df:d5:af brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n4: flannel.1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default \n    link/ether 8e:53:a8:6d:99:1e brd ff:ff:ff:ff:ff:ff\n    inet 10.244.0.0/32 scope global flannel.1\n       valid_lft forever preferred_lft forever\n    inet6 fe80::8c53:a8ff:fe6d:991e/64 scope link \n       valid_lft forever preferred_lft forever\n5: cni0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000\n    link/ether 7a:33:a2:1a:15:65 brd ff:ff:ff:ff:ff:ff\n    inet 10.244.0.1/24 brd 10.244.0.255 scope global cni0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::7833:a2ff:fe1a:1565/64 scope link \n       valid_lft forever preferred_lft forever\n6: vethefc85590@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue master cni0 state UP group default \n    link/ether 5a:3e:58:6a:8c:d2 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet6 fe80::583e:58ff:fe6a:8cd2/64 scope link \n       valid_lft forever preferred_lft forever\n7: veth991a2bde@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue master cni0 state UP group default \n    link/ether fe:6f:eb:91:71:71 brd ff:ff:ff:ff:ff:ff link-netnsid 1\n    inet6 fe80::fc6f:ebff:fe91:7171/64 scope link \n       valid_lft forever preferred_lft forever\n```\n\n**lo**\n\n本地环回接口\n\n**eno16777736**\n\n真实网卡\n\n**docker0**\n\ndocker ip信息，默认IP 172.17.0.1/16\n\n可修改 /etc/docker/daemon.json, 指定ip地址，例如：\n\n```\nvi /etc/docker/daemon.json\n{\n \"bip\": \"172.18.0.1/24\",\n}\nservice docker restart\n```\n\n**flannel.1**\n\ndocker集群跨主机通讯的覆盖网络 10.244.0.0/32\n\n**cni0**\n\npod分配 网络 10.244.0.1/24\n\nnode1 IP信息：\n\n```\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: eno16777736: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 00:0c:29:1a:1c:d4 brd ff:ff:ff:ff:ff:ff\n    inet 10.0.0.21/24 brd 10.0.0.255 scope global noprefixroute eno16777736\n       valid_lft forever preferred_lft forever\n    inet6 fd56:a9ae:cb0f::7a1/128 scope global noprefixroute dynamic \n       valid_lft 29510sec preferred_lft 29510sec\n    inet6 fd56:a9ae:cb0f:0:20c:29ff:fe1a:1cd4/64 scope global noprefixroute \n       valid_lft forever preferred_lft forever\n    inet6 fe80::20c:29ff:fe1a:1cd4/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n    link/ether 02:42:b8:ae:c9:24 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n4: flannel.1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default \n    link/ether 1e:6d:47:69:f7:6a brd ff:ff:ff:ff:ff:ff\n    inet 10.244.1.0/32 scope global flannel.1\n       valid_lft forever preferred_lft forever\n    inet6 fe80::1c6d:47ff:fe69:f76a/64 scope link \n       valid_lft forever preferred_lft forever\n```\n\nnode2 IP信息\n\n```\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: eno16777736: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 00:0c:29:67:c3:4a brd ff:ff:ff:ff:ff:ff\n    inet 10.0.0.22/24 brd 10.0.0.255 scope global noprefixroute eno16777736\n       valid_lft forever preferred_lft forever\n    inet6 fd56:a9ae:cb0f::853/128 scope global noprefixroute dynamic \n       valid_lft 29262sec preferred_lft 29262sec\n    inet6 fd56:a9ae:cb0f:0:20c:29ff:fe67:c34a/64 scope global noprefixroute \n       valid_lft forever preferred_lft forever\n    inet6 fe80::20c:29ff:fe67:c34a/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n    link/ether 02:42:b2:7e:58:1f brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n4: flannel.1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default \n    link/ether 66:5b:e2:87:5c:22 brd ff:ff:ff:ff:ff:ff\n    inet 10.244.2.0/32 scope global flannel.1\n       valid_lft forever preferred_lft forever\n    inet6 fe80::645b:e2ff:fe87:5c22/64 scope link \n       valid_lft forever preferred_lft forever\n```\n\n7 测试kubernetes集群\n\n在Kubernetes集群中创建一个pod，验证是否正常运行：\n\n```\n[root@k8s-master01 ~]# kubectl create deployment nginx --image=nginx\ndeployment.apps/nginx created\n[root@k8s-master01 ~]# kubectl expose deployment nginx --port=80 --type=NodePort\nservice/nginx exposed\n[root@k8s-master01 ~]# kubectl get pod,svc\nNAME                         READY   STATUS              RESTARTS   AGE\npod/nginx-6799fc88d8-zzsw7   0/1     ContainerCreating   0          31s\n\nNAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nservice/kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        24h\nservice/nginx        NodePort    10.103.32.138   <none>        80:30029/TCP   13s\n```\n\n访问地址：[http://NodeIP:Port](http://nodeip:Port/)\n\n可以通过 [http://10.0.0.21:31263](http://10.0.0.21:31263/) 和 [http://10.0.0.22:31263](http://10.0.0.22:31263/) 访问\n\n# 8 **错误排查**\n\n启动日志获取\n\n```\n#查看启动日志\njournalctl -f -u kubelet.service\n```\n\n配置加载与重启服务\n\n```\nsystemctl daemon-reload && systemctl restart kubelet\n```\n\n# 9 ipvs修改\n\n```\nkubectl edit configmap kube-proxy -n kube-system\n...\n43   mode: \"ipvs\"\n   ...\n```\n\n**删除pod,会自动拉起**\n\n```\nkubectl delete pod kube-proxy-btz4p -n kube-system  \n```\n\n**查看是否启用ipvs**\n\n```\nkubectl logs kube-proxy-wwqbh -n kube-system        \n```\n\n**注：**\n\n```\n1、 kube-proxy配置文件以configmap方式存储\n2、 如果让所有节点生效，需要重建所有节点kube-proxy pod\n```\n\n# 10 **问题及解决**\n\n1 failed to find subsystem mount for required subsystem: pids failed to find subsystem mount for required subsystem: pids\n\n解决方法：\n\n```\nvi /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf\n#发现ExecStart=后面添加参数\nExecStart=\"--feature-gates SupportPodPidsLimit=false --feature-gates SupportNodePidsLimit=false\"\n#或者更改引用变量$KUBELET_EXTRA_ARGS\nvi /etc/sysconfig/kubelet\nKUBELET_EXTRA_ARGS=--feature-gates SupportPodPidsLimit=false --feature-gates SupportNodePidsLimit=false\n```\n\n2 kubelet cgroup driver: \\“systemd\\“ is different from docker cgroup driver: \\“cgroupfs\\“\n\ndocker的驱动查看是否有systemd\n\n```\ndocker info |grep Cgroup\n```\n\n解决方案步骤如下：\n\n(1)、先修改docker的Cgroup Driver，修改/etc/docker/daemon.json文件\n\n```\n{\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"]\n}\n```\n\n重启docker\n\n```\nsystemctl daemon-reload\nsystemctl restart docker\n```\n\n(2)、然后修改kubelet的Cgroup Driver\n修改 “/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf ” 文件，增加（或修改成）“–cgroup-driver=systemd” (官方推荐用systemd)\n\n```\nEnvironment=\"KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --cgroup-driver=systemd\"\n```\n\n修改 “/var/lib/kubelet/kubeadm-flags.env ”文件，增加（或修改成）“-–cgroup-driver=systemd”\n\n```\nKUBELET_KUBEADM_ARGS=\"--cgroup-driver=systemd --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.2\"\n```\n\n重启：\n\n```\nsystemctl daemon-reload\nsystemctl restart kubelet\n```\n3 missing required cgroups: cpu\n\n修改`/etc/default/grub`\n\n添加一行`GRUB_CMDLINE_LINUX=\"cgroup_enable=cpu\"`\n\n运行 `update-grub2`\n\n重启机器 `reboot`\n\n4  Failed to start CRI Interface for Docker Application Container Engine Defined-By: systemd\n\n```\n7月 29 20:35:14 k8s-master02 systemd[1]: cri-docker.service: main process exited, code=exited, status=203/EXEC\n7月 29 20:35:14 k8s-master02 systemd[1]: Failed to start CRI Interface for Docker Application Container Engine.\n-- Subject: Unit cri-docker.service has failed\n-- Defined-By: systemd\n-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel\n-- \n-- Unit cri-docker.service has failed.\n-- \n-- The result is failed.\n7月 29 20:35:14 k8s-master02 systemd[1]: Unit cri-docker.service entered failed state.\n7月 29 20:35:14 k8s-master02 systemd[1]: cri-docker.service failed.\n```\n\n修改 docker 控制组\n\n```\nvi /etc/docker/daemon.json \n{\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"]\n}\n```\n\n从重启服务\n\n```\nsystemctl daemon-reload\nsystemctl restart docker\nsystemctl restart cri-docker\n```\n\n5  error execution phase preflight: couldn't validate the identity of the API Server: Get \"https://10.0.0.150:16443/api/v1/namespaces/kube-public/configmaps/cluster-info?timeout=10s\": x509: certificate has expired or is not yet valid: current time 2022-07-30T16:12:40+08:00 is before 2022-07-30T13:31:36Z\n\n```\nyum install ntpdate -y\nntpdate time.windows.com\n# 强制把系统时间写入CMOS\nclock -w\n```\n\n","source":"_posts/kubeadm快速部署kubernetes集群.md","raw":"---\ntitle: kubernetes调度器scheduler\ndate: 2021-08-04 18:11:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - 集群部署\n---\n\n# kubeadm快速部署kubernetes集群\n\n# 1 安装要求\n\n- 一台或多台机器，操作系统 CentOS7.x-86_x64\n- 硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多(master必须2cpu,node可以不用)\n- 可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点\n- 禁止swap分区\n\n[安装 kubeadm | Kubernetes](https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)\n\n# 2 准备环境\n\n| 角色   | IP            |\n| ------ | ------------- |\n| master | 192.168.66.11 |\n| node1  | 192.168.66.21 |\n| node2  | 192.168.66.22 |\n\n```\nyum update -y\nyum install -y firewalld ntpdate net-tools ipvsadm wget\n```\n\n## 2.1 关闭防火墙及selinux\n\n所有节点执行一下命令\n\n```\n# 关闭防火墙\nsystemctl stop firewalld\nsystemctl disable firewalld\n\n# 关闭selinux\n# 永久\nsed -i 's/enforcing/disabled/' /etc/selinux/config  \n# 临时\nsetenforce 0  \n```\n\n## 2.2 关闭swap\n\n所有节点执行一下命令\n\n```\n# 关闭swap\n# 临时\nswapoff -a  \n# 永久\nsed -ri 's/.*swap.*/#&/' /etc/fstab    \n```\n\n## 2.3 根据规划设置主机名及hosts\n\n所有节点执行hostnamectl set-hostname <hostname>命令\n\n```\n# k8smaster节点执行\nhostnamectl set-hostname k8s-master01\n# k8snode1节点执行\nhostnamectl set-hostname k8s-node01\n# k8snode2节点执行\nhostnamectl set-hostname k8s-node02\n```\n\nk8smaster主节点执行\n\n```\ncat >> /etc/hosts << EOF\n192.168.66.11 k8s-master01\n192.168.66.21 k8s-node01\n192.168.66.22 k8s-node02\nEOF\n```\n\n## 2.4 将桥接的IPv4流量传递到iptables的链\n\n确保 `br_netfilter` 模块被加载。这一操作可以通过运行 `lsmod | grep br_netfilter` 来完成。若要显式加载该模块，可执行 `sudo modprobe br_netfilter`。 \n\n确保在你的 `sysctl` 配置中将 `net.bridge.bridge-nf-call-iptables` 设置为 1。 \n\n```\ncat <<EOF | sudo tee /etc/modules-load.d/k8s.conf\nbr_netfilter\nEOF\n\n#将桥接的IPv4流量传递到iptables的链\ncat > /etc/sysctl.d/k8s.conf << EOF\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nEOF\n# 生效\nsysctl --system  \n```\n\n## 2.5 时间同步\n\n所有节点执行一下命令\n\n```\nyum install ntpdate -y\nntpdate time.windows.com\n# 强制把系统时间写入CMOS\nclock -w\n```\n\n# 3 所有节点安装Docker/kubeadm/kubelet\n\n## 3.1 安装Docker\n\nk8snode1和k8snode2下安装docker\n\n```\nwget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo\nyum -y install docker-ce-18.06.1.ce-3.el7\nsystemctl enable docker && systemctl start docker\ndocker --version\n```\n\n## 3.2 配置docker镜像加速\n\n![img](kubeadm快速部署kubernetes集群/1629031322356.png)\n\n```\ncat > /etc/docker/daemon.json << EOF\n{\n  \"registry-mirrors\": [\"https://onozxvpe.mirror.aliyuncs.com\",\"http://hub-mirror.c.163.com\", \"https://registry.docker-cn.com\"],\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"]\n}\nEOF\n```\n\n添加镜像加入和本地搭建harbor后：\n\n```\n{\n  \"registry-mirrors\": [\"https://onozxvpe.mirror.aliyuncs.com\"],\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"],\n  \"insecure-registries\": [\"harborcloud.com\"]\n}\n```\n\n\n\n## 3.3 添加阿里云YUM软件源\n\n```\ncat > /etc/yum.repos.d/kubernetes.repo << EOF\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=0\nrepo_gpgcheck=0\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n```\n\n## 3.4 安装kubeadm，kubelet和kubectl\n\n```\nyum install -y kubeadm-1.22.0 kubectl-1.22.0 kubelet-1.22.0\nsystemctl enable kubelet\n```\n\n# 4 部署Kubernetes Master\n\nhttps://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/kubeadm-init/\n\n在192.168.66.10（k8smaster）执行。\n\n由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址\n\n**–pod-network-cidr**\n\n指定pod网络的IP地址范围。 设置后，控制平面将自动为每个节点分配cidr。\n\n**–service-cidr**\n\n集群内部虚拟网络，Pod统一访问入口\n\n```\nkubeadm init \\\n--apiserver-advertise-address=192.168.66.10 \\\n--image-repository registry.aliyuncs.com/google_containers \\\n--kubernetes-version v1.22.0 \\\n--service-cidr=10.96.0.0/12 \\\n--pod-network-cidr=10.244.0.0/16\n```\n\n执行结果\n\n```\n[init] Using Kubernetes version: v1.22.0\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [k8s-master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.66.11]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [k8s-master01 localhost] and IPs [192.168.66.11 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [k8s-master01 localhost] and IPs [192.168.66.11 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Starting the kubelet\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 12.003757 seconds\n[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.22\" in namespace kube-system with the configuration for the kubelets in the cluster\n[upload-certs] Skipping phase. Please see --upload-certs\n[mark-control-plane] Marking the node k8s-master01 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]\n[mark-control-plane] Marking the node k8s-master01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[bootstrap-token] Using token: ii3pse.bfxj9fqc9tvz6yrr\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.66.11:6443 --token ii3pse.bfxj9fqc9tvz6yrr \\\n        --discovery-token-ca-cert-hash sha256:643b48706d97589356e2a4be7294a898ac9a909baa56fecca277b7b4e5634e0e \n```\n\n- preflight，系统前置检查\n- certs 各种证书的文件生成\n- kubeconfig生成kubeconfig文件，主要是kubenetes的几大组件的配置文件。\n- kubelet-start 启动kubelet\n- control-plane 生成所有静态pod的manifest文件，这些静态pod组成了kubenetes的控制面板，apiserver，controller，scheduler，生成这个文件后，kubelet会自动依据此文件描述的信息拉起镜像\n- etcd 生成etcd的manifest\n- upload-config 上传kubeadm和kubelet的配置文件到configmap中\n- upload-certs 上传配置证书文件\n- mark-control-plane mark一个node作为控制台\n- bootstrap-token 生成bootstrap tokens用于把node节点加入到集群。\n- kubelet-finalize 更新kubelet的设置\n- addon 安装其他的相关组件。主要是网络组件dns和kube-proxy\n\n所有node执行：\n\n注：`kubectl` 在 `$HOME/.kube` 目录中查找一个名为 `config` 的配置文件。 你可以通过设置 KUBECONFIG 环境变量或设置 [`--kubeconfig`](https://kubernetes.io/zh/docs/concepts/configuration/organize-cluster-access-kubeconfig/) 参数来指定其它 [kubeconfig](https://kubernetes.io/zh/docs/concepts/configuration/organize-cluster-access-kubeconfig/) 文件。\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n$ kubectl get nodes\n```\n\n如果出现错误通过一下命令重置\n\n```\nkubeadm reset\n```\n\n# 5 加入Kubernetes Node\n\n执行上面kubeadm init后显示的信息提示，加入kubernates\n\n```\nkubeadm join 192.168.66.11:6443 --token ii3pse.bfxj9fqc9tvz6yrr \\\n        --discovery-token-ca-cert-hash sha256:643b48706d97589356e2a4be7294a898ac9a909baa56fecca277b7b4e5634e0e\n```\n\n默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，操作如下：\n\n```\nkubeadm token create --print-join-command\n```\n\n# 6 部署CNI网络插件\n\n![img](kubeadm快速部署kubernetes集群/image-25.png)\n\n这里可能需要代理下载，可以先下载下来\n\n```\n$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n$ kubectl get pods -n kube-system\nNAME                          READY   STATUS    RESTARTS   AGE\nkube-flannel-ds-amd64-2pc95   1/1     Running   0          72s\n```\n\n![img](kubeadm快速部署kubernetes集群/image-26.png)\n\n**Flannel工作原理**\n\nk8s网络通讯方式：[k8s网络通讯方式 – 青叶水间 (youhang.site)](http://jishu.youhang.site/25.html)\n\n每个主机配置一个ip段和子网个数。 例如，可以配置一个覆盖网络使用 10.244.0.0/16段，每个主机/24个子网。因此主机a可以接受10.244.1.0/24，主机B可以接受10.244.2.0/24的包。flannel使用etcd来维护分配的子网到实际的ip地址之间的映射。\n\nmaster IP信息：\n\n```\n[root@k8s-master01 ~]# ip addr\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: eno16777736: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 00:0c:29:6b:de:b6 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.66.11/24 brd 10.0.0.255 scope global noprefixroute eno16777736\n       valid_lft forever preferred_lft forever\n    inet6 fd56:a9ae:cb0f::a49/128 scope global noprefixroute dynamic \n       valid_lft 29570sec preferred_lft 29570sec\n    inet6 fd56:a9ae:cb0f:0:20c:29ff:fe6b:deb6/64 scope global noprefixroute \n       valid_lft forever preferred_lft forever\n    inet6 fe80::20c:29ff:fe6b:deb6/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n    link/ether 02:42:f0:df:d5:af brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n4: flannel.1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default \n    link/ether 8e:53:a8:6d:99:1e brd ff:ff:ff:ff:ff:ff\n    inet 10.244.0.0/32 scope global flannel.1\n       valid_lft forever preferred_lft forever\n    inet6 fe80::8c53:a8ff:fe6d:991e/64 scope link \n       valid_lft forever preferred_lft forever\n5: cni0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000\n    link/ether 7a:33:a2:1a:15:65 brd ff:ff:ff:ff:ff:ff\n    inet 10.244.0.1/24 brd 10.244.0.255 scope global cni0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::7833:a2ff:fe1a:1565/64 scope link \n       valid_lft forever preferred_lft forever\n6: vethefc85590@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue master cni0 state UP group default \n    link/ether 5a:3e:58:6a:8c:d2 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet6 fe80::583e:58ff:fe6a:8cd2/64 scope link \n       valid_lft forever preferred_lft forever\n7: veth991a2bde@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue master cni0 state UP group default \n    link/ether fe:6f:eb:91:71:71 brd ff:ff:ff:ff:ff:ff link-netnsid 1\n    inet6 fe80::fc6f:ebff:fe91:7171/64 scope link \n       valid_lft forever preferred_lft forever\n```\n\n**lo**\n\n本地环回接口\n\n**eno16777736**\n\n真实网卡\n\n**docker0**\n\ndocker ip信息，默认IP 172.17.0.1/16\n\n可修改 /etc/docker/daemon.json, 指定ip地址，例如：\n\n```\nvi /etc/docker/daemon.json\n{\n \"bip\": \"172.18.0.1/24\",\n}\nservice docker restart\n```\n\n**flannel.1**\n\ndocker集群跨主机通讯的覆盖网络 10.244.0.0/32\n\n**cni0**\n\npod分配 网络 10.244.0.1/24\n\nnode1 IP信息：\n\n```\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: eno16777736: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 00:0c:29:1a:1c:d4 brd ff:ff:ff:ff:ff:ff\n    inet 10.0.0.21/24 brd 10.0.0.255 scope global noprefixroute eno16777736\n       valid_lft forever preferred_lft forever\n    inet6 fd56:a9ae:cb0f::7a1/128 scope global noprefixroute dynamic \n       valid_lft 29510sec preferred_lft 29510sec\n    inet6 fd56:a9ae:cb0f:0:20c:29ff:fe1a:1cd4/64 scope global noprefixroute \n       valid_lft forever preferred_lft forever\n    inet6 fe80::20c:29ff:fe1a:1cd4/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n    link/ether 02:42:b8:ae:c9:24 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n4: flannel.1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default \n    link/ether 1e:6d:47:69:f7:6a brd ff:ff:ff:ff:ff:ff\n    inet 10.244.1.0/32 scope global flannel.1\n       valid_lft forever preferred_lft forever\n    inet6 fe80::1c6d:47ff:fe69:f76a/64 scope link \n       valid_lft forever preferred_lft forever\n```\n\nnode2 IP信息\n\n```\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: eno16777736: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 00:0c:29:67:c3:4a brd ff:ff:ff:ff:ff:ff\n    inet 10.0.0.22/24 brd 10.0.0.255 scope global noprefixroute eno16777736\n       valid_lft forever preferred_lft forever\n    inet6 fd56:a9ae:cb0f::853/128 scope global noprefixroute dynamic \n       valid_lft 29262sec preferred_lft 29262sec\n    inet6 fd56:a9ae:cb0f:0:20c:29ff:fe67:c34a/64 scope global noprefixroute \n       valid_lft forever preferred_lft forever\n    inet6 fe80::20c:29ff:fe67:c34a/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n    link/ether 02:42:b2:7e:58:1f brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n4: flannel.1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default \n    link/ether 66:5b:e2:87:5c:22 brd ff:ff:ff:ff:ff:ff\n    inet 10.244.2.0/32 scope global flannel.1\n       valid_lft forever preferred_lft forever\n    inet6 fe80::645b:e2ff:fe87:5c22/64 scope link \n       valid_lft forever preferred_lft forever\n```\n\n7 测试kubernetes集群\n\n在Kubernetes集群中创建一个pod，验证是否正常运行：\n\n```\n[root@k8s-master01 ~]# kubectl create deployment nginx --image=nginx\ndeployment.apps/nginx created\n[root@k8s-master01 ~]# kubectl expose deployment nginx --port=80 --type=NodePort\nservice/nginx exposed\n[root@k8s-master01 ~]# kubectl get pod,svc\nNAME                         READY   STATUS              RESTARTS   AGE\npod/nginx-6799fc88d8-zzsw7   0/1     ContainerCreating   0          31s\n\nNAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nservice/kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        24h\nservice/nginx        NodePort    10.103.32.138   <none>        80:30029/TCP   13s\n```\n\n访问地址：[http://NodeIP:Port](http://nodeip:Port/)\n\n可以通过 [http://10.0.0.21:31263](http://10.0.0.21:31263/) 和 [http://10.0.0.22:31263](http://10.0.0.22:31263/) 访问\n\n# 8 **错误排查**\n\n启动日志获取\n\n```\n#查看启动日志\njournalctl -f -u kubelet.service\n```\n\n配置加载与重启服务\n\n```\nsystemctl daemon-reload && systemctl restart kubelet\n```\n\n# 9 ipvs修改\n\n```\nkubectl edit configmap kube-proxy -n kube-system\n...\n43   mode: \"ipvs\"\n   ...\n```\n\n**删除pod,会自动拉起**\n\n```\nkubectl delete pod kube-proxy-btz4p -n kube-system  \n```\n\n**查看是否启用ipvs**\n\n```\nkubectl logs kube-proxy-wwqbh -n kube-system        \n```\n\n**注：**\n\n```\n1、 kube-proxy配置文件以configmap方式存储\n2、 如果让所有节点生效，需要重建所有节点kube-proxy pod\n```\n\n# 10 **问题及解决**\n\n1 failed to find subsystem mount for required subsystem: pids failed to find subsystem mount for required subsystem: pids\n\n解决方法：\n\n```\nvi /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf\n#发现ExecStart=后面添加参数\nExecStart=\"--feature-gates SupportPodPidsLimit=false --feature-gates SupportNodePidsLimit=false\"\n#或者更改引用变量$KUBELET_EXTRA_ARGS\nvi /etc/sysconfig/kubelet\nKUBELET_EXTRA_ARGS=--feature-gates SupportPodPidsLimit=false --feature-gates SupportNodePidsLimit=false\n```\n\n2 kubelet cgroup driver: \\“systemd\\“ is different from docker cgroup driver: \\“cgroupfs\\“\n\ndocker的驱动查看是否有systemd\n\n```\ndocker info |grep Cgroup\n```\n\n解决方案步骤如下：\n\n(1)、先修改docker的Cgroup Driver，修改/etc/docker/daemon.json文件\n\n```\n{\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"]\n}\n```\n\n重启docker\n\n```\nsystemctl daemon-reload\nsystemctl restart docker\n```\n\n(2)、然后修改kubelet的Cgroup Driver\n修改 “/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf ” 文件，增加（或修改成）“–cgroup-driver=systemd” (官方推荐用systemd)\n\n```\nEnvironment=\"KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --cgroup-driver=systemd\"\n```\n\n修改 “/var/lib/kubelet/kubeadm-flags.env ”文件，增加（或修改成）“-–cgroup-driver=systemd”\n\n```\nKUBELET_KUBEADM_ARGS=\"--cgroup-driver=systemd --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.2\"\n```\n\n重启：\n\n```\nsystemctl daemon-reload\nsystemctl restart kubelet\n```\n3 missing required cgroups: cpu\n\n修改`/etc/default/grub`\n\n添加一行`GRUB_CMDLINE_LINUX=\"cgroup_enable=cpu\"`\n\n运行 `update-grub2`\n\n重启机器 `reboot`\n\n4  Failed to start CRI Interface for Docker Application Container Engine Defined-By: systemd\n\n```\n7月 29 20:35:14 k8s-master02 systemd[1]: cri-docker.service: main process exited, code=exited, status=203/EXEC\n7月 29 20:35:14 k8s-master02 systemd[1]: Failed to start CRI Interface for Docker Application Container Engine.\n-- Subject: Unit cri-docker.service has failed\n-- Defined-By: systemd\n-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel\n-- \n-- Unit cri-docker.service has failed.\n-- \n-- The result is failed.\n7月 29 20:35:14 k8s-master02 systemd[1]: Unit cri-docker.service entered failed state.\n7月 29 20:35:14 k8s-master02 systemd[1]: cri-docker.service failed.\n```\n\n修改 docker 控制组\n\n```\nvi /etc/docker/daemon.json \n{\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"]\n}\n```\n\n从重启服务\n\n```\nsystemctl daemon-reload\nsystemctl restart docker\nsystemctl restart cri-docker\n```\n\n5  error execution phase preflight: couldn't validate the identity of the API Server: Get \"https://10.0.0.150:16443/api/v1/namespaces/kube-public/configmaps/cluster-info?timeout=10s\": x509: certificate has expired or is not yet valid: current time 2022-07-30T16:12:40+08:00 is before 2022-07-30T13:31:36Z\n\n```\nyum install ntpdate -y\nntpdate time.windows.com\n# 强制把系统时间写入CMOS\nclock -w\n```\n\n","slug":"kubeadm快速部署kubernetes集群","published":1,"updated":"2022-09-23T17:05:13.623Z","_id":"cl8eqf8po0006d4vj61te6fa7","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"kubeadm快速部署kubernetes集群\"><a href=\"#kubeadm快速部署kubernetes集群\" class=\"headerlink\" title=\"kubeadm快速部署kubernetes集群\"></a>kubeadm快速部署kubernetes集群</h1><h1 id=\"1-安装要求\"><a href=\"#1-安装要求\" class=\"headerlink\" title=\"1 安装要求\"></a>1 安装要求</h1><ul>\n<li>一台或多台机器，操作系统 CentOS7.x-86_x64</li>\n<li>硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多(master必须2cpu,node可以不用)</li>\n<li>可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点</li>\n<li>禁止swap分区</li>\n</ul>\n<p><a href=\"https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\">安装 kubeadm | Kubernetes</a></p>\n<h1 id=\"2-准备环境\"><a href=\"#2-准备环境\" class=\"headerlink\" title=\"2 准备环境\"></a>2 准备环境</h1><table>\n<thead>\n<tr>\n<th>角色</th>\n<th>IP</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>master</td>\n<td>192.168.66.11</td>\n</tr>\n<tr>\n<td>node1</td>\n<td>192.168.66.21</td>\n</tr>\n<tr>\n<td>node2</td>\n<td>192.168.66.22</td>\n</tr>\n</tbody></table>\n<figure class=\"highlight stata\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stata\">yum <span class=\"hljs-keyword\">update</span> -y<br>yum install -y firewalld ntpdate <span class=\"hljs-keyword\">net</span>-tools ipvsadm wget<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-1-关闭防火墙及selinux\"><a href=\"#2-1-关闭防火墙及selinux\" class=\"headerlink\" title=\"2.1 关闭防火墙及selinux\"></a>2.1 关闭防火墙及selinux</h2><p>所有节点执行一下命令</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\"><span class=\"hljs-comment\"># 关闭防火墙</span><br>systemctl stop firewalld<br>systemctl <span class=\"hljs-built_in\">disable</span> firewalld<br><br><span class=\"hljs-comment\"># 关闭selinux</span><br><span class=\"hljs-comment\"># 永久</span><br>sed -i <span class=\"hljs-string\">&#x27;s/enforcing/disabled/&#x27;</span> /etc/selinux<span class=\"hljs-built_in\">/config </span> <br><span class=\"hljs-comment\"># 临时</span><br>setenforce 0  <br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-2-关闭swap\"><a href=\"#2-2-关闭swap\" class=\"headerlink\" title=\"2.2 关闭swap\"></a>2.2 关闭swap</h2><p>所有节点执行一下命令</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-comment\"># 关闭swap</span><br><span class=\"hljs-comment\"># 临时</span><br>swapoff -a  <br><span class=\"hljs-comment\"># 永久</span><br>sed -ri <span class=\"hljs-string\">&#x27;s/.*swap.*/#&amp;/&#x27;</span> <span class=\"hljs-regexp\">/etc/</span>fstab    <br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-3-根据规划设置主机名及hosts\"><a href=\"#2-3-根据规划设置主机名及hosts\" class=\"headerlink\" title=\"2.3 根据规划设置主机名及hosts\"></a>2.3 根据规划设置主机名及hosts</h2><p>所有节点执行hostnamectl set-hostname <hostname>命令</p>\n<figure class=\"highlight dsconfig\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dsconfig\"><span class=\"hljs-comment\"># k8smaster节点执行</span><br><span class=\"hljs-string\">hostnamectl</span> <span class=\"hljs-built_in\">set-hostname</span> <span class=\"hljs-string\">k8s-master01</span><br><span class=\"hljs-comment\"># k8snode1节点执行</span><br><span class=\"hljs-string\">hostnamectl</span> <span class=\"hljs-built_in\">set-hostname</span> <span class=\"hljs-string\">k8s-node01</span><br><span class=\"hljs-comment\"># k8snode2节点执行</span><br><span class=\"hljs-string\">hostnamectl</span> <span class=\"hljs-built_in\">set-hostname</span> <span class=\"hljs-string\">k8s-node02</span><br></code></pre></td></tr></table></figure>\n\n<p>k8smaster主节点执行</p>\n<figure class=\"highlight accesslog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs accesslog\">cat &gt;&gt; /etc/hosts &lt;&lt; EOF<br><span class=\"hljs-number\">192.168.66.11</span> k8s-master01<br><span class=\"hljs-number\">192.168.66.21</span> k8s-node01<br><span class=\"hljs-number\">192.168.66.22</span> k8s-node02<br>EOF<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-4-将桥接的IPv4流量传递到iptables的链\"><a href=\"#2-4-将桥接的IPv4流量传递到iptables的链\" class=\"headerlink\" title=\"2.4 将桥接的IPv4流量传递到iptables的链\"></a>2.4 将桥接的IPv4流量传递到iptables的链</h2><p>确保 <code>br_netfilter</code> 模块被加载。这一操作可以通过运行 <code>lsmod | grep br_netfilter</code> 来完成。若要显式加载该模块，可执行 <code>sudo modprobe br_netfilter</code>。 </p>\n<p>确保在你的 <code>sysctl</code> 配置中将 <code>net.bridge.bridge-nf-call-iptables</code> 设置为 1。 </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\"><span class=\"hljs-built_in\">cat</span> &lt;&lt;<span class=\"hljs-string\">EOF | sudo tee /etc/modules-load.d/k8s.conf</span><br><span class=\"hljs-string\">br_netfilter</span><br><span class=\"hljs-string\">EOF</span><br><br><span class=\"hljs-comment\">#将桥接的IPv4流量传递到iptables的链</span><br><span class=\"hljs-built_in\">cat</span> &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class=\"hljs-string\">EOF</span><br><span class=\"hljs-string\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"hljs-string\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"hljs-string\">EOF</span><br><span class=\"hljs-comment\"># 生效</span><br>sysctl --system  <br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-5-时间同步\"><a href=\"#2-5-时间同步\" class=\"headerlink\" title=\"2.5 时间同步\"></a>2.5 时间同步</h2><p>所有节点执行一下命令</p>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">yum <span class=\"hljs-keyword\">install </span>ntpdate -y<br>ntpdate time.windows.com<br><span class=\"hljs-comment\"># 强制把系统时间写入CMOS</span><br><span class=\"hljs-keyword\">clock </span>-w<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"3-所有节点安装Docker-kubeadm-kubelet\"><a href=\"#3-所有节点安装Docker-kubeadm-kubelet\" class=\"headerlink\" title=\"3 所有节点安装Docker/kubeadm/kubelet\"></a>3 所有节点安装Docker/kubeadm/kubelet</h1><h2 id=\"3-1-安装Docker\"><a href=\"#3-1-安装Docker\" class=\"headerlink\" title=\"3.1 安装Docker\"></a>3.1 安装Docker</h2><p>k8snode1和k8snode2下安装docker</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">wget https:<span class=\"hljs-regexp\">//mi</span>rrors.aliyun.com<span class=\"hljs-regexp\">/docker-ce/</span>linux<span class=\"hljs-regexp\">/centos/</span>docker-ce.repo -O <span class=\"hljs-regexp\">/etc/yum</span>.repos.d/docker-ce.repo<br>yum -y install docker-ce-<span class=\"hljs-number\">18.06</span>.<span class=\"hljs-number\">1</span>.ce-<span class=\"hljs-number\">3</span>.el7<br>systemctl enable docker &amp;&amp; systemctl start docker<br>docker --version<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"3-2-配置docker镜像加速\"><a href=\"#3-2-配置docker镜像加速\" class=\"headerlink\" title=\"3.2 配置docker镜像加速\"></a>3.2 配置docker镜像加速</h2><img src=\"/2021/08/04/kubeadm%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2kubernetes%E9%9B%86%E7%BE%A4/1629031322356.png\" class=\"\" title=\"img\">\n\n<figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\">cat &gt; /etc/docker/daemon<span class=\"hljs-selector-class\">.json</span> &lt;&lt; EOF<br>&#123;<br>  <span class=\"hljs-string\">&quot;registry-mirrors&quot;</span>: <span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">&quot;https://onozxvpe.mirror.aliyuncs.com&quot;</span>,<span class=\"hljs-string\">&quot;http://hub-mirror.c.163.com&quot;</span>, <span class=\"hljs-string\">&quot;https://registry.docker-cn.com&quot;</span>]</span>,<br>  <span class=\"hljs-string\">&quot;exec-opts&quot;</span>: <span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">&quot;native.cgroupdriver=systemd&quot;</span>]</span><br>&#125;<br>EOF<br></code></pre></td></tr></table></figure>\n\n<p>添加镜像加入和本地搭建harbor后：</p>\n<figure class=\"highlight prolog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs prolog\">&#123;<br>  <span class=\"hljs-string\">&quot;registry-mirrors&quot;</span>: [<span class=\"hljs-string\">&quot;https://onozxvpe.mirror.aliyuncs.com&quot;</span>],<br>  <span class=\"hljs-string\">&quot;exec-opts&quot;</span>: [<span class=\"hljs-string\">&quot;native.cgroupdriver=systemd&quot;</span>],<br>  <span class=\"hljs-string\">&quot;insecure-registries&quot;</span>: [<span class=\"hljs-string\">&quot;harborcloud.com&quot;</span>]<br>&#125;<br></code></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"3-3-添加阿里云YUM软件源\"><a href=\"#3-3-添加阿里云YUM软件源\" class=\"headerlink\" title=\"3.3 添加阿里云YUM软件源\"></a>3.3 添加阿里云YUM软件源</h2><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">cat &gt; <span class=\"hljs-regexp\">/etc/yum</span>.repos.d/kubernetes.repo &lt;&lt; EOF<br>[kubernetes]<br>name=Kubernetes<br>baseurl=https:<span class=\"hljs-regexp\">//mi</span>rrors.aliyun.com<span class=\"hljs-regexp\">/kubernetes/yum</span><span class=\"hljs-regexp\">/repos/</span>kubernetes-el7-x86_64<br>enabled=<span class=\"hljs-number\">1</span><br>gpgcheck=<span class=\"hljs-number\">0</span><br>repo_gpgcheck=<span class=\"hljs-number\">0</span><br>gpgkey=https:<span class=\"hljs-regexp\">//mi</span>rrors.aliyun.com<span class=\"hljs-regexp\">/kubernetes/yum</span><span class=\"hljs-regexp\">/doc/yum</span>-key.gpg https:<span class=\"hljs-regexp\">//mi</span>rrors.aliyun.com<span class=\"hljs-regexp\">/kubernetes/yum</span><span class=\"hljs-regexp\">/doc/</span>rpm-package-key.gpg<br>EOF<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"3-4-安装kubeadm，kubelet和kubectl\"><a href=\"#3-4-安装kubeadm，kubelet和kubectl\" class=\"headerlink\" title=\"3.4 安装kubeadm，kubelet和kubectl\"></a>3.4 安装kubeadm，kubelet和kubectl</h2><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">yum</span> install -y kubeadm-<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">22</span>.<span class=\"hljs-number\">0</span> kubectl-<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">22</span>.<span class=\"hljs-number\">0</span> kubelet-<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">22</span>.<span class=\"hljs-number\">0</span><br><span class=\"hljs-attribute\">systemctl</span> enable kubelet<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"4-部署Kubernetes-Master\"><a href=\"#4-部署Kubernetes-Master\" class=\"headerlink\" title=\"4 部署Kubernetes Master\"></a>4 部署Kubernetes Master</h1><p><a href=\"https://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/kubeadm-init/\">https://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/kubeadm-init/</a></p>\n<p>在192.168.66.10（k8smaster）执行。</p>\n<p>由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址</p>\n<p><strong>–pod-network-cidr</strong></p>\n<p>指定pod网络的IP地址范围。 设置后，控制平面将自动为每个节点分配cidr。</p>\n<p><strong>–service-cidr</strong></p>\n<p>集群内部虚拟网络，Pod统一访问入口</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubeadm init \\<br><span class=\"hljs-attribute\">--apiserver-advertise-address</span>=192.168.66.10 \\<br>--image-repository registry.aliyuncs.com/google_containers \\<br>--kubernetes-version v1.22.0 \\<br><span class=\"hljs-attribute\">--service-cidr</span>=10.96.0.0/12 \\<br><span class=\"hljs-attribute\">--pod-network-cidr</span>=10.244.0.0/16<br></code></pre></td></tr></table></figure>\n\n<p>执行结果</p>\n<figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\"><span class=\"hljs-selector-attr\">[init]</span> Using Kubernetes version: v1.<span class=\"hljs-number\">22.0</span><br><span class=\"hljs-selector-attr\">[preflight]</span> Running pre-flight checks<br><span class=\"hljs-selector-attr\">[preflight]</span> Pulling images required <span class=\"hljs-keyword\">for</span> setting up <span class=\"hljs-selector-tag\">a</span> Kubernetes cluster<br><span class=\"hljs-selector-attr\">[preflight]</span> This might take <span class=\"hljs-selector-tag\">a</span> minute or two, depending on the speed of your internet connection<br><span class=\"hljs-selector-attr\">[preflight]</span> You can also perform this action <span class=\"hljs-keyword\">in</span> beforehand using <span class=\"hljs-string\">&#x27;kubeadm config images pull&#x27;</span><br><span class=\"hljs-selector-attr\">[certs]</span> Using certificateDir folder <span class=\"hljs-string\">&quot;/etc/kubernetes/pki&quot;</span><br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;ca&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;apiserver&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> apiserver serving cert is signed <span class=\"hljs-keyword\">for</span> DNS names <span class=\"hljs-selector-attr\">[k8s-master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local]</span> and IPs <span class=\"hljs-selector-attr\">[10.96.0.1 192.168.66.11]</span><br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;apiserver-kubelet-client&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;front-proxy-ca&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;front-proxy-client&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;etcd/ca&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;etcd/server&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> etcd/server serving cert is signed <span class=\"hljs-keyword\">for</span> DNS names <span class=\"hljs-selector-attr\">[k8s-master01 localhost]</span> and IPs <span class=\"hljs-selector-attr\">[192.168.66.11 127.0.0.1 ::1]</span><br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;etcd/peer&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> etcd/peer serving cert is signed <span class=\"hljs-keyword\">for</span> DNS names <span class=\"hljs-selector-attr\">[k8s-master01 localhost]</span> and IPs <span class=\"hljs-selector-attr\">[192.168.66.11 127.0.0.1 ::1]</span><br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;etcd/healthcheck-client&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;apiserver-etcd-client&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;sa&quot;</span> key and public key<br><span class=\"hljs-selector-attr\">[kubeconfig]</span> Using kubeconfig folder <span class=\"hljs-string\">&quot;/etc/kubernetes&quot;</span><br><span class=\"hljs-selector-attr\">[kubeconfig]</span> Writing <span class=\"hljs-string\">&quot;admin.conf&quot;</span> kubeconfig file<br><span class=\"hljs-selector-attr\">[kubeconfig]</span> Writing <span class=\"hljs-string\">&quot;kubelet.conf&quot;</span> kubeconfig file<br><span class=\"hljs-selector-attr\">[kubeconfig]</span> Writing <span class=\"hljs-string\">&quot;controller-manager.conf&quot;</span> kubeconfig file<br><span class=\"hljs-selector-attr\">[kubeconfig]</span> Writing <span class=\"hljs-string\">&quot;scheduler.conf&quot;</span> kubeconfig file<br><span class=\"hljs-selector-attr\">[kubelet-start]</span> Writing kubelet environment file with flags to file <span class=\"hljs-string\">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class=\"hljs-selector-attr\">[kubelet-start]</span> Writing kubelet configuration to file <span class=\"hljs-string\">&quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class=\"hljs-selector-attr\">[kubelet-start]</span> Starting the kubelet<br><span class=\"hljs-selector-attr\">[control-plane]</span> Using manifest folder <span class=\"hljs-string\">&quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"hljs-selector-attr\">[control-plane]</span> Creating static Pod manifest <span class=\"hljs-keyword\">for</span> <span class=\"hljs-string\">&quot;kube-apiserver&quot;</span><br><span class=\"hljs-selector-attr\">[control-plane]</span> Creating static Pod manifest <span class=\"hljs-keyword\">for</span> <span class=\"hljs-string\">&quot;kube-controller-manager&quot;</span><br><span class=\"hljs-selector-attr\">[control-plane]</span> Creating static Pod manifest <span class=\"hljs-keyword\">for</span> <span class=\"hljs-string\">&quot;kube-scheduler&quot;</span><br><span class=\"hljs-selector-attr\">[etcd]</span> Creating static Pod manifest <span class=\"hljs-keyword\">for</span> local etcd <span class=\"hljs-keyword\">in</span> <span class=\"hljs-string\">&quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"hljs-selector-attr\">[wait-control-plane]</span> Waiting <span class=\"hljs-keyword\">for</span> the kubelet to boot up the control plane as static Pods from directory <span class=\"hljs-string\">&quot;/etc/kubernetes/manifests&quot;</span>. This can take up to <span class=\"hljs-number\">4</span>m0s<br><span class=\"hljs-selector-attr\">[apiclient]</span> All control plane components are healthy after <span class=\"hljs-number\">12.003757</span> seconds<br><span class=\"hljs-selector-attr\">[upload-config]</span> Storing the configuration used <span class=\"hljs-keyword\">in</span> ConfigMap <span class=\"hljs-string\">&quot;kubeadm-config&quot;</span> <span class=\"hljs-keyword\">in</span> the <span class=\"hljs-string\">&quot;kube-system&quot;</span> Namespace<br><span class=\"hljs-selector-attr\">[kubelet]</span> Creating <span class=\"hljs-selector-tag\">a</span> ConfigMap <span class=\"hljs-string\">&quot;kubelet-config-1.22&quot;</span> <span class=\"hljs-keyword\">in</span> namespace kube-system with the configuration <span class=\"hljs-keyword\">for</span> the kubelets <span class=\"hljs-keyword\">in</span> the cluster<br><span class=\"hljs-selector-attr\">[upload-certs]</span> Skipping phase. Please see <span class=\"hljs-attr\">--upload-certs</span><br><span class=\"hljs-selector-attr\">[mark-control-plane]</span> Marking the node k8s-master01 as control-plane by adding the labels: <span class=\"hljs-selector-attr\">[node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]</span><br><span class=\"hljs-selector-attr\">[mark-control-plane]</span> Marking the node k8s-master01 as control-plane by adding the taints <span class=\"hljs-selector-attr\">[node-role.kubernetes.io/master:NoSchedule]</span><br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> Using token: ii3pse<span class=\"hljs-selector-class\">.bfxj9fqc9tvz6yrr</span><br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles<br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> configured RBAC rules to allow Node Bootstrap tokens to get nodes<br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> configured RBAC rules to allow Node Bootstrap tokens to post CSRs <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attribute\">order</span> for nodes to get long term certificate credentials<br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> configured RBAC rules to allow the csrapprover controller automatically approve CSRs from <span class=\"hljs-selector-tag\">a</span> Node Bootstrap Token<br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> configured RBAC rules to allow certificate rotation <span class=\"hljs-keyword\">for</span> <span class=\"hljs-attribute\">all</span> node client certificates in the cluster<br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> Creating the <span class=\"hljs-string\">&quot;cluster-info&quot;</span> ConfigMap <span class=\"hljs-keyword\">in</span> the <span class=\"hljs-string\">&quot;kube-public&quot;</span> namespace<br><span class=\"hljs-selector-attr\">[kubelet-finalize]</span> Updating <span class=\"hljs-string\">&quot;/etc/kubernetes/kubelet.conf&quot;</span> to point to <span class=\"hljs-selector-tag\">a</span> rotatable kubelet client certificate and key<br><span class=\"hljs-selector-attr\">[addons]</span> Applied essential addon: CoreDNS<br><span class=\"hljs-selector-attr\">[addons]</span> Applied essential addon: kube-proxy<br><br>Your Kubernetes control-plane has initialized successfully!<br><br>To start using your cluster, you need to run the following as <span class=\"hljs-selector-tag\">a</span> regular user:<br><br>  mkdir -<span class=\"hljs-selector-tag\">p</span> <span class=\"hljs-variable\">$HOME</span>/<span class=\"hljs-selector-class\">.kube</span><br>  sudo cp -<span class=\"hljs-selector-tag\">i</span> /etc/kubernetes/admin<span class=\"hljs-selector-class\">.conf</span> <span class=\"hljs-variable\">$HOME</span>/.kube/config<br>  sudo chown $(id -u):$(id -g) <span class=\"hljs-variable\">$HOME</span>/.kube/config<br><br>Alternatively, <span class=\"hljs-keyword\">if</span> you are the root user, you can run:<br><br>  export KUBECONFIG=/etc/kubernetes/admin<span class=\"hljs-selector-class\">.conf</span><br><br>You should now deploy <span class=\"hljs-selector-tag\">a</span> pod network to the cluster.<br>Run <span class=\"hljs-string\">&quot;kubectl apply -f [podnetwork].yaml&quot;</span> with one of the options listed at:<br>  https:<span class=\"hljs-comment\">//kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><br>Then you can join any number of worker nodes by running the following on each as root:<br><br>kubeadm join <span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">66.11</span>:<span class=\"hljs-number\">6443</span> <span class=\"hljs-attr\">--token</span> ii3pse<span class=\"hljs-selector-class\">.bfxj9fqc9tvz6yrr</span> \\<br>        <span class=\"hljs-attr\">--discovery-token-ca-cert-hash</span> sha256:<span class=\"hljs-number\">643</span>b48706d97589356e2a4be7294a898ac9a909baa56fecca277b7b4e5634e0e <br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>preflight，系统前置检查</li>\n<li>certs 各种证书的文件生成</li>\n<li>kubeconfig生成kubeconfig文件，主要是kubenetes的几大组件的配置文件。</li>\n<li>kubelet-start 启动kubelet</li>\n<li>control-plane 生成所有静态pod的manifest文件，这些静态pod组成了kubenetes的控制面板，apiserver，controller，scheduler，生成这个文件后，kubelet会自动依据此文件描述的信息拉起镜像</li>\n<li>etcd 生成etcd的manifest</li>\n<li>upload-config 上传kubeadm和kubelet的配置文件到configmap中</li>\n<li>upload-certs 上传配置证书文件</li>\n<li>mark-control-plane mark一个node作为控制台</li>\n<li>bootstrap-token 生成bootstrap tokens用于把node节点加入到集群。</li>\n<li>kubelet-finalize 更新kubelet的设置</li>\n<li>addon 安装其他的相关组件。主要是网络组件dns和kube-proxy</li>\n</ul>\n<p>所有node执行：</p>\n<p>注：<code>kubectl</code> 在 <code>$HOME/.kube</code> 目录中查找一个名为 <code>config</code> 的配置文件。 你可以通过设置 KUBECONFIG 环境变量或设置 <a href=\"https://kubernetes.io/zh/docs/concepts/configuration/organize-cluster-access-kubeconfig/\"><code>--kubeconfig</code></a> 参数来指定其它 <a href=\"https://kubernetes.io/zh/docs/concepts/configuration/organize-cluster-access-kubeconfig/\">kubeconfig</a> 文件。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\"><span class=\"hljs-built_in\">mkdir</span> -p <span class=\"hljs-variable\">$HOME</span>/.kube<br>sudo <span class=\"hljs-built_in\">cp</span> -i /etc/kubernetes/admin.conf <span class=\"hljs-variable\">$HOME</span>/.kube/config<br>sudo <span class=\"hljs-built_in\">chown</span> $(<span class=\"hljs-built_in\">id</span> -u):$(<span class=\"hljs-built_in\">id</span> -g) <span class=\"hljs-variable\">$HOME</span>/.kube/config<br>$ kubectl get nodes<br></code></pre></td></tr></table></figure>\n\n<p>如果出现错误通过一下命令重置</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">kubeadm reset</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"5-加入Kubernetes-Node\"><a href=\"#5-加入Kubernetes-Node\" class=\"headerlink\" title=\"5 加入Kubernetes Node\"></a>5 加入Kubernetes Node</h1><p>执行上面kubeadm init后显示的信息提示，加入kubernates</p>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">kubeadm <span class=\"hljs-keyword\">join </span><span class=\"hljs-number\">192</span>.<span class=\"hljs-number\">168</span>.<span class=\"hljs-number\">66</span>.<span class=\"hljs-number\">11</span>:<span class=\"hljs-number\">6443</span> --token ii3pse.<span class=\"hljs-keyword\">bfxj9fqc9tvz6yrr </span>\\<br>        --<span class=\"hljs-keyword\">discovery-token-ca-cert-hash </span><span class=\"hljs-keyword\">sha256:643b48706d97589356e2a4be7294a898ac9a909baa56fecca277b7b4e5634e0e</span><br></code></pre></td></tr></table></figure>\n\n<p>默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，操作如下：</p>\n<figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gauss\">kubeadm <span class=\"hljs-built_in\">token</span> <span class=\"hljs-keyword\">create</span> --<span class=\"hljs-keyword\">print</span>-join-command<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"6-部署CNI网络插件\"><a href=\"#6-部署CNI网络插件\" class=\"headerlink\" title=\"6 部署CNI网络插件\"></a>6 部署CNI网络插件</h1><img src=\"/2021/08/04/kubeadm%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2kubernetes%E9%9B%86%E7%BE%A4/image-25.png\" class=\"\" title=\"img\">\n\n<p>这里可能需要代理下载，可以先下载下来</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">$ kubectl apply -f https:<span class=\"hljs-regexp\">//</span>raw.githubusercontent.com<span class=\"hljs-regexp\">/coreos/</span>flannel<span class=\"hljs-regexp\">/master/</span>Documentation/kube-flannel.yml<br>$ kubectl get pods -n kube-system<br>NAME                          READY   STATUS    RESTARTS   AGE<br>kube-flannel-ds-amd64-<span class=\"hljs-number\">2</span>pc95   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">72</span>s<br></code></pre></td></tr></table></figure>\n\n<img src=\"/2021/08/04/kubeadm%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2kubernetes%E9%9B%86%E7%BE%A4/image-26.png\" class=\"\" title=\"img\">\n\n<p><strong>Flannel工作原理</strong></p>\n<p>k8s网络通讯方式：<a href=\"http://jishu.youhang.site/25.html\">k8s网络通讯方式 – 青叶水间 (youhang.site)</a></p>\n<p>每个主机配置一个ip段和子网个数。 例如，可以配置一个覆盖网络使用 10.244.0.0/16段，每个主机/24个子网。因此主机a可以接受10.244.1.0/24，主机B可以接受10.244.2.0/24的包。flannel使用etcd来维护分配的子网到实际的ip地址之间的映射。</p>\n<p>master IP信息：</p>\n<figure class=\"highlight pf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pf\">[root@k8s-master01 ~]<span class=\"hljs-comment\"># ip addr</span><br><span class=\"hljs-number\">1</span>: lo: <span class=\"hljs-variable\">&lt;LOOPBACK,UP,LOWER_UP&gt;</span> mtu <span class=\"hljs-number\">65536</span> qdisc noqueue <span class=\"hljs-keyword\">state</span> UNKNOWN <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> qlen <span class=\"hljs-number\">1000</span><br>    link/loopback <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> brd <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span><br>    <span class=\"hljs-keyword\">inet</span> <span class=\"hljs-number\">127.0</span>.<span class=\"hljs-number\">0.1</span>/<span class=\"hljs-number\">8</span> scope host lo<br>       valid_lft forever preferred_lft forever<br>    <span class=\"hljs-keyword\">inet6</span> ::<span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">128</span> scope host <br>       valid_lft forever preferred_lft forever<br><span class=\"hljs-number\">2</span>: eno16777736: <span class=\"hljs-variable\">&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span> mtu <span class=\"hljs-number\">1500</span> qdisc pfifo_fast <span class=\"hljs-keyword\">state</span> UP <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> qlen <span class=\"hljs-number\">1000</span><br>    link/ether <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">0</span>c:<span class=\"hljs-number\">29</span>:<span class=\"hljs-number\">6</span>b:de:b6 brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-keyword\">inet</span> <span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">66.11</span>/<span class=\"hljs-number\">24</span> brd <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.255</span> scope <span class=\"hljs-keyword\">global</span> noprefixroute eno16777736<br>       valid_lft forever preferred_lft forever<br>    <span class=\"hljs-keyword\">inet6</span> fd56:a9ae:cb0f::a49/<span class=\"hljs-number\">128</span> scope <span class=\"hljs-keyword\">global</span> noprefixroute dynamic <br>       valid_lft <span class=\"hljs-number\">29570</span>sec preferred_lft <span class=\"hljs-number\">29570</span>sec<br>    <span class=\"hljs-keyword\">inet6</span> fd56:a9ae:cb0f:<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">20</span>c:<span class=\"hljs-number\">29</span>ff:fe6b:deb6/<span class=\"hljs-number\">64</span> scope <span class=\"hljs-keyword\">global</span> noprefixroute <br>       valid_lft forever preferred_lft forever<br>    <span class=\"hljs-keyword\">inet6</span> fe80::<span class=\"hljs-number\">20</span>c:<span class=\"hljs-number\">29</span>ff:fe6b:deb6/<span class=\"hljs-number\">64</span> scope link noprefixroute <br>       valid_lft forever preferred_lft forever<br><span class=\"hljs-number\">3</span>: docker0: <span class=\"hljs-variable\">&lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt;</span> mtu <span class=\"hljs-number\">1500</span> qdisc noqueue <span class=\"hljs-keyword\">state</span> DOWN <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> <br>    link/ether <span class=\"hljs-number\">02</span>:<span class=\"hljs-number\">42</span>:f0:df:d5:af brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-keyword\">inet</span> <span class=\"hljs-number\">172.17</span>.<span class=\"hljs-number\">0.1</span>/<span class=\"hljs-number\">16</span> brd <span class=\"hljs-number\">172.17</span>.<span class=\"hljs-number\">255.255</span> scope <span class=\"hljs-keyword\">global</span> docker0<br>       valid_lft forever preferred_lft forever<br><span class=\"hljs-number\">4</span>: flannel.<span class=\"hljs-number\">1</span>: <span class=\"hljs-variable\">&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span> mtu <span class=\"hljs-number\">1450</span> qdisc noqueue <span class=\"hljs-keyword\">state</span> UNKNOWN <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> <br>    link/ether <span class=\"hljs-number\">8</span>e:<span class=\"hljs-number\">53</span>:a8:<span class=\"hljs-number\">6</span>d:<span class=\"hljs-number\">99</span>:<span class=\"hljs-number\">1</span>e brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-keyword\">inet</span> <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.0</span>/<span class=\"hljs-number\">32</span> scope <span class=\"hljs-keyword\">global</span> flannel.<span class=\"hljs-number\">1</span><br>       valid_lft forever preferred_lft forever<br>    <span class=\"hljs-keyword\">inet6</span> fe80::<span class=\"hljs-number\">8</span>c53:a8ff:fe6d:<span class=\"hljs-number\">991</span>e/<span class=\"hljs-number\">64</span> scope link <br>       valid_lft forever preferred_lft forever<br><span class=\"hljs-number\">5</span>: cni0: <span class=\"hljs-variable\">&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span> mtu <span class=\"hljs-number\">1450</span> qdisc noqueue <span class=\"hljs-keyword\">state</span> UP <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> qlen <span class=\"hljs-number\">1000</span><br>    link/ether <span class=\"hljs-number\">7</span>a:<span class=\"hljs-number\">33</span>:a2:<span class=\"hljs-number\">1</span>a:<span class=\"hljs-number\">15</span>:<span class=\"hljs-number\">65</span> brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-keyword\">inet</span> <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.1</span>/<span class=\"hljs-number\">24</span> brd <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.255</span> scope <span class=\"hljs-keyword\">global</span> cni0<br>       valid_lft forever preferred_lft forever<br>    <span class=\"hljs-keyword\">inet6</span> fe80::<span class=\"hljs-number\">7833</span>:a2ff:fe1a:<span class=\"hljs-number\">1565</span>/<span class=\"hljs-number\">64</span> scope link <br>       valid_lft forever preferred_lft forever<br><span class=\"hljs-number\">6</span>: vethefc85590@if3: <span class=\"hljs-variable\">&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span> mtu <span class=\"hljs-number\">1450</span> qdisc noqueue master cni0 <span class=\"hljs-keyword\">state</span> UP <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> <br>    link/ether <span class=\"hljs-number\">5</span>a:<span class=\"hljs-number\">3</span>e:<span class=\"hljs-number\">58</span>:<span class=\"hljs-number\">6</span>a:<span class=\"hljs-number\">8</span>c:d2 brd ff:ff:ff:ff:ff:ff link-netnsid <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-keyword\">inet6</span> fe80::<span class=\"hljs-number\">583</span>e:<span class=\"hljs-number\">58</span>ff:fe6a:<span class=\"hljs-number\">8</span>cd2/<span class=\"hljs-number\">64</span> scope link <br>       valid_lft forever preferred_lft forever<br><span class=\"hljs-number\">7</span>: veth991a2bde@if3: <span class=\"hljs-variable\">&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span> mtu <span class=\"hljs-number\">1450</span> qdisc noqueue master cni0 <span class=\"hljs-keyword\">state</span> UP <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> <br>    link/ether fe:<span class=\"hljs-number\">6</span>f:eb:<span class=\"hljs-number\">91</span>:<span class=\"hljs-number\">71</span>:<span class=\"hljs-number\">71</span> brd ff:ff:ff:ff:ff:ff link-netnsid <span class=\"hljs-number\">1</span><br>    <span class=\"hljs-keyword\">inet6</span> fe80::fc6f:ebff:fe91:<span class=\"hljs-number\">7171</span>/<span class=\"hljs-number\">64</span> scope link <br>       valid_lft forever preferred_lft forever<br></code></pre></td></tr></table></figure>\n\n<p><strong>lo</strong></p>\n<p>本地环回接口</p>\n<p><strong>eno16777736</strong></p>\n<p>真实网卡</p>\n<p><strong>docker0</strong></p>\n<p>docker ip信息，默认IP 172.17.0.1/16</p>\n<p>可修改 /etc/docker/daemon.json, 指定ip地址，例如：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">vi <span class=\"hljs-regexp\">/etc/</span>docker/daemon.json<br>&#123;<br> <span class=\"hljs-string\">&quot;bip&quot;</span>: <span class=\"hljs-string\">&quot;172.18.0.1/24&quot;</span>,<br>&#125;<br>service docker restart<br></code></pre></td></tr></table></figure>\n\n<p><strong>flannel.1</strong></p>\n<p>docker集群跨主机通讯的覆盖网络 10.244.0.0/32</p>\n<p><strong>cni0</strong></p>\n<p>pod分配 网络 10.244.0.1/24</p>\n<p>node1 IP信息：</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">1</span>: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span class=\"hljs-number\">65536</span> qdisc noqueue state UNKNOWN group default qlen <span class=\"hljs-number\">1000</span><br>    <span class=\"hljs-attribute\">link</span>/loopback <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> brd <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span><br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">127.0.0.1</span>/<span class=\"hljs-number\">8</span> scope host lo<br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> ::<span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">128</span> scope host <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br><span class=\"hljs-attribute\">2</span>: eno16777736: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class=\"hljs-number\">1500</span> qdisc pfifo_fast state UP group default qlen <span class=\"hljs-number\">1000</span><br>    <span class=\"hljs-attribute\">link</span>/ether <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">0</span>c:<span class=\"hljs-number\">29</span>:<span class=\"hljs-number\">1</span>a:<span class=\"hljs-number\">1</span>c:d4 brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">10.0.0.21</span>/<span class=\"hljs-number\">24</span> brd <span class=\"hljs-number\">10.0.0.255</span> scope global noprefixroute eno16777736<br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> fd56:a9ae:cb0f::<span class=\"hljs-number\">7</span>a1/<span class=\"hljs-number\">128</span> scope global noprefixroute dynamic <br>       <span class=\"hljs-attribute\">valid_lft</span> <span class=\"hljs-number\">29510</span>sec preferred_lft <span class=\"hljs-number\">29510</span>sec<br>    <span class=\"hljs-attribute\">inet6</span> fd56:a9ae:cb0f:<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">20</span>c:<span class=\"hljs-number\">29</span>ff:fe1a:<span class=\"hljs-number\">1</span>cd4/<span class=\"hljs-number\">64</span> scope global noprefixroute <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> fe80::<span class=\"hljs-number\">20</span>c:<span class=\"hljs-number\">29</span>ff:fe1a:<span class=\"hljs-number\">1</span>cd4/<span class=\"hljs-number\">64</span> scope link noprefixroute <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br><span class=\"hljs-attribute\">3</span>: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span class=\"hljs-number\">1500</span> qdisc noqueue state DOWN group default <br>    <span class=\"hljs-attribute\">link</span>/ether <span class=\"hljs-number\">02</span>:<span class=\"hljs-number\">42</span>:b8:ae:c9:<span class=\"hljs-number\">24</span> brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">172.17.0.1</span>/<span class=\"hljs-number\">16</span> brd <span class=\"hljs-number\">172.17.255.255</span> scope global docker0<br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br><span class=\"hljs-attribute\">4</span>: flannel.<span class=\"hljs-number\">1</span>: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class=\"hljs-number\">1450</span> qdisc noqueue state UNKNOWN group default <br>    <span class=\"hljs-attribute\">link</span>/ether <span class=\"hljs-number\">1</span>e:<span class=\"hljs-number\">6</span>d:<span class=\"hljs-number\">47</span>:<span class=\"hljs-number\">69</span>:f7:<span class=\"hljs-number\">6</span>a brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">10.244.1.0</span>/<span class=\"hljs-number\">32</span> scope global flannel.<span class=\"hljs-number\">1</span><br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> fe80::<span class=\"hljs-number\">1</span>c6d:<span class=\"hljs-number\">47</span>ff:fe69:f76a/<span class=\"hljs-number\">64</span> scope link <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br></code></pre></td></tr></table></figure>\n\n<p>node2 IP信息</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">1</span>: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span class=\"hljs-number\">65536</span> qdisc noqueue state UNKNOWN group default qlen <span class=\"hljs-number\">1000</span><br>    <span class=\"hljs-attribute\">link</span>/loopback <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> brd <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span><br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">127.0.0.1</span>/<span class=\"hljs-number\">8</span> scope host lo<br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> ::<span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">128</span> scope host <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br><span class=\"hljs-attribute\">2</span>: eno16777736: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class=\"hljs-number\">1500</span> qdisc pfifo_fast state UP group default qlen <span class=\"hljs-number\">1000</span><br>    <span class=\"hljs-attribute\">link</span>/ether <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">0</span>c:<span class=\"hljs-number\">29</span>:<span class=\"hljs-number\">67</span>:c3:<span class=\"hljs-number\">4</span>a brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">10.0.0.22</span>/<span class=\"hljs-number\">24</span> brd <span class=\"hljs-number\">10.0.0.255</span> scope global noprefixroute eno16777736<br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> fd56:a9ae:cb0f::<span class=\"hljs-number\">853</span>/<span class=\"hljs-number\">128</span> scope global noprefixroute dynamic <br>       <span class=\"hljs-attribute\">valid_lft</span> <span class=\"hljs-number\">29262</span>sec preferred_lft <span class=\"hljs-number\">29262</span>sec<br>    <span class=\"hljs-attribute\">inet6</span> fd56:a9ae:cb0f:<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">20</span>c:<span class=\"hljs-number\">29</span>ff:fe67:c34a/<span class=\"hljs-number\">64</span> scope global noprefixroute <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> fe80::<span class=\"hljs-number\">20</span>c:<span class=\"hljs-number\">29</span>ff:fe67:c34a/<span class=\"hljs-number\">64</span> scope link noprefixroute <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br><span class=\"hljs-attribute\">3</span>: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span class=\"hljs-number\">1500</span> qdisc noqueue state DOWN group default <br>    <span class=\"hljs-attribute\">link</span>/ether <span class=\"hljs-number\">02</span>:<span class=\"hljs-number\">42</span>:b2:<span class=\"hljs-number\">7</span>e:<span class=\"hljs-number\">58</span>:<span class=\"hljs-number\">1</span>f brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">172.17.0.1</span>/<span class=\"hljs-number\">16</span> brd <span class=\"hljs-number\">172.17.255.255</span> scope global docker0<br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br><span class=\"hljs-attribute\">4</span>: flannel.<span class=\"hljs-number\">1</span>: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class=\"hljs-number\">1450</span> qdisc noqueue state UNKNOWN group default <br>    <span class=\"hljs-attribute\">link</span>/ether <span class=\"hljs-number\">66</span>:<span class=\"hljs-number\">5</span>b:e2:<span class=\"hljs-number\">87</span>:<span class=\"hljs-number\">5</span>c:<span class=\"hljs-number\">22</span> brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">10.244.2.0</span>/<span class=\"hljs-number\">32</span> scope global flannel.<span class=\"hljs-number\">1</span><br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> fe80::<span class=\"hljs-number\">645</span>b:e2ff:fe87:<span class=\"hljs-number\">5</span>c22/<span class=\"hljs-number\">64</span> scope link <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br></code></pre></td></tr></table></figure>\n\n<p>7 测试kubernetes集群</p>\n<p>在Kubernetes集群中创建一个pod，验证是否正常运行：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">[root@k8s-master01 ~]<span class=\"hljs-comment\"># kubectl create deployment nginx --image=nginx</span><br>deployment.apps/nginx created<br>[root@k8s-master01 ~]<span class=\"hljs-comment\"># kubectl expose deployment nginx --port=80 --type=NodePort</span><br>service/nginx exposed<br>[root@k8s-master01 ~]<span class=\"hljs-comment\"># kubectl get pod,svc</span><br>NAME                         READY   STATUS              RESTARTS   AGE<br>pod<span class=\"hljs-regexp\">/nginx-6799fc88d8-zzsw7   0/</span><span class=\"hljs-number\">1</span>     ContainerCreating   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">31</span>s<br><br>NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE<br>service<span class=\"hljs-regexp\">/kubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/</span>TCP        <span class=\"hljs-number\">24</span>h<br>service<span class=\"hljs-regexp\">/nginx        NodePort    10.103.32.138   &lt;none&gt;        80:30029/</span>TCP   <span class=\"hljs-number\">13</span>s<br></code></pre></td></tr></table></figure>\n\n<p>访问地址：<a href=\"http://nodeip:Port/\">http://NodeIP:Port</a></p>\n<p>可以通过 <a href=\"http://10.0.0.21:31263/\">http://10.0.0.21:31263</a> 和 <a href=\"http://10.0.0.22:31263/\">http://10.0.0.22:31263</a> 访问</p>\n<h1 id=\"8-错误排查\"><a href=\"#8-错误排查\" class=\"headerlink\" title=\"8 错误排查\"></a>8 <strong>错误排查</strong></h1><p>启动日志获取</p>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\"><span class=\"hljs-comment\">#查看启动日志</span><br><span class=\"hljs-keyword\">journalctl </span>-f -u kubelet.service<br></code></pre></td></tr></table></figure>\n\n<p>配置加载与重启服务</p>\n<figure class=\"highlight nsis\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nsis\"><span class=\"hljs-params\">system</span>ctl daemon-reload &amp;&amp; <span class=\"hljs-params\">system</span>ctl restart kubelet<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"9-ipvs修改\"><a href=\"#9-ipvs修改\" class=\"headerlink\" title=\"9 ipvs修改\"></a>9 ipvs修改</h1><figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs vim\">kubectl <span class=\"hljs-keyword\">edit</span> configmap kube-proxy -n kube-<span class=\"hljs-built_in\">system</span><br>...<br><span class=\"hljs-number\">43</span>   <span class=\"hljs-keyword\">mode</span>: <span class=\"hljs-string\">&quot;ipvs&quot;</span><br>   ...<br></code></pre></td></tr></table></figure>\n\n<p><strong>删除pod,会自动拉起</strong></p>\n<figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gauss\">kubectl <span class=\"hljs-keyword\">delete</span> pod kube-proxy-btz4p -n kube-<span class=\"hljs-keyword\">system</span>  <br></code></pre></td></tr></table></figure>\n\n<p><strong>查看是否启用ipvs</strong></p>\n<figure class=\"highlight clean\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs clean\">kubectl logs kube-proxy-wwqbh -n kube-<span class=\"hljs-keyword\">system</span>        <br></code></pre></td></tr></table></figure>\n\n<p><strong>注：</strong></p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">1、 kube-proxy配置文件以configmap方式存储<br>2、 如果让所有节点生效，需要重建所有节点kube-proxy pod<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"10-问题及解决\"><a href=\"#10-问题及解决\" class=\"headerlink\" title=\"10 问题及解决\"></a>10 <strong>问题及解决</strong></h1><p>1 failed to find subsystem mount for required subsystem: pids failed to find subsystem mount for required subsystem: pids</p>\n<p>解决方法：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">vi <span class=\"hljs-regexp\">/usr/</span>lib<span class=\"hljs-regexp\">/systemd/</span>system<span class=\"hljs-regexp\">/kubelet.service.d/</span><span class=\"hljs-number\">10</span>-kubeadm.conf<br><span class=\"hljs-comment\">#发现ExecStart=后面添加参数</span><br>ExecStart=<span class=\"hljs-string\">&quot;--feature-gates SupportPodPidsLimit=false --feature-gates SupportNodePidsLimit=false&quot;</span><br><span class=\"hljs-comment\">#或者更改引用变量$KUBELET_EXTRA_ARGS</span><br>vi <span class=\"hljs-regexp\">/etc/</span>sysconfig/kubelet<br>KUBELET_EXTRA_ARGS=--feature-gates SupportPodPidsLimit=false --feature-gates SupportNodePidsLimit=false<br></code></pre></td></tr></table></figure>\n\n<p>2 kubelet cgroup driver: \\“systemd\\“ is different from docker cgroup driver: \\“cgroupfs\\“</p>\n<p>docker的驱动查看是否有systemd</p>\n<figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-attribute\">docker</span> <span class=\"hljs-literal\">info</span> |grep Cgroup<br></code></pre></td></tr></table></figure>\n\n<p>解决方案步骤如下：</p>\n<p>(1)、先修改docker的Cgroup Driver，修改/etc/docker/daemon.json文件</p>\n<figure class=\"highlight prolog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs prolog\">&#123;<br>  <span class=\"hljs-string\">&quot;exec-opts&quot;</span>: [<span class=\"hljs-string\">&quot;native.cgroupdriver=systemd&quot;</span>]<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>重启docker</p>\n<figure class=\"highlight nsis\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nsis\"><span class=\"hljs-params\">system</span>ctl daemon-reload<br><span class=\"hljs-params\">system</span>ctl restart docker<br></code></pre></td></tr></table></figure>\n\n<p>(2)、然后修改kubelet的Cgroup Driver<br>修改 “/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf ” 文件，增加（或修改成）“–cgroup-driver=systemd” (官方推荐用systemd)</p>\n<figure class=\"highlight abnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs abnf\"><span class=\"hljs-attribute\">Environment</span><span class=\"hljs-operator\">=</span><span class=\"hljs-string\">&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --cgroup-driver=systemd&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>修改 “/var/lib/kubelet/kubeadm-flags.env ”文件，增加（或修改成）“-–cgroup-driver=systemd”</p>\n<figure class=\"highlight brainfuck\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs brainfuck\"><span class=\"hljs-comment\">KUBELET_KUBEADM_ARGS=&quot;</span><span class=\"hljs-literal\">--</span><span class=\"hljs-comment\">cgroup</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">driver=systemd</span> <span class=\"hljs-literal\">--</span><span class=\"hljs-comment\">network</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">plugin=cni</span> <span class=\"hljs-literal\">--</span><span class=\"hljs-comment\">pod</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">infra</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">container</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">image=registry</span><span class=\"hljs-string\">.</span><span class=\"hljs-comment\">aliyuncs</span><span class=\"hljs-string\">.</span><span class=\"hljs-comment\">com/google_containers/pause:3</span><span class=\"hljs-string\">.</span><span class=\"hljs-comment\">2&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>重启：</p>\n<figure class=\"highlight nsis\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nsis\"><span class=\"hljs-params\">system</span>ctl daemon-reload<br><span class=\"hljs-params\">system</span>ctl restart kubelet<br></code></pre></td></tr></table></figure>\n<p>3 missing required cgroups: cpu</p>\n<p>修改<code>/etc/default/grub</code></p>\n<p>添加一行<code>GRUB_CMDLINE_LINUX=&quot;cgroup_enable=cpu&quot;</code></p>\n<p>运行 <code>update-grub2</code></p>\n<p>重启机器 <code>reboot</code></p>\n<p>4  Failed to start CRI Interface for Docker Application Container Engine Defined-By: systemd</p>\n<figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs livecodeserver\"><span class=\"hljs-number\">7</span>月 <span class=\"hljs-number\">29</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">35</span>:<span class=\"hljs-number\">14</span> k8s-master02 systemd[<span class=\"hljs-number\">1</span>]: cri-docker.service: main <span class=\"hljs-built_in\">process</span> exited, code=exited, status=<span class=\"hljs-number\">203</span>/EXEC<br><span class=\"hljs-number\">7</span>月 <span class=\"hljs-number\">29</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">35</span>:<span class=\"hljs-number\">14</span> k8s-master02 systemd[<span class=\"hljs-number\">1</span>]: Failed <span class=\"hljs-built_in\">to</span> <span class=\"hljs-built_in\">start</span> CRI Interface <span class=\"hljs-keyword\">for</span> Docker Application Container Engine.<br><span class=\"hljs-comment\">-- Subject: Unit cri-docker.service has failed</span><br><span class=\"hljs-comment\">-- Defined-By: systemd</span><br><span class=\"hljs-comment\">-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel</span><br><span class=\"hljs-comment\">-- </span><br><span class=\"hljs-comment\">-- Unit cri-docker.service has failed.</span><br><span class=\"hljs-comment\">-- </span><br><span class=\"hljs-comment\">-- The result is failed.</span><br><span class=\"hljs-number\">7</span>月 <span class=\"hljs-number\">29</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">35</span>:<span class=\"hljs-number\">14</span> k8s-master02 systemd[<span class=\"hljs-number\">1</span>]: Unit cri-docker.service entered failed state.<br><span class=\"hljs-number\">7</span>月 <span class=\"hljs-number\">29</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">35</span>:<span class=\"hljs-number\">14</span> k8s-master02 systemd[<span class=\"hljs-number\">1</span>]: cri-docker.service failed.<br></code></pre></td></tr></table></figure>\n\n<p>修改 docker 控制组</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">vi <span class=\"hljs-regexp\">/etc/</span>docker/daemon.json <br>&#123;<br>  <span class=\"hljs-string\">&quot;exec-opts&quot;</span>: [<span class=\"hljs-string\">&quot;native.cgroupdriver=systemd&quot;</span>]<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>从重启服务</p>\n<figure class=\"highlight nsis\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nsis\"><span class=\"hljs-params\">system</span>ctl daemon-reload<br><span class=\"hljs-params\">system</span>ctl restart docker<br><span class=\"hljs-params\">system</span>ctl restart cri-docker<br></code></pre></td></tr></table></figure>\n\n<p>5  error execution phase preflight: couldn’t validate the identity of the API Server: Get “<a href=\"https://10.0.0.150:16443/api/v1/namespaces/kube-public/configmaps/cluster-info?timeout=10s&quot;\">https://10.0.0.150:16443/api/v1/namespaces/kube-public/configmaps/cluster-info?timeout=10s&quot;</a>: x509: certificate has expired or is not yet valid: current time 2022-07-30T16:12:40+08:00 is before 2022-07-30T13:31:36Z</p>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">yum <span class=\"hljs-keyword\">install </span>ntpdate -y<br>ntpdate time.windows.com<br><span class=\"hljs-comment\"># 强制把系统时间写入CMOS</span><br><span class=\"hljs-keyword\">clock </span>-w<br></code></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"kubeadm快速部署kubernetes集群\"><a href=\"#kubeadm快速部署kubernetes集群\" class=\"headerlink\" title=\"kubeadm快速部署kubernetes集群\"></a>kubeadm快速部署kubernetes集群</h1><h1 id=\"1-安装要求\"><a href=\"#1-安装要求\" class=\"headerlink\" title=\"1 安装要求\"></a>1 安装要求</h1><ul>\n<li>一台或多台机器，操作系统 CentOS7.x-86_x64</li>\n<li>硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多(master必须2cpu,node可以不用)</li>\n<li>可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点</li>\n<li>禁止swap分区</li>\n</ul>\n<p><a href=\"https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\">安装 kubeadm | Kubernetes</a></p>\n<h1 id=\"2-准备环境\"><a href=\"#2-准备环境\" class=\"headerlink\" title=\"2 准备环境\"></a>2 准备环境</h1><table>\n<thead>\n<tr>\n<th>角色</th>\n<th>IP</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>master</td>\n<td>192.168.66.11</td>\n</tr>\n<tr>\n<td>node1</td>\n<td>192.168.66.21</td>\n</tr>\n<tr>\n<td>node2</td>\n<td>192.168.66.22</td>\n</tr>\n</tbody></table>\n<figure class=\"highlight stata\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stata\">yum <span class=\"hljs-keyword\">update</span> -y<br>yum install -y firewalld ntpdate <span class=\"hljs-keyword\">net</span>-tools ipvsadm wget<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-1-关闭防火墙及selinux\"><a href=\"#2-1-关闭防火墙及selinux\" class=\"headerlink\" title=\"2.1 关闭防火墙及selinux\"></a>2.1 关闭防火墙及selinux</h2><p>所有节点执行一下命令</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\"><span class=\"hljs-comment\"># 关闭防火墙</span><br>systemctl stop firewalld<br>systemctl <span class=\"hljs-built_in\">disable</span> firewalld<br><br><span class=\"hljs-comment\"># 关闭selinux</span><br><span class=\"hljs-comment\"># 永久</span><br>sed -i <span class=\"hljs-string\">&#x27;s/enforcing/disabled/&#x27;</span> /etc/selinux<span class=\"hljs-built_in\">/config </span> <br><span class=\"hljs-comment\"># 临时</span><br>setenforce 0  <br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-2-关闭swap\"><a href=\"#2-2-关闭swap\" class=\"headerlink\" title=\"2.2 关闭swap\"></a>2.2 关闭swap</h2><p>所有节点执行一下命令</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-comment\"># 关闭swap</span><br><span class=\"hljs-comment\"># 临时</span><br>swapoff -a  <br><span class=\"hljs-comment\"># 永久</span><br>sed -ri <span class=\"hljs-string\">&#x27;s/.*swap.*/#&amp;/&#x27;</span> <span class=\"hljs-regexp\">/etc/</span>fstab    <br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-3-根据规划设置主机名及hosts\"><a href=\"#2-3-根据规划设置主机名及hosts\" class=\"headerlink\" title=\"2.3 根据规划设置主机名及hosts\"></a>2.3 根据规划设置主机名及hosts</h2><p>所有节点执行hostnamectl set-hostname <hostname>命令</p>\n<figure class=\"highlight dsconfig\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dsconfig\"><span class=\"hljs-comment\"># k8smaster节点执行</span><br><span class=\"hljs-string\">hostnamectl</span> <span class=\"hljs-built_in\">set-hostname</span> <span class=\"hljs-string\">k8s-master01</span><br><span class=\"hljs-comment\"># k8snode1节点执行</span><br><span class=\"hljs-string\">hostnamectl</span> <span class=\"hljs-built_in\">set-hostname</span> <span class=\"hljs-string\">k8s-node01</span><br><span class=\"hljs-comment\"># k8snode2节点执行</span><br><span class=\"hljs-string\">hostnamectl</span> <span class=\"hljs-built_in\">set-hostname</span> <span class=\"hljs-string\">k8s-node02</span><br></code></pre></td></tr></table></figure>\n\n<p>k8smaster主节点执行</p>\n<figure class=\"highlight accesslog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs accesslog\">cat &gt;&gt; /etc/hosts &lt;&lt; EOF<br><span class=\"hljs-number\">192.168.66.11</span> k8s-master01<br><span class=\"hljs-number\">192.168.66.21</span> k8s-node01<br><span class=\"hljs-number\">192.168.66.22</span> k8s-node02<br>EOF<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-4-将桥接的IPv4流量传递到iptables的链\"><a href=\"#2-4-将桥接的IPv4流量传递到iptables的链\" class=\"headerlink\" title=\"2.4 将桥接的IPv4流量传递到iptables的链\"></a>2.4 将桥接的IPv4流量传递到iptables的链</h2><p>确保 <code>br_netfilter</code> 模块被加载。这一操作可以通过运行 <code>lsmod | grep br_netfilter</code> 来完成。若要显式加载该模块，可执行 <code>sudo modprobe br_netfilter</code>。 </p>\n<p>确保在你的 <code>sysctl</code> 配置中将 <code>net.bridge.bridge-nf-call-iptables</code> 设置为 1。 </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\"><span class=\"hljs-built_in\">cat</span> &lt;&lt;<span class=\"hljs-string\">EOF | sudo tee /etc/modules-load.d/k8s.conf</span><br><span class=\"hljs-string\">br_netfilter</span><br><span class=\"hljs-string\">EOF</span><br><br><span class=\"hljs-comment\">#将桥接的IPv4流量传递到iptables的链</span><br><span class=\"hljs-built_in\">cat</span> &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class=\"hljs-string\">EOF</span><br><span class=\"hljs-string\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"hljs-string\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"hljs-string\">EOF</span><br><span class=\"hljs-comment\"># 生效</span><br>sysctl --system  <br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-5-时间同步\"><a href=\"#2-5-时间同步\" class=\"headerlink\" title=\"2.5 时间同步\"></a>2.5 时间同步</h2><p>所有节点执行一下命令</p>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">yum <span class=\"hljs-keyword\">install </span>ntpdate -y<br>ntpdate time.windows.com<br><span class=\"hljs-comment\"># 强制把系统时间写入CMOS</span><br><span class=\"hljs-keyword\">clock </span>-w<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"3-所有节点安装Docker-kubeadm-kubelet\"><a href=\"#3-所有节点安装Docker-kubeadm-kubelet\" class=\"headerlink\" title=\"3 所有节点安装Docker/kubeadm/kubelet\"></a>3 所有节点安装Docker/kubeadm/kubelet</h1><h2 id=\"3-1-安装Docker\"><a href=\"#3-1-安装Docker\" class=\"headerlink\" title=\"3.1 安装Docker\"></a>3.1 安装Docker</h2><p>k8snode1和k8snode2下安装docker</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">wget https:<span class=\"hljs-regexp\">//mi</span>rrors.aliyun.com<span class=\"hljs-regexp\">/docker-ce/</span>linux<span class=\"hljs-regexp\">/centos/</span>docker-ce.repo -O <span class=\"hljs-regexp\">/etc/yum</span>.repos.d/docker-ce.repo<br>yum -y install docker-ce-<span class=\"hljs-number\">18.06</span>.<span class=\"hljs-number\">1</span>.ce-<span class=\"hljs-number\">3</span>.el7<br>systemctl enable docker &amp;&amp; systemctl start docker<br>docker --version<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"3-2-配置docker镜像加速\"><a href=\"#3-2-配置docker镜像加速\" class=\"headerlink\" title=\"3.2 配置docker镜像加速\"></a>3.2 配置docker镜像加速</h2><img src=\"/2021/08/04/kubeadm%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2kubernetes%E9%9B%86%E7%BE%A4/1629031322356.png\" class=\"\" title=\"img\">\n\n<figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\">cat &gt; /etc/docker/daemon<span class=\"hljs-selector-class\">.json</span> &lt;&lt; EOF<br>&#123;<br>  <span class=\"hljs-string\">&quot;registry-mirrors&quot;</span>: <span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">&quot;https://onozxvpe.mirror.aliyuncs.com&quot;</span>,<span class=\"hljs-string\">&quot;http://hub-mirror.c.163.com&quot;</span>, <span class=\"hljs-string\">&quot;https://registry.docker-cn.com&quot;</span>]</span>,<br>  <span class=\"hljs-string\">&quot;exec-opts&quot;</span>: <span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">&quot;native.cgroupdriver=systemd&quot;</span>]</span><br>&#125;<br>EOF<br></code></pre></td></tr></table></figure>\n\n<p>添加镜像加入和本地搭建harbor后：</p>\n<figure class=\"highlight prolog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs prolog\">&#123;<br>  <span class=\"hljs-string\">&quot;registry-mirrors&quot;</span>: [<span class=\"hljs-string\">&quot;https://onozxvpe.mirror.aliyuncs.com&quot;</span>],<br>  <span class=\"hljs-string\">&quot;exec-opts&quot;</span>: [<span class=\"hljs-string\">&quot;native.cgroupdriver=systemd&quot;</span>],<br>  <span class=\"hljs-string\">&quot;insecure-registries&quot;</span>: [<span class=\"hljs-string\">&quot;harborcloud.com&quot;</span>]<br>&#125;<br></code></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"3-3-添加阿里云YUM软件源\"><a href=\"#3-3-添加阿里云YUM软件源\" class=\"headerlink\" title=\"3.3 添加阿里云YUM软件源\"></a>3.3 添加阿里云YUM软件源</h2><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">cat &gt; <span class=\"hljs-regexp\">/etc/yum</span>.repos.d/kubernetes.repo &lt;&lt; EOF<br>[kubernetes]<br>name=Kubernetes<br>baseurl=https:<span class=\"hljs-regexp\">//mi</span>rrors.aliyun.com<span class=\"hljs-regexp\">/kubernetes/yum</span><span class=\"hljs-regexp\">/repos/</span>kubernetes-el7-x86_64<br>enabled=<span class=\"hljs-number\">1</span><br>gpgcheck=<span class=\"hljs-number\">0</span><br>repo_gpgcheck=<span class=\"hljs-number\">0</span><br>gpgkey=https:<span class=\"hljs-regexp\">//mi</span>rrors.aliyun.com<span class=\"hljs-regexp\">/kubernetes/yum</span><span class=\"hljs-regexp\">/doc/yum</span>-key.gpg https:<span class=\"hljs-regexp\">//mi</span>rrors.aliyun.com<span class=\"hljs-regexp\">/kubernetes/yum</span><span class=\"hljs-regexp\">/doc/</span>rpm-package-key.gpg<br>EOF<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"3-4-安装kubeadm，kubelet和kubectl\"><a href=\"#3-4-安装kubeadm，kubelet和kubectl\" class=\"headerlink\" title=\"3.4 安装kubeadm，kubelet和kubectl\"></a>3.4 安装kubeadm，kubelet和kubectl</h2><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">yum</span> install -y kubeadm-<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">22</span>.<span class=\"hljs-number\">0</span> kubectl-<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">22</span>.<span class=\"hljs-number\">0</span> kubelet-<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">22</span>.<span class=\"hljs-number\">0</span><br><span class=\"hljs-attribute\">systemctl</span> enable kubelet<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"4-部署Kubernetes-Master\"><a href=\"#4-部署Kubernetes-Master\" class=\"headerlink\" title=\"4 部署Kubernetes Master\"></a>4 部署Kubernetes Master</h1><p><a href=\"https://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/kubeadm-init/\">https://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/kubeadm-init/</a></p>\n<p>在192.168.66.10（k8smaster）执行。</p>\n<p>由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址</p>\n<p><strong>–pod-network-cidr</strong></p>\n<p>指定pod网络的IP地址范围。 设置后，控制平面将自动为每个节点分配cidr。</p>\n<p><strong>–service-cidr</strong></p>\n<p>集群内部虚拟网络，Pod统一访问入口</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubeadm init \\<br><span class=\"hljs-attribute\">--apiserver-advertise-address</span>=192.168.66.10 \\<br>--image-repository registry.aliyuncs.com/google_containers \\<br>--kubernetes-version v1.22.0 \\<br><span class=\"hljs-attribute\">--service-cidr</span>=10.96.0.0/12 \\<br><span class=\"hljs-attribute\">--pod-network-cidr</span>=10.244.0.0/16<br></code></pre></td></tr></table></figure>\n\n<p>执行结果</p>\n<figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\"><span class=\"hljs-selector-attr\">[init]</span> Using Kubernetes version: v1.<span class=\"hljs-number\">22.0</span><br><span class=\"hljs-selector-attr\">[preflight]</span> Running pre-flight checks<br><span class=\"hljs-selector-attr\">[preflight]</span> Pulling images required <span class=\"hljs-keyword\">for</span> setting up <span class=\"hljs-selector-tag\">a</span> Kubernetes cluster<br><span class=\"hljs-selector-attr\">[preflight]</span> This might take <span class=\"hljs-selector-tag\">a</span> minute or two, depending on the speed of your internet connection<br><span class=\"hljs-selector-attr\">[preflight]</span> You can also perform this action <span class=\"hljs-keyword\">in</span> beforehand using <span class=\"hljs-string\">&#x27;kubeadm config images pull&#x27;</span><br><span class=\"hljs-selector-attr\">[certs]</span> Using certificateDir folder <span class=\"hljs-string\">&quot;/etc/kubernetes/pki&quot;</span><br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;ca&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;apiserver&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> apiserver serving cert is signed <span class=\"hljs-keyword\">for</span> DNS names <span class=\"hljs-selector-attr\">[k8s-master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local]</span> and IPs <span class=\"hljs-selector-attr\">[10.96.0.1 192.168.66.11]</span><br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;apiserver-kubelet-client&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;front-proxy-ca&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;front-proxy-client&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;etcd/ca&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;etcd/server&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> etcd/server serving cert is signed <span class=\"hljs-keyword\">for</span> DNS names <span class=\"hljs-selector-attr\">[k8s-master01 localhost]</span> and IPs <span class=\"hljs-selector-attr\">[192.168.66.11 127.0.0.1 ::1]</span><br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;etcd/peer&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> etcd/peer serving cert is signed <span class=\"hljs-keyword\">for</span> DNS names <span class=\"hljs-selector-attr\">[k8s-master01 localhost]</span> and IPs <span class=\"hljs-selector-attr\">[192.168.66.11 127.0.0.1 ::1]</span><br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;etcd/healthcheck-client&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;apiserver-etcd-client&quot;</span> certificate and key<br><span class=\"hljs-selector-attr\">[certs]</span> Generating <span class=\"hljs-string\">&quot;sa&quot;</span> key and public key<br><span class=\"hljs-selector-attr\">[kubeconfig]</span> Using kubeconfig folder <span class=\"hljs-string\">&quot;/etc/kubernetes&quot;</span><br><span class=\"hljs-selector-attr\">[kubeconfig]</span> Writing <span class=\"hljs-string\">&quot;admin.conf&quot;</span> kubeconfig file<br><span class=\"hljs-selector-attr\">[kubeconfig]</span> Writing <span class=\"hljs-string\">&quot;kubelet.conf&quot;</span> kubeconfig file<br><span class=\"hljs-selector-attr\">[kubeconfig]</span> Writing <span class=\"hljs-string\">&quot;controller-manager.conf&quot;</span> kubeconfig file<br><span class=\"hljs-selector-attr\">[kubeconfig]</span> Writing <span class=\"hljs-string\">&quot;scheduler.conf&quot;</span> kubeconfig file<br><span class=\"hljs-selector-attr\">[kubelet-start]</span> Writing kubelet environment file with flags to file <span class=\"hljs-string\">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class=\"hljs-selector-attr\">[kubelet-start]</span> Writing kubelet configuration to file <span class=\"hljs-string\">&quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class=\"hljs-selector-attr\">[kubelet-start]</span> Starting the kubelet<br><span class=\"hljs-selector-attr\">[control-plane]</span> Using manifest folder <span class=\"hljs-string\">&quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"hljs-selector-attr\">[control-plane]</span> Creating static Pod manifest <span class=\"hljs-keyword\">for</span> <span class=\"hljs-string\">&quot;kube-apiserver&quot;</span><br><span class=\"hljs-selector-attr\">[control-plane]</span> Creating static Pod manifest <span class=\"hljs-keyword\">for</span> <span class=\"hljs-string\">&quot;kube-controller-manager&quot;</span><br><span class=\"hljs-selector-attr\">[control-plane]</span> Creating static Pod manifest <span class=\"hljs-keyword\">for</span> <span class=\"hljs-string\">&quot;kube-scheduler&quot;</span><br><span class=\"hljs-selector-attr\">[etcd]</span> Creating static Pod manifest <span class=\"hljs-keyword\">for</span> local etcd <span class=\"hljs-keyword\">in</span> <span class=\"hljs-string\">&quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"hljs-selector-attr\">[wait-control-plane]</span> Waiting <span class=\"hljs-keyword\">for</span> the kubelet to boot up the control plane as static Pods from directory <span class=\"hljs-string\">&quot;/etc/kubernetes/manifests&quot;</span>. This can take up to <span class=\"hljs-number\">4</span>m0s<br><span class=\"hljs-selector-attr\">[apiclient]</span> All control plane components are healthy after <span class=\"hljs-number\">12.003757</span> seconds<br><span class=\"hljs-selector-attr\">[upload-config]</span> Storing the configuration used <span class=\"hljs-keyword\">in</span> ConfigMap <span class=\"hljs-string\">&quot;kubeadm-config&quot;</span> <span class=\"hljs-keyword\">in</span> the <span class=\"hljs-string\">&quot;kube-system&quot;</span> Namespace<br><span class=\"hljs-selector-attr\">[kubelet]</span> Creating <span class=\"hljs-selector-tag\">a</span> ConfigMap <span class=\"hljs-string\">&quot;kubelet-config-1.22&quot;</span> <span class=\"hljs-keyword\">in</span> namespace kube-system with the configuration <span class=\"hljs-keyword\">for</span> the kubelets <span class=\"hljs-keyword\">in</span> the cluster<br><span class=\"hljs-selector-attr\">[upload-certs]</span> Skipping phase. Please see <span class=\"hljs-attr\">--upload-certs</span><br><span class=\"hljs-selector-attr\">[mark-control-plane]</span> Marking the node k8s-master01 as control-plane by adding the labels: <span class=\"hljs-selector-attr\">[node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]</span><br><span class=\"hljs-selector-attr\">[mark-control-plane]</span> Marking the node k8s-master01 as control-plane by adding the taints <span class=\"hljs-selector-attr\">[node-role.kubernetes.io/master:NoSchedule]</span><br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> Using token: ii3pse<span class=\"hljs-selector-class\">.bfxj9fqc9tvz6yrr</span><br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles<br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> configured RBAC rules to allow Node Bootstrap tokens to get nodes<br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> configured RBAC rules to allow Node Bootstrap tokens to post CSRs <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attribute\">order</span> for nodes to get long term certificate credentials<br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> configured RBAC rules to allow the csrapprover controller automatically approve CSRs from <span class=\"hljs-selector-tag\">a</span> Node Bootstrap Token<br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> configured RBAC rules to allow certificate rotation <span class=\"hljs-keyword\">for</span> <span class=\"hljs-attribute\">all</span> node client certificates in the cluster<br><span class=\"hljs-selector-attr\">[bootstrap-token]</span> Creating the <span class=\"hljs-string\">&quot;cluster-info&quot;</span> ConfigMap <span class=\"hljs-keyword\">in</span> the <span class=\"hljs-string\">&quot;kube-public&quot;</span> namespace<br><span class=\"hljs-selector-attr\">[kubelet-finalize]</span> Updating <span class=\"hljs-string\">&quot;/etc/kubernetes/kubelet.conf&quot;</span> to point to <span class=\"hljs-selector-tag\">a</span> rotatable kubelet client certificate and key<br><span class=\"hljs-selector-attr\">[addons]</span> Applied essential addon: CoreDNS<br><span class=\"hljs-selector-attr\">[addons]</span> Applied essential addon: kube-proxy<br><br>Your Kubernetes control-plane has initialized successfully!<br><br>To start using your cluster, you need to run the following as <span class=\"hljs-selector-tag\">a</span> regular user:<br><br>  mkdir -<span class=\"hljs-selector-tag\">p</span> <span class=\"hljs-variable\">$HOME</span>/<span class=\"hljs-selector-class\">.kube</span><br>  sudo cp -<span class=\"hljs-selector-tag\">i</span> /etc/kubernetes/admin<span class=\"hljs-selector-class\">.conf</span> <span class=\"hljs-variable\">$HOME</span>/.kube/config<br>  sudo chown $(id -u):$(id -g) <span class=\"hljs-variable\">$HOME</span>/.kube/config<br><br>Alternatively, <span class=\"hljs-keyword\">if</span> you are the root user, you can run:<br><br>  export KUBECONFIG=/etc/kubernetes/admin<span class=\"hljs-selector-class\">.conf</span><br><br>You should now deploy <span class=\"hljs-selector-tag\">a</span> pod network to the cluster.<br>Run <span class=\"hljs-string\">&quot;kubectl apply -f [podnetwork].yaml&quot;</span> with one of the options listed at:<br>  https:<span class=\"hljs-comment\">//kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><br>Then you can join any number of worker nodes by running the following on each as root:<br><br>kubeadm join <span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">66.11</span>:<span class=\"hljs-number\">6443</span> <span class=\"hljs-attr\">--token</span> ii3pse<span class=\"hljs-selector-class\">.bfxj9fqc9tvz6yrr</span> \\<br>        <span class=\"hljs-attr\">--discovery-token-ca-cert-hash</span> sha256:<span class=\"hljs-number\">643</span>b48706d97589356e2a4be7294a898ac9a909baa56fecca277b7b4e5634e0e <br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>preflight，系统前置检查</li>\n<li>certs 各种证书的文件生成</li>\n<li>kubeconfig生成kubeconfig文件，主要是kubenetes的几大组件的配置文件。</li>\n<li>kubelet-start 启动kubelet</li>\n<li>control-plane 生成所有静态pod的manifest文件，这些静态pod组成了kubenetes的控制面板，apiserver，controller，scheduler，生成这个文件后，kubelet会自动依据此文件描述的信息拉起镜像</li>\n<li>etcd 生成etcd的manifest</li>\n<li>upload-config 上传kubeadm和kubelet的配置文件到configmap中</li>\n<li>upload-certs 上传配置证书文件</li>\n<li>mark-control-plane mark一个node作为控制台</li>\n<li>bootstrap-token 生成bootstrap tokens用于把node节点加入到集群。</li>\n<li>kubelet-finalize 更新kubelet的设置</li>\n<li>addon 安装其他的相关组件。主要是网络组件dns和kube-proxy</li>\n</ul>\n<p>所有node执行：</p>\n<p>注：<code>kubectl</code> 在 <code>$HOME/.kube</code> 目录中查找一个名为 <code>config</code> 的配置文件。 你可以通过设置 KUBECONFIG 环境变量或设置 <a href=\"https://kubernetes.io/zh/docs/concepts/configuration/organize-cluster-access-kubeconfig/\"><code>--kubeconfig</code></a> 参数来指定其它 <a href=\"https://kubernetes.io/zh/docs/concepts/configuration/organize-cluster-access-kubeconfig/\">kubeconfig</a> 文件。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\"><span class=\"hljs-built_in\">mkdir</span> -p <span class=\"hljs-variable\">$HOME</span>/.kube<br>sudo <span class=\"hljs-built_in\">cp</span> -i /etc/kubernetes/admin.conf <span class=\"hljs-variable\">$HOME</span>/.kube/config<br>sudo <span class=\"hljs-built_in\">chown</span> $(<span class=\"hljs-built_in\">id</span> -u):$(<span class=\"hljs-built_in\">id</span> -g) <span class=\"hljs-variable\">$HOME</span>/.kube/config<br>$ kubectl get nodes<br></code></pre></td></tr></table></figure>\n\n<p>如果出现错误通过一下命令重置</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">kubeadm reset</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"5-加入Kubernetes-Node\"><a href=\"#5-加入Kubernetes-Node\" class=\"headerlink\" title=\"5 加入Kubernetes Node\"></a>5 加入Kubernetes Node</h1><p>执行上面kubeadm init后显示的信息提示，加入kubernates</p>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">kubeadm <span class=\"hljs-keyword\">join </span><span class=\"hljs-number\">192</span>.<span class=\"hljs-number\">168</span>.<span class=\"hljs-number\">66</span>.<span class=\"hljs-number\">11</span>:<span class=\"hljs-number\">6443</span> --token ii3pse.<span class=\"hljs-keyword\">bfxj9fqc9tvz6yrr </span>\\<br>        --<span class=\"hljs-keyword\">discovery-token-ca-cert-hash </span><span class=\"hljs-keyword\">sha256:643b48706d97589356e2a4be7294a898ac9a909baa56fecca277b7b4e5634e0e</span><br></code></pre></td></tr></table></figure>\n\n<p>默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，操作如下：</p>\n<figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gauss\">kubeadm <span class=\"hljs-built_in\">token</span> <span class=\"hljs-keyword\">create</span> --<span class=\"hljs-keyword\">print</span>-join-command<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"6-部署CNI网络插件\"><a href=\"#6-部署CNI网络插件\" class=\"headerlink\" title=\"6 部署CNI网络插件\"></a>6 部署CNI网络插件</h1><img src=\"/2021/08/04/kubeadm%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2kubernetes%E9%9B%86%E7%BE%A4/image-25.png\" class=\"\" title=\"img\">\n\n<p>这里可能需要代理下载，可以先下载下来</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">$ kubectl apply -f https:<span class=\"hljs-regexp\">//</span>raw.githubusercontent.com<span class=\"hljs-regexp\">/coreos/</span>flannel<span class=\"hljs-regexp\">/master/</span>Documentation/kube-flannel.yml<br>$ kubectl get pods -n kube-system<br>NAME                          READY   STATUS    RESTARTS   AGE<br>kube-flannel-ds-amd64-<span class=\"hljs-number\">2</span>pc95   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">72</span>s<br></code></pre></td></tr></table></figure>\n\n<img src=\"/2021/08/04/kubeadm%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2kubernetes%E9%9B%86%E7%BE%A4/image-26.png\" class=\"\" title=\"img\">\n\n<p><strong>Flannel工作原理</strong></p>\n<p>k8s网络通讯方式：<a href=\"http://jishu.youhang.site/25.html\">k8s网络通讯方式 – 青叶水间 (youhang.site)</a></p>\n<p>每个主机配置一个ip段和子网个数。 例如，可以配置一个覆盖网络使用 10.244.0.0/16段，每个主机/24个子网。因此主机a可以接受10.244.1.0/24，主机B可以接受10.244.2.0/24的包。flannel使用etcd来维护分配的子网到实际的ip地址之间的映射。</p>\n<p>master IP信息：</p>\n<figure class=\"highlight pf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pf\">[root@k8s-master01 ~]<span class=\"hljs-comment\"># ip addr</span><br><span class=\"hljs-number\">1</span>: lo: <span class=\"hljs-variable\">&lt;LOOPBACK,UP,LOWER_UP&gt;</span> mtu <span class=\"hljs-number\">65536</span> qdisc noqueue <span class=\"hljs-keyword\">state</span> UNKNOWN <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> qlen <span class=\"hljs-number\">1000</span><br>    link/loopback <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> brd <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span><br>    <span class=\"hljs-keyword\">inet</span> <span class=\"hljs-number\">127.0</span>.<span class=\"hljs-number\">0.1</span>/<span class=\"hljs-number\">8</span> scope host lo<br>       valid_lft forever preferred_lft forever<br>    <span class=\"hljs-keyword\">inet6</span> ::<span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">128</span> scope host <br>       valid_lft forever preferred_lft forever<br><span class=\"hljs-number\">2</span>: eno16777736: <span class=\"hljs-variable\">&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span> mtu <span class=\"hljs-number\">1500</span> qdisc pfifo_fast <span class=\"hljs-keyword\">state</span> UP <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> qlen <span class=\"hljs-number\">1000</span><br>    link/ether <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">0</span>c:<span class=\"hljs-number\">29</span>:<span class=\"hljs-number\">6</span>b:de:b6 brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-keyword\">inet</span> <span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">66.11</span>/<span class=\"hljs-number\">24</span> brd <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.255</span> scope <span class=\"hljs-keyword\">global</span> noprefixroute eno16777736<br>       valid_lft forever preferred_lft forever<br>    <span class=\"hljs-keyword\">inet6</span> fd56:a9ae:cb0f::a49/<span class=\"hljs-number\">128</span> scope <span class=\"hljs-keyword\">global</span> noprefixroute dynamic <br>       valid_lft <span class=\"hljs-number\">29570</span>sec preferred_lft <span class=\"hljs-number\">29570</span>sec<br>    <span class=\"hljs-keyword\">inet6</span> fd56:a9ae:cb0f:<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">20</span>c:<span class=\"hljs-number\">29</span>ff:fe6b:deb6/<span class=\"hljs-number\">64</span> scope <span class=\"hljs-keyword\">global</span> noprefixroute <br>       valid_lft forever preferred_lft forever<br>    <span class=\"hljs-keyword\">inet6</span> fe80::<span class=\"hljs-number\">20</span>c:<span class=\"hljs-number\">29</span>ff:fe6b:deb6/<span class=\"hljs-number\">64</span> scope link noprefixroute <br>       valid_lft forever preferred_lft forever<br><span class=\"hljs-number\">3</span>: docker0: <span class=\"hljs-variable\">&lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt;</span> mtu <span class=\"hljs-number\">1500</span> qdisc noqueue <span class=\"hljs-keyword\">state</span> DOWN <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> <br>    link/ether <span class=\"hljs-number\">02</span>:<span class=\"hljs-number\">42</span>:f0:df:d5:af brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-keyword\">inet</span> <span class=\"hljs-number\">172.17</span>.<span class=\"hljs-number\">0.1</span>/<span class=\"hljs-number\">16</span> brd <span class=\"hljs-number\">172.17</span>.<span class=\"hljs-number\">255.255</span> scope <span class=\"hljs-keyword\">global</span> docker0<br>       valid_lft forever preferred_lft forever<br><span class=\"hljs-number\">4</span>: flannel.<span class=\"hljs-number\">1</span>: <span class=\"hljs-variable\">&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span> mtu <span class=\"hljs-number\">1450</span> qdisc noqueue <span class=\"hljs-keyword\">state</span> UNKNOWN <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> <br>    link/ether <span class=\"hljs-number\">8</span>e:<span class=\"hljs-number\">53</span>:a8:<span class=\"hljs-number\">6</span>d:<span class=\"hljs-number\">99</span>:<span class=\"hljs-number\">1</span>e brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-keyword\">inet</span> <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.0</span>/<span class=\"hljs-number\">32</span> scope <span class=\"hljs-keyword\">global</span> flannel.<span class=\"hljs-number\">1</span><br>       valid_lft forever preferred_lft forever<br>    <span class=\"hljs-keyword\">inet6</span> fe80::<span class=\"hljs-number\">8</span>c53:a8ff:fe6d:<span class=\"hljs-number\">991</span>e/<span class=\"hljs-number\">64</span> scope link <br>       valid_lft forever preferred_lft forever<br><span class=\"hljs-number\">5</span>: cni0: <span class=\"hljs-variable\">&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span> mtu <span class=\"hljs-number\">1450</span> qdisc noqueue <span class=\"hljs-keyword\">state</span> UP <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> qlen <span class=\"hljs-number\">1000</span><br>    link/ether <span class=\"hljs-number\">7</span>a:<span class=\"hljs-number\">33</span>:a2:<span class=\"hljs-number\">1</span>a:<span class=\"hljs-number\">15</span>:<span class=\"hljs-number\">65</span> brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-keyword\">inet</span> <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.1</span>/<span class=\"hljs-number\">24</span> brd <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.255</span> scope <span class=\"hljs-keyword\">global</span> cni0<br>       valid_lft forever preferred_lft forever<br>    <span class=\"hljs-keyword\">inet6</span> fe80::<span class=\"hljs-number\">7833</span>:a2ff:fe1a:<span class=\"hljs-number\">1565</span>/<span class=\"hljs-number\">64</span> scope link <br>       valid_lft forever preferred_lft forever<br><span class=\"hljs-number\">6</span>: vethefc85590@if3: <span class=\"hljs-variable\">&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span> mtu <span class=\"hljs-number\">1450</span> qdisc noqueue master cni0 <span class=\"hljs-keyword\">state</span> UP <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> <br>    link/ether <span class=\"hljs-number\">5</span>a:<span class=\"hljs-number\">3</span>e:<span class=\"hljs-number\">58</span>:<span class=\"hljs-number\">6</span>a:<span class=\"hljs-number\">8</span>c:d2 brd ff:ff:ff:ff:ff:ff link-netnsid <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-keyword\">inet6</span> fe80::<span class=\"hljs-number\">583</span>e:<span class=\"hljs-number\">58</span>ff:fe6a:<span class=\"hljs-number\">8</span>cd2/<span class=\"hljs-number\">64</span> scope link <br>       valid_lft forever preferred_lft forever<br><span class=\"hljs-number\">7</span>: veth991a2bde@if3: <span class=\"hljs-variable\">&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span> mtu <span class=\"hljs-number\">1450</span> qdisc noqueue master cni0 <span class=\"hljs-keyword\">state</span> UP <span class=\"hljs-keyword\">group</span> <span class=\"hljs-keyword\">default</span> <br>    link/ether fe:<span class=\"hljs-number\">6</span>f:eb:<span class=\"hljs-number\">91</span>:<span class=\"hljs-number\">71</span>:<span class=\"hljs-number\">71</span> brd ff:ff:ff:ff:ff:ff link-netnsid <span class=\"hljs-number\">1</span><br>    <span class=\"hljs-keyword\">inet6</span> fe80::fc6f:ebff:fe91:<span class=\"hljs-number\">7171</span>/<span class=\"hljs-number\">64</span> scope link <br>       valid_lft forever preferred_lft forever<br></code></pre></td></tr></table></figure>\n\n<p><strong>lo</strong></p>\n<p>本地环回接口</p>\n<p><strong>eno16777736</strong></p>\n<p>真实网卡</p>\n<p><strong>docker0</strong></p>\n<p>docker ip信息，默认IP 172.17.0.1/16</p>\n<p>可修改 /etc/docker/daemon.json, 指定ip地址，例如：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">vi <span class=\"hljs-regexp\">/etc/</span>docker/daemon.json<br>&#123;<br> <span class=\"hljs-string\">&quot;bip&quot;</span>: <span class=\"hljs-string\">&quot;172.18.0.1/24&quot;</span>,<br>&#125;<br>service docker restart<br></code></pre></td></tr></table></figure>\n\n<p><strong>flannel.1</strong></p>\n<p>docker集群跨主机通讯的覆盖网络 10.244.0.0/32</p>\n<p><strong>cni0</strong></p>\n<p>pod分配 网络 10.244.0.1/24</p>\n<p>node1 IP信息：</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">1</span>: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span class=\"hljs-number\">65536</span> qdisc noqueue state UNKNOWN group default qlen <span class=\"hljs-number\">1000</span><br>    <span class=\"hljs-attribute\">link</span>/loopback <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> brd <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span><br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">127.0.0.1</span>/<span class=\"hljs-number\">8</span> scope host lo<br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> ::<span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">128</span> scope host <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br><span class=\"hljs-attribute\">2</span>: eno16777736: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class=\"hljs-number\">1500</span> qdisc pfifo_fast state UP group default qlen <span class=\"hljs-number\">1000</span><br>    <span class=\"hljs-attribute\">link</span>/ether <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">0</span>c:<span class=\"hljs-number\">29</span>:<span class=\"hljs-number\">1</span>a:<span class=\"hljs-number\">1</span>c:d4 brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">10.0.0.21</span>/<span class=\"hljs-number\">24</span> brd <span class=\"hljs-number\">10.0.0.255</span> scope global noprefixroute eno16777736<br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> fd56:a9ae:cb0f::<span class=\"hljs-number\">7</span>a1/<span class=\"hljs-number\">128</span> scope global noprefixroute dynamic <br>       <span class=\"hljs-attribute\">valid_lft</span> <span class=\"hljs-number\">29510</span>sec preferred_lft <span class=\"hljs-number\">29510</span>sec<br>    <span class=\"hljs-attribute\">inet6</span> fd56:a9ae:cb0f:<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">20</span>c:<span class=\"hljs-number\">29</span>ff:fe1a:<span class=\"hljs-number\">1</span>cd4/<span class=\"hljs-number\">64</span> scope global noprefixroute <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> fe80::<span class=\"hljs-number\">20</span>c:<span class=\"hljs-number\">29</span>ff:fe1a:<span class=\"hljs-number\">1</span>cd4/<span class=\"hljs-number\">64</span> scope link noprefixroute <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br><span class=\"hljs-attribute\">3</span>: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span class=\"hljs-number\">1500</span> qdisc noqueue state DOWN group default <br>    <span class=\"hljs-attribute\">link</span>/ether <span class=\"hljs-number\">02</span>:<span class=\"hljs-number\">42</span>:b8:ae:c9:<span class=\"hljs-number\">24</span> brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">172.17.0.1</span>/<span class=\"hljs-number\">16</span> brd <span class=\"hljs-number\">172.17.255.255</span> scope global docker0<br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br><span class=\"hljs-attribute\">4</span>: flannel.<span class=\"hljs-number\">1</span>: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class=\"hljs-number\">1450</span> qdisc noqueue state UNKNOWN group default <br>    <span class=\"hljs-attribute\">link</span>/ether <span class=\"hljs-number\">1</span>e:<span class=\"hljs-number\">6</span>d:<span class=\"hljs-number\">47</span>:<span class=\"hljs-number\">69</span>:f7:<span class=\"hljs-number\">6</span>a brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">10.244.1.0</span>/<span class=\"hljs-number\">32</span> scope global flannel.<span class=\"hljs-number\">1</span><br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> fe80::<span class=\"hljs-number\">1</span>c6d:<span class=\"hljs-number\">47</span>ff:fe69:f76a/<span class=\"hljs-number\">64</span> scope link <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br></code></pre></td></tr></table></figure>\n\n<p>node2 IP信息</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">1</span>: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span class=\"hljs-number\">65536</span> qdisc noqueue state UNKNOWN group default qlen <span class=\"hljs-number\">1000</span><br>    <span class=\"hljs-attribute\">link</span>/loopback <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> brd <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span><br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">127.0.0.1</span>/<span class=\"hljs-number\">8</span> scope host lo<br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> ::<span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">128</span> scope host <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br><span class=\"hljs-attribute\">2</span>: eno16777736: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class=\"hljs-number\">1500</span> qdisc pfifo_fast state UP group default qlen <span class=\"hljs-number\">1000</span><br>    <span class=\"hljs-attribute\">link</span>/ether <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">0</span>c:<span class=\"hljs-number\">29</span>:<span class=\"hljs-number\">67</span>:c3:<span class=\"hljs-number\">4</span>a brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">10.0.0.22</span>/<span class=\"hljs-number\">24</span> brd <span class=\"hljs-number\">10.0.0.255</span> scope global noprefixroute eno16777736<br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> fd56:a9ae:cb0f::<span class=\"hljs-number\">853</span>/<span class=\"hljs-number\">128</span> scope global noprefixroute dynamic <br>       <span class=\"hljs-attribute\">valid_lft</span> <span class=\"hljs-number\">29262</span>sec preferred_lft <span class=\"hljs-number\">29262</span>sec<br>    <span class=\"hljs-attribute\">inet6</span> fd56:a9ae:cb0f:<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">20</span>c:<span class=\"hljs-number\">29</span>ff:fe67:c34a/<span class=\"hljs-number\">64</span> scope global noprefixroute <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> fe80::<span class=\"hljs-number\">20</span>c:<span class=\"hljs-number\">29</span>ff:fe67:c34a/<span class=\"hljs-number\">64</span> scope link noprefixroute <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br><span class=\"hljs-attribute\">3</span>: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span class=\"hljs-number\">1500</span> qdisc noqueue state DOWN group default <br>    <span class=\"hljs-attribute\">link</span>/ether <span class=\"hljs-number\">02</span>:<span class=\"hljs-number\">42</span>:b2:<span class=\"hljs-number\">7</span>e:<span class=\"hljs-number\">58</span>:<span class=\"hljs-number\">1</span>f brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">172.17.0.1</span>/<span class=\"hljs-number\">16</span> brd <span class=\"hljs-number\">172.17.255.255</span> scope global docker0<br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br><span class=\"hljs-attribute\">4</span>: flannel.<span class=\"hljs-number\">1</span>: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class=\"hljs-number\">1450</span> qdisc noqueue state UNKNOWN group default <br>    <span class=\"hljs-attribute\">link</span>/ether <span class=\"hljs-number\">66</span>:<span class=\"hljs-number\">5</span>b:e2:<span class=\"hljs-number\">87</span>:<span class=\"hljs-number\">5</span>c:<span class=\"hljs-number\">22</span> brd ff:ff:ff:ff:ff:ff<br>    <span class=\"hljs-attribute\">inet</span> <span class=\"hljs-number\">10.244.2.0</span>/<span class=\"hljs-number\">32</span> scope global flannel.<span class=\"hljs-number\">1</span><br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br>    <span class=\"hljs-attribute\">inet6</span> fe80::<span class=\"hljs-number\">645</span>b:e2ff:fe87:<span class=\"hljs-number\">5</span>c22/<span class=\"hljs-number\">64</span> scope link <br>       <span class=\"hljs-attribute\">valid_lft</span> forever preferred_lft forever<br></code></pre></td></tr></table></figure>\n\n<p>7 测试kubernetes集群</p>\n<p>在Kubernetes集群中创建一个pod，验证是否正常运行：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">[root@k8s-master01 ~]<span class=\"hljs-comment\"># kubectl create deployment nginx --image=nginx</span><br>deployment.apps/nginx created<br>[root@k8s-master01 ~]<span class=\"hljs-comment\"># kubectl expose deployment nginx --port=80 --type=NodePort</span><br>service/nginx exposed<br>[root@k8s-master01 ~]<span class=\"hljs-comment\"># kubectl get pod,svc</span><br>NAME                         READY   STATUS              RESTARTS   AGE<br>pod<span class=\"hljs-regexp\">/nginx-6799fc88d8-zzsw7   0/</span><span class=\"hljs-number\">1</span>     ContainerCreating   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">31</span>s<br><br>NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE<br>service<span class=\"hljs-regexp\">/kubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/</span>TCP        <span class=\"hljs-number\">24</span>h<br>service<span class=\"hljs-regexp\">/nginx        NodePort    10.103.32.138   &lt;none&gt;        80:30029/</span>TCP   <span class=\"hljs-number\">13</span>s<br></code></pre></td></tr></table></figure>\n\n<p>访问地址：<a href=\"http://nodeip:Port/\">http://NodeIP:Port</a></p>\n<p>可以通过 <a href=\"http://10.0.0.21:31263/\">http://10.0.0.21:31263</a> 和 <a href=\"http://10.0.0.22:31263/\">http://10.0.0.22:31263</a> 访问</p>\n<h1 id=\"8-错误排查\"><a href=\"#8-错误排查\" class=\"headerlink\" title=\"8 错误排查\"></a>8 <strong>错误排查</strong></h1><p>启动日志获取</p>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\"><span class=\"hljs-comment\">#查看启动日志</span><br><span class=\"hljs-keyword\">journalctl </span>-f -u kubelet.service<br></code></pre></td></tr></table></figure>\n\n<p>配置加载与重启服务</p>\n<figure class=\"highlight nsis\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nsis\"><span class=\"hljs-params\">system</span>ctl daemon-reload &amp;&amp; <span class=\"hljs-params\">system</span>ctl restart kubelet<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"9-ipvs修改\"><a href=\"#9-ipvs修改\" class=\"headerlink\" title=\"9 ipvs修改\"></a>9 ipvs修改</h1><figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs vim\">kubectl <span class=\"hljs-keyword\">edit</span> configmap kube-proxy -n kube-<span class=\"hljs-built_in\">system</span><br>...<br><span class=\"hljs-number\">43</span>   <span class=\"hljs-keyword\">mode</span>: <span class=\"hljs-string\">&quot;ipvs&quot;</span><br>   ...<br></code></pre></td></tr></table></figure>\n\n<p><strong>删除pod,会自动拉起</strong></p>\n<figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gauss\">kubectl <span class=\"hljs-keyword\">delete</span> pod kube-proxy-btz4p -n kube-<span class=\"hljs-keyword\">system</span>  <br></code></pre></td></tr></table></figure>\n\n<p><strong>查看是否启用ipvs</strong></p>\n<figure class=\"highlight clean\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs clean\">kubectl logs kube-proxy-wwqbh -n kube-<span class=\"hljs-keyword\">system</span>        <br></code></pre></td></tr></table></figure>\n\n<p><strong>注：</strong></p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">1、 kube-proxy配置文件以configmap方式存储<br>2、 如果让所有节点生效，需要重建所有节点kube-proxy pod<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"10-问题及解决\"><a href=\"#10-问题及解决\" class=\"headerlink\" title=\"10 问题及解决\"></a>10 <strong>问题及解决</strong></h1><p>1 failed to find subsystem mount for required subsystem: pids failed to find subsystem mount for required subsystem: pids</p>\n<p>解决方法：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">vi <span class=\"hljs-regexp\">/usr/</span>lib<span class=\"hljs-regexp\">/systemd/</span>system<span class=\"hljs-regexp\">/kubelet.service.d/</span><span class=\"hljs-number\">10</span>-kubeadm.conf<br><span class=\"hljs-comment\">#发现ExecStart=后面添加参数</span><br>ExecStart=<span class=\"hljs-string\">&quot;--feature-gates SupportPodPidsLimit=false --feature-gates SupportNodePidsLimit=false&quot;</span><br><span class=\"hljs-comment\">#或者更改引用变量$KUBELET_EXTRA_ARGS</span><br>vi <span class=\"hljs-regexp\">/etc/</span>sysconfig/kubelet<br>KUBELET_EXTRA_ARGS=--feature-gates SupportPodPidsLimit=false --feature-gates SupportNodePidsLimit=false<br></code></pre></td></tr></table></figure>\n\n<p>2 kubelet cgroup driver: \\“systemd\\“ is different from docker cgroup driver: \\“cgroupfs\\“</p>\n<p>docker的驱动查看是否有systemd</p>\n<figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-attribute\">docker</span> <span class=\"hljs-literal\">info</span> |grep Cgroup<br></code></pre></td></tr></table></figure>\n\n<p>解决方案步骤如下：</p>\n<p>(1)、先修改docker的Cgroup Driver，修改/etc/docker/daemon.json文件</p>\n<figure class=\"highlight prolog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs prolog\">&#123;<br>  <span class=\"hljs-string\">&quot;exec-opts&quot;</span>: [<span class=\"hljs-string\">&quot;native.cgroupdriver=systemd&quot;</span>]<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>重启docker</p>\n<figure class=\"highlight nsis\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nsis\"><span class=\"hljs-params\">system</span>ctl daemon-reload<br><span class=\"hljs-params\">system</span>ctl restart docker<br></code></pre></td></tr></table></figure>\n\n<p>(2)、然后修改kubelet的Cgroup Driver<br>修改 “/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf ” 文件，增加（或修改成）“–cgroup-driver=systemd” (官方推荐用systemd)</p>\n<figure class=\"highlight abnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs abnf\"><span class=\"hljs-attribute\">Environment</span><span class=\"hljs-operator\">=</span><span class=\"hljs-string\">&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --cgroup-driver=systemd&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>修改 “/var/lib/kubelet/kubeadm-flags.env ”文件，增加（或修改成）“-–cgroup-driver=systemd”</p>\n<figure class=\"highlight brainfuck\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs brainfuck\"><span class=\"hljs-comment\">KUBELET_KUBEADM_ARGS=&quot;</span><span class=\"hljs-literal\">--</span><span class=\"hljs-comment\">cgroup</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">driver=systemd</span> <span class=\"hljs-literal\">--</span><span class=\"hljs-comment\">network</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">plugin=cni</span> <span class=\"hljs-literal\">--</span><span class=\"hljs-comment\">pod</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">infra</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">container</span><span class=\"hljs-literal\">-</span><span class=\"hljs-comment\">image=registry</span><span class=\"hljs-string\">.</span><span class=\"hljs-comment\">aliyuncs</span><span class=\"hljs-string\">.</span><span class=\"hljs-comment\">com/google_containers/pause:3</span><span class=\"hljs-string\">.</span><span class=\"hljs-comment\">2&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>重启：</p>\n<figure class=\"highlight nsis\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nsis\"><span class=\"hljs-params\">system</span>ctl daemon-reload<br><span class=\"hljs-params\">system</span>ctl restart kubelet<br></code></pre></td></tr></table></figure>\n<p>3 missing required cgroups: cpu</p>\n<p>修改<code>/etc/default/grub</code></p>\n<p>添加一行<code>GRUB_CMDLINE_LINUX=&quot;cgroup_enable=cpu&quot;</code></p>\n<p>运行 <code>update-grub2</code></p>\n<p>重启机器 <code>reboot</code></p>\n<p>4  Failed to start CRI Interface for Docker Application Container Engine Defined-By: systemd</p>\n<figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs livecodeserver\"><span class=\"hljs-number\">7</span>月 <span class=\"hljs-number\">29</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">35</span>:<span class=\"hljs-number\">14</span> k8s-master02 systemd[<span class=\"hljs-number\">1</span>]: cri-docker.service: main <span class=\"hljs-built_in\">process</span> exited, code=exited, status=<span class=\"hljs-number\">203</span>/EXEC<br><span class=\"hljs-number\">7</span>月 <span class=\"hljs-number\">29</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">35</span>:<span class=\"hljs-number\">14</span> k8s-master02 systemd[<span class=\"hljs-number\">1</span>]: Failed <span class=\"hljs-built_in\">to</span> <span class=\"hljs-built_in\">start</span> CRI Interface <span class=\"hljs-keyword\">for</span> Docker Application Container Engine.<br><span class=\"hljs-comment\">-- Subject: Unit cri-docker.service has failed</span><br><span class=\"hljs-comment\">-- Defined-By: systemd</span><br><span class=\"hljs-comment\">-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel</span><br><span class=\"hljs-comment\">-- </span><br><span class=\"hljs-comment\">-- Unit cri-docker.service has failed.</span><br><span class=\"hljs-comment\">-- </span><br><span class=\"hljs-comment\">-- The result is failed.</span><br><span class=\"hljs-number\">7</span>月 <span class=\"hljs-number\">29</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">35</span>:<span class=\"hljs-number\">14</span> k8s-master02 systemd[<span class=\"hljs-number\">1</span>]: Unit cri-docker.service entered failed state.<br><span class=\"hljs-number\">7</span>月 <span class=\"hljs-number\">29</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">35</span>:<span class=\"hljs-number\">14</span> k8s-master02 systemd[<span class=\"hljs-number\">1</span>]: cri-docker.service failed.<br></code></pre></td></tr></table></figure>\n\n<p>修改 docker 控制组</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">vi <span class=\"hljs-regexp\">/etc/</span>docker/daemon.json <br>&#123;<br>  <span class=\"hljs-string\">&quot;exec-opts&quot;</span>: [<span class=\"hljs-string\">&quot;native.cgroupdriver=systemd&quot;</span>]<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>从重启服务</p>\n<figure class=\"highlight nsis\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nsis\"><span class=\"hljs-params\">system</span>ctl daemon-reload<br><span class=\"hljs-params\">system</span>ctl restart docker<br><span class=\"hljs-params\">system</span>ctl restart cri-docker<br></code></pre></td></tr></table></figure>\n\n<p>5  error execution phase preflight: couldn’t validate the identity of the API Server: Get “<a href=\"https://10.0.0.150:16443/api/v1/namespaces/kube-public/configmaps/cluster-info?timeout=10s&quot;\">https://10.0.0.150:16443/api/v1/namespaces/kube-public/configmaps/cluster-info?timeout=10s&quot;</a>: x509: certificate has expired or is not yet valid: current time 2022-07-30T16:12:40+08:00 is before 2022-07-30T13:31:36Z</p>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">yum <span class=\"hljs-keyword\">install </span>ntpdate -y<br>ntpdate time.windows.com<br><span class=\"hljs-comment\"># 强制把系统时间写入CMOS</span><br><span class=\"hljs-keyword\">clock </span>-w<br></code></pre></td></tr></table></figure>\n\n"},{"title":"k8s常用控制器及特点","date":"2021-08-01T12:24:02.000Z","_content":"\n# 什么是控制器\n\nKubernetes 中内建了很多controller (控制器),这些相当于一个状态机,用来控制Pod的具体状态和行为\n\n# 控制器类型\n\n- ReplicationController 和 ReplicaSet\n- Deployment\n- DaemonSet\n- StateFulSet\n- Job/CronJob\n- Horizontal Pod Autoscaling\n\n## ReplicationController 和 ReplicaSet\n\nReplicationController (RC)用来确保容器应用的副本数始终保持在用户定义的副本数,即如果有容器异常退出,会自动创建新的Pod来替代;而如果异常多出来的容器也会自动回收;\n\n在新版本的Kubernetes 中建议使用ReplicaSet 来取代ReplicationController. ReplicaSet 跟ReplicationController 没有本质的不同,只是名字不一样,并且ReplicaSet支持集合式的selector;\n\n虽然ReplicaSet 可以独立使用，但一般还是建议使用Deployment来自动管理ReplicaSet ，这样就无需担心跟其他机制的不兼容问题(比如ReplicaSet不支持rolling-update，但Deployment 支持)\n\n## Deployment\n\nDeployment为Pod和ReplicaSet提供了一个声明式定义(declarative)方法,用来替代以前的ReplicationController来方便的管理应用。\n\nDeployment 是Kubenetes v1.2 引入的新概念，引入的目的是为了更好的解决Pod 的编排问题，Deployment 内部使用了Replica Set 来实现。\n\n典型的应用场景包括;\n\n- 定义Deployment 来创建Pod和ReplicaSet\n- 滚动升级和回滚应用\n- 扩容和缩容\n- 暂停和继续Deployment\n\n## DaemonSet\n\nDaemonSet确保全部(或者一些) Node上运行一个Pod的副本。当有Node加入集群时,也会为他们新增一个Pod.当有Node从集群移除时,这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod\n\n使用DaemonSet的一些典型用法:\n\n- 运行集群存储daemon,例如在每个Node上运行 glusterd,ceph\n- 在每个Node上运行日志收集daemon,例如fluentd, logstash\n- 在每个Node上运行监控daemon,例如Prometheus Node Exporter, collectd, Datadog 代理、New Relic 代理,或 Ganglia gmond\n\n## Job\n\nJob负责批处理任务,即仅执行一次的任务,它保证批处理任务的一个或多个Pod成功结束\n\n## CronJob\n\nCronJob管理基于时间的Job,即:\n\n- 在给定时间点只运行一次\n- 周期性地在给定时间点运行\n\n使用前提条件:林当前使用的Kubernetes集群,版本>=1.8 (对Cronjob).对于先前版本的集群,版本<1.8,启动API Server时,通过传递选项-runtime-config=batch/v2alphal=true可以开启batch/v2alpha API**\n\n典型的用法如下所示:\n\n- 在给定的时间点调度Job运行\n- 创建周期性运行的Job,例如:数据库备份、发送邮件\n\n## StatefulSet\n\nStatefulSet 作为Controller 为Pod提供唯一的标识。它可以保证部署和scale的顺序。\n\nStatefulSet是为了解决有状态服务的问题(对应Deployments和ReplicaSets是为无状态服务而设计),其应用场景包括:\n\n- 稳定的持久化存储,即Pod重新调度后还是能访问到相同的持久化数据,基于PVC来实现\n- 稳定的网络标志,即Pod重新调度后其PodName和HostName不变,基于Headless Service (即没有Cluster IP的Service)来实现\n- 有序部署,有序扩展,即Pod是有顺序的,在部署或者扩展的时候要依据定义的顺序依次依次进行(即从0到N-1, 在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态),基于init containers来实现\n- 有序收缩,有序删除(即从N-1到0)\n\n## Horizontal Pod Autoscaling\n\n应用的资源使用率通常都有高峰和低谷的时候,如何削峰填谷,提高集群的整体资源利用率,让service中的Pod个数自动调整呢?这就有赖于Horizontal Pod Autoscaling了,顾名思义,使Pod水平自动缩放.\n\nHorizontal Pod Autoscaling 仅适用于Deployment和ReplicaSet ,在V1版本中仅支持根据Pod的CPU利用率扩所容,在vlalpha版本中,支持根据内存和用户自定义的metric扩缩容。","source":"_posts/k8s常用控制器及特点.md","raw":"---\ntitle: k8s常用控制器及特点\ndate: 2021-08-01 20:24:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - 控制器\n---\n\n# 什么是控制器\n\nKubernetes 中内建了很多controller (控制器),这些相当于一个状态机,用来控制Pod的具体状态和行为\n\n# 控制器类型\n\n- ReplicationController 和 ReplicaSet\n- Deployment\n- DaemonSet\n- StateFulSet\n- Job/CronJob\n- Horizontal Pod Autoscaling\n\n## ReplicationController 和 ReplicaSet\n\nReplicationController (RC)用来确保容器应用的副本数始终保持在用户定义的副本数,即如果有容器异常退出,会自动创建新的Pod来替代;而如果异常多出来的容器也会自动回收;\n\n在新版本的Kubernetes 中建议使用ReplicaSet 来取代ReplicationController. ReplicaSet 跟ReplicationController 没有本质的不同,只是名字不一样,并且ReplicaSet支持集合式的selector;\n\n虽然ReplicaSet 可以独立使用，但一般还是建议使用Deployment来自动管理ReplicaSet ，这样就无需担心跟其他机制的不兼容问题(比如ReplicaSet不支持rolling-update，但Deployment 支持)\n\n## Deployment\n\nDeployment为Pod和ReplicaSet提供了一个声明式定义(declarative)方法,用来替代以前的ReplicationController来方便的管理应用。\n\nDeployment 是Kubenetes v1.2 引入的新概念，引入的目的是为了更好的解决Pod 的编排问题，Deployment 内部使用了Replica Set 来实现。\n\n典型的应用场景包括;\n\n- 定义Deployment 来创建Pod和ReplicaSet\n- 滚动升级和回滚应用\n- 扩容和缩容\n- 暂停和继续Deployment\n\n## DaemonSet\n\nDaemonSet确保全部(或者一些) Node上运行一个Pod的副本。当有Node加入集群时,也会为他们新增一个Pod.当有Node从集群移除时,这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod\n\n使用DaemonSet的一些典型用法:\n\n- 运行集群存储daemon,例如在每个Node上运行 glusterd,ceph\n- 在每个Node上运行日志收集daemon,例如fluentd, logstash\n- 在每个Node上运行监控daemon,例如Prometheus Node Exporter, collectd, Datadog 代理、New Relic 代理,或 Ganglia gmond\n\n## Job\n\nJob负责批处理任务,即仅执行一次的任务,它保证批处理任务的一个或多个Pod成功结束\n\n## CronJob\n\nCronJob管理基于时间的Job,即:\n\n- 在给定时间点只运行一次\n- 周期性地在给定时间点运行\n\n使用前提条件:林当前使用的Kubernetes集群,版本>=1.8 (对Cronjob).对于先前版本的集群,版本<1.8,启动API Server时,通过传递选项-runtime-config=batch/v2alphal=true可以开启batch/v2alpha API**\n\n典型的用法如下所示:\n\n- 在给定的时间点调度Job运行\n- 创建周期性运行的Job,例如:数据库备份、发送邮件\n\n## StatefulSet\n\nStatefulSet 作为Controller 为Pod提供唯一的标识。它可以保证部署和scale的顺序。\n\nStatefulSet是为了解决有状态服务的问题(对应Deployments和ReplicaSets是为无状态服务而设计),其应用场景包括:\n\n- 稳定的持久化存储,即Pod重新调度后还是能访问到相同的持久化数据,基于PVC来实现\n- 稳定的网络标志,即Pod重新调度后其PodName和HostName不变,基于Headless Service (即没有Cluster IP的Service)来实现\n- 有序部署,有序扩展,即Pod是有顺序的,在部署或者扩展的时候要依据定义的顺序依次依次进行(即从0到N-1, 在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态),基于init containers来实现\n- 有序收缩,有序删除(即从N-1到0)\n\n## Horizontal Pod Autoscaling\n\n应用的资源使用率通常都有高峰和低谷的时候,如何削峰填谷,提高集群的整体资源利用率,让service中的Pod个数自动调整呢?这就有赖于Horizontal Pod Autoscaling了,顾名思义,使Pod水平自动缩放.\n\nHorizontal Pod Autoscaling 仅适用于Deployment和ReplicaSet ,在V1版本中仅支持根据Pod的CPU利用率扩所容,在vlalpha版本中,支持根据内存和用户自定义的metric扩缩容。","slug":"k8s常用控制器及特点","published":1,"updated":"2022-09-23T17:07:32.298Z","_id":"cl8eqiw1g000cd4vje4iyg1w2","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"什么是控制器\"><a href=\"#什么是控制器\" class=\"headerlink\" title=\"什么是控制器\"></a>什么是控制器</h1><p>Kubernetes 中内建了很多controller (控制器),这些相当于一个状态机,用来控制Pod的具体状态和行为</p>\n<h1 id=\"控制器类型\"><a href=\"#控制器类型\" class=\"headerlink\" title=\"控制器类型\"></a>控制器类型</h1><ul>\n<li>ReplicationController 和 ReplicaSet</li>\n<li>Deployment</li>\n<li>DaemonSet</li>\n<li>StateFulSet</li>\n<li>Job/CronJob</li>\n<li>Horizontal Pod Autoscaling</li>\n</ul>\n<h2 id=\"ReplicationController-和-ReplicaSet\"><a href=\"#ReplicationController-和-ReplicaSet\" class=\"headerlink\" title=\"ReplicationController 和 ReplicaSet\"></a>ReplicationController 和 ReplicaSet</h2><p>ReplicationController (RC)用来确保容器应用的副本数始终保持在用户定义的副本数,即如果有容器异常退出,会自动创建新的Pod来替代;而如果异常多出来的容器也会自动回收;</p>\n<p>在新版本的Kubernetes 中建议使用ReplicaSet 来取代ReplicationController. ReplicaSet 跟ReplicationController 没有本质的不同,只是名字不一样,并且ReplicaSet支持集合式的selector;</p>\n<p>虽然ReplicaSet 可以独立使用，但一般还是建议使用Deployment来自动管理ReplicaSet ，这样就无需担心跟其他机制的不兼容问题(比如ReplicaSet不支持rolling-update，但Deployment 支持)</p>\n<h2 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h2><p>Deployment为Pod和ReplicaSet提供了一个声明式定义(declarative)方法,用来替代以前的ReplicationController来方便的管理应用。</p>\n<p>Deployment 是Kubenetes v1.2 引入的新概念，引入的目的是为了更好的解决Pod 的编排问题，Deployment 内部使用了Replica Set 来实现。</p>\n<p>典型的应用场景包括;</p>\n<ul>\n<li>定义Deployment 来创建Pod和ReplicaSet</li>\n<li>滚动升级和回滚应用</li>\n<li>扩容和缩容</li>\n<li>暂停和继续Deployment</li>\n</ul>\n<h2 id=\"DaemonSet\"><a href=\"#DaemonSet\" class=\"headerlink\" title=\"DaemonSet\"></a>DaemonSet</h2><p>DaemonSet确保全部(或者一些) Node上运行一个Pod的副本。当有Node加入集群时,也会为他们新增一个Pod.当有Node从集群移除时,这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod</p>\n<p>使用DaemonSet的一些典型用法:</p>\n<ul>\n<li>运行集群存储daemon,例如在每个Node上运行 glusterd,ceph</li>\n<li>在每个Node上运行日志收集daemon,例如fluentd, logstash</li>\n<li>在每个Node上运行监控daemon,例如Prometheus Node Exporter, collectd, Datadog 代理、New Relic 代理,或 Ganglia gmond</li>\n</ul>\n<h2 id=\"Job\"><a href=\"#Job\" class=\"headerlink\" title=\"Job\"></a>Job</h2><p>Job负责批处理任务,即仅执行一次的任务,它保证批处理任务的一个或多个Pod成功结束</p>\n<h2 id=\"CronJob\"><a href=\"#CronJob\" class=\"headerlink\" title=\"CronJob\"></a>CronJob</h2><p>CronJob管理基于时间的Job,即:</p>\n<ul>\n<li>在给定时间点只运行一次</li>\n<li>周期性地在给定时间点运行</li>\n</ul>\n<p>使用前提条件:林当前使用的Kubernetes集群,版本&gt;=1.8 (对Cronjob).对于先前版本的集群,版本&lt;1.8,启动API Server时,通过传递选项-runtime-config=batch/v2alphal=true可以开启batch/v2alpha API**</p>\n<p>典型的用法如下所示:</p>\n<ul>\n<li>在给定的时间点调度Job运行</li>\n<li>创建周期性运行的Job,例如:数据库备份、发送邮件</li>\n</ul>\n<h2 id=\"StatefulSet\"><a href=\"#StatefulSet\" class=\"headerlink\" title=\"StatefulSet\"></a>StatefulSet</h2><p>StatefulSet 作为Controller 为Pod提供唯一的标识。它可以保证部署和scale的顺序。</p>\n<p>StatefulSet是为了解决有状态服务的问题(对应Deployments和ReplicaSets是为无状态服务而设计),其应用场景包括:</p>\n<ul>\n<li>稳定的持久化存储,即Pod重新调度后还是能访问到相同的持久化数据,基于PVC来实现</li>\n<li>稳定的网络标志,即Pod重新调度后其PodName和HostName不变,基于Headless Service (即没有Cluster IP的Service)来实现</li>\n<li>有序部署,有序扩展,即Pod是有顺序的,在部署或者扩展的时候要依据定义的顺序依次依次进行(即从0到N-1, 在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态),基于init containers来实现</li>\n<li>有序收缩,有序删除(即从N-1到0)</li>\n</ul>\n<h2 id=\"Horizontal-Pod-Autoscaling\"><a href=\"#Horizontal-Pod-Autoscaling\" class=\"headerlink\" title=\"Horizontal Pod Autoscaling\"></a>Horizontal Pod Autoscaling</h2><p>应用的资源使用率通常都有高峰和低谷的时候,如何削峰填谷,提高集群的整体资源利用率,让service中的Pod个数自动调整呢?这就有赖于Horizontal Pod Autoscaling了,顾名思义,使Pod水平自动缩放.</p>\n<p>Horizontal Pod Autoscaling 仅适用于Deployment和ReplicaSet ,在V1版本中仅支持根据Pod的CPU利用率扩所容,在vlalpha版本中,支持根据内存和用户自定义的metric扩缩容。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"什么是控制器\"><a href=\"#什么是控制器\" class=\"headerlink\" title=\"什么是控制器\"></a>什么是控制器</h1><p>Kubernetes 中内建了很多controller (控制器),这些相当于一个状态机,用来控制Pod的具体状态和行为</p>\n<h1 id=\"控制器类型\"><a href=\"#控制器类型\" class=\"headerlink\" title=\"控制器类型\"></a>控制器类型</h1><ul>\n<li>ReplicationController 和 ReplicaSet</li>\n<li>Deployment</li>\n<li>DaemonSet</li>\n<li>StateFulSet</li>\n<li>Job/CronJob</li>\n<li>Horizontal Pod Autoscaling</li>\n</ul>\n<h2 id=\"ReplicationController-和-ReplicaSet\"><a href=\"#ReplicationController-和-ReplicaSet\" class=\"headerlink\" title=\"ReplicationController 和 ReplicaSet\"></a>ReplicationController 和 ReplicaSet</h2><p>ReplicationController (RC)用来确保容器应用的副本数始终保持在用户定义的副本数,即如果有容器异常退出,会自动创建新的Pod来替代;而如果异常多出来的容器也会自动回收;</p>\n<p>在新版本的Kubernetes 中建议使用ReplicaSet 来取代ReplicationController. ReplicaSet 跟ReplicationController 没有本质的不同,只是名字不一样,并且ReplicaSet支持集合式的selector;</p>\n<p>虽然ReplicaSet 可以独立使用，但一般还是建议使用Deployment来自动管理ReplicaSet ，这样就无需担心跟其他机制的不兼容问题(比如ReplicaSet不支持rolling-update，但Deployment 支持)</p>\n<h2 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h2><p>Deployment为Pod和ReplicaSet提供了一个声明式定义(declarative)方法,用来替代以前的ReplicationController来方便的管理应用。</p>\n<p>Deployment 是Kubenetes v1.2 引入的新概念，引入的目的是为了更好的解决Pod 的编排问题，Deployment 内部使用了Replica Set 来实现。</p>\n<p>典型的应用场景包括;</p>\n<ul>\n<li>定义Deployment 来创建Pod和ReplicaSet</li>\n<li>滚动升级和回滚应用</li>\n<li>扩容和缩容</li>\n<li>暂停和继续Deployment</li>\n</ul>\n<h2 id=\"DaemonSet\"><a href=\"#DaemonSet\" class=\"headerlink\" title=\"DaemonSet\"></a>DaemonSet</h2><p>DaemonSet确保全部(或者一些) Node上运行一个Pod的副本。当有Node加入集群时,也会为他们新增一个Pod.当有Node从集群移除时,这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod</p>\n<p>使用DaemonSet的一些典型用法:</p>\n<ul>\n<li>运行集群存储daemon,例如在每个Node上运行 glusterd,ceph</li>\n<li>在每个Node上运行日志收集daemon,例如fluentd, logstash</li>\n<li>在每个Node上运行监控daemon,例如Prometheus Node Exporter, collectd, Datadog 代理、New Relic 代理,或 Ganglia gmond</li>\n</ul>\n<h2 id=\"Job\"><a href=\"#Job\" class=\"headerlink\" title=\"Job\"></a>Job</h2><p>Job负责批处理任务,即仅执行一次的任务,它保证批处理任务的一个或多个Pod成功结束</p>\n<h2 id=\"CronJob\"><a href=\"#CronJob\" class=\"headerlink\" title=\"CronJob\"></a>CronJob</h2><p>CronJob管理基于时间的Job,即:</p>\n<ul>\n<li>在给定时间点只运行一次</li>\n<li>周期性地在给定时间点运行</li>\n</ul>\n<p>使用前提条件:林当前使用的Kubernetes集群,版本&gt;=1.8 (对Cronjob).对于先前版本的集群,版本&lt;1.8,启动API Server时,通过传递选项-runtime-config=batch/v2alphal=true可以开启batch/v2alpha API**</p>\n<p>典型的用法如下所示:</p>\n<ul>\n<li>在给定的时间点调度Job运行</li>\n<li>创建周期性运行的Job,例如:数据库备份、发送邮件</li>\n</ul>\n<h2 id=\"StatefulSet\"><a href=\"#StatefulSet\" class=\"headerlink\" title=\"StatefulSet\"></a>StatefulSet</h2><p>StatefulSet 作为Controller 为Pod提供唯一的标识。它可以保证部署和scale的顺序。</p>\n<p>StatefulSet是为了解决有状态服务的问题(对应Deployments和ReplicaSets是为无状态服务而设计),其应用场景包括:</p>\n<ul>\n<li>稳定的持久化存储,即Pod重新调度后还是能访问到相同的持久化数据,基于PVC来实现</li>\n<li>稳定的网络标志,即Pod重新调度后其PodName和HostName不变,基于Headless Service (即没有Cluster IP的Service)来实现</li>\n<li>有序部署,有序扩展,即Pod是有顺序的,在部署或者扩展的时候要依据定义的顺序依次依次进行(即从0到N-1, 在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态),基于init containers来实现</li>\n<li>有序收缩,有序删除(即从N-1到0)</li>\n</ul>\n<h2 id=\"Horizontal-Pod-Autoscaling\"><a href=\"#Horizontal-Pod-Autoscaling\" class=\"headerlink\" title=\"Horizontal Pod Autoscaling\"></a>Horizontal Pod Autoscaling</h2><p>应用的资源使用率通常都有高峰和低谷的时候,如何削峰填谷,提高集群的整体资源利用率,让service中的Pod个数自动调整呢?这就有赖于Horizontal Pod Autoscaling了,顾名思义,使Pod水平自动缩放.</p>\n<p>Horizontal Pod Autoscaling 仅适用于Deployment和ReplicaSet ,在V1版本中仅支持根据Pod的CPU利用率扩所容,在vlalpha版本中,支持根据内存和用户自定义的metric扩缩容。</p>\n"},{"title":"kubernetes基础控制器","date":"2021-06-30T12:24:02.000Z","_content":"\n**ReplicationController**\n\nReplicationController 用来确保容器应用的副本数始终保持在用户定义的副本数,即如果有容器异常退出，会自动创建新的Pod来替代；而如果异常多出来的容器也会自动回收。\n在新版本的Kubernetes 中建议使用ReplicaSet取代ReplicationController。\n\n**ReplicaSet**\n\nReplicaSet 和ReplicationController 没有本质的不同,只是名字不一样,并且ReplicaSet支持集合式的selector\n虽然ReplicaSet 可以独立使用，但一般还是建议使用Deployment来自动管理ReplicaSet ，这样就无需担心跟其他机制的不兼容问题(比如ReplicaSet不支持rolling-update，但Deployment 支持)\n\n**Deployment**\n\nDeployment Pod和ReplicaSet提供了一个声明式定义(declarative)方法,用来替代以前的ReplicationController来方便的管理应用。\n\nDeployment 是Kubenetes v1.2 引入的新概念，引入的目的是为了更好的解决Pod 的编排问题，Deployment 内部使用了Replica Set 来实现。\n\n典型的应用场景包括：\n\n- 定义Deployment 来创建Pod和ReplicaSet\n- 滚动升级和回滚应用\n- 扩容和缩容\n- 暂停和继续Deployment\n\n**Horizontal Pod Autoscaling**\n\nHorizontal Pod Autoscaling 仅适用于Deployment和ReplicaSet ,在V1版本中仅支持根据Pod的CPU利用率扩所容,在vlalpha版本中,支持根据内存和用户自定义的metric扩缩容。\n\n**StatefulSet**\n\nStatefulSet是为了解决有状态服务的问题(对应Deployments和ReplicaSets是为无状态服务而设计) ,其应用场景包括:\n\n- 稳定的持久化存储,即Pod重新调度后还是能访问到相同的持久化数据,基于PVC来实现\n- 稳定的网络标志,即Pod重新调度后其PodName和HostNameT变,基于Headless Service(即没有Cluster IP的Service)来实现\n- 有序部署,有序扩展,即Pod是有顺序的,在部署或者扩展的时候要依据定义的顺序依次依次进行(即从0到N-1,在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态)基于init containers来实现\n- 有序收缩,有序删除(即从N-1到0)\n\n**DaemonSet**\n\nDaemonSet确保全部(或者一些)Node上运行一个Pod的副本。当有Node加入集群时,也会为他们新增一个Pod。当有Node从集群移除时,这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod\n使用DaemonSet的一些典型用法:\n\n- 运行集群存储daemon,例如在每个Node上运行 glusterd,ceph.\n- 在每个Node上运行日志收集daemon,例如fluentd、 logstash\n- 在 Node上运行监控 daemon,例如Prometheus Node Exporter\n\n**Job**\n\nJob负责批处理任务,即仅执行一次的任务,它保证批处理任务的一个或多个Pod成功结束\n\n**Cron Job **\n\n管理基于时间的Job,即:\n\n- 在给定时间点只运行一次\n- 周期性地在给定时间点运行","source":"_posts/kubernetes基础控制器.md","raw":"---\ntitle: kubernetes基础控制器\ndate: 2021-06-30 20:24:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - 控制器\n---\n\n**ReplicationController**\n\nReplicationController 用来确保容器应用的副本数始终保持在用户定义的副本数,即如果有容器异常退出，会自动创建新的Pod来替代；而如果异常多出来的容器也会自动回收。\n在新版本的Kubernetes 中建议使用ReplicaSet取代ReplicationController。\n\n**ReplicaSet**\n\nReplicaSet 和ReplicationController 没有本质的不同,只是名字不一样,并且ReplicaSet支持集合式的selector\n虽然ReplicaSet 可以独立使用，但一般还是建议使用Deployment来自动管理ReplicaSet ，这样就无需担心跟其他机制的不兼容问题(比如ReplicaSet不支持rolling-update，但Deployment 支持)\n\n**Deployment**\n\nDeployment Pod和ReplicaSet提供了一个声明式定义(declarative)方法,用来替代以前的ReplicationController来方便的管理应用。\n\nDeployment 是Kubenetes v1.2 引入的新概念，引入的目的是为了更好的解决Pod 的编排问题，Deployment 内部使用了Replica Set 来实现。\n\n典型的应用场景包括：\n\n- 定义Deployment 来创建Pod和ReplicaSet\n- 滚动升级和回滚应用\n- 扩容和缩容\n- 暂停和继续Deployment\n\n**Horizontal Pod Autoscaling**\n\nHorizontal Pod Autoscaling 仅适用于Deployment和ReplicaSet ,在V1版本中仅支持根据Pod的CPU利用率扩所容,在vlalpha版本中,支持根据内存和用户自定义的metric扩缩容。\n\n**StatefulSet**\n\nStatefulSet是为了解决有状态服务的问题(对应Deployments和ReplicaSets是为无状态服务而设计) ,其应用场景包括:\n\n- 稳定的持久化存储,即Pod重新调度后还是能访问到相同的持久化数据,基于PVC来实现\n- 稳定的网络标志,即Pod重新调度后其PodName和HostNameT变,基于Headless Service(即没有Cluster IP的Service)来实现\n- 有序部署,有序扩展,即Pod是有顺序的,在部署或者扩展的时候要依据定义的顺序依次依次进行(即从0到N-1,在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态)基于init containers来实现\n- 有序收缩,有序删除(即从N-1到0)\n\n**DaemonSet**\n\nDaemonSet确保全部(或者一些)Node上运行一个Pod的副本。当有Node加入集群时,也会为他们新增一个Pod。当有Node从集群移除时,这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod\n使用DaemonSet的一些典型用法:\n\n- 运行集群存储daemon,例如在每个Node上运行 glusterd,ceph.\n- 在每个Node上运行日志收集daemon,例如fluentd、 logstash\n- 在 Node上运行监控 daemon,例如Prometheus Node Exporter\n\n**Job**\n\nJob负责批处理任务,即仅执行一次的任务,它保证批处理任务的一个或多个Pod成功结束\n\n**Cron Job **\n\n管理基于时间的Job,即:\n\n- 在给定时间点只运行一次\n- 周期性地在给定时间点运行","slug":"kubernetes基础控制器","published":1,"updated":"2022-09-23T17:18:17.500Z","_id":"cl8eqx9sn000128vj4zyi19ns","comments":1,"layout":"post","photos":[],"link":"","content":"<p><strong>ReplicationController</strong></p>\n<p>ReplicationController 用来确保容器应用的副本数始终保持在用户定义的副本数,即如果有容器异常退出，会自动创建新的Pod来替代；而如果异常多出来的容器也会自动回收。<br>在新版本的Kubernetes 中建议使用ReplicaSet取代ReplicationController。</p>\n<p><strong>ReplicaSet</strong></p>\n<p>ReplicaSet 和ReplicationController 没有本质的不同,只是名字不一样,并且ReplicaSet支持集合式的selector<br>虽然ReplicaSet 可以独立使用，但一般还是建议使用Deployment来自动管理ReplicaSet ，这样就无需担心跟其他机制的不兼容问题(比如ReplicaSet不支持rolling-update，但Deployment 支持)</p>\n<p><strong>Deployment</strong></p>\n<p>Deployment Pod和ReplicaSet提供了一个声明式定义(declarative)方法,用来替代以前的ReplicationController来方便的管理应用。</p>\n<p>Deployment 是Kubenetes v1.2 引入的新概念，引入的目的是为了更好的解决Pod 的编排问题，Deployment 内部使用了Replica Set 来实现。</p>\n<p>典型的应用场景包括：</p>\n<ul>\n<li>定义Deployment 来创建Pod和ReplicaSet</li>\n<li>滚动升级和回滚应用</li>\n<li>扩容和缩容</li>\n<li>暂停和继续Deployment</li>\n</ul>\n<p><strong>Horizontal Pod Autoscaling</strong></p>\n<p>Horizontal Pod Autoscaling 仅适用于Deployment和ReplicaSet ,在V1版本中仅支持根据Pod的CPU利用率扩所容,在vlalpha版本中,支持根据内存和用户自定义的metric扩缩容。</p>\n<p><strong>StatefulSet</strong></p>\n<p>StatefulSet是为了解决有状态服务的问题(对应Deployments和ReplicaSets是为无状态服务而设计) ,其应用场景包括:</p>\n<ul>\n<li>稳定的持久化存储,即Pod重新调度后还是能访问到相同的持久化数据,基于PVC来实现</li>\n<li>稳定的网络标志,即Pod重新调度后其PodName和HostNameT变,基于Headless Service(即没有Cluster IP的Service)来实现</li>\n<li>有序部署,有序扩展,即Pod是有顺序的,在部署或者扩展的时候要依据定义的顺序依次依次进行(即从0到N-1,在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态)基于init containers来实现</li>\n<li>有序收缩,有序删除(即从N-1到0)</li>\n</ul>\n<p><strong>DaemonSet</strong></p>\n<p>DaemonSet确保全部(或者一些)Node上运行一个Pod的副本。当有Node加入集群时,也会为他们新增一个Pod。当有Node从集群移除时,这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod<br>使用DaemonSet的一些典型用法:</p>\n<ul>\n<li>运行集群存储daemon,例如在每个Node上运行 glusterd,ceph.</li>\n<li>在每个Node上运行日志收集daemon,例如fluentd、 logstash</li>\n<li>在 Node上运行监控 daemon,例如Prometheus Node Exporter</li>\n</ul>\n<p><strong>Job</strong></p>\n<p>Job负责批处理任务,即仅执行一次的任务,它保证批处理任务的一个或多个Pod成功结束</p>\n<p>**Cron Job **</p>\n<p>管理基于时间的Job,即:</p>\n<ul>\n<li>在给定时间点只运行一次</li>\n<li>周期性地在给定时间点运行</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>ReplicationController</strong></p>\n<p>ReplicationController 用来确保容器应用的副本数始终保持在用户定义的副本数,即如果有容器异常退出，会自动创建新的Pod来替代；而如果异常多出来的容器也会自动回收。<br>在新版本的Kubernetes 中建议使用ReplicaSet取代ReplicationController。</p>\n<p><strong>ReplicaSet</strong></p>\n<p>ReplicaSet 和ReplicationController 没有本质的不同,只是名字不一样,并且ReplicaSet支持集合式的selector<br>虽然ReplicaSet 可以独立使用，但一般还是建议使用Deployment来自动管理ReplicaSet ，这样就无需担心跟其他机制的不兼容问题(比如ReplicaSet不支持rolling-update，但Deployment 支持)</p>\n<p><strong>Deployment</strong></p>\n<p>Deployment Pod和ReplicaSet提供了一个声明式定义(declarative)方法,用来替代以前的ReplicationController来方便的管理应用。</p>\n<p>Deployment 是Kubenetes v1.2 引入的新概念，引入的目的是为了更好的解决Pod 的编排问题，Deployment 内部使用了Replica Set 来实现。</p>\n<p>典型的应用场景包括：</p>\n<ul>\n<li>定义Deployment 来创建Pod和ReplicaSet</li>\n<li>滚动升级和回滚应用</li>\n<li>扩容和缩容</li>\n<li>暂停和继续Deployment</li>\n</ul>\n<p><strong>Horizontal Pod Autoscaling</strong></p>\n<p>Horizontal Pod Autoscaling 仅适用于Deployment和ReplicaSet ,在V1版本中仅支持根据Pod的CPU利用率扩所容,在vlalpha版本中,支持根据内存和用户自定义的metric扩缩容。</p>\n<p><strong>StatefulSet</strong></p>\n<p>StatefulSet是为了解决有状态服务的问题(对应Deployments和ReplicaSets是为无状态服务而设计) ,其应用场景包括:</p>\n<ul>\n<li>稳定的持久化存储,即Pod重新调度后还是能访问到相同的持久化数据,基于PVC来实现</li>\n<li>稳定的网络标志,即Pod重新调度后其PodName和HostNameT变,基于Headless Service(即没有Cluster IP的Service)来实现</li>\n<li>有序部署,有序扩展,即Pod是有顺序的,在部署或者扩展的时候要依据定义的顺序依次依次进行(即从0到N-1,在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态)基于init containers来实现</li>\n<li>有序收缩,有序删除(即从N-1到0)</li>\n</ul>\n<p><strong>DaemonSet</strong></p>\n<p>DaemonSet确保全部(或者一些)Node上运行一个Pod的副本。当有Node加入集群时,也会为他们新增一个Pod。当有Node从集群移除时,这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod<br>使用DaemonSet的一些典型用法:</p>\n<ul>\n<li>运行集群存储daemon,例如在每个Node上运行 glusterd,ceph.</li>\n<li>在每个Node上运行日志收集daemon,例如fluentd、 logstash</li>\n<li>在 Node上运行监控 daemon,例如Prometheus Node Exporter</li>\n</ul>\n<p><strong>Job</strong></p>\n<p>Job负责批处理任务,即仅执行一次的任务,它保证批处理任务的一个或多个Pod成功结束</p>\n<p>**Cron Job **</p>\n<p>管理基于时间的Job,即:</p>\n<ul>\n<li>在给定时间点只运行一次</li>\n<li>周期性地在给定时间点运行</li>\n</ul>\n"},{"title":"RC与RS与Deployment关联","date":"2021-07-16T02:24:02.000Z","_content":"\n# RC\n\nRC (ReplicationController )主要的作用就是用来确保容器应用的副本数始终保持在用户定义的副本数。即如果有容器异常退出,会自动创建新的Pod来替代:而如果异常多出来的容器也会自动回收\n\nKubernetes 官方建议使用RS (ReplicaSet)替代RC (ReplicationController)进行部署,RS跟RC没有本质的不同,只是名字不一样,并且RS支持集合式的selector\n\n```yaml\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google_samples/gb-frontend:v3\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 88\n```\n\n操作：\n\n```\n[root@k8s-master01 data5]# kubectl create -f rs.yaml \n[root@k8s-master01 data5]# kubectl get pod -o wide\nNAME             READY   STATUS    RESTARTS   AGE   IP           NODE         NOMINATED NODE   READINESS GATES\nfrontend-dflfh   1/1     Running   0          11m   10.244.2.6   k8s-node02   <none>           <none>\nfrontend-vnjfd   1/1     Running   0          11m   10.244.1.9   k8s-node01   <none>           <none>\nfrontend-x9kfr   1/1     Running   0          11m   10.244.1.8   k8s-node01   <none>           <none>\n```\n\n修改label过程\n\n```\n[root@k8s-master01 data5]# kubectl get pod --show-labels\nNAME             READY   STATUS              RESTARTS   AGE    LABELS\nfrontend-dflfh   0/1     ContainerCreating   0          109s   tier=frontend\nfrontend-vnjfd   0/1     ContainerCreating   0          109s   tier=frontend\nfrontend-x9kfr   0/1     ContainerCreating   0          109s   tier=frontend\n[root@k8s-master01 data5]# kubectl label pod frontend-vnjfd tier=frontend1 --overwrite\npod/frontend-vnjfd labeled\n[root@k8s-master01 data5]# kubectl get pod --show-labels\nNAME             READY   STATUS    RESTARTS   AGE   LABELS\nfrontend-dflfh   1/1     Running   0          15m   tier=frontend\nfrontend-vnjfd   1/1     Running   0          15m   tier=frontend1\nfrontend-x9kfr   1/1     Running   0          15m   tier=frontend\nfrontend-zqxxj   1/1     Running   0          40s   tier=frontend\n```\n\n结论：当label修改为frontend1后，rs将会创建一个新的pod，因为rs通过label控制pod，当其中一个pod的label修改了，rs就会自动创建一个\n\n将pod的label修改回frontend：\n\n```\n[root@k8s-master01 data5]# kubectl label pod frontend-vnjfd tier=frontend --overwrite \npod/frontend-vnjfd labeled\n[root@k8s-master01 data5]# kubectl get pod --show-labels                             \nNAME             READY   STATUS    RESTARTS   AGE   LABELS\nfrontend-dflfh   1/1     Running   0          17m   tier=frontend\nfrontend-vnjfd   1/1     Running   0          17m   tier=frontend\nfrontend-x9kfr   1/1     Running   0          17m   tier=frontend\n```\n\n结论：rs会自动的缩减pod，将上面新增的pod去掉。\n\n# RS 与Deployment 的关联\n\n![1657973507960](RC与RS与Deployment关联/1657973507960.png)\n\n# Deployment\n\nDeployment为Pod和ReplicaSet提供了一个声明式定义(declarative)方法,用来替代以前的ReplicationController 来方便的管理应用。典型的应用场景包括:\n\n- 定义Deployment来创建Pod和ReplicaSet\n- 滚动升级和回滚应用\n- 扩容和缩容\n- 暂停和继续Deployment\n\n## 1、部署一个简单的Nginx应用\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: harborcloud.com/library/nginx:1.7.9\n        ports:\n        - containerPort: 88\n```\n\n````yaml\nkubectl create -f nginx-deployment.yaml -record\n# --record参数可以记录命令,我们可以很方便的查看每次revision的变化\n````\n\n## 2、扩容\n\n```\n[root@k8s-master01 data5]# kubectl scale deployment nginx-deployment --replicas 10\n[root@k8s-master01 data5]# kubectl get pod -o wide\nNAME                                READY   STATUS    RESTARTS   AGE     IP            NODE         NOMINATED NODE   READINESS GATES\nnginx-deployment-56bd657787-4qvb6   1/1     Running   0          17m     10.244.1.11   k8s-node01   <none>           <none>\nnginx-deployment-56bd657787-777rm   1/1     Running   0          17m     10.244.1.10   k8s-node01   <none>           <none>\nnginx-deployment-56bd657787-78hq6   1/1     Running   0          2m36s   10.244.2.13   k8s-node02   <none>           <none>\nnginx-deployment-56bd657787-86wzj   1/1     Running   0          2m36s   10.244.2.11   k8s-node02   <none>           <none>\nnginx-deployment-56bd657787-98tn6   1/1     Running   0          2m36s   10.244.1.12   k8s-node01   <none>           <none>\nnginx-deployment-56bd657787-9wnvc   1/1     Running   0          2m36s   10.244.1.13   k8s-node01   <none>           <none>\nnginx-deployment-56bd657787-n5b9r   1/1     Running   0          2m36s   10.244.2.14   k8s-node02   <none>           <none>\nnginx-deployment-56bd657787-phd6z   1/1     Running   0          2m36s   10.244.1.14   k8s-node01   <none>           <none>\nnginx-deployment-56bd657787-rdzst   1/1     Running   0          2m36s   10.244.2.12   k8s-node02   <none>           <none>\nnginx-deployment-56bd657787-xbfqr   1/1     Running   0          9m4s    10.244.2.10   k8s-node02   <none>           <none>\n```\n\n## 3、如果集群支持horizontal pod autoscaling 的话,还可以为Deployment设置自动扩展\n\n```\nkubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80\n```\n\n## 4、更新镜像也比较简单\n\n```\nkubectl set image deployment/nginx-deployment nginx=harborcloud.com/library/nginx:1.9.1\n```\n\n## 5、回滚\n\n```\n[root@k8s-master01 data5]# kubectl rollout undo deployment/nginx-deployment\ndeployment.apps/nginx-deployment rolled back\n```\n\n## 6、删除deployment\n\n```\nkubectl delete -f nginx-deployment.yaml \n```\n\n# 更新Deployment\n\n假如我们现在想要让nginx pod使用nginx:1.9.1的镜像来代替原来的nginx:1.7.9的镜像\n\n```\n$ kubectl set image deployment/nginx-deployment nginx=harborcloud.com/library/nginx:1.9.1\n```\n\n可以使用 edit 命令来编辑Deployment\n\n```\n$ kubectl edit deployment/nginx-deployment\n```\n\n查看更新记录\n\n```\n[root@k8s-master01 data5]# kubectl rollout history deployment nginx-deployment\ndeployment.apps/nginx-deployment \nREVISION  CHANGE-CAUSE\n1         <none>\n2         <none>\n```\n\n查看rollout的状态\n\n```\n$ kubectl rollout status deployment/nginx-deployment\n```\n\n查看历史RS\n\n```\n$ kubectl get rs\n```\n\n回滚到指定版本 \n\n```\nkubectl rollout undo deployment nginx-deployment --to-revision=2\n```\n\n```\n[root@k8s-master01 data5]# kubectl rollout history deployment nginx-deployment\ndeployment.apps/nginx-deployment \nREVISION  CHANGE-CAUSE\n2         <none>\n3         <none>\n\n[root@k8s-master01 data5]# kubectl rollout undo deployment nginx-deployment --to-revision=2\ndeployment.apps/nginx-deployment rolled back\n[root@k8s-master01 data5]# kubectl rollout history deployment nginx-deployment             \ndeployment.apps/nginx-deployment \nREVISION  CHANGE-CAUSE\n3         <none>\n4         <none>\n```\n\n# Deployment 更新策略\n\nDeployment 可以保证在升级时只有一定数量的Pod 是 down的。默认的,它会确保至少有比期望的Pod数量少一个是up状态(最多一个不可用)\n\nDeployment同时也可以确保只创建出超过期望数量的一定数量的Pod。默认的,它会确保最多比期望的Pod数量多一个的Pod是up的(最多1个surge)\n未来的Kuberentes版本中,将从1-1变成25%-25%\n\n```\n$ kubectl describe deployments\n```\n\n# Rollover (多个rollout并行)\n\n假如您创建了一个有5个niginx:1.7.9 replica的Deployment,但是当还只有3个nginx:1.7.9的replica创建出来的时候您就开始更新含有5个 nginx:1.9.1 replica的Deployment.在这种情况下, Deployment会立即杀掉已创建的3个nginx:1.7.9的Pod,并开始创建nginx:1.9.1的Pod。它不会等到所有的5个nginx:1.7.9的\nPod都创建完成后才开始改变航道\n\n# 回退Deployment\n\n```\nkubectl set image deployment/nginx-deployment nginx=harborcloud.com/library/nginx:1.91\nkubectl rollout status deployments nginx-deployment ## 回退状态\nkubectl get pods\nkubectl rollout history deployment/nginx-deployment ## 历史 版本 \nkubectl rollout undo deployment/nginx-deployment ##回退版本\nkubectl rollout undo deployment/nginx-deployment --to-revision=2 ## 可以使用--revision参数指定某个历史版本\nkubectl rollout pause deployment/nginx-deployment## 暂停deployment更新\n```\n\n您可以用 kubectl rollout status Deployment 是否完成。如果 rollout 成完成, kubectl rollout status将返回一个0值的Exit Code\n\n```\n$ kubectl rollout status deploy/nginx\n```\n\n# 清理Policy\n\n您可以通过设置.spec. revisonHistoryLimit项来指定deployment 最多保留多少 revision历史记录。默认的会保留所有的revision;如果将该项设置为0, Deployment就不允许回退了\n\n","source":"_posts/RC与RS与Deployment关联.md","raw":"---\ntitle: RC与RS与Deployment关联\ndate: 2021-07-16 10:24:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n---\n\n# RC\n\nRC (ReplicationController )主要的作用就是用来确保容器应用的副本数始终保持在用户定义的副本数。即如果有容器异常退出,会自动创建新的Pod来替代:而如果异常多出来的容器也会自动回收\n\nKubernetes 官方建议使用RS (ReplicaSet)替代RC (ReplicationController)进行部署,RS跟RC没有本质的不同,只是名字不一样,并且RS支持集合式的selector\n\n```yaml\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google_samples/gb-frontend:v3\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 88\n```\n\n操作：\n\n```\n[root@k8s-master01 data5]# kubectl create -f rs.yaml \n[root@k8s-master01 data5]# kubectl get pod -o wide\nNAME             READY   STATUS    RESTARTS   AGE   IP           NODE         NOMINATED NODE   READINESS GATES\nfrontend-dflfh   1/1     Running   0          11m   10.244.2.6   k8s-node02   <none>           <none>\nfrontend-vnjfd   1/1     Running   0          11m   10.244.1.9   k8s-node01   <none>           <none>\nfrontend-x9kfr   1/1     Running   0          11m   10.244.1.8   k8s-node01   <none>           <none>\n```\n\n修改label过程\n\n```\n[root@k8s-master01 data5]# kubectl get pod --show-labels\nNAME             READY   STATUS              RESTARTS   AGE    LABELS\nfrontend-dflfh   0/1     ContainerCreating   0          109s   tier=frontend\nfrontend-vnjfd   0/1     ContainerCreating   0          109s   tier=frontend\nfrontend-x9kfr   0/1     ContainerCreating   0          109s   tier=frontend\n[root@k8s-master01 data5]# kubectl label pod frontend-vnjfd tier=frontend1 --overwrite\npod/frontend-vnjfd labeled\n[root@k8s-master01 data5]# kubectl get pod --show-labels\nNAME             READY   STATUS    RESTARTS   AGE   LABELS\nfrontend-dflfh   1/1     Running   0          15m   tier=frontend\nfrontend-vnjfd   1/1     Running   0          15m   tier=frontend1\nfrontend-x9kfr   1/1     Running   0          15m   tier=frontend\nfrontend-zqxxj   1/1     Running   0          40s   tier=frontend\n```\n\n结论：当label修改为frontend1后，rs将会创建一个新的pod，因为rs通过label控制pod，当其中一个pod的label修改了，rs就会自动创建一个\n\n将pod的label修改回frontend：\n\n```\n[root@k8s-master01 data5]# kubectl label pod frontend-vnjfd tier=frontend --overwrite \npod/frontend-vnjfd labeled\n[root@k8s-master01 data5]# kubectl get pod --show-labels                             \nNAME             READY   STATUS    RESTARTS   AGE   LABELS\nfrontend-dflfh   1/1     Running   0          17m   tier=frontend\nfrontend-vnjfd   1/1     Running   0          17m   tier=frontend\nfrontend-x9kfr   1/1     Running   0          17m   tier=frontend\n```\n\n结论：rs会自动的缩减pod，将上面新增的pod去掉。\n\n# RS 与Deployment 的关联\n\n![1657973507960](RC与RS与Deployment关联/1657973507960.png)\n\n# Deployment\n\nDeployment为Pod和ReplicaSet提供了一个声明式定义(declarative)方法,用来替代以前的ReplicationController 来方便的管理应用。典型的应用场景包括:\n\n- 定义Deployment来创建Pod和ReplicaSet\n- 滚动升级和回滚应用\n- 扩容和缩容\n- 暂停和继续Deployment\n\n## 1、部署一个简单的Nginx应用\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: harborcloud.com/library/nginx:1.7.9\n        ports:\n        - containerPort: 88\n```\n\n````yaml\nkubectl create -f nginx-deployment.yaml -record\n# --record参数可以记录命令,我们可以很方便的查看每次revision的变化\n````\n\n## 2、扩容\n\n```\n[root@k8s-master01 data5]# kubectl scale deployment nginx-deployment --replicas 10\n[root@k8s-master01 data5]# kubectl get pod -o wide\nNAME                                READY   STATUS    RESTARTS   AGE     IP            NODE         NOMINATED NODE   READINESS GATES\nnginx-deployment-56bd657787-4qvb6   1/1     Running   0          17m     10.244.1.11   k8s-node01   <none>           <none>\nnginx-deployment-56bd657787-777rm   1/1     Running   0          17m     10.244.1.10   k8s-node01   <none>           <none>\nnginx-deployment-56bd657787-78hq6   1/1     Running   0          2m36s   10.244.2.13   k8s-node02   <none>           <none>\nnginx-deployment-56bd657787-86wzj   1/1     Running   0          2m36s   10.244.2.11   k8s-node02   <none>           <none>\nnginx-deployment-56bd657787-98tn6   1/1     Running   0          2m36s   10.244.1.12   k8s-node01   <none>           <none>\nnginx-deployment-56bd657787-9wnvc   1/1     Running   0          2m36s   10.244.1.13   k8s-node01   <none>           <none>\nnginx-deployment-56bd657787-n5b9r   1/1     Running   0          2m36s   10.244.2.14   k8s-node02   <none>           <none>\nnginx-deployment-56bd657787-phd6z   1/1     Running   0          2m36s   10.244.1.14   k8s-node01   <none>           <none>\nnginx-deployment-56bd657787-rdzst   1/1     Running   0          2m36s   10.244.2.12   k8s-node02   <none>           <none>\nnginx-deployment-56bd657787-xbfqr   1/1     Running   0          9m4s    10.244.2.10   k8s-node02   <none>           <none>\n```\n\n## 3、如果集群支持horizontal pod autoscaling 的话,还可以为Deployment设置自动扩展\n\n```\nkubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80\n```\n\n## 4、更新镜像也比较简单\n\n```\nkubectl set image deployment/nginx-deployment nginx=harborcloud.com/library/nginx:1.9.1\n```\n\n## 5、回滚\n\n```\n[root@k8s-master01 data5]# kubectl rollout undo deployment/nginx-deployment\ndeployment.apps/nginx-deployment rolled back\n```\n\n## 6、删除deployment\n\n```\nkubectl delete -f nginx-deployment.yaml \n```\n\n# 更新Deployment\n\n假如我们现在想要让nginx pod使用nginx:1.9.1的镜像来代替原来的nginx:1.7.9的镜像\n\n```\n$ kubectl set image deployment/nginx-deployment nginx=harborcloud.com/library/nginx:1.9.1\n```\n\n可以使用 edit 命令来编辑Deployment\n\n```\n$ kubectl edit deployment/nginx-deployment\n```\n\n查看更新记录\n\n```\n[root@k8s-master01 data5]# kubectl rollout history deployment nginx-deployment\ndeployment.apps/nginx-deployment \nREVISION  CHANGE-CAUSE\n1         <none>\n2         <none>\n```\n\n查看rollout的状态\n\n```\n$ kubectl rollout status deployment/nginx-deployment\n```\n\n查看历史RS\n\n```\n$ kubectl get rs\n```\n\n回滚到指定版本 \n\n```\nkubectl rollout undo deployment nginx-deployment --to-revision=2\n```\n\n```\n[root@k8s-master01 data5]# kubectl rollout history deployment nginx-deployment\ndeployment.apps/nginx-deployment \nREVISION  CHANGE-CAUSE\n2         <none>\n3         <none>\n\n[root@k8s-master01 data5]# kubectl rollout undo deployment nginx-deployment --to-revision=2\ndeployment.apps/nginx-deployment rolled back\n[root@k8s-master01 data5]# kubectl rollout history deployment nginx-deployment             \ndeployment.apps/nginx-deployment \nREVISION  CHANGE-CAUSE\n3         <none>\n4         <none>\n```\n\n# Deployment 更新策略\n\nDeployment 可以保证在升级时只有一定数量的Pod 是 down的。默认的,它会确保至少有比期望的Pod数量少一个是up状态(最多一个不可用)\n\nDeployment同时也可以确保只创建出超过期望数量的一定数量的Pod。默认的,它会确保最多比期望的Pod数量多一个的Pod是up的(最多1个surge)\n未来的Kuberentes版本中,将从1-1变成25%-25%\n\n```\n$ kubectl describe deployments\n```\n\n# Rollover (多个rollout并行)\n\n假如您创建了一个有5个niginx:1.7.9 replica的Deployment,但是当还只有3个nginx:1.7.9的replica创建出来的时候您就开始更新含有5个 nginx:1.9.1 replica的Deployment.在这种情况下, Deployment会立即杀掉已创建的3个nginx:1.7.9的Pod,并开始创建nginx:1.9.1的Pod。它不会等到所有的5个nginx:1.7.9的\nPod都创建完成后才开始改变航道\n\n# 回退Deployment\n\n```\nkubectl set image deployment/nginx-deployment nginx=harborcloud.com/library/nginx:1.91\nkubectl rollout status deployments nginx-deployment ## 回退状态\nkubectl get pods\nkubectl rollout history deployment/nginx-deployment ## 历史 版本 \nkubectl rollout undo deployment/nginx-deployment ##回退版本\nkubectl rollout undo deployment/nginx-deployment --to-revision=2 ## 可以使用--revision参数指定某个历史版本\nkubectl rollout pause deployment/nginx-deployment## 暂停deployment更新\n```\n\n您可以用 kubectl rollout status Deployment 是否完成。如果 rollout 成完成, kubectl rollout status将返回一个0值的Exit Code\n\n```\n$ kubectl rollout status deploy/nginx\n```\n\n# 清理Policy\n\n您可以通过设置.spec. revisonHistoryLimit项来指定deployment 最多保留多少 revision历史记录。默认的会保留所有的revision;如果将该项设置为0, Deployment就不允许回退了\n\n","slug":"RC与RS与Deployment关联","published":1,"updated":"2022-09-23T17:21:50.824Z","_id":"cl8er1d4d000628vjeuva6s6v","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"RC\"><a href=\"#RC\" class=\"headerlink\" title=\"RC\"></a>RC</h1><p>RC (ReplicationController )主要的作用就是用来确保容器应用的副本数始终保持在用户定义的副本数。即如果有容器异常退出,会自动创建新的Pod来替代:而如果异常多出来的容器也会自动回收</p>\n<p>Kubernetes 官方建议使用RS (ReplicaSet)替代RC (ReplicationController)进行部署,RS跟RC没有本质的不同,只是名字不一样,并且RS支持集合式的selector</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">apps/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">ReplicaSet</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">frontend</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-number\">3</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">matchLabels:</span><br>      <span class=\"hljs-attr\">tier:</span> <span class=\"hljs-string\">frontend</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">labels:</span><br>        <span class=\"hljs-attr\">tier:</span> <span class=\"hljs-string\">frontend</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">php-redis</span><br>        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">gcr.io/google_samples/gb-frontend:v3</span><br>        <span class=\"hljs-attr\">env:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">GET_HOSTS_FROM</span><br>          <span class=\"hljs-attr\">value:</span> <span class=\"hljs-string\">dns</span><br>        <span class=\"hljs-attr\">ports:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">88</span><br></code></pre></td></tr></table></figure>\n\n<p>操作：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\">[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 data5]# kubectl <span class=\"hljs-keyword\">create</span> <span class=\"hljs-operator\">-</span>f rs.yaml <br>[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 data5]# kubectl <span class=\"hljs-keyword\">get</span> pod <span class=\"hljs-operator\">-</span>o wide<br>NAME             READY   STATUS    RESTARTS   AGE   IP           NODE         NOMINATED NODE   READINESS GATES<br>frontend<span class=\"hljs-operator\">-</span>dflfh   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">11</span>m   <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.2</span><span class=\"hljs-number\">.6</span>   k8s<span class=\"hljs-operator\">-</span>node02   <span class=\"hljs-operator\">&lt;</span><span class=\"hljs-keyword\">none</span><span class=\"hljs-operator\">&gt;</span>           <span class=\"hljs-operator\">&lt;</span><span class=\"hljs-keyword\">none</span><span class=\"hljs-operator\">&gt;</span><br>frontend<span class=\"hljs-operator\">-</span>vnjfd   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">11</span>m   <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.1</span><span class=\"hljs-number\">.9</span>   k8s<span class=\"hljs-operator\">-</span>node01   <span class=\"hljs-operator\">&lt;</span><span class=\"hljs-keyword\">none</span><span class=\"hljs-operator\">&gt;</span>           <span class=\"hljs-operator\">&lt;</span><span class=\"hljs-keyword\">none</span><span class=\"hljs-operator\">&gt;</span><br>frontend<span class=\"hljs-operator\">-</span>x9kfr   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">11</span>m   <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.1</span><span class=\"hljs-number\">.8</span>   k8s<span class=\"hljs-operator\">-</span>node01   <span class=\"hljs-operator\">&lt;</span><span class=\"hljs-keyword\">none</span><span class=\"hljs-operator\">&gt;</span>           <span class=\"hljs-operator\">&lt;</span><span class=\"hljs-keyword\">none</span><span class=\"hljs-operator\">&gt;</span><br></code></pre></td></tr></table></figure>\n\n<p>修改label过程</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">[root@k8s-master01 data5]# kubectl <span class=\"hljs-built_in\">get</span> pod --show-labels<br>NAME             READY   STATUS              RESTARTS   AGE    LABELS<br>frontend-dflfh   0/1     ContainerCreating   0          109s   <span class=\"hljs-attribute\">tier</span>=frontend<br>frontend-vnjfd   0/1     ContainerCreating   0          109s   <span class=\"hljs-attribute\">tier</span>=frontend<br>frontend-x9kfr   0/1     ContainerCreating   0          109s   <span class=\"hljs-attribute\">tier</span>=frontend<br>[root@k8s-master01 data5]# kubectl label pod frontend-vnjfd <span class=\"hljs-attribute\">tier</span>=frontend1 --overwrite<br>pod/frontend-vnjfd labeled<br>[root@k8s-master01 data5]# kubectl <span class=\"hljs-built_in\">get</span> pod --show-labels<br>NAME             READY   STATUS    RESTARTS   AGE   LABELS<br>frontend-dflfh   1/1     Running   0          15m   <span class=\"hljs-attribute\">tier</span>=frontend<br>frontend-vnjfd   1/1     Running   0          15m   <span class=\"hljs-attribute\">tier</span>=frontend1<br>frontend-x9kfr   1/1     Running   0          15m   <span class=\"hljs-attribute\">tier</span>=frontend<br>frontend-zqxxj   1/1     Running   0          40s   <span class=\"hljs-attribute\">tier</span>=frontend<br></code></pre></td></tr></table></figure>\n\n<p>结论：当label修改为frontend1后，rs将会创建一个新的pod，因为rs通过label控制pod，当其中一个pod的label修改了，rs就会自动创建一个</p>\n<p>将pod的label修改回frontend：</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">[root@k8s-master01 data5]# kubectl label pod frontend-vnjfd <span class=\"hljs-attribute\">tier</span>=frontend --overwrite <br>pod/frontend-vnjfd labeled<br>[root@k8s-master01 data5]# kubectl <span class=\"hljs-built_in\">get</span> pod --show-labels                             <br>NAME             READY   STATUS    RESTARTS   AGE   LABELS<br>frontend-dflfh   1/1     Running   0          17m   <span class=\"hljs-attribute\">tier</span>=frontend<br>frontend-vnjfd   1/1     Running   0          17m   <span class=\"hljs-attribute\">tier</span>=frontend<br>frontend-x9kfr   1/1     Running   0          17m   <span class=\"hljs-attribute\">tier</span>=frontend<br></code></pre></td></tr></table></figure>\n\n<p>结论：rs会自动的缩减pod，将上面新增的pod去掉。</p>\n<h1 id=\"RS-与Deployment-的关联\"><a href=\"#RS-与Deployment-的关联\" class=\"headerlink\" title=\"RS 与Deployment 的关联\"></a>RS 与Deployment 的关联</h1><img src=\"/2021/07/16/RC%E4%B8%8ERS%E4%B8%8EDeployment%E5%85%B3%E8%81%94/1657973507960.png\" class=\"\" width=\"1657973507960\">\n\n<h1 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h1><p>Deployment为Pod和ReplicaSet提供了一个声明式定义(declarative)方法,用来替代以前的ReplicationController 来方便的管理应用。典型的应用场景包括:</p>\n<ul>\n<li>定义Deployment来创建Pod和ReplicaSet</li>\n<li>滚动升级和回滚应用</li>\n<li>扩容和缩容</li>\n<li>暂停和继续Deployment</li>\n</ul>\n<h2 id=\"1、部署一个简单的Nginx应用\"><a href=\"#1、部署一个简单的Nginx应用\" class=\"headerlink\" title=\"1、部署一个简单的Nginx应用\"></a>1、部署一个简单的Nginx应用</h2><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">apps/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Deployment</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">nginx-deployment</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-number\">3</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">matchLabels:</span><br>      <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">nginx</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">labels:</span><br>        <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">nginx</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">nginx</span><br>        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.7.9</span><br>        <span class=\"hljs-attr\">ports:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">88</span><br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-string\">kubectl</span> <span class=\"hljs-string\">create</span> <span class=\"hljs-string\">-f</span> <span class=\"hljs-string\">nginx-deployment.yaml</span> <span class=\"hljs-string\">-record</span><br><span class=\"hljs-comment\"># --record参数可以记录命令,我们可以很方便的查看每次revision的变化</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2、扩容\"><a href=\"#2、扩容\" class=\"headerlink\" title=\"2、扩容\"></a>2、扩容</h2><figure class=\"highlight gherkin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gherkin\">[root<span class=\"hljs-meta\">@k8s-master01</span> data5]<span class=\"hljs-comment\"># kubectl scale deployment nginx-deployment --replicas 10</span><br>[root<span class=\"hljs-meta\">@k8s-master01</span> data5]<span class=\"hljs-comment\"># kubectl get pod -o wide</span><br>NAME                                READY   STATUS    RESTARTS   AGE     IP            NODE         NOMINATED NODE   READINESS GATES<br>nginx-deployment-56bd657787-4qvb6   1/1     Running   0          17m     10.244.1.11   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-777rm   1/1     Running   0          17m     10.244.1.10   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-78hq6   1/1     Running   0          2m36s   10.244.2.13   k8s-node02   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-86wzj   1/1     Running   0          2m36s   10.244.2.11   k8s-node02   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-98tn6   1/1     Running   0          2m36s   10.244.1.12   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-9wnvc   1/1     Running   0          2m36s   10.244.1.13   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-n5b9r   1/1     Running   0          2m36s   10.244.2.14   k8s-node02   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-phd6z   1/1     Running   0          2m36s   10.244.1.14   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-rdzst   1/1     Running   0          2m36s   10.244.2.12   k8s-node02   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-xbfqr   1/1     Running   0          9m4s    10.244.2.10   k8s-node02   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"3、如果集群支持horizontal-pod-autoscaling-的话-还可以为Deployment设置自动扩展\"><a href=\"#3、如果集群支持horizontal-pod-autoscaling-的话-还可以为Deployment设置自动扩展\" class=\"headerlink\" title=\"3、如果集群支持horizontal pod autoscaling 的话,还可以为Deployment设置自动扩展\"></a>3、如果集群支持horizontal pod autoscaling 的话,还可以为Deployment设置自动扩展</h2><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl autoscale deployment nginx-deployment <span class=\"hljs-attribute\">--min</span>=10 <span class=\"hljs-attribute\">--max</span>=15 <span class=\"hljs-attribute\">--cpu-percent</span>=80<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"4、更新镜像也比较简单\"><a href=\"#4、更新镜像也比较简单\" class=\"headerlink\" title=\"4、更新镜像也比较简单\"></a>4、更新镜像也比较简单</h2><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl <span class=\"hljs-built_in\">set</span> image deployment/nginx-deployment <span class=\"hljs-attribute\">nginx</span>=harborcloud.com/library/nginx:1.9.1<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5、回滚\"><a href=\"#5、回滚\" class=\"headerlink\" title=\"5、回滚\"></a>5、回滚</h2><figure class=\"highlight applescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs applescript\">[root@k8s-master01 data5]<span class=\"hljs-comment\"># kubectl rollout undo deployment/nginx-deployment</span><br>deployment.apps/nginx-deployment rolled <span class=\"hljs-keyword\">back</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"6、删除deployment\"><a href=\"#6、删除deployment\" class=\"headerlink\" title=\"6、删除deployment\"></a>6、删除deployment</h2><figure class=\"highlight actionscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs actionscript\">kubectl <span class=\"hljs-keyword\">delete</span> -f nginx-deployment.yaml <br></code></pre></td></tr></table></figure>\n\n<h1 id=\"更新Deployment\"><a href=\"#更新Deployment\" class=\"headerlink\" title=\"更新Deployment\"></a>更新Deployment</h1><p>假如我们现在想要让nginx pod使用nginx:1.9.1的镜像来代替原来的nginx:1.7.9的镜像</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">$ kubectl <span class=\"hljs-built_in\">set</span> image deployment/nginx-deployment <span class=\"hljs-attribute\">nginx</span>=harborcloud.com/library/nginx:1.9.1<br></code></pre></td></tr></table></figure>\n\n<p>可以使用 edit 命令来编辑Deployment</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">$ kubectl <span class=\"hljs-built_in\">edit</span> deployment/nginx-deployment<br></code></pre></td></tr></table></figure>\n\n<p>查看更新记录</p>\n<figure class=\"highlight gherkin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gherkin\">[root<span class=\"hljs-meta\">@k8s-master01</span> data5]<span class=\"hljs-comment\"># kubectl rollout history deployment nginx-deployment</span><br>deployment.apps/nginx-deployment <br>REVISION  CHANGE-CAUSE<br>1         <span class=\"hljs-variable\">&lt;none&gt;</span><br>2         <span class=\"hljs-variable\">&lt;none&gt;</span><br></code></pre></td></tr></table></figure>\n\n<p>查看rollout的状态</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl rollout status deployment/nginx-deployment</span><br></code></pre></td></tr></table></figure>\n\n<p>查看历史RS</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">$ kubectl <span class=\"hljs-built_in\">get</span> rs<br></code></pre></td></tr></table></figure>\n\n<p>回滚到指定版本 </p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl rollout undo deployment nginx-deployment <span class=\"hljs-attribute\">--to-revision</span>=2<br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight gherkin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gherkin\">[root<span class=\"hljs-meta\">@k8s-master01</span> data5]<span class=\"hljs-comment\"># kubectl rollout history deployment nginx-deployment</span><br>deployment.apps/nginx-deployment <br>REVISION  CHANGE-CAUSE<br>2         <span class=\"hljs-variable\">&lt;none&gt;</span><br>3         <span class=\"hljs-variable\">&lt;none&gt;</span><br><br>[root<span class=\"hljs-meta\">@k8s-master01</span> data5]<span class=\"hljs-comment\"># kubectl rollout undo deployment nginx-deployment --to-revision=2</span><br>deployment.apps/nginx-deployment rolled back<br>[root<span class=\"hljs-meta\">@k8s-master01</span> data5]<span class=\"hljs-comment\"># kubectl rollout history deployment nginx-deployment             </span><br>deployment.apps/nginx-deployment <br>REVISION  CHANGE-CAUSE<br>3         <span class=\"hljs-variable\">&lt;none&gt;</span><br>4         <span class=\"hljs-variable\">&lt;none&gt;</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"Deployment-更新策略\"><a href=\"#Deployment-更新策略\" class=\"headerlink\" title=\"Deployment 更新策略\"></a>Deployment 更新策略</h1><p>Deployment 可以保证在升级时只有一定数量的Pod 是 down的。默认的,它会确保至少有比期望的Pod数量少一个是up状态(最多一个不可用)</p>\n<p>Deployment同时也可以确保只创建出超过期望数量的一定数量的Pod。默认的,它会确保最多比期望的Pod数量多一个的Pod是up的(最多1个surge)<br>未来的Kuberentes版本中,将从1-1变成25%-25%</p>\n<figure class=\"highlight crystal\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crystal\"><span class=\"hljs-variable\">$ </span>kubectl describe deployments<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"Rollover-多个rollout并行\"><a href=\"#Rollover-多个rollout并行\" class=\"headerlink\" title=\"Rollover (多个rollout并行)\"></a>Rollover (多个rollout并行)</h1><p>假如您创建了一个有5个niginx:1.7.9 replica的Deployment,但是当还只有3个nginx:1.7.9的replica创建出来的时候您就开始更新含有5个 nginx:1.9.1 replica的Deployment.在这种情况下, Deployment会立即杀掉已创建的3个nginx:1.7.9的Pod,并开始创建nginx:1.9.1的Pod。它不会等到所有的5个nginx:1.7.9的<br>Pod都创建完成后才开始改变航道</p>\n<h1 id=\"回退Deployment\"><a href=\"#回退Deployment\" class=\"headerlink\" title=\"回退Deployment\"></a>回退Deployment</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">kubectl <span class=\"hljs-built_in\">set</span> image deployment/nginx-deployment nginx=harborcloud.com/library/nginx:1.91<br>kubectl rollout status deployments nginx-deployment <span class=\"hljs-comment\">## 回退状态</span><br>kubectl get pods<br>kubectl rollout <span class=\"hljs-built_in\">history</span> deployment/nginx-deployment <span class=\"hljs-comment\">## 历史 版本 </span><br>kubectl rollout undo deployment/nginx-deployment <span class=\"hljs-comment\">##回退版本</span><br>kubectl rollout undo deployment/nginx-deployment --to-revision=2 <span class=\"hljs-comment\">## 可以使用--revision参数指定某个历史版本</span><br>kubectl rollout pause deployment/nginx-deployment<span class=\"hljs-comment\">## 暂停deployment更新</span><br></code></pre></td></tr></table></figure>\n\n<p>您可以用 kubectl rollout status Deployment 是否完成。如果 rollout 成完成, kubectl rollout status将返回一个0值的Exit Code</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl rollout status deploy/nginx</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"清理Policy\"><a href=\"#清理Policy\" class=\"headerlink\" title=\"清理Policy\"></a>清理Policy</h1><p>您可以通过设置.spec. revisonHistoryLimit项来指定deployment 最多保留多少 revision历史记录。默认的会保留所有的revision;如果将该项设置为0, Deployment就不允许回退了</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"RC\"><a href=\"#RC\" class=\"headerlink\" title=\"RC\"></a>RC</h1><p>RC (ReplicationController )主要的作用就是用来确保容器应用的副本数始终保持在用户定义的副本数。即如果有容器异常退出,会自动创建新的Pod来替代:而如果异常多出来的容器也会自动回收</p>\n<p>Kubernetes 官方建议使用RS (ReplicaSet)替代RC (ReplicationController)进行部署,RS跟RC没有本质的不同,只是名字不一样,并且RS支持集合式的selector</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">apps/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">ReplicaSet</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">frontend</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-number\">3</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">matchLabels:</span><br>      <span class=\"hljs-attr\">tier:</span> <span class=\"hljs-string\">frontend</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">labels:</span><br>        <span class=\"hljs-attr\">tier:</span> <span class=\"hljs-string\">frontend</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">php-redis</span><br>        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">gcr.io/google_samples/gb-frontend:v3</span><br>        <span class=\"hljs-attr\">env:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">GET_HOSTS_FROM</span><br>          <span class=\"hljs-attr\">value:</span> <span class=\"hljs-string\">dns</span><br>        <span class=\"hljs-attr\">ports:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">88</span><br></code></pre></td></tr></table></figure>\n\n<p>操作：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\">[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 data5]# kubectl <span class=\"hljs-keyword\">create</span> <span class=\"hljs-operator\">-</span>f rs.yaml <br>[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 data5]# kubectl <span class=\"hljs-keyword\">get</span> pod <span class=\"hljs-operator\">-</span>o wide<br>NAME             READY   STATUS    RESTARTS   AGE   IP           NODE         NOMINATED NODE   READINESS GATES<br>frontend<span class=\"hljs-operator\">-</span>dflfh   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">11</span>m   <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.2</span><span class=\"hljs-number\">.6</span>   k8s<span class=\"hljs-operator\">-</span>node02   <span class=\"hljs-operator\">&lt;</span><span class=\"hljs-keyword\">none</span><span class=\"hljs-operator\">&gt;</span>           <span class=\"hljs-operator\">&lt;</span><span class=\"hljs-keyword\">none</span><span class=\"hljs-operator\">&gt;</span><br>frontend<span class=\"hljs-operator\">-</span>vnjfd   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">11</span>m   <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.1</span><span class=\"hljs-number\">.9</span>   k8s<span class=\"hljs-operator\">-</span>node01   <span class=\"hljs-operator\">&lt;</span><span class=\"hljs-keyword\">none</span><span class=\"hljs-operator\">&gt;</span>           <span class=\"hljs-operator\">&lt;</span><span class=\"hljs-keyword\">none</span><span class=\"hljs-operator\">&gt;</span><br>frontend<span class=\"hljs-operator\">-</span>x9kfr   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">11</span>m   <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.1</span><span class=\"hljs-number\">.8</span>   k8s<span class=\"hljs-operator\">-</span>node01   <span class=\"hljs-operator\">&lt;</span><span class=\"hljs-keyword\">none</span><span class=\"hljs-operator\">&gt;</span>           <span class=\"hljs-operator\">&lt;</span><span class=\"hljs-keyword\">none</span><span class=\"hljs-operator\">&gt;</span><br></code></pre></td></tr></table></figure>\n\n<p>修改label过程</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">[root@k8s-master01 data5]# kubectl <span class=\"hljs-built_in\">get</span> pod --show-labels<br>NAME             READY   STATUS              RESTARTS   AGE    LABELS<br>frontend-dflfh   0/1     ContainerCreating   0          109s   <span class=\"hljs-attribute\">tier</span>=frontend<br>frontend-vnjfd   0/1     ContainerCreating   0          109s   <span class=\"hljs-attribute\">tier</span>=frontend<br>frontend-x9kfr   0/1     ContainerCreating   0          109s   <span class=\"hljs-attribute\">tier</span>=frontend<br>[root@k8s-master01 data5]# kubectl label pod frontend-vnjfd <span class=\"hljs-attribute\">tier</span>=frontend1 --overwrite<br>pod/frontend-vnjfd labeled<br>[root@k8s-master01 data5]# kubectl <span class=\"hljs-built_in\">get</span> pod --show-labels<br>NAME             READY   STATUS    RESTARTS   AGE   LABELS<br>frontend-dflfh   1/1     Running   0          15m   <span class=\"hljs-attribute\">tier</span>=frontend<br>frontend-vnjfd   1/1     Running   0          15m   <span class=\"hljs-attribute\">tier</span>=frontend1<br>frontend-x9kfr   1/1     Running   0          15m   <span class=\"hljs-attribute\">tier</span>=frontend<br>frontend-zqxxj   1/1     Running   0          40s   <span class=\"hljs-attribute\">tier</span>=frontend<br></code></pre></td></tr></table></figure>\n\n<p>结论：当label修改为frontend1后，rs将会创建一个新的pod，因为rs通过label控制pod，当其中一个pod的label修改了，rs就会自动创建一个</p>\n<p>将pod的label修改回frontend：</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">[root@k8s-master01 data5]# kubectl label pod frontend-vnjfd <span class=\"hljs-attribute\">tier</span>=frontend --overwrite <br>pod/frontend-vnjfd labeled<br>[root@k8s-master01 data5]# kubectl <span class=\"hljs-built_in\">get</span> pod --show-labels                             <br>NAME             READY   STATUS    RESTARTS   AGE   LABELS<br>frontend-dflfh   1/1     Running   0          17m   <span class=\"hljs-attribute\">tier</span>=frontend<br>frontend-vnjfd   1/1     Running   0          17m   <span class=\"hljs-attribute\">tier</span>=frontend<br>frontend-x9kfr   1/1     Running   0          17m   <span class=\"hljs-attribute\">tier</span>=frontend<br></code></pre></td></tr></table></figure>\n\n<p>结论：rs会自动的缩减pod，将上面新增的pod去掉。</p>\n<h1 id=\"RS-与Deployment-的关联\"><a href=\"#RS-与Deployment-的关联\" class=\"headerlink\" title=\"RS 与Deployment 的关联\"></a>RS 与Deployment 的关联</h1><img src=\"/2021/07/16/RC%E4%B8%8ERS%E4%B8%8EDeployment%E5%85%B3%E8%81%94/1657973507960.png\" class=\"\" width=\"1657973507960\">\n\n<h1 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h1><p>Deployment为Pod和ReplicaSet提供了一个声明式定义(declarative)方法,用来替代以前的ReplicationController 来方便的管理应用。典型的应用场景包括:</p>\n<ul>\n<li>定义Deployment来创建Pod和ReplicaSet</li>\n<li>滚动升级和回滚应用</li>\n<li>扩容和缩容</li>\n<li>暂停和继续Deployment</li>\n</ul>\n<h2 id=\"1、部署一个简单的Nginx应用\"><a href=\"#1、部署一个简单的Nginx应用\" class=\"headerlink\" title=\"1、部署一个简单的Nginx应用\"></a>1、部署一个简单的Nginx应用</h2><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">apps/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Deployment</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">nginx-deployment</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-number\">3</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">matchLabels:</span><br>      <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">nginx</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">labels:</span><br>        <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">nginx</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">nginx</span><br>        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.7.9</span><br>        <span class=\"hljs-attr\">ports:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">88</span><br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-string\">kubectl</span> <span class=\"hljs-string\">create</span> <span class=\"hljs-string\">-f</span> <span class=\"hljs-string\">nginx-deployment.yaml</span> <span class=\"hljs-string\">-record</span><br><span class=\"hljs-comment\"># --record参数可以记录命令,我们可以很方便的查看每次revision的变化</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2、扩容\"><a href=\"#2、扩容\" class=\"headerlink\" title=\"2、扩容\"></a>2、扩容</h2><figure class=\"highlight gherkin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gherkin\">[root<span class=\"hljs-meta\">@k8s-master01</span> data5]<span class=\"hljs-comment\"># kubectl scale deployment nginx-deployment --replicas 10</span><br>[root<span class=\"hljs-meta\">@k8s-master01</span> data5]<span class=\"hljs-comment\"># kubectl get pod -o wide</span><br>NAME                                READY   STATUS    RESTARTS   AGE     IP            NODE         NOMINATED NODE   READINESS GATES<br>nginx-deployment-56bd657787-4qvb6   1/1     Running   0          17m     10.244.1.11   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-777rm   1/1     Running   0          17m     10.244.1.10   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-78hq6   1/1     Running   0          2m36s   10.244.2.13   k8s-node02   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-86wzj   1/1     Running   0          2m36s   10.244.2.11   k8s-node02   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-98tn6   1/1     Running   0          2m36s   10.244.1.12   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-9wnvc   1/1     Running   0          2m36s   10.244.1.13   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-n5b9r   1/1     Running   0          2m36s   10.244.2.14   k8s-node02   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-phd6z   1/1     Running   0          2m36s   10.244.1.14   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-rdzst   1/1     Running   0          2m36s   10.244.2.12   k8s-node02   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>nginx-deployment-56bd657787-xbfqr   1/1     Running   0          9m4s    10.244.2.10   k8s-node02   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"3、如果集群支持horizontal-pod-autoscaling-的话-还可以为Deployment设置自动扩展\"><a href=\"#3、如果集群支持horizontal-pod-autoscaling-的话-还可以为Deployment设置自动扩展\" class=\"headerlink\" title=\"3、如果集群支持horizontal pod autoscaling 的话,还可以为Deployment设置自动扩展\"></a>3、如果集群支持horizontal pod autoscaling 的话,还可以为Deployment设置自动扩展</h2><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl autoscale deployment nginx-deployment <span class=\"hljs-attribute\">--min</span>=10 <span class=\"hljs-attribute\">--max</span>=15 <span class=\"hljs-attribute\">--cpu-percent</span>=80<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"4、更新镜像也比较简单\"><a href=\"#4、更新镜像也比较简单\" class=\"headerlink\" title=\"4、更新镜像也比较简单\"></a>4、更新镜像也比较简单</h2><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl <span class=\"hljs-built_in\">set</span> image deployment/nginx-deployment <span class=\"hljs-attribute\">nginx</span>=harborcloud.com/library/nginx:1.9.1<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"5、回滚\"><a href=\"#5、回滚\" class=\"headerlink\" title=\"5、回滚\"></a>5、回滚</h2><figure class=\"highlight applescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs applescript\">[root@k8s-master01 data5]<span class=\"hljs-comment\"># kubectl rollout undo deployment/nginx-deployment</span><br>deployment.apps/nginx-deployment rolled <span class=\"hljs-keyword\">back</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"6、删除deployment\"><a href=\"#6、删除deployment\" class=\"headerlink\" title=\"6、删除deployment\"></a>6、删除deployment</h2><figure class=\"highlight actionscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs actionscript\">kubectl <span class=\"hljs-keyword\">delete</span> -f nginx-deployment.yaml <br></code></pre></td></tr></table></figure>\n\n<h1 id=\"更新Deployment\"><a href=\"#更新Deployment\" class=\"headerlink\" title=\"更新Deployment\"></a>更新Deployment</h1><p>假如我们现在想要让nginx pod使用nginx:1.9.1的镜像来代替原来的nginx:1.7.9的镜像</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">$ kubectl <span class=\"hljs-built_in\">set</span> image deployment/nginx-deployment <span class=\"hljs-attribute\">nginx</span>=harborcloud.com/library/nginx:1.9.1<br></code></pre></td></tr></table></figure>\n\n<p>可以使用 edit 命令来编辑Deployment</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">$ kubectl <span class=\"hljs-built_in\">edit</span> deployment/nginx-deployment<br></code></pre></td></tr></table></figure>\n\n<p>查看更新记录</p>\n<figure class=\"highlight gherkin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gherkin\">[root<span class=\"hljs-meta\">@k8s-master01</span> data5]<span class=\"hljs-comment\"># kubectl rollout history deployment nginx-deployment</span><br>deployment.apps/nginx-deployment <br>REVISION  CHANGE-CAUSE<br>1         <span class=\"hljs-variable\">&lt;none&gt;</span><br>2         <span class=\"hljs-variable\">&lt;none&gt;</span><br></code></pre></td></tr></table></figure>\n\n<p>查看rollout的状态</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl rollout status deployment/nginx-deployment</span><br></code></pre></td></tr></table></figure>\n\n<p>查看历史RS</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">$ kubectl <span class=\"hljs-built_in\">get</span> rs<br></code></pre></td></tr></table></figure>\n\n<p>回滚到指定版本 </p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">kubectl rollout undo deployment nginx-deployment <span class=\"hljs-attribute\">--to-revision</span>=2<br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight gherkin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gherkin\">[root<span class=\"hljs-meta\">@k8s-master01</span> data5]<span class=\"hljs-comment\"># kubectl rollout history deployment nginx-deployment</span><br>deployment.apps/nginx-deployment <br>REVISION  CHANGE-CAUSE<br>2         <span class=\"hljs-variable\">&lt;none&gt;</span><br>3         <span class=\"hljs-variable\">&lt;none&gt;</span><br><br>[root<span class=\"hljs-meta\">@k8s-master01</span> data5]<span class=\"hljs-comment\"># kubectl rollout undo deployment nginx-deployment --to-revision=2</span><br>deployment.apps/nginx-deployment rolled back<br>[root<span class=\"hljs-meta\">@k8s-master01</span> data5]<span class=\"hljs-comment\"># kubectl rollout history deployment nginx-deployment             </span><br>deployment.apps/nginx-deployment <br>REVISION  CHANGE-CAUSE<br>3         <span class=\"hljs-variable\">&lt;none&gt;</span><br>4         <span class=\"hljs-variable\">&lt;none&gt;</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"Deployment-更新策略\"><a href=\"#Deployment-更新策略\" class=\"headerlink\" title=\"Deployment 更新策略\"></a>Deployment 更新策略</h1><p>Deployment 可以保证在升级时只有一定数量的Pod 是 down的。默认的,它会确保至少有比期望的Pod数量少一个是up状态(最多一个不可用)</p>\n<p>Deployment同时也可以确保只创建出超过期望数量的一定数量的Pod。默认的,它会确保最多比期望的Pod数量多一个的Pod是up的(最多1个surge)<br>未来的Kuberentes版本中,将从1-1变成25%-25%</p>\n<figure class=\"highlight crystal\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crystal\"><span class=\"hljs-variable\">$ </span>kubectl describe deployments<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"Rollover-多个rollout并行\"><a href=\"#Rollover-多个rollout并行\" class=\"headerlink\" title=\"Rollover (多个rollout并行)\"></a>Rollover (多个rollout并行)</h1><p>假如您创建了一个有5个niginx:1.7.9 replica的Deployment,但是当还只有3个nginx:1.7.9的replica创建出来的时候您就开始更新含有5个 nginx:1.9.1 replica的Deployment.在这种情况下, Deployment会立即杀掉已创建的3个nginx:1.7.9的Pod,并开始创建nginx:1.9.1的Pod。它不会等到所有的5个nginx:1.7.9的<br>Pod都创建完成后才开始改变航道</p>\n<h1 id=\"回退Deployment\"><a href=\"#回退Deployment\" class=\"headerlink\" title=\"回退Deployment\"></a>回退Deployment</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">kubectl <span class=\"hljs-built_in\">set</span> image deployment/nginx-deployment nginx=harborcloud.com/library/nginx:1.91<br>kubectl rollout status deployments nginx-deployment <span class=\"hljs-comment\">## 回退状态</span><br>kubectl get pods<br>kubectl rollout <span class=\"hljs-built_in\">history</span> deployment/nginx-deployment <span class=\"hljs-comment\">## 历史 版本 </span><br>kubectl rollout undo deployment/nginx-deployment <span class=\"hljs-comment\">##回退版本</span><br>kubectl rollout undo deployment/nginx-deployment --to-revision=2 <span class=\"hljs-comment\">## 可以使用--revision参数指定某个历史版本</span><br>kubectl rollout pause deployment/nginx-deployment<span class=\"hljs-comment\">## 暂停deployment更新</span><br></code></pre></td></tr></table></figure>\n\n<p>您可以用 kubectl rollout status Deployment 是否完成。如果 rollout 成完成, kubectl rollout status将返回一个0值的Exit Code</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta prompt_\">$ </span><span class=\"language-bash\">kubectl rollout status deploy/nginx</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"清理Policy\"><a href=\"#清理Policy\" class=\"headerlink\" title=\"清理Policy\"></a>清理Policy</h1><p>您可以通过设置.spec. revisonHistoryLimit项来指定deployment 最多保留多少 revision历史记录。默认的会保留所有的revision;如果将该项设置为0, Deployment就不允许回退了</p>\n"},{"title":"kubernetes控制器DaemonSet","date":"2021-07-13T05:32:02.000Z","_content":"\n# 什么是DaemonSet？\n\nDaemonSet 确保全部(或者一些) Node上运行一个Pod的副本。当有Node加入集群时,也会为他们新增一个Pod.当有Node从集群移除时,这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod。\n\nDaemonSet 的一些典型用法：\n\n- 在每个节点上运行集群守护进程，集群存储daemon,例如在每个Node上运行glusterd,ceph。\n- 在每个节点上运行日志收集守护进程，例如fluentd,logstash。\n- 在每个节点上运行监控守护进程，例如Prometheus Node Exporter, collectd, Datadog 代理、New Relic 代理,或 Ganglia gmond\n\n一种简单的用法是为每种类型的守护进程在所有的节点上都启动一个 DaemonSet。 一个稍微复杂的用法是为同一种守护进程部署多个 DaemonSet；每个具有不同的标志， 并且对不同硬件类型具有不同的内存、CPU 要求。 \n\n# 编写 DaemonSet Spec\n\n简单DaemonSet资源配置\n\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: deamonset-example\n  labels:\n    app: daemonset\nspec:\n  selector:\n    matchLabels:\n      name: deamonset-example\n  template:\n    metadata:\n      labels:\n        name: deamonset-example\n    spec:\n      containers:\n      - name: daemonset-example\n        image: harborcloud.com/library/nginx:1.9.1\n```\n\n详细 DaemonSet 资源配置\n\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd-elasticsearch\n  namespace: kube-system\n  labels:\n    k8s-app: fluentd-logging\nspec:\n  selector:\n    matchLabels:\n      name: fluentd-elasticsearch\n  template:\n    metadata:\n      labels:\n        name: fluentd-elasticsearch\n    spec:\n      tolerations:\n      # 这些容忍度设置是为了让该守护进程集在控制平面节点上运行\n      # 如果你不希望自己的控制平面节点运行 Pod，可以删除它们\n      - key: node-role.kubernetes.io/control-plane\n        operator: Exists\n        effect: NoSchedule\n      - key: node-role.kubernetes.io/master\n        operator: Exists\n        effect: NoSchedule\n      containers:\n      - name: fluentd-elasticsearch\n        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2\n        resources:\n          limits:\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlibdockercontainers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n      terminationGracePeriodSeconds: 30\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n```\n\n## 仅在某些节点上运行 Pod\n\n如果指定了 .spec.template.spec.nodeSelector，DaemonSet 控制器将在能够与 Node 选择算符 匹配的节点上创建 Pod。 类似这种情况，可以指定 .spec.template.spec.affinity，之后 DaemonSet 控制器 将在能够与节点亲和性 匹配的节点上创建 Pod。 如果根本就没有指定，则 DaemonSet Controller 将在所有节点上创建 Pod\n\n","source":"_posts/kubernetes控制器DaemonSet.md","raw":"---\ntitle: kubernetes控制器DaemonSet\ndate: 2021-07-13 13:32:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - daemonset\n---\n\n# 什么是DaemonSet？\n\nDaemonSet 确保全部(或者一些) Node上运行一个Pod的副本。当有Node加入集群时,也会为他们新增一个Pod.当有Node从集群移除时,这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod。\n\nDaemonSet 的一些典型用法：\n\n- 在每个节点上运行集群守护进程，集群存储daemon,例如在每个Node上运行glusterd,ceph。\n- 在每个节点上运行日志收集守护进程，例如fluentd,logstash。\n- 在每个节点上运行监控守护进程，例如Prometheus Node Exporter, collectd, Datadog 代理、New Relic 代理,或 Ganglia gmond\n\n一种简单的用法是为每种类型的守护进程在所有的节点上都启动一个 DaemonSet。 一个稍微复杂的用法是为同一种守护进程部署多个 DaemonSet；每个具有不同的标志， 并且对不同硬件类型具有不同的内存、CPU 要求。 \n\n# 编写 DaemonSet Spec\n\n简单DaemonSet资源配置\n\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: deamonset-example\n  labels:\n    app: daemonset\nspec:\n  selector:\n    matchLabels:\n      name: deamonset-example\n  template:\n    metadata:\n      labels:\n        name: deamonset-example\n    spec:\n      containers:\n      - name: daemonset-example\n        image: harborcloud.com/library/nginx:1.9.1\n```\n\n详细 DaemonSet 资源配置\n\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd-elasticsearch\n  namespace: kube-system\n  labels:\n    k8s-app: fluentd-logging\nspec:\n  selector:\n    matchLabels:\n      name: fluentd-elasticsearch\n  template:\n    metadata:\n      labels:\n        name: fluentd-elasticsearch\n    spec:\n      tolerations:\n      # 这些容忍度设置是为了让该守护进程集在控制平面节点上运行\n      # 如果你不希望自己的控制平面节点运行 Pod，可以删除它们\n      - key: node-role.kubernetes.io/control-plane\n        operator: Exists\n        effect: NoSchedule\n      - key: node-role.kubernetes.io/master\n        operator: Exists\n        effect: NoSchedule\n      containers:\n      - name: fluentd-elasticsearch\n        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2\n        resources:\n          limits:\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlibdockercontainers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n      terminationGracePeriodSeconds: 30\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n```\n\n## 仅在某些节点上运行 Pod\n\n如果指定了 .spec.template.spec.nodeSelector，DaemonSet 控制器将在能够与 Node 选择算符 匹配的节点上创建 Pod。 类似这种情况，可以指定 .spec.template.spec.affinity，之后 DaemonSet 控制器 将在能够与节点亲和性 匹配的节点上创建 Pod。 如果根本就没有指定，则 DaemonSet Controller 将在所有节点上创建 Pod\n\n","slug":"kubernetes控制器DaemonSet","published":1,"updated":"2022-09-23T17:23:23.753Z","_id":"cl8er3rmy000b28vjf7kl0z9j","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"什么是DaemonSet？\"><a href=\"#什么是DaemonSet？\" class=\"headerlink\" title=\"什么是DaemonSet？\"></a>什么是DaemonSet？</h1><p>DaemonSet 确保全部(或者一些) Node上运行一个Pod的副本。当有Node加入集群时,也会为他们新增一个Pod.当有Node从集群移除时,这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod。</p>\n<p>DaemonSet 的一些典型用法：</p>\n<ul>\n<li>在每个节点上运行集群守护进程，集群存储daemon,例如在每个Node上运行glusterd,ceph。</li>\n<li>在每个节点上运行日志收集守护进程，例如fluentd,logstash。</li>\n<li>在每个节点上运行监控守护进程，例如Prometheus Node Exporter, collectd, Datadog 代理、New Relic 代理,或 Ganglia gmond</li>\n</ul>\n<p>一种简单的用法是为每种类型的守护进程在所有的节点上都启动一个 DaemonSet。 一个稍微复杂的用法是为同一种守护进程部署多个 DaemonSet；每个具有不同的标志， 并且对不同硬件类型具有不同的内存、CPU 要求。 </p>\n<h1 id=\"编写-DaemonSet-Spec\"><a href=\"#编写-DaemonSet-Spec\" class=\"headerlink\" title=\"编写 DaemonSet Spec\"></a>编写 DaemonSet Spec</h1><p>简单DaemonSet资源配置</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">apps/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">DaemonSet</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">deamonset-example</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">daemonset</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">matchLabels:</span><br>      <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">deamonset-example</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">labels:</span><br>        <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">deamonset-example</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">daemonset-example</span><br>        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.9.1</span><br></code></pre></td></tr></table></figure>\n\n<p>详细 DaemonSet 资源配置</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">apps/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">DaemonSet</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">fluentd-elasticsearch</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">kube-system</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">k8s-app:</span> <span class=\"hljs-string\">fluentd-logging</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">matchLabels:</span><br>      <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">fluentd-elasticsearch</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">labels:</span><br>        <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">fluentd-elasticsearch</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">tolerations:</span><br>      <span class=\"hljs-comment\"># 这些容忍度设置是为了让该守护进程集在控制平面节点上运行</span><br>      <span class=\"hljs-comment\"># 如果你不希望自己的控制平面节点运行 Pod，可以删除它们</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">node-role.kubernetes.io/control-plane</span><br>        <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">Exists</span><br>        <span class=\"hljs-attr\">effect:</span> <span class=\"hljs-string\">NoSchedule</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">node-role.kubernetes.io/master</span><br>        <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">Exists</span><br>        <span class=\"hljs-attr\">effect:</span> <span class=\"hljs-string\">NoSchedule</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">fluentd-elasticsearch</span><br>        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">quay.io/fluentd_elasticsearch/fluentd:v2.5.2</span><br>        <span class=\"hljs-attr\">resources:</span><br>          <span class=\"hljs-attr\">limits:</span><br>            <span class=\"hljs-attr\">memory:</span> <span class=\"hljs-string\">200Mi</span><br>          <span class=\"hljs-attr\">requests:</span><br>            <span class=\"hljs-attr\">cpu:</span> <span class=\"hljs-string\">100m</span><br>            <span class=\"hljs-attr\">memory:</span> <span class=\"hljs-string\">200Mi</span><br>        <span class=\"hljs-attr\">volumeMounts:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">varlog</span><br>          <span class=\"hljs-attr\">mountPath:</span> <span class=\"hljs-string\">/var/log</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">varlibdockercontainers</span><br>          <span class=\"hljs-attr\">mountPath:</span> <span class=\"hljs-string\">/var/lib/docker/containers</span><br>          <span class=\"hljs-attr\">readOnly:</span> <span class=\"hljs-literal\">true</span><br>      <span class=\"hljs-attr\">terminationGracePeriodSeconds:</span> <span class=\"hljs-number\">30</span><br>      <span class=\"hljs-attr\">volumes:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">varlog</span><br>        <span class=\"hljs-attr\">hostPath:</span><br>          <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">/var/log</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">varlibdockercontainers</span><br>        <span class=\"hljs-attr\">hostPath:</span><br>          <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">/var/lib/docker/containers</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"仅在某些节点上运行-Pod\"><a href=\"#仅在某些节点上运行-Pod\" class=\"headerlink\" title=\"仅在某些节点上运行 Pod\"></a>仅在某些节点上运行 Pod</h2><p>如果指定了 .spec.template.spec.nodeSelector，DaemonSet 控制器将在能够与 Node 选择算符 匹配的节点上创建 Pod。 类似这种情况，可以指定 .spec.template.spec.affinity，之后 DaemonSet 控制器 将在能够与节点亲和性 匹配的节点上创建 Pod。 如果根本就没有指定，则 DaemonSet Controller 将在所有节点上创建 Pod</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"什么是DaemonSet？\"><a href=\"#什么是DaemonSet？\" class=\"headerlink\" title=\"什么是DaemonSet？\"></a>什么是DaemonSet？</h1><p>DaemonSet 确保全部(或者一些) Node上运行一个Pod的副本。当有Node加入集群时,也会为他们新增一个Pod.当有Node从集群移除时,这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod。</p>\n<p>DaemonSet 的一些典型用法：</p>\n<ul>\n<li>在每个节点上运行集群守护进程，集群存储daemon,例如在每个Node上运行glusterd,ceph。</li>\n<li>在每个节点上运行日志收集守护进程，例如fluentd,logstash。</li>\n<li>在每个节点上运行监控守护进程，例如Prometheus Node Exporter, collectd, Datadog 代理、New Relic 代理,或 Ganglia gmond</li>\n</ul>\n<p>一种简单的用法是为每种类型的守护进程在所有的节点上都启动一个 DaemonSet。 一个稍微复杂的用法是为同一种守护进程部署多个 DaemonSet；每个具有不同的标志， 并且对不同硬件类型具有不同的内存、CPU 要求。 </p>\n<h1 id=\"编写-DaemonSet-Spec\"><a href=\"#编写-DaemonSet-Spec\" class=\"headerlink\" title=\"编写 DaemonSet Spec\"></a>编写 DaemonSet Spec</h1><p>简单DaemonSet资源配置</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">apps/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">DaemonSet</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">deamonset-example</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">daemonset</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">matchLabels:</span><br>      <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">deamonset-example</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">labels:</span><br>        <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">deamonset-example</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">daemonset-example</span><br>        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.9.1</span><br></code></pre></td></tr></table></figure>\n\n<p>详细 DaemonSet 资源配置</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">apps/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">DaemonSet</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">fluentd-elasticsearch</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">kube-system</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">k8s-app:</span> <span class=\"hljs-string\">fluentd-logging</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">matchLabels:</span><br>      <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">fluentd-elasticsearch</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">labels:</span><br>        <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">fluentd-elasticsearch</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">tolerations:</span><br>      <span class=\"hljs-comment\"># 这些容忍度设置是为了让该守护进程集在控制平面节点上运行</span><br>      <span class=\"hljs-comment\"># 如果你不希望自己的控制平面节点运行 Pod，可以删除它们</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">node-role.kubernetes.io/control-plane</span><br>        <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">Exists</span><br>        <span class=\"hljs-attr\">effect:</span> <span class=\"hljs-string\">NoSchedule</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">key:</span> <span class=\"hljs-string\">node-role.kubernetes.io/master</span><br>        <span class=\"hljs-attr\">operator:</span> <span class=\"hljs-string\">Exists</span><br>        <span class=\"hljs-attr\">effect:</span> <span class=\"hljs-string\">NoSchedule</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">fluentd-elasticsearch</span><br>        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">quay.io/fluentd_elasticsearch/fluentd:v2.5.2</span><br>        <span class=\"hljs-attr\">resources:</span><br>          <span class=\"hljs-attr\">limits:</span><br>            <span class=\"hljs-attr\">memory:</span> <span class=\"hljs-string\">200Mi</span><br>          <span class=\"hljs-attr\">requests:</span><br>            <span class=\"hljs-attr\">cpu:</span> <span class=\"hljs-string\">100m</span><br>            <span class=\"hljs-attr\">memory:</span> <span class=\"hljs-string\">200Mi</span><br>        <span class=\"hljs-attr\">volumeMounts:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">varlog</span><br>          <span class=\"hljs-attr\">mountPath:</span> <span class=\"hljs-string\">/var/log</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">varlibdockercontainers</span><br>          <span class=\"hljs-attr\">mountPath:</span> <span class=\"hljs-string\">/var/lib/docker/containers</span><br>          <span class=\"hljs-attr\">readOnly:</span> <span class=\"hljs-literal\">true</span><br>      <span class=\"hljs-attr\">terminationGracePeriodSeconds:</span> <span class=\"hljs-number\">30</span><br>      <span class=\"hljs-attr\">volumes:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">varlog</span><br>        <span class=\"hljs-attr\">hostPath:</span><br>          <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">/var/log</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">varlibdockercontainers</span><br>        <span class=\"hljs-attr\">hostPath:</span><br>          <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">/var/lib/docker/containers</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"仅在某些节点上运行-Pod\"><a href=\"#仅在某些节点上运行-Pod\" class=\"headerlink\" title=\"仅在某些节点上运行 Pod\"></a>仅在某些节点上运行 Pod</h2><p>如果指定了 .spec.template.spec.nodeSelector，DaemonSet 控制器将在能够与 Node 选择算符 匹配的节点上创建 Pod。 类似这种情况，可以指定 .spec.template.spec.affinity，之后 DaemonSet 控制器 将在能够与节点亲和性 匹配的节点上创建 Pod。 如果根本就没有指定，则 DaemonSet Controller 将在所有节点上创建 Pod</p>\n"},{"title":"kubernetes控制器Job与CronJob","date":"2021-07-17T05:32:02.000Z","_content":"\n# Job\n\nJob负责批处理任务,即仅执行一次的任务,它保证批处理任务的一个或多个Pod成功结束\n\n特殊说明\n\n- spec.template格式同Pod\n- RestartPolicy仅支持NeverdOnFailure\n- 单个Pod时,默认Pod成功运行后Job即结束\n- .spec. completions 标志Job结束需要成功运行的Pod个数,默认为1\n- .spec. parallelism 标志并行运行的Pod的个数,默认为1\n- spec.activeDeadlineSeconds标志失败Pod的重试最大时间,超过这个时间不会继续重试\n\n例子：\n\n```yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: pi\nspec:\n  template:\n    metadata:\n      name: pi\n    spec:\n      containers:\n      - name: pi\n        image: harborcloud.com/library/perl:\n        command: [\"perl\",\"-Mbignum=bpi\",\"-wle\",\"print bpi(2000)\"]\n      restartPolicy: Never\n```\n\n## Spec\n\n- spec.template格式同Pod\n- RestartPolicy仅支持Never或OnFailure\n- 单个Pod时,默认Pod成功运行后Job即结束\n- spec. completions 标志Job结束需要成功运行的Pod个数,默认为1\n- spec. parallelism标志并行运行的Pod的个数,默认为1\n- spec.activeDeadlineSeconds标志失败Pod的重试最大时间,超过这个时间不会继续重试\n\n# CronJob\n\nCronJob管理基于时间的Job,即:\n\n- 在给定时间点只运行一次\n- 周期性地在给定时间点运行\n\n使用条件:当前使用的Kubernetes 集群,版本>=1.8 (对Cronjob)\n\n典型的用法如下所示:\n在给定的时间点调度Job运行\n创建周期性运行的Job,例如:数据库备份、发送邮件\n\n## CronJob Spec\n\n- spec. schedule:调度,必需字段,指定任务运行周期,格式同Cron\n- spec. jobTemplate: Job模板,必需字段,指定需要运行的任务,格式同Job\n- spec. startingDeadlineSeconds:启动 Job 的期限(秒级别) ,该字段是可选的。如果因为任何原因而错过了被调度的时间,那么错过执行时间的Job将被认为是失败的。如果没有指定,则没有期限\n- spec. concurrencyPolicy：并发策略,该字段也是可选的。它指定了如何处理被CronJob创建的Job的并发执行。只允许指定下面策略中的一种:Allow (默认) :允许并发运行 Job；Forbid ：禁止并发运行,如果前一个还没有完成,则直接跳过下一个；Replace：取消当前正在运行的Job,用一个新的来替换。\n  注意：当前策略只能应用于同一个Cron Job 创建的Job。如果存在多个Cron Job,它们创建的Job之间总是允许并发运行。\n- spec. suspend：挂起,该字段也是可选的。如果设置为true,后续所有执行都会被挂起。它对已经开始执行的Job不起作用。默认值为false。\n- spec. successfullobsHistoryLimit.spec.failedJobsHistoryLimit ：历史限制,是可选的字段。它们指定了可以保留多少完成和失败的Job。默认情况下,它们分别设置为3和1，设置限制的值为e,相关类型的Job完成后将不会被保留。\n\n```yaml\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  schedule: \"*/1 * * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: hello\n            image: harborcloud.com/library/busybox:v1.35\n            args:\n            - /bin/sh\n            - -c\n            - date; echo Hello from the Kubernetes cluster\n          restartPolicy: OnFailure\n```\n\n\n\n","source":"_posts/kubernetes控制器Job与CronJob.md","raw":"---\ntitle: kubernetes控制器Job与CronJob\ndate: 2021-07-17 13:32:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - job\n  - cronjob\n---\n\n# Job\n\nJob负责批处理任务,即仅执行一次的任务,它保证批处理任务的一个或多个Pod成功结束\n\n特殊说明\n\n- spec.template格式同Pod\n- RestartPolicy仅支持NeverdOnFailure\n- 单个Pod时,默认Pod成功运行后Job即结束\n- .spec. completions 标志Job结束需要成功运行的Pod个数,默认为1\n- .spec. parallelism 标志并行运行的Pod的个数,默认为1\n- spec.activeDeadlineSeconds标志失败Pod的重试最大时间,超过这个时间不会继续重试\n\n例子：\n\n```yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: pi\nspec:\n  template:\n    metadata:\n      name: pi\n    spec:\n      containers:\n      - name: pi\n        image: harborcloud.com/library/perl:\n        command: [\"perl\",\"-Mbignum=bpi\",\"-wle\",\"print bpi(2000)\"]\n      restartPolicy: Never\n```\n\n## Spec\n\n- spec.template格式同Pod\n- RestartPolicy仅支持Never或OnFailure\n- 单个Pod时,默认Pod成功运行后Job即结束\n- spec. completions 标志Job结束需要成功运行的Pod个数,默认为1\n- spec. parallelism标志并行运行的Pod的个数,默认为1\n- spec.activeDeadlineSeconds标志失败Pod的重试最大时间,超过这个时间不会继续重试\n\n# CronJob\n\nCronJob管理基于时间的Job,即:\n\n- 在给定时间点只运行一次\n- 周期性地在给定时间点运行\n\n使用条件:当前使用的Kubernetes 集群,版本>=1.8 (对Cronjob)\n\n典型的用法如下所示:\n在给定的时间点调度Job运行\n创建周期性运行的Job,例如:数据库备份、发送邮件\n\n## CronJob Spec\n\n- spec. schedule:调度,必需字段,指定任务运行周期,格式同Cron\n- spec. jobTemplate: Job模板,必需字段,指定需要运行的任务,格式同Job\n- spec. startingDeadlineSeconds:启动 Job 的期限(秒级别) ,该字段是可选的。如果因为任何原因而错过了被调度的时间,那么错过执行时间的Job将被认为是失败的。如果没有指定,则没有期限\n- spec. concurrencyPolicy：并发策略,该字段也是可选的。它指定了如何处理被CronJob创建的Job的并发执行。只允许指定下面策略中的一种:Allow (默认) :允许并发运行 Job；Forbid ：禁止并发运行,如果前一个还没有完成,则直接跳过下一个；Replace：取消当前正在运行的Job,用一个新的来替换。\n  注意：当前策略只能应用于同一个Cron Job 创建的Job。如果存在多个Cron Job,它们创建的Job之间总是允许并发运行。\n- spec. suspend：挂起,该字段也是可选的。如果设置为true,后续所有执行都会被挂起。它对已经开始执行的Job不起作用。默认值为false。\n- spec. successfullobsHistoryLimit.spec.failedJobsHistoryLimit ：历史限制,是可选的字段。它们指定了可以保留多少完成和失败的Job。默认情况下,它们分别设置为3和1，设置限制的值为e,相关类型的Job完成后将不会被保留。\n\n```yaml\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  schedule: \"*/1 * * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: hello\n            image: harborcloud.com/library/busybox:v1.35\n            args:\n            - /bin/sh\n            - -c\n            - date; echo Hello from the Kubernetes cluster\n          restartPolicy: OnFailure\n```\n\n\n\n","slug":"kubernetes控制器Job与CronJob","published":1,"updated":"2022-09-23T17:26:17.623Z","_id":"cl8er7e3s000h28vj73dhh0o0","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"Job\"><a href=\"#Job\" class=\"headerlink\" title=\"Job\"></a>Job</h1><p>Job负责批处理任务,即仅执行一次的任务,它保证批处理任务的一个或多个Pod成功结束</p>\n<p>特殊说明</p>\n<ul>\n<li>spec.template格式同Pod</li>\n<li>RestartPolicy仅支持NeverdOnFailure</li>\n<li>单个Pod时,默认Pod成功运行后Job即结束</li>\n<li>.spec. completions 标志Job结束需要成功运行的Pod个数,默认为1</li>\n<li>.spec. parallelism 标志并行运行的Pod的个数,默认为1</li>\n<li>spec.activeDeadlineSeconds标志失败Pod的重试最大时间,超过这个时间不会继续重试</li>\n</ul>\n<p>例子：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">batch/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Job</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">pi</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">pi</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">pi</span><br>        <span class=\"hljs-attr\">image: harborcloud.com/library/perl:</span><br>        <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&quot;perl&quot;</span>,<span class=\"hljs-string\">&quot;-Mbignum=bpi&quot;</span>,<span class=\"hljs-string\">&quot;-wle&quot;</span>,<span class=\"hljs-string\">&quot;print bpi(2000)&quot;</span>]<br>      <span class=\"hljs-attr\">restartPolicy:</span> <span class=\"hljs-string\">Never</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"Spec\"><a href=\"#Spec\" class=\"headerlink\" title=\"Spec\"></a>Spec</h2><ul>\n<li>spec.template格式同Pod</li>\n<li>RestartPolicy仅支持Never或OnFailure</li>\n<li>单个Pod时,默认Pod成功运行后Job即结束</li>\n<li>spec. completions 标志Job结束需要成功运行的Pod个数,默认为1</li>\n<li>spec. parallelism标志并行运行的Pod的个数,默认为1</li>\n<li>spec.activeDeadlineSeconds标志失败Pod的重试最大时间,超过这个时间不会继续重试</li>\n</ul>\n<h1 id=\"CronJob\"><a href=\"#CronJob\" class=\"headerlink\" title=\"CronJob\"></a>CronJob</h1><p>CronJob管理基于时间的Job,即:</p>\n<ul>\n<li>在给定时间点只运行一次</li>\n<li>周期性地在给定时间点运行</li>\n</ul>\n<p>使用条件:当前使用的Kubernetes 集群,版本&gt;=1.8 (对Cronjob)</p>\n<p>典型的用法如下所示:<br>在给定的时间点调度Job运行<br>创建周期性运行的Job,例如:数据库备份、发送邮件</p>\n<h2 id=\"CronJob-Spec\"><a href=\"#CronJob-Spec\" class=\"headerlink\" title=\"CronJob Spec\"></a>CronJob Spec</h2><ul>\n<li>spec. schedule:调度,必需字段,指定任务运行周期,格式同Cron</li>\n<li>spec. jobTemplate: Job模板,必需字段,指定需要运行的任务,格式同Job</li>\n<li>spec. startingDeadlineSeconds:启动 Job 的期限(秒级别) ,该字段是可选的。如果因为任何原因而错过了被调度的时间,那么错过执行时间的Job将被认为是失败的。如果没有指定,则没有期限</li>\n<li>spec. concurrencyPolicy：并发策略,该字段也是可选的。它指定了如何处理被CronJob创建的Job的并发执行。只允许指定下面策略中的一种:Allow (默认) :允许并发运行 Job；Forbid ：禁止并发运行,如果前一个还没有完成,则直接跳过下一个；Replace：取消当前正在运行的Job,用一个新的来替换。<br>注意：当前策略只能应用于同一个Cron Job 创建的Job。如果存在多个Cron Job,它们创建的Job之间总是允许并发运行。</li>\n<li>spec. suspend：挂起,该字段也是可选的。如果设置为true,后续所有执行都会被挂起。它对已经开始执行的Job不起作用。默认值为false。</li>\n<li>spec. successfullobsHistoryLimit.spec.failedJobsHistoryLimit ：历史限制,是可选的字段。它们指定了可以保留多少完成和失败的Job。默认情况下,它们分别设置为3和1，设置限制的值为e,相关类型的Job完成后将不会被保留。</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">batch/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">CronJob</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">hello</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">schedule:</span> <span class=\"hljs-string\">&quot;*/1 * * * *&quot;</span><br>  <span class=\"hljs-attr\">jobTemplate:</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">template:</span><br>        <span class=\"hljs-attr\">spec:</span><br>          <span class=\"hljs-attr\">containers:</span><br>          <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">hello</span><br>            <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/busybox:v1.35</span><br>            <span class=\"hljs-attr\">args:</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">/bin/sh</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">-c</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">date;</span> <span class=\"hljs-string\">echo</span> <span class=\"hljs-string\">Hello</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">the</span> <span class=\"hljs-string\">Kubernetes</span> <span class=\"hljs-string\">cluster</span><br>          <span class=\"hljs-attr\">restartPolicy:</span> <span class=\"hljs-string\">OnFailure</span><br></code></pre></td></tr></table></figure>\n\n\n\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Job\"><a href=\"#Job\" class=\"headerlink\" title=\"Job\"></a>Job</h1><p>Job负责批处理任务,即仅执行一次的任务,它保证批处理任务的一个或多个Pod成功结束</p>\n<p>特殊说明</p>\n<ul>\n<li>spec.template格式同Pod</li>\n<li>RestartPolicy仅支持NeverdOnFailure</li>\n<li>单个Pod时,默认Pod成功运行后Job即结束</li>\n<li>.spec. completions 标志Job结束需要成功运行的Pod个数,默认为1</li>\n<li>.spec. parallelism 标志并行运行的Pod的个数,默认为1</li>\n<li>spec.activeDeadlineSeconds标志失败Pod的重试最大时间,超过这个时间不会继续重试</li>\n</ul>\n<p>例子：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">batch/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Job</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">pi</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">pi</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">pi</span><br>        <span class=\"hljs-attr\">image: harborcloud.com/library/perl:</span><br>        <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&quot;perl&quot;</span>,<span class=\"hljs-string\">&quot;-Mbignum=bpi&quot;</span>,<span class=\"hljs-string\">&quot;-wle&quot;</span>,<span class=\"hljs-string\">&quot;print bpi(2000)&quot;</span>]<br>      <span class=\"hljs-attr\">restartPolicy:</span> <span class=\"hljs-string\">Never</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"Spec\"><a href=\"#Spec\" class=\"headerlink\" title=\"Spec\"></a>Spec</h2><ul>\n<li>spec.template格式同Pod</li>\n<li>RestartPolicy仅支持Never或OnFailure</li>\n<li>单个Pod时,默认Pod成功运行后Job即结束</li>\n<li>spec. completions 标志Job结束需要成功运行的Pod个数,默认为1</li>\n<li>spec. parallelism标志并行运行的Pod的个数,默认为1</li>\n<li>spec.activeDeadlineSeconds标志失败Pod的重试最大时间,超过这个时间不会继续重试</li>\n</ul>\n<h1 id=\"CronJob\"><a href=\"#CronJob\" class=\"headerlink\" title=\"CronJob\"></a>CronJob</h1><p>CronJob管理基于时间的Job,即:</p>\n<ul>\n<li>在给定时间点只运行一次</li>\n<li>周期性地在给定时间点运行</li>\n</ul>\n<p>使用条件:当前使用的Kubernetes 集群,版本&gt;=1.8 (对Cronjob)</p>\n<p>典型的用法如下所示:<br>在给定的时间点调度Job运行<br>创建周期性运行的Job,例如:数据库备份、发送邮件</p>\n<h2 id=\"CronJob-Spec\"><a href=\"#CronJob-Spec\" class=\"headerlink\" title=\"CronJob Spec\"></a>CronJob Spec</h2><ul>\n<li>spec. schedule:调度,必需字段,指定任务运行周期,格式同Cron</li>\n<li>spec. jobTemplate: Job模板,必需字段,指定需要运行的任务,格式同Job</li>\n<li>spec. startingDeadlineSeconds:启动 Job 的期限(秒级别) ,该字段是可选的。如果因为任何原因而错过了被调度的时间,那么错过执行时间的Job将被认为是失败的。如果没有指定,则没有期限</li>\n<li>spec. concurrencyPolicy：并发策略,该字段也是可选的。它指定了如何处理被CronJob创建的Job的并发执行。只允许指定下面策略中的一种:Allow (默认) :允许并发运行 Job；Forbid ：禁止并发运行,如果前一个还没有完成,则直接跳过下一个；Replace：取消当前正在运行的Job,用一个新的来替换。<br>注意：当前策略只能应用于同一个Cron Job 创建的Job。如果存在多个Cron Job,它们创建的Job之间总是允许并发运行。</li>\n<li>spec. suspend：挂起,该字段也是可选的。如果设置为true,后续所有执行都会被挂起。它对已经开始执行的Job不起作用。默认值为false。</li>\n<li>spec. successfullobsHistoryLimit.spec.failedJobsHistoryLimit ：历史限制,是可选的字段。它们指定了可以保留多少完成和失败的Job。默认情况下,它们分别设置为3和1，设置限制的值为e,相关类型的Job完成后将不会被保留。</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">batch/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">CronJob</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">hello</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">schedule:</span> <span class=\"hljs-string\">&quot;*/1 * * * *&quot;</span><br>  <span class=\"hljs-attr\">jobTemplate:</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">template:</span><br>        <span class=\"hljs-attr\">spec:</span><br>          <span class=\"hljs-attr\">containers:</span><br>          <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">hello</span><br>            <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/busybox:v1.35</span><br>            <span class=\"hljs-attr\">args:</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">/bin/sh</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">-c</span><br>            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">date;</span> <span class=\"hljs-string\">echo</span> <span class=\"hljs-string\">Hello</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">the</span> <span class=\"hljs-string\">Kubernetes</span> <span class=\"hljs-string\">cluster</span><br>          <span class=\"hljs-attr\">restartPolicy:</span> <span class=\"hljs-string\">OnFailure</span><br></code></pre></td></tr></table></figure>\n\n\n\n"},{"title":"k8s Service的概述、类型及代理模式","date":"2021-08-13T15:32:02.000Z","_content":"\n# 一、概述\n\nKubernete Service 是一个定义了一组Pod的策略的抽象，我们也有时候叫做宏观服务。这些被服务标记的Pod都是（一般）通过label Selector决定的 。\n\n通过创建Service,可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载分发到后端的各个容器应用上。\n\n对于Kubernete原生的应用，Kubernete提供了一个简单的Endpoints API，这个Endpoints api的作用就是当一个服务中的pod发生变化时，Endpoints API随之变化，对于哪些不是原生的程序，Kubernetes提供了一个基于虚拟IP的网桥的服务，这个服务会将请求转发到对应的后台pod 。\n\n![1658045368211](k8s Service的概述、类型及代理模式/1658045368211.png)\n\n# 二、代理模式\n\nService能够提供负载均衡的能力,但是在使用上有以下限制:\n\n只提供4层负载均衡能力,而没有7层功能,但有时我们可能需要更多的匹配规则来转发请求,这点上4层负载均衡是不支持的\n\nVIP和Service代理：\n\n在Kubernetes 集群中,每个Node运行一个 kube-proxy进程。kube-proxy负责为Service实现了一种VIP (虚拟IP)的形式,而不是ExternalName的形式。\n\n- 在Kubernetes v1.0版本,代理完全在userspace.\n- 在Kubernetes v1.1版本,新增了 iptables 代理,但并不是默认的运行模式。\n- 从Kubemetes v1.2起,默认就是iptables代理。\n- 在Kubernetes v1.8.0-beta.0中,添加了ipvs代理\n- 在Kubernetes 1.14版本开始默认使用ipvs代理\n- 在Kubernetes v1.0版本, Service是4层概念。在Kubernetes v1.1版本，新增了  Ingress API (beta版) ,用来表示“7层（Http）服务\n\n为什么不用DNS?\n\n因为DNS需要在客服端保留记录，存在缓存等干扰，可能导致过期解析。\n\n## 1 userspace代理模式\n\n![1658044956049](k8s Service的概述、类型及代理模式/1658044956049.png)\n\n## 2 iptables代理模式\n\n![1658044977401](k8s Service的概述、类型及代理模式/1658044977401.png)\n\n## 3  ipvs代理模式\n\n这种模式, kube-proxy会监视Kubernetes Service对象和Endpoints,调用netlink接口以相应地创建ipvs规则并定期与Kubernetes Service对象和Endpoints对象同步ipvs规则,以确保ipvs状态与期望一致。访问服务时,流量将被重定向到其中一个后端Pod与iptables 类似, ipvs于netfilter的hook功能,但使用哈希表作为底层数据结构并在内核空间中工作。这意味着ipvs可以更快地重定向流量,并且在同步代理规则时具有更好的性能。此外,ipvs为负载均衡算法提供了更多选项,例如:\n\n- rr:轮询调度\n- 1c:最小连接数\n- dh:目标哈希\n- sh:源哈希\n- sed:最短期望延迟\n- nq:不排队调度\n\n![1658045067670](k8s Service的概述、类型及代理模式/1658045067670.png)\n\n# 三、Service 的类型\n\nService 在K8s中有以下四种类型\n\n- Clusterlp:默认类型,自动分配一个仅Cluster内部可以访问的虚拟IP\n- NodePort: 在ClusterIP基础上为Service在每台机器上绑定一个端口,这样就可以通过:NodePort来访问该服务\n- LoadBalancer: 在NodePort的基础上,借助cloud provider创建一个外部负载均衡器,并将请求转发到: NodePort\n- ExternalName:把集群外部的服务引入到集群内部来,在集群内部直接使用。没有任何类型代理被创建,这只有kubernetes 1.7或更高版本的kube-dns才支持\n\n## 1 ClusterIP\n\nclusterIP 主要在每个 node 节点使用iptables,将发向 clusterIP 对应端口的数据,转发到kube-proxy中。然后kube-proxy 自己内部实现有负载均衡的方法,并可以查询到这个 service下对应pod的地址和端口,进而把数据转发给对应的pod的地址和端口\n\n![1658045231642](k8s Service的概述、类型及代理模式/1658045231642.png)\n\n协同工作原理:\n\n- apiserver 用户通过kubectl命令向apiserver发送创建service的命令, apiserver接收到请求后将数据存储到etcd中\n- kube-proxy kubernetes的每个节点中都有一个叫做kube-porxy的进程,这个进程负责感知service, pod的变化,并将变化的信息写入本地的iptables规则中\n- iptables 使用NAT等技术将virtualIP的流量转至endpoint中\n\n创建myapp-deploy.yaml文件\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deploy\n  namespace: default\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n      release: stabel\n  template:\n    metadata:\n      labels:\n        app: myapp\n        release: stabel\n        env: test\n    spec:\n      containers:\n      - name: myapp\n        image: harborcloud.com/library/nginx:1.9.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 80\n```\n\n创建Service信息，myapp-service.yaml\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\n  namespace: default\nspec:\n  type: ClusterIP\n  selector:\n    app: myapp\n    release: stabel\n  ports:\n  - name: http\n    port: 80\n    targetPort: 80\n```\n\n## 2 Headless Service\n\n有时不需要或不想要负载均衡,以及单独的Service IP.遇到这种情况,可以通过指定ClusterIP(spec.clusterIP) 的值为\"None\"来创建Headless Service。这类Service并不会分配Cluster IP，kube-proxy不会处理它们,而且平台也不会为它们进行负载均衡和路由。\n\n```\n[root@k8s-master mainfests]# vim myapp-svc-headless.yaml\n```\n\nmyapp-svc-headless.yaml\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-headless\n  namespace: default\nspec:\n  selector:\n    app: myapp\n  clusterIP: \"None\"\n  ports:\n  - port: 80\n    targetPort: 80\n```\n\n```\n[root@k8s-master01 service]# yum install -y  bind-utils\n[root@k8s-master01 service]# dig -t A myapp-headless.default.svc.cluster.local. @10.244.0.12\n```\n\n```\n[root@k8s-master01 service]# kubectl get pod -n kube-system -o wide\nNAME                                   READY   STATUS    RESTARTS        AGE     IP                    NODE           NOMINATED NODE   READINESS GATES\ncoredns-7f6cbbb7b8-pbv77               1/1     Running   4 (2d20h ago)   5d20h   10.244.0.13           k8s-master01   <none>           <none>\ncoredns-7f6cbbb7b8-qxw99               1/1     Running   4 (2d20h ago)   5d20h   10.244.0.12           k8s-master01   <none>           <none>\netcd-k8s-master01                      1/1     Running   7 (2d20h ago)   5d20h   10.0.0.10             k8s-master01   <none>           <none>\nkube-apiserver-k8s-master01            1/1     Running   7 (2d20h ago)   5d20h   10.0.0.10             k8s-master01   <none>           <none>\nkube-controller-manager-k8s-master01   1/1     Running   9 (2d20h ago)   5d20h   10.0.0.10             k8s-master01   <none>           <none>\nkube-proxy-ml24c                       1/1     Running   3 (2d20h ago)   3d22h   fd56:a9ae:cb0f::7a1   k8s-node01     <none>           <none>\nkube-proxy-mrbsk                       1/1     Running   4 (2d20h ago)   3d22h   10.0.0.10             k8s-master01   <none>           <none>\nkube-proxy-tkszd                       1/1     Running   2 (22h ago)     3d22h   fd56:a9ae:cb0f::853   k8s-node02     <none>           <none>\nkube-scheduler-k8s-master01            1/1     Running   8 (2d20h ago)   5d20h   10.0.0.10             k8s-master01   <none>           <none>\n[root@k8s-master01 service]# dig -t A myapp-headless.default.svc.cluster.local. @10.244.0.12\n\n; <<>> DiG 9.11.4-P2-RedHat-9.11.4-26.P2.el7_9.9 <<>> -t A myapp-headless.default.svc.cluster.local. @10.244.0.12\n;; global options: +cmd\n;; Got answer:\n;; WARNING: .local is reserved for Multicast DNS\n;; You are currently testing what happens when an mDNS query is leaked to DNS\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 14989\n;; flags: qr aa rd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;myapp-headless.default.svc.cluster.local. IN A\n\n;; ANSWER SECTION:\nmyapp-headless.default.svc.cluster.local. 30 IN A 10.244.2.109\nmyapp-headless.default.svc.cluster.local. 30 IN A 10.244.1.165\nmyapp-headless.default.svc.cluster.local. 30 IN A 10.244.2.108\n\n;; Query time: 2 msec\n;; SERVER: 10.244.0.12#53(10.244.0.12)\n;; WHEN: 一 7月 18 05:05:52 CST 2022\n;; MSG SIZE  rcvd: 237\n\n[root@k8s-master01 service]# kubectl get pod -o wide\nNAME                            READY   STATUS    RESTARTS   AGE     IP             NODE         NOMINATED NODE   READINESS GATES\nmyapp-deploy-85bb565996-2tvcg   1/1     Running   0          2m20s   10.244.2.108   k8s-node02   <none>           <none>\nmyapp-deploy-85bb565996-dgzgz   1/1     Running   0          2m20s   10.244.2.109   k8s-node02   <none>           <none>\nmyapp-deploy-85bb565996-mlnh8   1/1     Running   0          2m20s   10.244.1.165   k8s-node01   <none>           <none>\n```\n\n通过Headless Service一样可以访问到对应的pod上去\n\n## 3 NodePort\n\nnodePort 的原理在于在node上开了一个端口,将向该端口的流量导入到kube-proxy,然后由kube-proxy进一步到给对应的pod\n\n```\n[root@master manifests]# vi myapp-np-service.yaml\n```\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\n  namespace: default\nspec:\n  type: NodePort\n  selector:\n    app: myapp\n    release: stabel\n  ports:\n  - name: http\n    port: 80\n    targetPort: 80\n```\n\n查看结果\n\n```\n# 查看service服务暴露端口\n[root@k8s-master01 service]# kubectl get svc -o wide\nNAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE     SELECTOR\nkubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        5d20h   <none>\nmyapp        NodePort    10.98.226.253   <none>        80:30247/TCP   17s     app=myapp,release=stabel\n#查看myapp分布在哪些节点\n[root@k8s-master01 service]# kubectl get pod -o wide\nNAME                            READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES\nmyapp-deploy-85bb565996-dcgzh   1/1     Running   0          54s   10.244.1.167   k8s-node01   <none>           <none>\nmyapp-deploy-85bb565996-snpfg   1/1     Running   0          54s   10.244.1.166   k8s-node01   <none>           <none>\nmyapp-deploy-85bb565996-xv2q4   1/1     Running   0          54s   10.244.2.110   k8s-node02   <none>           <none>\n#查看所有节点的信息\n[root@k8s-master01 service]# kubectl get node -o wide           \nNAME           STATUS   ROLES                  AGE     VERSION   INTERNAL-IP           EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME\nk8s-master01   Ready    control-plane,master   5d20h   v1.22.0   10.0.0.10             <none>        CentOS Linux 7 (Core)   3.10.0-1160.71.1.el7.x86_64   docker://18.6.1\nk8s-node01     Ready    <none>                 4d22h   v1.22.0   10.0.0.21             <none>        CentOS Linux 7 (Core)   3.10.0-1160.71.1.el7.x86_64   docker://18.6.1\nk8s-node02     Ready    <none>                 4d22h   v1.22.0   10.0.0.22             <none>        CentOS Linux 7 (Core)   3.10.0-1160.71.1.el7.x86_64   docker://18.6.1\n```\n\n通过访问10.0.0.10:30247,10.0.0.21:30247,10.0.0.22:30247都可以得到：\n\n![1658064476544](k8s Service的概述、类型及代理模式.assets/1658064476544.png)\n\n查询流程\n\n```\n[root@k8s-master01 service]# iptables -t nat -nvL KUBE-NODEPORTS\nChain KUBE-NODEPORTS (0 references)\n pkts bytes target     prot opt in     out     source               destination         \n    0     0 KUBE-SVC-2CMXP7HKUVJN7L6M  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/nginx */ tcp dpt:30029\n```\n\n## 4 LoadBalancer\n\nloadBalancer 和 nodePort其实是同一种方式,区别在于loadBalancer 比 nodePort多了一步,就是可以调用cloud provider 去创建 LB 来向节点导流。\n\n![1658046066962](k8s Service的概述、类型及代理模式/1658046066962.png)\n\n# 5 ExternalName\n\n这种类型的Service通过返回CNAME和它的值,可以将服务映射到externalName字段的内容(例如:hub.atguigu.com). ExternalName Service 是 Service的特例,它没有 selector,也没有定义任何的端口和Endpoint。相反的,对于运行在集群外部的服务,它通过返回该外部服务的别名这种方式来提供服务\n\n```yaml\nkind: Service\napiversion: v1\nmetadata:\n  name: my-service-1\n  namespace: default\nspec:\n  type: ExternalName\n  externalName: www.qingyeshuijian.com\n```\n\n当查询主机 my-service-1.defalut.svc.cluster.local (SVC_NAME.NAMESPACE.svc.cluster.local )时,集群的DNS服务将返回一个值my.database.example.com的CNAME记录。访问这个服务的工作方式和其他的相同,唯一不同的是重定向发生在DNS层,而且不会进行代理或转发。\n\n```\n[root@k8s-master01 service]# dig -t A my-service-1.default.svc.cluster.local. @10.244.0.12              \n\n; <<>> DiG 9.11.4-P2-RedHat-9.11.4-26.P2.el7_9.9 <<>> -t A my-service-1.default.svc.cluster.local. @10.244.0.12\n;; global options: +cmd\n;; Got answer:\n;; WARNING: .local is reserved for Multicast DNS\n;; You are currently testing what happens when an mDNS query is leaked to DNS\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 3150\n;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;my-service-1.default.svc.cluster.local.        IN A\n\n;; ANSWER SECTION:\nmy-service-1.default.svc.cluster.local. 30 IN CNAME www.qingyeshuijian.com.\nwww.qingyeshuijian.com. 30      IN      A       39.107.115.153\n\n;; Query time: 50 msec\n;; SERVER: 10.244.0.12#53(10.244.0.12)\n;; WHEN: 一 7月 18 05:30:32 CST 2022\n;; MSG SIZE  rcvd: 179\n```\n\n通过上面的dig查看ExternalName找到cname指向了www.qingyeshuijian.com","source":"_posts/k8s Service的概述、类型及代理模式.md","raw":"---\ntitle: k8s Service的概述、类型及代理模式\ndate: 2021-08-13 23:32:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - service\n---\n\n# 一、概述\n\nKubernete Service 是一个定义了一组Pod的策略的抽象，我们也有时候叫做宏观服务。这些被服务标记的Pod都是（一般）通过label Selector决定的 。\n\n通过创建Service,可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载分发到后端的各个容器应用上。\n\n对于Kubernete原生的应用，Kubernete提供了一个简单的Endpoints API，这个Endpoints api的作用就是当一个服务中的pod发生变化时，Endpoints API随之变化，对于哪些不是原生的程序，Kubernetes提供了一个基于虚拟IP的网桥的服务，这个服务会将请求转发到对应的后台pod 。\n\n![1658045368211](k8s Service的概述、类型及代理模式/1658045368211.png)\n\n# 二、代理模式\n\nService能够提供负载均衡的能力,但是在使用上有以下限制:\n\n只提供4层负载均衡能力,而没有7层功能,但有时我们可能需要更多的匹配规则来转发请求,这点上4层负载均衡是不支持的\n\nVIP和Service代理：\n\n在Kubernetes 集群中,每个Node运行一个 kube-proxy进程。kube-proxy负责为Service实现了一种VIP (虚拟IP)的形式,而不是ExternalName的形式。\n\n- 在Kubernetes v1.0版本,代理完全在userspace.\n- 在Kubernetes v1.1版本,新增了 iptables 代理,但并不是默认的运行模式。\n- 从Kubemetes v1.2起,默认就是iptables代理。\n- 在Kubernetes v1.8.0-beta.0中,添加了ipvs代理\n- 在Kubernetes 1.14版本开始默认使用ipvs代理\n- 在Kubernetes v1.0版本, Service是4层概念。在Kubernetes v1.1版本，新增了  Ingress API (beta版) ,用来表示“7层（Http）服务\n\n为什么不用DNS?\n\n因为DNS需要在客服端保留记录，存在缓存等干扰，可能导致过期解析。\n\n## 1 userspace代理模式\n\n![1658044956049](k8s Service的概述、类型及代理模式/1658044956049.png)\n\n## 2 iptables代理模式\n\n![1658044977401](k8s Service的概述、类型及代理模式/1658044977401.png)\n\n## 3  ipvs代理模式\n\n这种模式, kube-proxy会监视Kubernetes Service对象和Endpoints,调用netlink接口以相应地创建ipvs规则并定期与Kubernetes Service对象和Endpoints对象同步ipvs规则,以确保ipvs状态与期望一致。访问服务时,流量将被重定向到其中一个后端Pod与iptables 类似, ipvs于netfilter的hook功能,但使用哈希表作为底层数据结构并在内核空间中工作。这意味着ipvs可以更快地重定向流量,并且在同步代理规则时具有更好的性能。此外,ipvs为负载均衡算法提供了更多选项,例如:\n\n- rr:轮询调度\n- 1c:最小连接数\n- dh:目标哈希\n- sh:源哈希\n- sed:最短期望延迟\n- nq:不排队调度\n\n![1658045067670](k8s Service的概述、类型及代理模式/1658045067670.png)\n\n# 三、Service 的类型\n\nService 在K8s中有以下四种类型\n\n- Clusterlp:默认类型,自动分配一个仅Cluster内部可以访问的虚拟IP\n- NodePort: 在ClusterIP基础上为Service在每台机器上绑定一个端口,这样就可以通过:NodePort来访问该服务\n- LoadBalancer: 在NodePort的基础上,借助cloud provider创建一个外部负载均衡器,并将请求转发到: NodePort\n- ExternalName:把集群外部的服务引入到集群内部来,在集群内部直接使用。没有任何类型代理被创建,这只有kubernetes 1.7或更高版本的kube-dns才支持\n\n## 1 ClusterIP\n\nclusterIP 主要在每个 node 节点使用iptables,将发向 clusterIP 对应端口的数据,转发到kube-proxy中。然后kube-proxy 自己内部实现有负载均衡的方法,并可以查询到这个 service下对应pod的地址和端口,进而把数据转发给对应的pod的地址和端口\n\n![1658045231642](k8s Service的概述、类型及代理模式/1658045231642.png)\n\n协同工作原理:\n\n- apiserver 用户通过kubectl命令向apiserver发送创建service的命令, apiserver接收到请求后将数据存储到etcd中\n- kube-proxy kubernetes的每个节点中都有一个叫做kube-porxy的进程,这个进程负责感知service, pod的变化,并将变化的信息写入本地的iptables规则中\n- iptables 使用NAT等技术将virtualIP的流量转至endpoint中\n\n创建myapp-deploy.yaml文件\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deploy\n  namespace: default\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n      release: stabel\n  template:\n    metadata:\n      labels:\n        app: myapp\n        release: stabel\n        env: test\n    spec:\n      containers:\n      - name: myapp\n        image: harborcloud.com/library/nginx:1.9.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 80\n```\n\n创建Service信息，myapp-service.yaml\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\n  namespace: default\nspec:\n  type: ClusterIP\n  selector:\n    app: myapp\n    release: stabel\n  ports:\n  - name: http\n    port: 80\n    targetPort: 80\n```\n\n## 2 Headless Service\n\n有时不需要或不想要负载均衡,以及单独的Service IP.遇到这种情况,可以通过指定ClusterIP(spec.clusterIP) 的值为\"None\"来创建Headless Service。这类Service并不会分配Cluster IP，kube-proxy不会处理它们,而且平台也不会为它们进行负载均衡和路由。\n\n```\n[root@k8s-master mainfests]# vim myapp-svc-headless.yaml\n```\n\nmyapp-svc-headless.yaml\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-headless\n  namespace: default\nspec:\n  selector:\n    app: myapp\n  clusterIP: \"None\"\n  ports:\n  - port: 80\n    targetPort: 80\n```\n\n```\n[root@k8s-master01 service]# yum install -y  bind-utils\n[root@k8s-master01 service]# dig -t A myapp-headless.default.svc.cluster.local. @10.244.0.12\n```\n\n```\n[root@k8s-master01 service]# kubectl get pod -n kube-system -o wide\nNAME                                   READY   STATUS    RESTARTS        AGE     IP                    NODE           NOMINATED NODE   READINESS GATES\ncoredns-7f6cbbb7b8-pbv77               1/1     Running   4 (2d20h ago)   5d20h   10.244.0.13           k8s-master01   <none>           <none>\ncoredns-7f6cbbb7b8-qxw99               1/1     Running   4 (2d20h ago)   5d20h   10.244.0.12           k8s-master01   <none>           <none>\netcd-k8s-master01                      1/1     Running   7 (2d20h ago)   5d20h   10.0.0.10             k8s-master01   <none>           <none>\nkube-apiserver-k8s-master01            1/1     Running   7 (2d20h ago)   5d20h   10.0.0.10             k8s-master01   <none>           <none>\nkube-controller-manager-k8s-master01   1/1     Running   9 (2d20h ago)   5d20h   10.0.0.10             k8s-master01   <none>           <none>\nkube-proxy-ml24c                       1/1     Running   3 (2d20h ago)   3d22h   fd56:a9ae:cb0f::7a1   k8s-node01     <none>           <none>\nkube-proxy-mrbsk                       1/1     Running   4 (2d20h ago)   3d22h   10.0.0.10             k8s-master01   <none>           <none>\nkube-proxy-tkszd                       1/1     Running   2 (22h ago)     3d22h   fd56:a9ae:cb0f::853   k8s-node02     <none>           <none>\nkube-scheduler-k8s-master01            1/1     Running   8 (2d20h ago)   5d20h   10.0.0.10             k8s-master01   <none>           <none>\n[root@k8s-master01 service]# dig -t A myapp-headless.default.svc.cluster.local. @10.244.0.12\n\n; <<>> DiG 9.11.4-P2-RedHat-9.11.4-26.P2.el7_9.9 <<>> -t A myapp-headless.default.svc.cluster.local. @10.244.0.12\n;; global options: +cmd\n;; Got answer:\n;; WARNING: .local is reserved for Multicast DNS\n;; You are currently testing what happens when an mDNS query is leaked to DNS\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 14989\n;; flags: qr aa rd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;myapp-headless.default.svc.cluster.local. IN A\n\n;; ANSWER SECTION:\nmyapp-headless.default.svc.cluster.local. 30 IN A 10.244.2.109\nmyapp-headless.default.svc.cluster.local. 30 IN A 10.244.1.165\nmyapp-headless.default.svc.cluster.local. 30 IN A 10.244.2.108\n\n;; Query time: 2 msec\n;; SERVER: 10.244.0.12#53(10.244.0.12)\n;; WHEN: 一 7月 18 05:05:52 CST 2022\n;; MSG SIZE  rcvd: 237\n\n[root@k8s-master01 service]# kubectl get pod -o wide\nNAME                            READY   STATUS    RESTARTS   AGE     IP             NODE         NOMINATED NODE   READINESS GATES\nmyapp-deploy-85bb565996-2tvcg   1/1     Running   0          2m20s   10.244.2.108   k8s-node02   <none>           <none>\nmyapp-deploy-85bb565996-dgzgz   1/1     Running   0          2m20s   10.244.2.109   k8s-node02   <none>           <none>\nmyapp-deploy-85bb565996-mlnh8   1/1     Running   0          2m20s   10.244.1.165   k8s-node01   <none>           <none>\n```\n\n通过Headless Service一样可以访问到对应的pod上去\n\n## 3 NodePort\n\nnodePort 的原理在于在node上开了一个端口,将向该端口的流量导入到kube-proxy,然后由kube-proxy进一步到给对应的pod\n\n```\n[root@master manifests]# vi myapp-np-service.yaml\n```\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\n  namespace: default\nspec:\n  type: NodePort\n  selector:\n    app: myapp\n    release: stabel\n  ports:\n  - name: http\n    port: 80\n    targetPort: 80\n```\n\n查看结果\n\n```\n# 查看service服务暴露端口\n[root@k8s-master01 service]# kubectl get svc -o wide\nNAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE     SELECTOR\nkubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        5d20h   <none>\nmyapp        NodePort    10.98.226.253   <none>        80:30247/TCP   17s     app=myapp,release=stabel\n#查看myapp分布在哪些节点\n[root@k8s-master01 service]# kubectl get pod -o wide\nNAME                            READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES\nmyapp-deploy-85bb565996-dcgzh   1/1     Running   0          54s   10.244.1.167   k8s-node01   <none>           <none>\nmyapp-deploy-85bb565996-snpfg   1/1     Running   0          54s   10.244.1.166   k8s-node01   <none>           <none>\nmyapp-deploy-85bb565996-xv2q4   1/1     Running   0          54s   10.244.2.110   k8s-node02   <none>           <none>\n#查看所有节点的信息\n[root@k8s-master01 service]# kubectl get node -o wide           \nNAME           STATUS   ROLES                  AGE     VERSION   INTERNAL-IP           EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME\nk8s-master01   Ready    control-plane,master   5d20h   v1.22.0   10.0.0.10             <none>        CentOS Linux 7 (Core)   3.10.0-1160.71.1.el7.x86_64   docker://18.6.1\nk8s-node01     Ready    <none>                 4d22h   v1.22.0   10.0.0.21             <none>        CentOS Linux 7 (Core)   3.10.0-1160.71.1.el7.x86_64   docker://18.6.1\nk8s-node02     Ready    <none>                 4d22h   v1.22.0   10.0.0.22             <none>        CentOS Linux 7 (Core)   3.10.0-1160.71.1.el7.x86_64   docker://18.6.1\n```\n\n通过访问10.0.0.10:30247,10.0.0.21:30247,10.0.0.22:30247都可以得到：\n\n![1658064476544](k8s Service的概述、类型及代理模式.assets/1658064476544.png)\n\n查询流程\n\n```\n[root@k8s-master01 service]# iptables -t nat -nvL KUBE-NODEPORTS\nChain KUBE-NODEPORTS (0 references)\n pkts bytes target     prot opt in     out     source               destination         \n    0     0 KUBE-SVC-2CMXP7HKUVJN7L6M  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/nginx */ tcp dpt:30029\n```\n\n## 4 LoadBalancer\n\nloadBalancer 和 nodePort其实是同一种方式,区别在于loadBalancer 比 nodePort多了一步,就是可以调用cloud provider 去创建 LB 来向节点导流。\n\n![1658046066962](k8s Service的概述、类型及代理模式/1658046066962.png)\n\n# 5 ExternalName\n\n这种类型的Service通过返回CNAME和它的值,可以将服务映射到externalName字段的内容(例如:hub.atguigu.com). ExternalName Service 是 Service的特例,它没有 selector,也没有定义任何的端口和Endpoint。相反的,对于运行在集群外部的服务,它通过返回该外部服务的别名这种方式来提供服务\n\n```yaml\nkind: Service\napiversion: v1\nmetadata:\n  name: my-service-1\n  namespace: default\nspec:\n  type: ExternalName\n  externalName: www.qingyeshuijian.com\n```\n\n当查询主机 my-service-1.defalut.svc.cluster.local (SVC_NAME.NAMESPACE.svc.cluster.local )时,集群的DNS服务将返回一个值my.database.example.com的CNAME记录。访问这个服务的工作方式和其他的相同,唯一不同的是重定向发生在DNS层,而且不会进行代理或转发。\n\n```\n[root@k8s-master01 service]# dig -t A my-service-1.default.svc.cluster.local. @10.244.0.12              \n\n; <<>> DiG 9.11.4-P2-RedHat-9.11.4-26.P2.el7_9.9 <<>> -t A my-service-1.default.svc.cluster.local. @10.244.0.12\n;; global options: +cmd\n;; Got answer:\n;; WARNING: .local is reserved for Multicast DNS\n;; You are currently testing what happens when an mDNS query is leaked to DNS\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 3150\n;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;my-service-1.default.svc.cluster.local.        IN A\n\n;; ANSWER SECTION:\nmy-service-1.default.svc.cluster.local. 30 IN CNAME www.qingyeshuijian.com.\nwww.qingyeshuijian.com. 30      IN      A       39.107.115.153\n\n;; Query time: 50 msec\n;; SERVER: 10.244.0.12#53(10.244.0.12)\n;; WHEN: 一 7月 18 05:30:32 CST 2022\n;; MSG SIZE  rcvd: 179\n```\n\n通过上面的dig查看ExternalName找到cname指向了www.qingyeshuijian.com","slug":"k8s Service的概述、类型及代理模式","published":1,"updated":"2022-09-23T17:28:36.172Z","_id":"cl8er9ep7000p28vj5nhv0mps","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、概述\"><a href=\"#一、概述\" class=\"headerlink\" title=\"一、概述\"></a>一、概述</h1><p>Kubernete Service 是一个定义了一组Pod的策略的抽象，我们也有时候叫做宏观服务。这些被服务标记的Pod都是（一般）通过label Selector决定的 。</p>\n<p>通过创建Service,可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载分发到后端的各个容器应用上。</p>\n<p>对于Kubernete原生的应用，Kubernete提供了一个简单的Endpoints API，这个Endpoints api的作用就是当一个服务中的pod发生变化时，Endpoints API随之变化，对于哪些不是原生的程序，Kubernetes提供了一个基于虚拟IP的网桥的服务，这个服务会将请求转发到对应的后台pod 。</p>\n<p>![1658045368211](k8s Service的概述、类型及代理模式/1658045368211.png)</p>\n<h1 id=\"二、代理模式\"><a href=\"#二、代理模式\" class=\"headerlink\" title=\"二、代理模式\"></a>二、代理模式</h1><p>Service能够提供负载均衡的能力,但是在使用上有以下限制:</p>\n<p>只提供4层负载均衡能力,而没有7层功能,但有时我们可能需要更多的匹配规则来转发请求,这点上4层负载均衡是不支持的</p>\n<p>VIP和Service代理：</p>\n<p>在Kubernetes 集群中,每个Node运行一个 kube-proxy进程。kube-proxy负责为Service实现了一种VIP (虚拟IP)的形式,而不是ExternalName的形式。</p>\n<ul>\n<li>在Kubernetes v1.0版本,代理完全在userspace.</li>\n<li>在Kubernetes v1.1版本,新增了 iptables 代理,但并不是默认的运行模式。</li>\n<li>从Kubemetes v1.2起,默认就是iptables代理。</li>\n<li>在Kubernetes v1.8.0-beta.0中,添加了ipvs代理</li>\n<li>在Kubernetes 1.14版本开始默认使用ipvs代理</li>\n<li>在Kubernetes v1.0版本, Service是4层概念。在Kubernetes v1.1版本，新增了  Ingress API (beta版) ,用来表示“7层（Http）服务</li>\n</ul>\n<p>为什么不用DNS?</p>\n<p>因为DNS需要在客服端保留记录，存在缓存等干扰，可能导致过期解析。</p>\n<h2 id=\"1-userspace代理模式\"><a href=\"#1-userspace代理模式\" class=\"headerlink\" title=\"1 userspace代理模式\"></a>1 userspace代理模式</h2><p>![1658044956049](k8s Service的概述、类型及代理模式/1658044956049.png)</p>\n<h2 id=\"2-iptables代理模式\"><a href=\"#2-iptables代理模式\" class=\"headerlink\" title=\"2 iptables代理模式\"></a>2 iptables代理模式</h2><p>![1658044977401](k8s Service的概述、类型及代理模式/1658044977401.png)</p>\n<h2 id=\"3-ipvs代理模式\"><a href=\"#3-ipvs代理模式\" class=\"headerlink\" title=\"3  ipvs代理模式\"></a>3  ipvs代理模式</h2><p>这种模式, kube-proxy会监视Kubernetes Service对象和Endpoints,调用netlink接口以相应地创建ipvs规则并定期与Kubernetes Service对象和Endpoints对象同步ipvs规则,以确保ipvs状态与期望一致。访问服务时,流量将被重定向到其中一个后端Pod与iptables 类似, ipvs于netfilter的hook功能,但使用哈希表作为底层数据结构并在内核空间中工作。这意味着ipvs可以更快地重定向流量,并且在同步代理规则时具有更好的性能。此外,ipvs为负载均衡算法提供了更多选项,例如:</p>\n<ul>\n<li>rr:轮询调度</li>\n<li>1c:最小连接数</li>\n<li>dh:目标哈希</li>\n<li>sh:源哈希</li>\n<li>sed:最短期望延迟</li>\n<li>nq:不排队调度</li>\n</ul>\n<p>![1658045067670](k8s Service的概述、类型及代理模式/1658045067670.png)</p>\n<h1 id=\"三、Service-的类型\"><a href=\"#三、Service-的类型\" class=\"headerlink\" title=\"三、Service 的类型\"></a>三、Service 的类型</h1><p>Service 在K8s中有以下四种类型</p>\n<ul>\n<li>Clusterlp:默认类型,自动分配一个仅Cluster内部可以访问的虚拟IP</li>\n<li>NodePort: 在ClusterIP基础上为Service在每台机器上绑定一个端口,这样就可以通过:NodePort来访问该服务</li>\n<li>LoadBalancer: 在NodePort的基础上,借助cloud provider创建一个外部负载均衡器,并将请求转发到: NodePort</li>\n<li>ExternalName:把集群外部的服务引入到集群内部来,在集群内部直接使用。没有任何类型代理被创建,这只有kubernetes 1.7或更高版本的kube-dns才支持</li>\n</ul>\n<h2 id=\"1-ClusterIP\"><a href=\"#1-ClusterIP\" class=\"headerlink\" title=\"1 ClusterIP\"></a>1 ClusterIP</h2><p>clusterIP 主要在每个 node 节点使用iptables,将发向 clusterIP 对应端口的数据,转发到kube-proxy中。然后kube-proxy 自己内部实现有负载均衡的方法,并可以查询到这个 service下对应pod的地址和端口,进而把数据转发给对应的pod的地址和端口</p>\n<p>![1658045231642](k8s Service的概述、类型及代理模式/1658045231642.png)</p>\n<p>协同工作原理:</p>\n<ul>\n<li>apiserver 用户通过kubectl命令向apiserver发送创建service的命令, apiserver接收到请求后将数据存储到etcd中</li>\n<li>kube-proxy kubernetes的每个节点中都有一个叫做kube-porxy的进程,这个进程负责感知service, pod的变化,并将变化的信息写入本地的iptables规则中</li>\n<li>iptables 使用NAT等技术将virtualIP的流量转至endpoint中</li>\n</ul>\n<p>创建myapp-deploy.yaml文件</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">apps/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Deployment</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp-deploy</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-number\">3</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">matchLabels:</span><br>      <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myapp</span><br>      <span class=\"hljs-attr\">release:</span> <span class=\"hljs-string\">stabel</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">labels:</span><br>        <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myapp</span><br>        <span class=\"hljs-attr\">release:</span> <span class=\"hljs-string\">stabel</span><br>        <span class=\"hljs-attr\">env:</span> <span class=\"hljs-string\">test</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp</span><br>        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.9.1</span><br>        <span class=\"hljs-attr\">imagePullPolicy:</span> <span class=\"hljs-string\">IfNotPresent</span><br>        <span class=\"hljs-attr\">ports:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">http</span><br>          <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n<p>创建Service信息，myapp-service.yaml</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Service</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">ClusterIP</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myapp</span><br>    <span class=\"hljs-attr\">release:</span> <span class=\"hljs-string\">stabel</span><br>  <span class=\"hljs-attr\">ports:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">http</span><br>    <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br>    <span class=\"hljs-attr\">targetPort:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-Headless-Service\"><a href=\"#2-Headless-Service\" class=\"headerlink\" title=\"2 Headless Service\"></a>2 Headless Service</h2><p>有时不需要或不想要负载均衡,以及单独的Service IP.遇到这种情况,可以通过指定ClusterIP(spec.clusterIP) 的值为”None”来创建Headless Service。这类Service并不会分配Cluster IP，kube-proxy不会处理它们,而且平台也不会为它们进行负载均衡和路由。</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">[root@k8s-<span class=\"hljs-keyword\">master</span> <span class=\"hljs-title\">mainfests</span>]<span class=\"hljs-comment\"># vim myapp-svc-headless.yaml</span><br></code></pre></td></tr></table></figure>\n\n<p>myapp-svc-headless.yaml</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Service</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp-headless</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myapp</span><br>  <span class=\"hljs-attr\">clusterIP:</span> <span class=\"hljs-string\">&quot;None&quot;</span><br>  <span class=\"hljs-attr\">ports:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br>    <span class=\"hljs-attr\">targetPort:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight mel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mel\">[root@k8s-master01 service]# yum install -y  bind-utils<br>[root@k8s-master01 service]# dig -t A myapp-headless.<span class=\"hljs-keyword\">default</span>.svc.<span class=\"hljs-keyword\">cluster</span>.local. @10<span class=\"hljs-number\">.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.12</span><br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-selector-attr\">[root@k8s-master01 service]</span># kubectl get pod -n kube-system -o wide<br>NAME                                   READY   STATUS    RESTARTS        AGE     IP                    NODE           NOMINATED NODE   READINESS GATES<br>coredns-<span class=\"hljs-number\">7</span>f6cbbb7b8-pbv77               <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">4</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">5</span>d20h   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.13</span>           k8s-master01   &lt;<span class=\"hljs-attribute\">none</span>&gt;           &lt;<span class=\"hljs-attribute\">none</span>&gt;<br>coredns-<span class=\"hljs-number\">7</span>f6cbbb7b8-qxw99               <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">4</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">5</span>d20h   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.12</span>           k8s-master01   &lt;<span class=\"hljs-attribute\">none</span>&gt;           &lt;<span class=\"hljs-attribute\">none</span>&gt;<br>etcd-k8s-master01                      <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">7</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">5</span>d20h   <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.10</span>             k8s-master01   &lt;<span class=\"hljs-attribute\">none</span>&gt;           &lt;<span class=\"hljs-attribute\">none</span>&gt;<br>kube-apiserver-k8s-master01            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">7</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">5</span>d20h   <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.10</span>             k8s-master01   &lt;<span class=\"hljs-attribute\">none</span>&gt;           &lt;<span class=\"hljs-attribute\">none</span>&gt;<br>kube-controller-manager-k8s-master01   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">9</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">5</span>d20h   <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.10</span>             k8s-master01   &lt;<span class=\"hljs-attribute\">none</span>&gt;           &lt;<span class=\"hljs-attribute\">none</span>&gt;<br>kube-proxy-ml24c                       <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">3</span>d22h   fd56:a9ae:cb0f::<span class=\"hljs-number\">7</span>a1   k8s-node01     &lt;none&gt;           &lt;none&gt;<br>kube-proxy-mrbsk                       <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">4</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">3</span>d22h   <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.10</span>             k8s-master01   &lt;none&gt;           &lt;none&gt;<br>kube-proxy-tkszd                       <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">2</span> (<span class=\"hljs-number\">22</span>h ago)     <span class=\"hljs-number\">3</span>d22h   fd56:a9ae:cb0f::<span class=\"hljs-number\">853</span>   k8s-node02     &lt;none&gt;           &lt;none&gt;<br>kube-scheduler-k8s-master01            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">8</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">5</span>d20h   <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.10</span>             k8s-master01   &lt;none&gt;           &lt;none&gt;<br>[root@k8s-master01 service]# dig -t A myapp-headless.default.svc.cluster.local. @<span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.12</span><br><br>; &lt;&lt;&gt;&gt; DiG <span class=\"hljs-number\">9.11</span>.<span class=\"hljs-number\">4</span>-P2-RedHat-<span class=\"hljs-number\">9.11</span>.<span class=\"hljs-number\">4</span>-<span class=\"hljs-number\">26</span><span class=\"hljs-selector-class\">.P2</span><span class=\"hljs-selector-class\">.el7_9</span>.<span class=\"hljs-number\">9</span> &lt;&lt;&gt;&gt; -t <span class=\"hljs-selector-tag\">A</span> myapp-headless<span class=\"hljs-selector-class\">.default</span><span class=\"hljs-selector-class\">.svc</span><span class=\"hljs-selector-class\">.cluster</span><span class=\"hljs-selector-class\">.local</span>. <span class=\"hljs-keyword\">@10</span>.244.0.12<br>;; global options: +cmd<br>;; Got answer:<br>;; WARNING: .local is reserved for Multicast DNS<br>;; You are currently testing what happens when an mDNS query is leaked <span class=\"hljs-selector-tag\">to</span> DNS<br>;; -&gt;&gt;<span class=\"hljs-selector-tag\">HEADER</span>&lt;&lt;- opcode: QUERY, status: NOERROR, id: <span class=\"hljs-number\">14989</span><br>;; flags: qr aa rd; QUERY: <span class=\"hljs-number\">1</span>, ANSWER: <span class=\"hljs-number\">3</span>, AUTHORITY: <span class=\"hljs-number\">0</span>, ADDITIONAL: <span class=\"hljs-number\">1</span><br>;; WARNING: recursion requested but not available<br><br>;; OPT PSEUDOSECTION:<br>; EDNS: version: <span class=\"hljs-number\">0</span>, flags:; udp: <span class=\"hljs-number\">4096</span><br>;; QUESTION <span class=\"hljs-selector-tag\">SECTION</span>:<br>;myapp-headless<span class=\"hljs-selector-class\">.default</span><span class=\"hljs-selector-class\">.svc</span><span class=\"hljs-selector-class\">.cluster</span><span class=\"hljs-selector-class\">.local</span>. IN <span class=\"hljs-selector-tag\">A</span><br><br>;; ANSWER <span class=\"hljs-selector-tag\">SECTION</span>:<br>myapp-headless.default.svc.cluster.local. <span class=\"hljs-number\">30</span> IN A <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">2.109</span><br>myapp-headless.default.svc.cluster.local. <span class=\"hljs-number\">30</span> IN A <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">1.165</span><br>myapp-headless.default.svc.cluster.local. <span class=\"hljs-number\">30</span> IN A <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">2.108</span><br><br>;; Query <span class=\"hljs-selector-tag\">time</span>: <span class=\"hljs-number\">2</span> msec<br>;; SERVER: <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.12</span>#<span class=\"hljs-number\">53</span>(<span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.12</span>)<br>;; WHEN: 一 <span class=\"hljs-number\">7</span>月 <span class=\"hljs-number\">18</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">52</span> CST <span class=\"hljs-number\">2022</span><br>;; MSG SIZE  rcvd: <span class=\"hljs-number\">237</span><br><br>[root@k8s-master01 service]# kubectl get pod -o wide<br>NAME                            READY   STATUS    RESTARTS   AGE     IP             NODE         NOMINATED NODE   READINESS GATES<br>myapp-deploy-<span class=\"hljs-number\">85</span>bb565996-<span class=\"hljs-number\">2</span>tvcg   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">2</span>m20s   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">2.108</span>   k8s-node02   &lt;none&gt;           &lt;none&gt;<br>myapp-deploy-<span class=\"hljs-number\">85</span>bb565996-dgzgz   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">2</span>m20s   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">2.109</span>   k8s-node02   &lt;none&gt;           &lt;none&gt;<br>myapp-deploy-<span class=\"hljs-number\">85</span>bb565996-mlnh8   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">2</span>m20s   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">1.165</span>   k8s-node01   &lt;none&gt;           &lt;none&gt;<br></code></pre></td></tr></table></figure>\n\n<p>通过Headless Service一样可以访问到对应的pod上去</p>\n<h2 id=\"3-NodePort\"><a href=\"#3-NodePort\" class=\"headerlink\" title=\"3 NodePort\"></a>3 NodePort</h2><p>nodePort 的原理在于在node上开了一个端口,将向该端口的流量导入到kube-proxy,然后由kube-proxy进一步到给对应的pod</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">[root@<span class=\"hljs-keyword\">master</span> <span class=\"hljs-title\">manifests</span>]<span class=\"hljs-comment\"># vi myapp-np-service.yaml</span><br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Service</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">NodePort</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myapp</span><br>    <span class=\"hljs-attr\">release:</span> <span class=\"hljs-string\">stabel</span><br>  <span class=\"hljs-attr\">ports:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">http</span><br>    <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br>    <span class=\"hljs-attr\">targetPort:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n<p>查看结果</p>\n<figure class=\"highlight gherkin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gherkin\"><span class=\"hljs-comment\"># 查看service服务暴露端口</span><br>[root<span class=\"hljs-meta\">@k8s-master01</span> service]<span class=\"hljs-comment\"># kubectl get svc -o wide</span><br>NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE     SELECTOR<br>kubernetes   ClusterIP   10.96.0.1       <span class=\"hljs-variable\">&lt;none&gt;</span>        443/TCP        5d20h   <span class=\"hljs-variable\">&lt;none&gt;</span><br>myapp        NodePort    10.98.226.253   <span class=\"hljs-variable\">&lt;none&gt;</span>        80:30247/TCP   17s     app=myapp,release=stabel<br><span class=\"hljs-comment\">#查看myapp分布在哪些节点</span><br>[root<span class=\"hljs-meta\">@k8s-master01</span> service]<span class=\"hljs-comment\"># kubectl get pod -o wide</span><br>NAME                            READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES<br>myapp-deploy-85bb565996-dcgzh   1/1     Running   0          54s   10.244.1.167   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>myapp-deploy-85bb565996-snpfg   1/1     Running   0          54s   10.244.1.166   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>myapp-deploy-85bb565996-xv2q4   1/1     Running   0          54s   10.244.2.110   k8s-node02   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br><span class=\"hljs-comment\">#查看所有节点的信息</span><br>[root<span class=\"hljs-meta\">@k8s-master01</span> service]<span class=\"hljs-comment\"># kubectl get node -o wide           </span><br>NAME           STATUS   ROLES                  AGE     VERSION   INTERNAL-IP           EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME<br>k8s-master01   Ready    control-plane,master   5d20h   v1.22.0   10.0.0.10             <span class=\"hljs-variable\">&lt;none&gt;</span>        CentOS Linux 7 (Core)   3.10.0-1160.71.1.el7.x86_64   docker://18.6.1<br>k8s-node01     Ready    <span class=\"hljs-variable\">&lt;none&gt;</span>                 4d22h   v1.22.0   10.0.0.21             <span class=\"hljs-variable\">&lt;none&gt;</span>        CentOS Linux 7 (Core)   3.10.0-1160.71.1.el7.x86_64   docker://18.6.1<br>k8s-node02     Ready    <span class=\"hljs-variable\">&lt;none&gt;</span>                 4d22h   v1.22.0   10.0.0.22             <span class=\"hljs-variable\">&lt;none&gt;</span>        CentOS Linux 7 (Core)   3.10.0-1160.71.1.el7.x86_64   docker://18.6.1<br></code></pre></td></tr></table></figure>\n\n<p>通过访问10.0.0.10:30247,10.0.0.21:30247,10.0.0.22:30247都可以得到：</p>\n<p>![1658064476544](k8s Service的概述、类型及代理模式.assets/1658064476544.png)</p>\n<p>查询流程</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">[root@k8s-master01 service]<span class=\"hljs-comment\"># iptables -t nat -nvL KUBE-NODEPORTS</span><br>Chain KUBE-NODEPORTS (<span class=\"hljs-number\">0</span> references)<br> pkts bytes target     prot opt <span class=\"hljs-keyword\">in</span>     out     source               destination         <br>    <span class=\"hljs-number\">0</span>     <span class=\"hljs-number\">0</span> KUBE-SVC-<span class=\"hljs-number\">2</span>CMXP7HKUVJN7L6M  tcp  --  *      *       <span class=\"hljs-number\">0.0</span>.<span class=\"hljs-number\">0.0</span><span class=\"hljs-regexp\">/0            0.0.0.0/</span><span class=\"hljs-number\">0</span>            <span class=\"hljs-regexp\">/* default/</span>nginx */ tcp dpt:<span class=\"hljs-number\">30029</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"4-LoadBalancer\"><a href=\"#4-LoadBalancer\" class=\"headerlink\" title=\"4 LoadBalancer\"></a>4 LoadBalancer</h2><p>loadBalancer 和 nodePort其实是同一种方式,区别在于loadBalancer 比 nodePort多了一步,就是可以调用cloud provider 去创建 LB 来向节点导流。</p>\n<p>![1658046066962](k8s Service的概述、类型及代理模式/1658046066962.png)</p>\n<h1 id=\"5-ExternalName\"><a href=\"#5-ExternalName\" class=\"headerlink\" title=\"5 ExternalName\"></a>5 ExternalName</h1><p>这种类型的Service通过返回CNAME和它的值,可以将服务映射到externalName字段的内容(例如:hub.atguigu.com). ExternalName Service 是 Service的特例,它没有 selector,也没有定义任何的端口和Endpoint。相反的,对于运行在集群外部的服务,它通过返回该外部服务的别名这种方式来提供服务</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Service</span><br><span class=\"hljs-attr\">apiversion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">my-service-1</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">ExternalName</span><br>  <span class=\"hljs-attr\">externalName:</span> <span class=\"hljs-string\">www.qingyeshuijian.com</span><br></code></pre></td></tr></table></figure>\n\n<p>当查询主机 my-service-1.defalut.svc.cluster.local (SVC_NAME.NAMESPACE.svc.cluster.local )时,集群的DNS服务将返回一个值my.database.example.com的CNAME记录。访问这个服务的工作方式和其他的相同,唯一不同的是重定向发生在DNS层,而且不会进行代理或转发。</p>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-selector-attr\">[root@k8s-master01 service]</span># dig -t <span class=\"hljs-selector-tag\">A</span> my-service-<span class=\"hljs-number\">1</span><span class=\"hljs-selector-class\">.default</span><span class=\"hljs-selector-class\">.svc</span><span class=\"hljs-selector-class\">.cluster</span><span class=\"hljs-selector-class\">.local</span>. <span class=\"hljs-keyword\">@10</span>.244.0.12              <br><br>; &lt;&lt;&gt;&gt; DiG <span class=\"hljs-number\">9.11</span>.<span class=\"hljs-number\">4</span>-P2-RedHat-<span class=\"hljs-number\">9.11</span>.<span class=\"hljs-number\">4</span>-<span class=\"hljs-number\">26</span><span class=\"hljs-selector-class\">.P2</span><span class=\"hljs-selector-class\">.el7_9</span>.<span class=\"hljs-number\">9</span> &lt;&lt;&gt;&gt; -t <span class=\"hljs-selector-tag\">A</span> my-service-<span class=\"hljs-number\">1</span><span class=\"hljs-selector-class\">.default</span><span class=\"hljs-selector-class\">.svc</span><span class=\"hljs-selector-class\">.cluster</span><span class=\"hljs-selector-class\">.local</span>. <span class=\"hljs-keyword\">@10</span>.244.0.12<br>;; global options: +cmd<br>;; Got answer:<br>;; WARNING: .local is reserved for Multicast DNS<br>;; You are currently testing what happens when an mDNS query is leaked <span class=\"hljs-selector-tag\">to</span> DNS<br>;; -&gt;&gt;<span class=\"hljs-selector-tag\">HEADER</span>&lt;&lt;- opcode: QUERY, status: NOERROR, id: <span class=\"hljs-number\">3150</span><br>;; flags: qr aa rd; QUERY: <span class=\"hljs-number\">1</span>, ANSWER: <span class=\"hljs-number\">2</span>, AUTHORITY: <span class=\"hljs-number\">0</span>, ADDITIONAL: <span class=\"hljs-number\">1</span><br>;; WARNING: recursion requested but not available<br><br>;; OPT PSEUDOSECTION:<br>; EDNS: version: <span class=\"hljs-number\">0</span>, flags:; udp: <span class=\"hljs-number\">4096</span><br>;; QUESTION <span class=\"hljs-selector-tag\">SECTION</span>:<br>;my-service-<span class=\"hljs-number\">1</span><span class=\"hljs-selector-class\">.default</span><span class=\"hljs-selector-class\">.svc</span><span class=\"hljs-selector-class\">.cluster</span><span class=\"hljs-selector-class\">.local</span>.        IN <span class=\"hljs-selector-tag\">A</span><br><br>;; ANSWER <span class=\"hljs-selector-tag\">SECTION</span>:<br>my-service-<span class=\"hljs-number\">1</span>.default.svc.cluster.local. <span class=\"hljs-number\">30</span> IN CNAME www.qingyeshuijian.com.<br>www.qingyeshuijian.com. <span class=\"hljs-number\">30</span>      IN      A       <span class=\"hljs-number\">39.107</span>.<span class=\"hljs-number\">115.153</span><br><br>;; Query <span class=\"hljs-selector-tag\">time</span>: <span class=\"hljs-number\">50</span> msec<br>;; SERVER: <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.12</span>#<span class=\"hljs-number\">53</span>(<span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.12</span>)<br>;; WHEN: 一 <span class=\"hljs-number\">7</span>月 <span class=\"hljs-number\">18</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">30</span>:<span class=\"hljs-number\">32</span> CST <span class=\"hljs-number\">2022</span><br>;; MSG SIZE  rcvd: <span class=\"hljs-number\">179</span><br></code></pre></td></tr></table></figure>\n\n<p>通过上面的dig查看ExternalName找到cname指向了<a href=\"http://www.qingyeshuijian.com/\">www.qingyeshuijian.com</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、概述\"><a href=\"#一、概述\" class=\"headerlink\" title=\"一、概述\"></a>一、概述</h1><p>Kubernete Service 是一个定义了一组Pod的策略的抽象，我们也有时候叫做宏观服务。这些被服务标记的Pod都是（一般）通过label Selector决定的 。</p>\n<p>通过创建Service,可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载分发到后端的各个容器应用上。</p>\n<p>对于Kubernete原生的应用，Kubernete提供了一个简单的Endpoints API，这个Endpoints api的作用就是当一个服务中的pod发生变化时，Endpoints API随之变化，对于哪些不是原生的程序，Kubernetes提供了一个基于虚拟IP的网桥的服务，这个服务会将请求转发到对应的后台pod 。</p>\n<p>![1658045368211](k8s Service的概述、类型及代理模式/1658045368211.png)</p>\n<h1 id=\"二、代理模式\"><a href=\"#二、代理模式\" class=\"headerlink\" title=\"二、代理模式\"></a>二、代理模式</h1><p>Service能够提供负载均衡的能力,但是在使用上有以下限制:</p>\n<p>只提供4层负载均衡能力,而没有7层功能,但有时我们可能需要更多的匹配规则来转发请求,这点上4层负载均衡是不支持的</p>\n<p>VIP和Service代理：</p>\n<p>在Kubernetes 集群中,每个Node运行一个 kube-proxy进程。kube-proxy负责为Service实现了一种VIP (虚拟IP)的形式,而不是ExternalName的形式。</p>\n<ul>\n<li>在Kubernetes v1.0版本,代理完全在userspace.</li>\n<li>在Kubernetes v1.1版本,新增了 iptables 代理,但并不是默认的运行模式。</li>\n<li>从Kubemetes v1.2起,默认就是iptables代理。</li>\n<li>在Kubernetes v1.8.0-beta.0中,添加了ipvs代理</li>\n<li>在Kubernetes 1.14版本开始默认使用ipvs代理</li>\n<li>在Kubernetes v1.0版本, Service是4层概念。在Kubernetes v1.1版本，新增了  Ingress API (beta版) ,用来表示“7层（Http）服务</li>\n</ul>\n<p>为什么不用DNS?</p>\n<p>因为DNS需要在客服端保留记录，存在缓存等干扰，可能导致过期解析。</p>\n<h2 id=\"1-userspace代理模式\"><a href=\"#1-userspace代理模式\" class=\"headerlink\" title=\"1 userspace代理模式\"></a>1 userspace代理模式</h2><p>![1658044956049](k8s Service的概述、类型及代理模式/1658044956049.png)</p>\n<h2 id=\"2-iptables代理模式\"><a href=\"#2-iptables代理模式\" class=\"headerlink\" title=\"2 iptables代理模式\"></a>2 iptables代理模式</h2><p>![1658044977401](k8s Service的概述、类型及代理模式/1658044977401.png)</p>\n<h2 id=\"3-ipvs代理模式\"><a href=\"#3-ipvs代理模式\" class=\"headerlink\" title=\"3  ipvs代理模式\"></a>3  ipvs代理模式</h2><p>这种模式, kube-proxy会监视Kubernetes Service对象和Endpoints,调用netlink接口以相应地创建ipvs规则并定期与Kubernetes Service对象和Endpoints对象同步ipvs规则,以确保ipvs状态与期望一致。访问服务时,流量将被重定向到其中一个后端Pod与iptables 类似, ipvs于netfilter的hook功能,但使用哈希表作为底层数据结构并在内核空间中工作。这意味着ipvs可以更快地重定向流量,并且在同步代理规则时具有更好的性能。此外,ipvs为负载均衡算法提供了更多选项,例如:</p>\n<ul>\n<li>rr:轮询调度</li>\n<li>1c:最小连接数</li>\n<li>dh:目标哈希</li>\n<li>sh:源哈希</li>\n<li>sed:最短期望延迟</li>\n<li>nq:不排队调度</li>\n</ul>\n<p>![1658045067670](k8s Service的概述、类型及代理模式/1658045067670.png)</p>\n<h1 id=\"三、Service-的类型\"><a href=\"#三、Service-的类型\" class=\"headerlink\" title=\"三、Service 的类型\"></a>三、Service 的类型</h1><p>Service 在K8s中有以下四种类型</p>\n<ul>\n<li>Clusterlp:默认类型,自动分配一个仅Cluster内部可以访问的虚拟IP</li>\n<li>NodePort: 在ClusterIP基础上为Service在每台机器上绑定一个端口,这样就可以通过:NodePort来访问该服务</li>\n<li>LoadBalancer: 在NodePort的基础上,借助cloud provider创建一个外部负载均衡器,并将请求转发到: NodePort</li>\n<li>ExternalName:把集群外部的服务引入到集群内部来,在集群内部直接使用。没有任何类型代理被创建,这只有kubernetes 1.7或更高版本的kube-dns才支持</li>\n</ul>\n<h2 id=\"1-ClusterIP\"><a href=\"#1-ClusterIP\" class=\"headerlink\" title=\"1 ClusterIP\"></a>1 ClusterIP</h2><p>clusterIP 主要在每个 node 节点使用iptables,将发向 clusterIP 对应端口的数据,转发到kube-proxy中。然后kube-proxy 自己内部实现有负载均衡的方法,并可以查询到这个 service下对应pod的地址和端口,进而把数据转发给对应的pod的地址和端口</p>\n<p>![1658045231642](k8s Service的概述、类型及代理模式/1658045231642.png)</p>\n<p>协同工作原理:</p>\n<ul>\n<li>apiserver 用户通过kubectl命令向apiserver发送创建service的命令, apiserver接收到请求后将数据存储到etcd中</li>\n<li>kube-proxy kubernetes的每个节点中都有一个叫做kube-porxy的进程,这个进程负责感知service, pod的变化,并将变化的信息写入本地的iptables规则中</li>\n<li>iptables 使用NAT等技术将virtualIP的流量转至endpoint中</li>\n</ul>\n<p>创建myapp-deploy.yaml文件</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">apps/v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Deployment</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp-deploy</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">replicas:</span> <span class=\"hljs-number\">3</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">matchLabels:</span><br>      <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myapp</span><br>      <span class=\"hljs-attr\">release:</span> <span class=\"hljs-string\">stabel</span><br>  <span class=\"hljs-attr\">template:</span><br>    <span class=\"hljs-attr\">metadata:</span><br>      <span class=\"hljs-attr\">labels:</span><br>        <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myapp</span><br>        <span class=\"hljs-attr\">release:</span> <span class=\"hljs-string\">stabel</span><br>        <span class=\"hljs-attr\">env:</span> <span class=\"hljs-string\">test</span><br>    <span class=\"hljs-attr\">spec:</span><br>      <span class=\"hljs-attr\">containers:</span><br>      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp</span><br>        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/nginx:1.9.1</span><br>        <span class=\"hljs-attr\">imagePullPolicy:</span> <span class=\"hljs-string\">IfNotPresent</span><br>        <span class=\"hljs-attr\">ports:</span><br>        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">http</span><br>          <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n<p>创建Service信息，myapp-service.yaml</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Service</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">ClusterIP</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myapp</span><br>    <span class=\"hljs-attr\">release:</span> <span class=\"hljs-string\">stabel</span><br>  <span class=\"hljs-attr\">ports:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">http</span><br>    <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br>    <span class=\"hljs-attr\">targetPort:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"2-Headless-Service\"><a href=\"#2-Headless-Service\" class=\"headerlink\" title=\"2 Headless Service\"></a>2 Headless Service</h2><p>有时不需要或不想要负载均衡,以及单独的Service IP.遇到这种情况,可以通过指定ClusterIP(spec.clusterIP) 的值为”None”来创建Headless Service。这类Service并不会分配Cluster IP，kube-proxy不会处理它们,而且平台也不会为它们进行负载均衡和路由。</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">[root@k8s-<span class=\"hljs-keyword\">master</span> <span class=\"hljs-title\">mainfests</span>]<span class=\"hljs-comment\"># vim myapp-svc-headless.yaml</span><br></code></pre></td></tr></table></figure>\n\n<p>myapp-svc-headless.yaml</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Service</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp-headless</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myapp</span><br>  <span class=\"hljs-attr\">clusterIP:</span> <span class=\"hljs-string\">&quot;None&quot;</span><br>  <span class=\"hljs-attr\">ports:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br>    <span class=\"hljs-attr\">targetPort:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight mel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mel\">[root@k8s-master01 service]# yum install -y  bind-utils<br>[root@k8s-master01 service]# dig -t A myapp-headless.<span class=\"hljs-keyword\">default</span>.svc.<span class=\"hljs-keyword\">cluster</span>.local. @10<span class=\"hljs-number\">.244</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.12</span><br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-selector-attr\">[root@k8s-master01 service]</span># kubectl get pod -n kube-system -o wide<br>NAME                                   READY   STATUS    RESTARTS        AGE     IP                    NODE           NOMINATED NODE   READINESS GATES<br>coredns-<span class=\"hljs-number\">7</span>f6cbbb7b8-pbv77               <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">4</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">5</span>d20h   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.13</span>           k8s-master01   &lt;<span class=\"hljs-attribute\">none</span>&gt;           &lt;<span class=\"hljs-attribute\">none</span>&gt;<br>coredns-<span class=\"hljs-number\">7</span>f6cbbb7b8-qxw99               <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">4</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">5</span>d20h   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.12</span>           k8s-master01   &lt;<span class=\"hljs-attribute\">none</span>&gt;           &lt;<span class=\"hljs-attribute\">none</span>&gt;<br>etcd-k8s-master01                      <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">7</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">5</span>d20h   <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.10</span>             k8s-master01   &lt;<span class=\"hljs-attribute\">none</span>&gt;           &lt;<span class=\"hljs-attribute\">none</span>&gt;<br>kube-apiserver-k8s-master01            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">7</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">5</span>d20h   <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.10</span>             k8s-master01   &lt;<span class=\"hljs-attribute\">none</span>&gt;           &lt;<span class=\"hljs-attribute\">none</span>&gt;<br>kube-controller-manager-k8s-master01   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">9</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">5</span>d20h   <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.10</span>             k8s-master01   &lt;<span class=\"hljs-attribute\">none</span>&gt;           &lt;<span class=\"hljs-attribute\">none</span>&gt;<br>kube-proxy-ml24c                       <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">3</span>d22h   fd56:a9ae:cb0f::<span class=\"hljs-number\">7</span>a1   k8s-node01     &lt;none&gt;           &lt;none&gt;<br>kube-proxy-mrbsk                       <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">4</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">3</span>d22h   <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.10</span>             k8s-master01   &lt;none&gt;           &lt;none&gt;<br>kube-proxy-tkszd                       <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">2</span> (<span class=\"hljs-number\">22</span>h ago)     <span class=\"hljs-number\">3</span>d22h   fd56:a9ae:cb0f::<span class=\"hljs-number\">853</span>   k8s-node02     &lt;none&gt;           &lt;none&gt;<br>kube-scheduler-k8s-master01            <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">8</span> (<span class=\"hljs-number\">2</span>d20h ago)   <span class=\"hljs-number\">5</span>d20h   <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.10</span>             k8s-master01   &lt;none&gt;           &lt;none&gt;<br>[root@k8s-master01 service]# dig -t A myapp-headless.default.svc.cluster.local. @<span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.12</span><br><br>; &lt;&lt;&gt;&gt; DiG <span class=\"hljs-number\">9.11</span>.<span class=\"hljs-number\">4</span>-P2-RedHat-<span class=\"hljs-number\">9.11</span>.<span class=\"hljs-number\">4</span>-<span class=\"hljs-number\">26</span><span class=\"hljs-selector-class\">.P2</span><span class=\"hljs-selector-class\">.el7_9</span>.<span class=\"hljs-number\">9</span> &lt;&lt;&gt;&gt; -t <span class=\"hljs-selector-tag\">A</span> myapp-headless<span class=\"hljs-selector-class\">.default</span><span class=\"hljs-selector-class\">.svc</span><span class=\"hljs-selector-class\">.cluster</span><span class=\"hljs-selector-class\">.local</span>. <span class=\"hljs-keyword\">@10</span>.244.0.12<br>;; global options: +cmd<br>;; Got answer:<br>;; WARNING: .local is reserved for Multicast DNS<br>;; You are currently testing what happens when an mDNS query is leaked <span class=\"hljs-selector-tag\">to</span> DNS<br>;; -&gt;&gt;<span class=\"hljs-selector-tag\">HEADER</span>&lt;&lt;- opcode: QUERY, status: NOERROR, id: <span class=\"hljs-number\">14989</span><br>;; flags: qr aa rd; QUERY: <span class=\"hljs-number\">1</span>, ANSWER: <span class=\"hljs-number\">3</span>, AUTHORITY: <span class=\"hljs-number\">0</span>, ADDITIONAL: <span class=\"hljs-number\">1</span><br>;; WARNING: recursion requested but not available<br><br>;; OPT PSEUDOSECTION:<br>; EDNS: version: <span class=\"hljs-number\">0</span>, flags:; udp: <span class=\"hljs-number\">4096</span><br>;; QUESTION <span class=\"hljs-selector-tag\">SECTION</span>:<br>;myapp-headless<span class=\"hljs-selector-class\">.default</span><span class=\"hljs-selector-class\">.svc</span><span class=\"hljs-selector-class\">.cluster</span><span class=\"hljs-selector-class\">.local</span>. IN <span class=\"hljs-selector-tag\">A</span><br><br>;; ANSWER <span class=\"hljs-selector-tag\">SECTION</span>:<br>myapp-headless.default.svc.cluster.local. <span class=\"hljs-number\">30</span> IN A <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">2.109</span><br>myapp-headless.default.svc.cluster.local. <span class=\"hljs-number\">30</span> IN A <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">1.165</span><br>myapp-headless.default.svc.cluster.local. <span class=\"hljs-number\">30</span> IN A <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">2.108</span><br><br>;; Query <span class=\"hljs-selector-tag\">time</span>: <span class=\"hljs-number\">2</span> msec<br>;; SERVER: <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.12</span>#<span class=\"hljs-number\">53</span>(<span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.12</span>)<br>;; WHEN: 一 <span class=\"hljs-number\">7</span>月 <span class=\"hljs-number\">18</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">52</span> CST <span class=\"hljs-number\">2022</span><br>;; MSG SIZE  rcvd: <span class=\"hljs-number\">237</span><br><br>[root@k8s-master01 service]# kubectl get pod -o wide<br>NAME                            READY   STATUS    RESTARTS   AGE     IP             NODE         NOMINATED NODE   READINESS GATES<br>myapp-deploy-<span class=\"hljs-number\">85</span>bb565996-<span class=\"hljs-number\">2</span>tvcg   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">2</span>m20s   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">2.108</span>   k8s-node02   &lt;none&gt;           &lt;none&gt;<br>myapp-deploy-<span class=\"hljs-number\">85</span>bb565996-dgzgz   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">2</span>m20s   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">2.109</span>   k8s-node02   &lt;none&gt;           &lt;none&gt;<br>myapp-deploy-<span class=\"hljs-number\">85</span>bb565996-mlnh8   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">2</span>m20s   <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">1.165</span>   k8s-node01   &lt;none&gt;           &lt;none&gt;<br></code></pre></td></tr></table></figure>\n\n<p>通过Headless Service一样可以访问到对应的pod上去</p>\n<h2 id=\"3-NodePort\"><a href=\"#3-NodePort\" class=\"headerlink\" title=\"3 NodePort\"></a>3 NodePort</h2><p>nodePort 的原理在于在node上开了一个端口,将向该端口的流量导入到kube-proxy,然后由kube-proxy进一步到给对应的pod</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">[root@<span class=\"hljs-keyword\">master</span> <span class=\"hljs-title\">manifests</span>]<span class=\"hljs-comment\"># vi myapp-np-service.yaml</span><br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Service</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">NodePort</span><br>  <span class=\"hljs-attr\">selector:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myapp</span><br>    <span class=\"hljs-attr\">release:</span> <span class=\"hljs-string\">stabel</span><br>  <span class=\"hljs-attr\">ports:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">http</span><br>    <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br>    <span class=\"hljs-attr\">targetPort:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n<p>查看结果</p>\n<figure class=\"highlight gherkin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gherkin\"><span class=\"hljs-comment\"># 查看service服务暴露端口</span><br>[root<span class=\"hljs-meta\">@k8s-master01</span> service]<span class=\"hljs-comment\"># kubectl get svc -o wide</span><br>NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE     SELECTOR<br>kubernetes   ClusterIP   10.96.0.1       <span class=\"hljs-variable\">&lt;none&gt;</span>        443/TCP        5d20h   <span class=\"hljs-variable\">&lt;none&gt;</span><br>myapp        NodePort    10.98.226.253   <span class=\"hljs-variable\">&lt;none&gt;</span>        80:30247/TCP   17s     app=myapp,release=stabel<br><span class=\"hljs-comment\">#查看myapp分布在哪些节点</span><br>[root<span class=\"hljs-meta\">@k8s-master01</span> service]<span class=\"hljs-comment\"># kubectl get pod -o wide</span><br>NAME                            READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES<br>myapp-deploy-85bb565996-dcgzh   1/1     Running   0          54s   10.244.1.167   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>myapp-deploy-85bb565996-snpfg   1/1     Running   0          54s   10.244.1.166   k8s-node01   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br>myapp-deploy-85bb565996-xv2q4   1/1     Running   0          54s   10.244.2.110   k8s-node02   <span class=\"hljs-variable\">&lt;none&gt;</span>           <span class=\"hljs-variable\">&lt;none&gt;</span><br><span class=\"hljs-comment\">#查看所有节点的信息</span><br>[root<span class=\"hljs-meta\">@k8s-master01</span> service]<span class=\"hljs-comment\"># kubectl get node -o wide           </span><br>NAME           STATUS   ROLES                  AGE     VERSION   INTERNAL-IP           EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME<br>k8s-master01   Ready    control-plane,master   5d20h   v1.22.0   10.0.0.10             <span class=\"hljs-variable\">&lt;none&gt;</span>        CentOS Linux 7 (Core)   3.10.0-1160.71.1.el7.x86_64   docker://18.6.1<br>k8s-node01     Ready    <span class=\"hljs-variable\">&lt;none&gt;</span>                 4d22h   v1.22.0   10.0.0.21             <span class=\"hljs-variable\">&lt;none&gt;</span>        CentOS Linux 7 (Core)   3.10.0-1160.71.1.el7.x86_64   docker://18.6.1<br>k8s-node02     Ready    <span class=\"hljs-variable\">&lt;none&gt;</span>                 4d22h   v1.22.0   10.0.0.22             <span class=\"hljs-variable\">&lt;none&gt;</span>        CentOS Linux 7 (Core)   3.10.0-1160.71.1.el7.x86_64   docker://18.6.1<br></code></pre></td></tr></table></figure>\n\n<p>通过访问10.0.0.10:30247,10.0.0.21:30247,10.0.0.22:30247都可以得到：</p>\n<p>![1658064476544](k8s Service的概述、类型及代理模式.assets/1658064476544.png)</p>\n<p>查询流程</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">[root@k8s-master01 service]<span class=\"hljs-comment\"># iptables -t nat -nvL KUBE-NODEPORTS</span><br>Chain KUBE-NODEPORTS (<span class=\"hljs-number\">0</span> references)<br> pkts bytes target     prot opt <span class=\"hljs-keyword\">in</span>     out     source               destination         <br>    <span class=\"hljs-number\">0</span>     <span class=\"hljs-number\">0</span> KUBE-SVC-<span class=\"hljs-number\">2</span>CMXP7HKUVJN7L6M  tcp  --  *      *       <span class=\"hljs-number\">0.0</span>.<span class=\"hljs-number\">0.0</span><span class=\"hljs-regexp\">/0            0.0.0.0/</span><span class=\"hljs-number\">0</span>            <span class=\"hljs-regexp\">/* default/</span>nginx */ tcp dpt:<span class=\"hljs-number\">30029</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"4-LoadBalancer\"><a href=\"#4-LoadBalancer\" class=\"headerlink\" title=\"4 LoadBalancer\"></a>4 LoadBalancer</h2><p>loadBalancer 和 nodePort其实是同一种方式,区别在于loadBalancer 比 nodePort多了一步,就是可以调用cloud provider 去创建 LB 来向节点导流。</p>\n<p>![1658046066962](k8s Service的概述、类型及代理模式/1658046066962.png)</p>\n<h1 id=\"5-ExternalName\"><a href=\"#5-ExternalName\" class=\"headerlink\" title=\"5 ExternalName\"></a>5 ExternalName</h1><p>这种类型的Service通过返回CNAME和它的值,可以将服务映射到externalName字段的内容(例如:hub.atguigu.com). ExternalName Service 是 Service的特例,它没有 selector,也没有定义任何的端口和Endpoint。相反的,对于运行在集群外部的服务,它通过返回该外部服务的别名这种方式来提供服务</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Service</span><br><span class=\"hljs-attr\">apiversion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">my-service-1</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">type:</span> <span class=\"hljs-string\">ExternalName</span><br>  <span class=\"hljs-attr\">externalName:</span> <span class=\"hljs-string\">www.qingyeshuijian.com</span><br></code></pre></td></tr></table></figure>\n\n<p>当查询主机 my-service-1.defalut.svc.cluster.local (SVC_NAME.NAMESPACE.svc.cluster.local )时,集群的DNS服务将返回一个值my.database.example.com的CNAME记录。访问这个服务的工作方式和其他的相同,唯一不同的是重定向发生在DNS层,而且不会进行代理或转发。</p>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-selector-attr\">[root@k8s-master01 service]</span># dig -t <span class=\"hljs-selector-tag\">A</span> my-service-<span class=\"hljs-number\">1</span><span class=\"hljs-selector-class\">.default</span><span class=\"hljs-selector-class\">.svc</span><span class=\"hljs-selector-class\">.cluster</span><span class=\"hljs-selector-class\">.local</span>. <span class=\"hljs-keyword\">@10</span>.244.0.12              <br><br>; &lt;&lt;&gt;&gt; DiG <span class=\"hljs-number\">9.11</span>.<span class=\"hljs-number\">4</span>-P2-RedHat-<span class=\"hljs-number\">9.11</span>.<span class=\"hljs-number\">4</span>-<span class=\"hljs-number\">26</span><span class=\"hljs-selector-class\">.P2</span><span class=\"hljs-selector-class\">.el7_9</span>.<span class=\"hljs-number\">9</span> &lt;&lt;&gt;&gt; -t <span class=\"hljs-selector-tag\">A</span> my-service-<span class=\"hljs-number\">1</span><span class=\"hljs-selector-class\">.default</span><span class=\"hljs-selector-class\">.svc</span><span class=\"hljs-selector-class\">.cluster</span><span class=\"hljs-selector-class\">.local</span>. <span class=\"hljs-keyword\">@10</span>.244.0.12<br>;; global options: +cmd<br>;; Got answer:<br>;; WARNING: .local is reserved for Multicast DNS<br>;; You are currently testing what happens when an mDNS query is leaked <span class=\"hljs-selector-tag\">to</span> DNS<br>;; -&gt;&gt;<span class=\"hljs-selector-tag\">HEADER</span>&lt;&lt;- opcode: QUERY, status: NOERROR, id: <span class=\"hljs-number\">3150</span><br>;; flags: qr aa rd; QUERY: <span class=\"hljs-number\">1</span>, ANSWER: <span class=\"hljs-number\">2</span>, AUTHORITY: <span class=\"hljs-number\">0</span>, ADDITIONAL: <span class=\"hljs-number\">1</span><br>;; WARNING: recursion requested but not available<br><br>;; OPT PSEUDOSECTION:<br>; EDNS: version: <span class=\"hljs-number\">0</span>, flags:; udp: <span class=\"hljs-number\">4096</span><br>;; QUESTION <span class=\"hljs-selector-tag\">SECTION</span>:<br>;my-service-<span class=\"hljs-number\">1</span><span class=\"hljs-selector-class\">.default</span><span class=\"hljs-selector-class\">.svc</span><span class=\"hljs-selector-class\">.cluster</span><span class=\"hljs-selector-class\">.local</span>.        IN <span class=\"hljs-selector-tag\">A</span><br><br>;; ANSWER <span class=\"hljs-selector-tag\">SECTION</span>:<br>my-service-<span class=\"hljs-number\">1</span>.default.svc.cluster.local. <span class=\"hljs-number\">30</span> IN CNAME www.qingyeshuijian.com.<br>www.qingyeshuijian.com. <span class=\"hljs-number\">30</span>      IN      A       <span class=\"hljs-number\">39.107</span>.<span class=\"hljs-number\">115.153</span><br><br>;; Query <span class=\"hljs-selector-tag\">time</span>: <span class=\"hljs-number\">50</span> msec<br>;; SERVER: <span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.12</span>#<span class=\"hljs-number\">53</span>(<span class=\"hljs-number\">10.244</span>.<span class=\"hljs-number\">0.12</span>)<br>;; WHEN: 一 <span class=\"hljs-number\">7</span>月 <span class=\"hljs-number\">18</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">30</span>:<span class=\"hljs-number\">32</span> CST <span class=\"hljs-number\">2022</span><br>;; MSG SIZE  rcvd: <span class=\"hljs-number\">179</span><br></code></pre></td></tr></table></figure>\n\n<p>通过上面的dig查看ExternalName找到cname指向了<a href=\"http://www.qingyeshuijian.com/\">www.qingyeshuijian.com</a></p>\n"},{"title":"k8s pod生命周期","date":"2021-08-06T14:32:02.000Z","_content":"\n# k8s pod生命周期—Init容器\n\n# pod生命周期\n\n![1657944206659](k8s pod生命周期/1657944206659.png)\n\nPod能够具有多个容器,应用运行在容器里面,但是它也可能有一个或多个先于应用容器启动的Init容器。\n\nInit容器与普通的容器非常像,除了如下两点:\n\n- Init 容器总是运行到成功完成为止\n- 每个Init容器都必须在下一个Init容器启动之前成功完成\n\n如果Pod的Init容器失败, Kubernetes会不断地重启该Pod,直到Init容器成功为止。然而,如果Pod对应的restartPolicy 为Never,它不会重新启动。\n\n**因为Init容器具有与应用程序容器分离的单独镜像,所以它们的启动相关代码具有如下优势:**\n\n- 它们可以包含并运行实用工具,但是出于安全考虑,是不建议在应用程序容器镜像中包含这些实用工具的。\n- 它们可以包含使用工具和定制化代码来安装,但是不能出现在应用程序镜像中。例如,创建镜像没必要FROM另一个镜像,只需要在安装过程中使用类似sed、 awk、 python或dig这样的工具。\n- 应用程序镜像可以分离出创建和部署的角色,而没有必要联合它们构建一个单独的镜像。\n- Init 容器使用Linux Namespace,所以相对应用程序容器来说具有不同的文件系统视图。因此,它们能够具有访问Secret的权限,而应用程序容器则不能。\n- 它们必须在应用程序容器启动之前运行完成,而应用程序容器是并行运行的,所以Init容器能够提供了一种简单的阻塞或延迟应用容器的启动的方法,直到满足了一组先决条件。\n\n在Pod启动过程中,Init容器会按顺序在网络和数据卷初始化之后启动。每个容器必须在下一个容器启动之前成功退出。\n\n如果由于运行时或失败退出,将导致容器启动失败,它会根据Pod的restartPolicy指定的策略进行重试。然而,如果Pod的restartPolicy设置为Always, Init容器失败时会使用RestartPolicy策略。\n\n在所有的Init容器没有成功之前, Pod将不会变成Ready状态。Init容器的端口将不会在Service 中进行聚集。正在初始化中的Pod处于Pending状态,但应该会将Initializing状态设置为true。\n\n如果Pod重启,所有Init容器必须重新执行。\n\n对Init容器spec的修改被限制在容器image字段,修改其他字段都不会生效。更改Init容器的image字段,等价于重启该Pod。(kubectl edit pod myapp-pod)\n\nInit容器具有应用容器的所有字段。除了readinessProbe，因为Init容器无法定义不同于完成(completion)的就绪(readiness)之外的其他状态。这会在验证过程中强制执行。\n\n在Pod中的每个app和Init容器的名称必须唯一；与任何其它容器共享同一个名称,会在验证时抛出错误。\n\n# Init容器\n\nInit模板\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    app: myapp\nspec:\n  containers:\n  - name: myapp-container\n    image: busybox\n    command: ['sh', '-c', 'echo The app is running! && sleep 3600']\n  initContainers:\n  - name: init-myservice\n    image: busybox\n    command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2;done;']\n  - name: init-mydb\n    image: busybox\n    command: ['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done; ']\n```\n\nmyservice模板\n\n```yaml\nkind: Service\napiVersion: v1\nmetadata:\n  name: myservice\nspec:\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 9376\n```\n\nmydb模板\n\n```yaml\nkind: Service\napiVersion: v1\nmetadata:\n  name: mydb\nspec:\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 9377\n```\n\n# Init容器操作查看\n\n## 第一步：之创建init状态检测pod\n\n通过init容器模板创建pod\n\n```\n# 先生成init配置清单\n[root@k8s-master01 init-container]# vi init.yaml\n# 通过init.yaml创建pod\n[root@k8s-master01 init-container]# kubectl create -f  init.yaml\n# 查看pod的状态\n[root@k8s-master01 init-container]# kubectl get pod\nNAME        READY   STATUS     RESTARTS   AGE\nmyapp-pod   0/1     Init:0/2   0          3m8s\n```\n\n查看myapp-pod的启动日志\n\n```\n[root@k8s-master01 init-container]# kubectl describe pod myapp-pod\nName:         myapp-pod\nNamespace:    default\nPriority:     0\nNode:         k8s-node02/fd56:a9ae:cb0f::853\nStart Time:   Sat, 16 Jul 2022 20:56:13 +0800\nLabels:       app=myapp\nAnnotations:  <none>\nStatus:       Pending\nIP:           10.244.2.4\nIPs:\n  IP:  10.244.2.4\nInit Containers:\n  init-myservice:\n    Container ID:  docker://b4e6898bf71991f1571f0750d7ed58f54aeb511ca175b9dcafbbdf457aac3971\n    Image:         busybox\n    Image ID:      docker-pullable://busybox@sha256:5acba83a746c7608ed544dc1533b87c737a0b0fb730301639a0179f9344b1678\n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sh\n      -c\n      until nslookup myservice; do echo waiting for myservice; sleep 2;done;\n    State:          Running\n      Started:      Sat, 16 Jul 2022 20:56:33 +0800\n    Ready:          False\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-4vx22 (ro)\n  init-mydb:\n    Container ID:  \n    Image:         busybox\n    Image ID:      \n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sh\n      -c\n      until nslookup mydb; do echo waiting for mydb; sleep 2; done; \n    State:          Waiting\n      Reason:       PodInitializing\n    Ready:          False\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-4vx22 (ro)\nContainers:\n  myapp-container:\n    Container ID:  \n    Image:         busybox\n    Image ID:      \n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sh\n      -c\n      echo The app is running! && sleep 3600\n    State:          Waiting\n      Reason:       PodInitializing\n    Ready:          False\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-4vx22 (ro)\nConditions:\n  Type              Status\n  Initialized       False \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  kube-api-access-4vx22:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age    From               Message\n  ----    ------     ----   ----               -------\n  Normal  Scheduled  4m6s   default-scheduler  Successfully assigned default/myapp-pod to k8s-node02\n  Normal  Pulling    2m34s  kubelet            Pulling image \"busybox\"\n  Normal  Pulled     2m16s  kubelet            Successfully pulled image \"busybox\" in 17.673975295s\n  Normal  Created    2m16s  kubelet            Created container init-myservice\n  Normal  Started    2m16s  kubelet            Started container init-myservice\n```\n\n查看日志\n\n```\n[root@k8s-master01 init-container]# kubectl logs myapp-pod -c  init-myservice\nwaiting for myservice\nServer:         10.96.0.10\nAddress:        10.96.0.10:53\n\n** server can't find myservice.default.svc.cluster.local: NXDOMAIN\n\n*** Can't find myservice.svc.cluster.local: No answer\n*** Can't find myservice.cluster.local: No answer\n*** Can't find myservice.default.svc.cluster.local: No answer\n*** Can't find myservice.svc.cluster.local: No answer\n*** Can't find myservice.cluster.local: No answer\n```\n\n## 第二步：创建myservice\n\n通过myservice模板创建svc\n\n```\nvi myservice.yaml\nkubectl create -f myservice.yaml\n```\n\n查看pod状态，可以看出status中的显示变成了Init:1/2,说明检测状态中，有一个service已经成功启动。\n\n```\n[root@k8s-master01 init-container]# kubectl get pod\nNAME        READY   STATUS     RESTARTS   AGE\nmyapp-pod   0/1     Init:1/2   0          16m\n```\n\n## 第三步：创建mydb\n\n通过myservice模板创建svc\n\n```\nvi mydb.yaml\nkubectl create -f mydb.yaml\n```\n\n查看pod状态，可以看出READY显示为1/1,status中的显示变成了Running,说明检测状态中，已经成功启动。\n\n```\n[root@k8s-master01 init-container]# kubectl get pod\nNAME        READY   STATUS    RESTARTS   AGE\nmyapp-pod   1/1     Running   0          22m\n```\n\n\n\n\n\n\n\n","source":"_posts/k8s pod生命周期.md","raw":"---\ntitle: k8s pod生命周期\ndate: 2021-08-06 22:32:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - pod\n---\n\n# k8s pod生命周期—Init容器\n\n# pod生命周期\n\n![1657944206659](k8s pod生命周期/1657944206659.png)\n\nPod能够具有多个容器,应用运行在容器里面,但是它也可能有一个或多个先于应用容器启动的Init容器。\n\nInit容器与普通的容器非常像,除了如下两点:\n\n- Init 容器总是运行到成功完成为止\n- 每个Init容器都必须在下一个Init容器启动之前成功完成\n\n如果Pod的Init容器失败, Kubernetes会不断地重启该Pod,直到Init容器成功为止。然而,如果Pod对应的restartPolicy 为Never,它不会重新启动。\n\n**因为Init容器具有与应用程序容器分离的单独镜像,所以它们的启动相关代码具有如下优势:**\n\n- 它们可以包含并运行实用工具,但是出于安全考虑,是不建议在应用程序容器镜像中包含这些实用工具的。\n- 它们可以包含使用工具和定制化代码来安装,但是不能出现在应用程序镜像中。例如,创建镜像没必要FROM另一个镜像,只需要在安装过程中使用类似sed、 awk、 python或dig这样的工具。\n- 应用程序镜像可以分离出创建和部署的角色,而没有必要联合它们构建一个单独的镜像。\n- Init 容器使用Linux Namespace,所以相对应用程序容器来说具有不同的文件系统视图。因此,它们能够具有访问Secret的权限,而应用程序容器则不能。\n- 它们必须在应用程序容器启动之前运行完成,而应用程序容器是并行运行的,所以Init容器能够提供了一种简单的阻塞或延迟应用容器的启动的方法,直到满足了一组先决条件。\n\n在Pod启动过程中,Init容器会按顺序在网络和数据卷初始化之后启动。每个容器必须在下一个容器启动之前成功退出。\n\n如果由于运行时或失败退出,将导致容器启动失败,它会根据Pod的restartPolicy指定的策略进行重试。然而,如果Pod的restartPolicy设置为Always, Init容器失败时会使用RestartPolicy策略。\n\n在所有的Init容器没有成功之前, Pod将不会变成Ready状态。Init容器的端口将不会在Service 中进行聚集。正在初始化中的Pod处于Pending状态,但应该会将Initializing状态设置为true。\n\n如果Pod重启,所有Init容器必须重新执行。\n\n对Init容器spec的修改被限制在容器image字段,修改其他字段都不会生效。更改Init容器的image字段,等价于重启该Pod。(kubectl edit pod myapp-pod)\n\nInit容器具有应用容器的所有字段。除了readinessProbe，因为Init容器无法定义不同于完成(completion)的就绪(readiness)之外的其他状态。这会在验证过程中强制执行。\n\n在Pod中的每个app和Init容器的名称必须唯一；与任何其它容器共享同一个名称,会在验证时抛出错误。\n\n# Init容器\n\nInit模板\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    app: myapp\nspec:\n  containers:\n  - name: myapp-container\n    image: busybox\n    command: ['sh', '-c', 'echo The app is running! && sleep 3600']\n  initContainers:\n  - name: init-myservice\n    image: busybox\n    command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2;done;']\n  - name: init-mydb\n    image: busybox\n    command: ['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done; ']\n```\n\nmyservice模板\n\n```yaml\nkind: Service\napiVersion: v1\nmetadata:\n  name: myservice\nspec:\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 9376\n```\n\nmydb模板\n\n```yaml\nkind: Service\napiVersion: v1\nmetadata:\n  name: mydb\nspec:\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 9377\n```\n\n# Init容器操作查看\n\n## 第一步：之创建init状态检测pod\n\n通过init容器模板创建pod\n\n```\n# 先生成init配置清单\n[root@k8s-master01 init-container]# vi init.yaml\n# 通过init.yaml创建pod\n[root@k8s-master01 init-container]# kubectl create -f  init.yaml\n# 查看pod的状态\n[root@k8s-master01 init-container]# kubectl get pod\nNAME        READY   STATUS     RESTARTS   AGE\nmyapp-pod   0/1     Init:0/2   0          3m8s\n```\n\n查看myapp-pod的启动日志\n\n```\n[root@k8s-master01 init-container]# kubectl describe pod myapp-pod\nName:         myapp-pod\nNamespace:    default\nPriority:     0\nNode:         k8s-node02/fd56:a9ae:cb0f::853\nStart Time:   Sat, 16 Jul 2022 20:56:13 +0800\nLabels:       app=myapp\nAnnotations:  <none>\nStatus:       Pending\nIP:           10.244.2.4\nIPs:\n  IP:  10.244.2.4\nInit Containers:\n  init-myservice:\n    Container ID:  docker://b4e6898bf71991f1571f0750d7ed58f54aeb511ca175b9dcafbbdf457aac3971\n    Image:         busybox\n    Image ID:      docker-pullable://busybox@sha256:5acba83a746c7608ed544dc1533b87c737a0b0fb730301639a0179f9344b1678\n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sh\n      -c\n      until nslookup myservice; do echo waiting for myservice; sleep 2;done;\n    State:          Running\n      Started:      Sat, 16 Jul 2022 20:56:33 +0800\n    Ready:          False\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-4vx22 (ro)\n  init-mydb:\n    Container ID:  \n    Image:         busybox\n    Image ID:      \n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sh\n      -c\n      until nslookup mydb; do echo waiting for mydb; sleep 2; done; \n    State:          Waiting\n      Reason:       PodInitializing\n    Ready:          False\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-4vx22 (ro)\nContainers:\n  myapp-container:\n    Container ID:  \n    Image:         busybox\n    Image ID:      \n    Port:          <none>\n    Host Port:     <none>\n    Command:\n      sh\n      -c\n      echo The app is running! && sleep 3600\n    State:          Waiting\n      Reason:       PodInitializing\n    Ready:          False\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-4vx22 (ro)\nConditions:\n  Type              Status\n  Initialized       False \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  kube-api-access-4vx22:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age    From               Message\n  ----    ------     ----   ----               -------\n  Normal  Scheduled  4m6s   default-scheduler  Successfully assigned default/myapp-pod to k8s-node02\n  Normal  Pulling    2m34s  kubelet            Pulling image \"busybox\"\n  Normal  Pulled     2m16s  kubelet            Successfully pulled image \"busybox\" in 17.673975295s\n  Normal  Created    2m16s  kubelet            Created container init-myservice\n  Normal  Started    2m16s  kubelet            Started container init-myservice\n```\n\n查看日志\n\n```\n[root@k8s-master01 init-container]# kubectl logs myapp-pod -c  init-myservice\nwaiting for myservice\nServer:         10.96.0.10\nAddress:        10.96.0.10:53\n\n** server can't find myservice.default.svc.cluster.local: NXDOMAIN\n\n*** Can't find myservice.svc.cluster.local: No answer\n*** Can't find myservice.cluster.local: No answer\n*** Can't find myservice.default.svc.cluster.local: No answer\n*** Can't find myservice.svc.cluster.local: No answer\n*** Can't find myservice.cluster.local: No answer\n```\n\n## 第二步：创建myservice\n\n通过myservice模板创建svc\n\n```\nvi myservice.yaml\nkubectl create -f myservice.yaml\n```\n\n查看pod状态，可以看出status中的显示变成了Init:1/2,说明检测状态中，有一个service已经成功启动。\n\n```\n[root@k8s-master01 init-container]# kubectl get pod\nNAME        READY   STATUS     RESTARTS   AGE\nmyapp-pod   0/1     Init:1/2   0          16m\n```\n\n## 第三步：创建mydb\n\n通过myservice模板创建svc\n\n```\nvi mydb.yaml\nkubectl create -f mydb.yaml\n```\n\n查看pod状态，可以看出READY显示为1/1,status中的显示变成了Running,说明检测状态中，已经成功启动。\n\n```\n[root@k8s-master01 init-container]# kubectl get pod\nNAME        READY   STATUS    RESTARTS   AGE\nmyapp-pod   1/1     Running   0          22m\n```\n\n\n\n\n\n\n\n","slug":"k8s pod生命周期","published":1,"updated":"2022-09-23T17:34:02.881Z","_id":"cl8erfec50000w8vjf909hlpz","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"k8s-pod生命周期—Init容器\"><a href=\"#k8s-pod生命周期—Init容器\" class=\"headerlink\" title=\"k8s pod生命周期—Init容器\"></a>k8s pod生命周期—Init容器</h1><h1 id=\"pod生命周期\"><a href=\"#pod生命周期\" class=\"headerlink\" title=\"pod生命周期\"></a>pod生命周期</h1><p>![1657944206659](k8s pod生命周期/1657944206659.png)</p>\n<p>Pod能够具有多个容器,应用运行在容器里面,但是它也可能有一个或多个先于应用容器启动的Init容器。</p>\n<p>Init容器与普通的容器非常像,除了如下两点:</p>\n<ul>\n<li>Init 容器总是运行到成功完成为止</li>\n<li>每个Init容器都必须在下一个Init容器启动之前成功完成</li>\n</ul>\n<p>如果Pod的Init容器失败, Kubernetes会不断地重启该Pod,直到Init容器成功为止。然而,如果Pod对应的restartPolicy 为Never,它不会重新启动。</p>\n<p><strong>因为Init容器具有与应用程序容器分离的单独镜像,所以它们的启动相关代码具有如下优势:</strong></p>\n<ul>\n<li>它们可以包含并运行实用工具,但是出于安全考虑,是不建议在应用程序容器镜像中包含这些实用工具的。</li>\n<li>它们可以包含使用工具和定制化代码来安装,但是不能出现在应用程序镜像中。例如,创建镜像没必要FROM另一个镜像,只需要在安装过程中使用类似sed、 awk、 python或dig这样的工具。</li>\n<li>应用程序镜像可以分离出创建和部署的角色,而没有必要联合它们构建一个单独的镜像。</li>\n<li>Init 容器使用Linux Namespace,所以相对应用程序容器来说具有不同的文件系统视图。因此,它们能够具有访问Secret的权限,而应用程序容器则不能。</li>\n<li>它们必须在应用程序容器启动之前运行完成,而应用程序容器是并行运行的,所以Init容器能够提供了一种简单的阻塞或延迟应用容器的启动的方法,直到满足了一组先决条件。</li>\n</ul>\n<p>在Pod启动过程中,Init容器会按顺序在网络和数据卷初始化之后启动。每个容器必须在下一个容器启动之前成功退出。</p>\n<p>如果由于运行时或失败退出,将导致容器启动失败,它会根据Pod的restartPolicy指定的策略进行重试。然而,如果Pod的restartPolicy设置为Always, Init容器失败时会使用RestartPolicy策略。</p>\n<p>在所有的Init容器没有成功之前, Pod将不会变成Ready状态。Init容器的端口将不会在Service 中进行聚集。正在初始化中的Pod处于Pending状态,但应该会将Initializing状态设置为true。</p>\n<p>如果Pod重启,所有Init容器必须重新执行。</p>\n<p>对Init容器spec的修改被限制在容器image字段,修改其他字段都不会生效。更改Init容器的image字段,等价于重启该Pod。(kubectl edit pod myapp-pod)</p>\n<p>Init容器具有应用容器的所有字段。除了readinessProbe，因为Init容器无法定义不同于完成(completion)的就绪(readiness)之外的其他状态。这会在验证过程中强制执行。</p>\n<p>在Pod中的每个app和Init容器的名称必须唯一；与任何其它容器共享同一个名称,会在验证时抛出错误。</p>\n<h1 id=\"Init容器\"><a href=\"#Init容器\" class=\"headerlink\" title=\"Init容器\"></a>Init容器</h1><p>Init模板</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp-pod</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myapp</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp-container</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">busybox</span><br>    <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&#x27;sh&#x27;</span>, <span class=\"hljs-string\">&#x27;-c&#x27;</span>, <span class=\"hljs-string\">&#x27;echo The app is running! &amp;&amp; sleep 3600&#x27;</span>]<br>  <span class=\"hljs-attr\">initContainers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">init-myservice</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">busybox</span><br>    <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&#x27;sh&#x27;</span>, <span class=\"hljs-string\">&#x27;-c&#x27;</span>, <span class=\"hljs-string\">&#x27;until nslookup myservice; do echo waiting for myservice; sleep 2;done;&#x27;</span>]<br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">init-mydb</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">busybox</span><br>    <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&#x27;sh&#x27;</span>, <span class=\"hljs-string\">&#x27;-c&#x27;</span>, <span class=\"hljs-string\">&#x27;until nslookup mydb; do echo waiting for mydb; sleep 2; done; &#x27;</span>]<br></code></pre></td></tr></table></figure>\n\n<p>myservice模板</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Service</span><br><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myservice</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">ports:</span><br>    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">protocol:</span> <span class=\"hljs-string\">TCP</span><br>      <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br>      <span class=\"hljs-attr\">targetPort:</span> <span class=\"hljs-number\">9376</span><br></code></pre></td></tr></table></figure>\n\n<p>mydb模板</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Service</span><br><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">mydb</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">ports:</span><br>    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">protocol:</span> <span class=\"hljs-string\">TCP</span><br>      <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br>      <span class=\"hljs-attr\">targetPort:</span> <span class=\"hljs-number\">9377</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"Init容器操作查看\"><a href=\"#Init容器操作查看\" class=\"headerlink\" title=\"Init容器操作查看\"></a>Init容器操作查看</h1><h2 id=\"第一步：之创建init状态检测pod\"><a href=\"#第一步：之创建init状态检测pod\" class=\"headerlink\" title=\"第一步：之创建init状态检测pod\"></a>第一步：之创建init状态检测pod</h2><p>通过init容器模板创建pod</p>\n<figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs kotlin\"># 先生成<span class=\"hljs-keyword\">init</span>配置清单<br>[<span class=\"hljs-symbol\">root@</span>k8s-master01 <span class=\"hljs-keyword\">init</span>-container]# vi <span class=\"hljs-keyword\">init</span>.yaml<br># 通过<span class=\"hljs-keyword\">init</span>.yaml创建pod<br>[<span class=\"hljs-symbol\">root@</span>k8s-master01 <span class=\"hljs-keyword\">init</span>-container]# kubectl create -f  <span class=\"hljs-keyword\">init</span>.yaml<br># 查看pod的状态<br>[<span class=\"hljs-symbol\">root@</span>k8s-master01 <span class=\"hljs-keyword\">init</span>-container]# kubectl <span class=\"hljs-keyword\">get</span> pod<br>NAME        READY   STATUS     RESTARTS   AGE<br>myapp-pod   <span class=\"hljs-number\">0</span>/<span class=\"hljs-number\">1</span>     Init:<span class=\"hljs-number\">0</span>/<span class=\"hljs-number\">2</span>   <span class=\"hljs-number\">0</span>          3m8s<br></code></pre></td></tr></table></figure>\n\n<p>查看myapp-pod的启动日志</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\">[<span class=\"hljs-string\">root@k8s-master01</span> <span class=\"hljs-string\">init-container</span>]<span class=\"hljs-comment\"># kubectl describe pod myapp-pod</span><br><span class=\"hljs-attr\">Name:</span>         <span class=\"hljs-string\">myapp-pod</span><br><span class=\"hljs-attr\">Namespace:</span>    <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">Priority:</span>     <span class=\"hljs-number\">0</span><br><span class=\"hljs-attr\">Node:</span>         <span class=\"hljs-string\">k8s-node02/fd56:a9ae:cb0f::853</span><br><span class=\"hljs-attr\">Start Time:</span>   <span class=\"hljs-string\">Sat,</span> <span class=\"hljs-number\">16</span> <span class=\"hljs-string\">Jul</span> <span class=\"hljs-number\">2022 20:56:13</span> <span class=\"hljs-string\">+0800</span><br><span class=\"hljs-attr\">Labels:</span>       <span class=\"hljs-string\">app=myapp</span><br><span class=\"hljs-attr\">Annotations:</span>  <span class=\"hljs-string\">&lt;none&gt;</span><br><span class=\"hljs-attr\">Status:</span>       <span class=\"hljs-string\">Pending</span><br><span class=\"hljs-attr\">IP:</span>           <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.2</span><span class=\"hljs-number\">.4</span><br><span class=\"hljs-attr\">IPs:</span><br>  <span class=\"hljs-attr\">IP:</span>  <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.2</span><span class=\"hljs-number\">.4</span><br><span class=\"hljs-attr\">Init Containers:</span><br>  <span class=\"hljs-attr\">init-myservice:</span><br>    <span class=\"hljs-attr\">Container ID:</span>  <span class=\"hljs-string\">docker://b4e6898bf71991f1571f0750d7ed58f54aeb511ca175b9dcafbbdf457aac3971</span><br>    <span class=\"hljs-attr\">Image:</span>         <span class=\"hljs-string\">busybox</span><br>    <span class=\"hljs-attr\">Image ID:</span>      <span class=\"hljs-string\">docker-pullable://busybox@sha256:5acba83a746c7608ed544dc1533b87c737a0b0fb730301639a0179f9344b1678</span><br>    <span class=\"hljs-attr\">Port:</span>          <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Host Port:</span>     <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Command:</span><br>      <span class=\"hljs-string\">sh</span><br>      <span class=\"hljs-string\">-c</span><br>      <span class=\"hljs-string\">until</span> <span class=\"hljs-string\">nslookup</span> <span class=\"hljs-string\">myservice;</span> <span class=\"hljs-string\">do</span> <span class=\"hljs-string\">echo</span> <span class=\"hljs-string\">waiting</span> <span class=\"hljs-string\">for</span> <span class=\"hljs-string\">myservice;</span> <span class=\"hljs-string\">sleep</span> <span class=\"hljs-number\">2</span><span class=\"hljs-string\">;done;</span><br>    <span class=\"hljs-attr\">State:</span>          <span class=\"hljs-string\">Running</span><br>      <span class=\"hljs-attr\">Started:</span>      <span class=\"hljs-string\">Sat,</span> <span class=\"hljs-number\">16</span> <span class=\"hljs-string\">Jul</span> <span class=\"hljs-number\">2022 20:56:33</span> <span class=\"hljs-string\">+0800</span><br>    <span class=\"hljs-attr\">Ready:</span>          <span class=\"hljs-literal\">False</span><br>    <span class=\"hljs-attr\">Restart Count:</span>  <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-attr\">Environment:</span>    <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Mounts:</span><br>      <span class=\"hljs-string\">/var/run/secrets/kubernetes.io/serviceaccount</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">kube-api-access-4vx22</span> <span class=\"hljs-string\">(ro)</span><br>  <span class=\"hljs-attr\">init-mydb:</span><br>    <span class=\"hljs-attr\">Container ID:</span>  <br>    <span class=\"hljs-attr\">Image:</span>         <span class=\"hljs-string\">busybox</span><br>    <span class=\"hljs-attr\">Image ID:</span>      <br>    <span class=\"hljs-attr\">Port:</span>          <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Host Port:</span>     <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Command:</span><br>      <span class=\"hljs-string\">sh</span><br>      <span class=\"hljs-string\">-c</span><br>      <span class=\"hljs-string\">until</span> <span class=\"hljs-string\">nslookup</span> <span class=\"hljs-string\">mydb;</span> <span class=\"hljs-string\">do</span> <span class=\"hljs-string\">echo</span> <span class=\"hljs-string\">waiting</span> <span class=\"hljs-string\">for</span> <span class=\"hljs-string\">mydb;</span> <span class=\"hljs-string\">sleep</span> <span class=\"hljs-number\">2</span><span class=\"hljs-string\">;</span> <span class=\"hljs-string\">done;</span> <br>    <span class=\"hljs-attr\">State:</span>          <span class=\"hljs-string\">Waiting</span><br>      <span class=\"hljs-attr\">Reason:</span>       <span class=\"hljs-string\">PodInitializing</span><br>    <span class=\"hljs-attr\">Ready:</span>          <span class=\"hljs-literal\">False</span><br>    <span class=\"hljs-attr\">Restart Count:</span>  <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-attr\">Environment:</span>    <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Mounts:</span><br>      <span class=\"hljs-string\">/var/run/secrets/kubernetes.io/serviceaccount</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">kube-api-access-4vx22</span> <span class=\"hljs-string\">(ro)</span><br><span class=\"hljs-attr\">Containers:</span><br>  <span class=\"hljs-attr\">myapp-container:</span><br>    <span class=\"hljs-attr\">Container ID:</span>  <br>    <span class=\"hljs-attr\">Image:</span>         <span class=\"hljs-string\">busybox</span><br>    <span class=\"hljs-attr\">Image ID:</span>      <br>    <span class=\"hljs-attr\">Port:</span>          <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Host Port:</span>     <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Command:</span><br>      <span class=\"hljs-string\">sh</span><br>      <span class=\"hljs-string\">-c</span><br>      <span class=\"hljs-string\">echo</span> <span class=\"hljs-string\">The</span> <span class=\"hljs-string\">app</span> <span class=\"hljs-string\">is</span> <span class=\"hljs-string\">running!</span> <span class=\"hljs-string\">&amp;&amp;</span> <span class=\"hljs-string\">sleep</span> <span class=\"hljs-number\">3600</span><br>    <span class=\"hljs-attr\">State:</span>          <span class=\"hljs-string\">Waiting</span><br>      <span class=\"hljs-attr\">Reason:</span>       <span class=\"hljs-string\">PodInitializing</span><br>    <span class=\"hljs-attr\">Ready:</span>          <span class=\"hljs-literal\">False</span><br>    <span class=\"hljs-attr\">Restart Count:</span>  <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-attr\">Environment:</span>    <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Mounts:</span><br>      <span class=\"hljs-string\">/var/run/secrets/kubernetes.io/serviceaccount</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">kube-api-access-4vx22</span> <span class=\"hljs-string\">(ro)</span><br><span class=\"hljs-attr\">Conditions:</span><br>  <span class=\"hljs-string\">Type</span>              <span class=\"hljs-string\">Status</span><br>  <span class=\"hljs-string\">Initialized</span>       <span class=\"hljs-literal\">False</span> <br>  <span class=\"hljs-string\">Ready</span>             <span class=\"hljs-literal\">False</span> <br>  <span class=\"hljs-string\">ContainersReady</span>   <span class=\"hljs-literal\">False</span> <br>  <span class=\"hljs-string\">PodScheduled</span>      <span class=\"hljs-literal\">True</span> <br><span class=\"hljs-attr\">Volumes:</span><br>  <span class=\"hljs-attr\">kube-api-access-4vx22:</span><br>    <span class=\"hljs-attr\">Type:</span>                    <span class=\"hljs-string\">Projected</span> <span class=\"hljs-string\">(a</span> <span class=\"hljs-string\">volume</span> <span class=\"hljs-string\">that</span> <span class=\"hljs-string\">contains</span> <span class=\"hljs-string\">injected</span> <span class=\"hljs-string\">data</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">multiple</span> <span class=\"hljs-string\">sources)</span><br>    <span class=\"hljs-attr\">TokenExpirationSeconds:</span>  <span class=\"hljs-number\">3607</span><br>    <span class=\"hljs-attr\">ConfigMapName:</span>           <span class=\"hljs-string\">kube-root-ca.crt</span><br>    <span class=\"hljs-attr\">ConfigMapOptional:</span>       <span class=\"hljs-string\">&lt;nil&gt;</span><br>    <span class=\"hljs-attr\">DownwardAPI:</span>             <span class=\"hljs-literal\">true</span><br><span class=\"hljs-attr\">QoS Class:</span>                   <span class=\"hljs-string\">BestEffort</span><br><span class=\"hljs-attr\">Node-Selectors:</span>              <span class=\"hljs-string\">&lt;none&gt;</span><br><span class=\"hljs-attr\">Tolerations:</span>                 <span class=\"hljs-string\">node.kubernetes.io/not-ready:NoExecute</span> <span class=\"hljs-string\">op=Exists</span> <span class=\"hljs-string\">for</span> <span class=\"hljs-string\">300s</span><br>                             <span class=\"hljs-string\">node.kubernetes.io/unreachable:NoExecute</span> <span class=\"hljs-string\">op=Exists</span> <span class=\"hljs-string\">for</span> <span class=\"hljs-string\">300s</span><br><span class=\"hljs-attr\">Events:</span><br>  <span class=\"hljs-string\">Type</span>    <span class=\"hljs-string\">Reason</span>     <span class=\"hljs-string\">Age</span>    <span class=\"hljs-string\">From</span>               <span class=\"hljs-string\">Message</span><br>  <span class=\"hljs-string\">----</span>    <span class=\"hljs-string\">------</span>     <span class=\"hljs-string\">----</span>   <span class=\"hljs-string\">----</span>               <span class=\"hljs-string\">-------</span><br>  <span class=\"hljs-string\">Normal</span>  <span class=\"hljs-string\">Scheduled</span>  <span class=\"hljs-string\">4m6s</span>   <span class=\"hljs-string\">default-scheduler</span>  <span class=\"hljs-string\">Successfully</span> <span class=\"hljs-string\">assigned</span> <span class=\"hljs-string\">default/myapp-pod</span> <span class=\"hljs-string\">to</span> <span class=\"hljs-string\">k8s-node02</span><br>  <span class=\"hljs-string\">Normal</span>  <span class=\"hljs-string\">Pulling</span>    <span class=\"hljs-string\">2m34s</span>  <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Pulling</span> <span class=\"hljs-string\">image</span> <span class=\"hljs-string\">&quot;busybox&quot;</span><br>  <span class=\"hljs-string\">Normal</span>  <span class=\"hljs-string\">Pulled</span>     <span class=\"hljs-string\">2m16s</span>  <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Successfully</span> <span class=\"hljs-string\">pulled</span> <span class=\"hljs-string\">image</span> <span class=\"hljs-string\">&quot;busybox&quot;</span> <span class=\"hljs-string\">in</span> <span class=\"hljs-number\">17.</span><span class=\"hljs-string\">673975295s</span><br>  <span class=\"hljs-string\">Normal</span>  <span class=\"hljs-string\">Created</span>    <span class=\"hljs-string\">2m16s</span>  <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Created</span> <span class=\"hljs-string\">container</span> <span class=\"hljs-string\">init-myservice</span><br>  <span class=\"hljs-string\">Normal</span>  <span class=\"hljs-string\">Started</span>    <span class=\"hljs-string\">2m16s</span>  <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Started</span> <span class=\"hljs-string\">container</span> <span class=\"hljs-string\">init-myservice</span><br></code></pre></td></tr></table></figure>\n\n<p>查看日志</p>\n<figure class=\"highlight golo\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs golo\">[root<span class=\"hljs-meta\">@k</span>8s-master01 init-container]<span class=\"hljs-comment\"># kubectl logs myapp-pod -c  init-myservice</span><br>waiting <span class=\"hljs-keyword\">for</span> myservice<br>Server:         <span class=\"hljs-number\">10.96</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.10</span><br>Address:        <span class=\"hljs-number\">10.96</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.10</span>:<span class=\"hljs-number\">53</span><br><br>** server can&#x27;t <span class=\"hljs-keyword\">find</span> myservice.default.svc.cluster.<span class=\"hljs-keyword\">local</span>: NXDOMAIN<br><br>*** Can&#x27;t <span class=\"hljs-keyword\">find</span> myservice.svc.cluster.<span class=\"hljs-keyword\">local</span>: No answer<br>*** Can&#x27;t <span class=\"hljs-keyword\">find</span> myservice.cluster.<span class=\"hljs-keyword\">local</span>: No answer<br>*** Can&#x27;t <span class=\"hljs-keyword\">find</span> myservice.default.svc.cluster.<span class=\"hljs-keyword\">local</span>: No answer<br>*** Can&#x27;t <span class=\"hljs-keyword\">find</span> myservice.svc.cluster.<span class=\"hljs-keyword\">local</span>: No answer<br>*** Can&#x27;t <span class=\"hljs-keyword\">find</span> myservice.cluster.<span class=\"hljs-keyword\">local</span>: No answer<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"第二步：创建myservice\"><a href=\"#第二步：创建myservice\" class=\"headerlink\" title=\"第二步：创建myservice\"></a>第二步：创建myservice</h2><p>通过myservice模板创建svc</p>\n<figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gauss\">vi myservice.yaml<br>kubectl <span class=\"hljs-keyword\">create</span> -f myservice.yaml<br></code></pre></td></tr></table></figure>\n\n<p>查看pod状态，可以看出status中的显示变成了Init:1/2,说明检测状态中，有一个service已经成功启动。</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">[root@k8s-master01 init-container]<span class=\"hljs-comment\"># kubectl get pod</span><br>NAME        READY   STATUS     RESTARTS   AGE<br>myapp-pod   <span class=\"hljs-number\">0</span><span class=\"hljs-regexp\">/1     Init:1/</span><span class=\"hljs-number\">2</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">16</span>m<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"第三步：创建mydb\"><a href=\"#第三步：创建mydb\" class=\"headerlink\" title=\"第三步：创建mydb\"></a>第三步：创建mydb</h2><p>通过myservice模板创建svc</p>\n<figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gauss\">vi mydb.yaml<br>kubectl <span class=\"hljs-keyword\">create</span> -f mydb.yaml<br></code></pre></td></tr></table></figure>\n\n<p>查看pod状态，可以看出READY显示为1/1,status中的显示变成了Running,说明检测状态中，已经成功启动。</p>\n<figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs kotlin\">[<span class=\"hljs-symbol\">root@</span>k8s-master01 <span class=\"hljs-keyword\">init</span>-container]# kubectl <span class=\"hljs-keyword\">get</span> pod<br>NAME        READY   STATUS    RESTARTS   AGE<br>myapp-pod   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          22m<br></code></pre></td></tr></table></figure>\n\n\n\n\n\n\n\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"k8s-pod生命周期—Init容器\"><a href=\"#k8s-pod生命周期—Init容器\" class=\"headerlink\" title=\"k8s pod生命周期—Init容器\"></a>k8s pod生命周期—Init容器</h1><h1 id=\"pod生命周期\"><a href=\"#pod生命周期\" class=\"headerlink\" title=\"pod生命周期\"></a>pod生命周期</h1><p>![1657944206659](k8s pod生命周期/1657944206659.png)</p>\n<p>Pod能够具有多个容器,应用运行在容器里面,但是它也可能有一个或多个先于应用容器启动的Init容器。</p>\n<p>Init容器与普通的容器非常像,除了如下两点:</p>\n<ul>\n<li>Init 容器总是运行到成功完成为止</li>\n<li>每个Init容器都必须在下一个Init容器启动之前成功完成</li>\n</ul>\n<p>如果Pod的Init容器失败, Kubernetes会不断地重启该Pod,直到Init容器成功为止。然而,如果Pod对应的restartPolicy 为Never,它不会重新启动。</p>\n<p><strong>因为Init容器具有与应用程序容器分离的单独镜像,所以它们的启动相关代码具有如下优势:</strong></p>\n<ul>\n<li>它们可以包含并运行实用工具,但是出于安全考虑,是不建议在应用程序容器镜像中包含这些实用工具的。</li>\n<li>它们可以包含使用工具和定制化代码来安装,但是不能出现在应用程序镜像中。例如,创建镜像没必要FROM另一个镜像,只需要在安装过程中使用类似sed、 awk、 python或dig这样的工具。</li>\n<li>应用程序镜像可以分离出创建和部署的角色,而没有必要联合它们构建一个单独的镜像。</li>\n<li>Init 容器使用Linux Namespace,所以相对应用程序容器来说具有不同的文件系统视图。因此,它们能够具有访问Secret的权限,而应用程序容器则不能。</li>\n<li>它们必须在应用程序容器启动之前运行完成,而应用程序容器是并行运行的,所以Init容器能够提供了一种简单的阻塞或延迟应用容器的启动的方法,直到满足了一组先决条件。</li>\n</ul>\n<p>在Pod启动过程中,Init容器会按顺序在网络和数据卷初始化之后启动。每个容器必须在下一个容器启动之前成功退出。</p>\n<p>如果由于运行时或失败退出,将导致容器启动失败,它会根据Pod的restartPolicy指定的策略进行重试。然而,如果Pod的restartPolicy设置为Always, Init容器失败时会使用RestartPolicy策略。</p>\n<p>在所有的Init容器没有成功之前, Pod将不会变成Ready状态。Init容器的端口将不会在Service 中进行聚集。正在初始化中的Pod处于Pending状态,但应该会将Initializing状态设置为true。</p>\n<p>如果Pod重启,所有Init容器必须重新执行。</p>\n<p>对Init容器spec的修改被限制在容器image字段,修改其他字段都不会生效。更改Init容器的image字段,等价于重启该Pod。(kubectl edit pod myapp-pod)</p>\n<p>Init容器具有应用容器的所有字段。除了readinessProbe，因为Init容器无法定义不同于完成(completion)的就绪(readiness)之外的其他状态。这会在验证过程中强制执行。</p>\n<p>在Pod中的每个app和Init容器的名称必须唯一；与任何其它容器共享同一个名称,会在验证时抛出错误。</p>\n<h1 id=\"Init容器\"><a href=\"#Init容器\" class=\"headerlink\" title=\"Init容器\"></a>Init容器</h1><p>Init模板</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp-pod</span><br>  <span class=\"hljs-attr\">labels:</span><br>    <span class=\"hljs-attr\">app:</span> <span class=\"hljs-string\">myapp</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myapp-container</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">busybox</span><br>    <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&#x27;sh&#x27;</span>, <span class=\"hljs-string\">&#x27;-c&#x27;</span>, <span class=\"hljs-string\">&#x27;echo The app is running! &amp;&amp; sleep 3600&#x27;</span>]<br>  <span class=\"hljs-attr\">initContainers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">init-myservice</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">busybox</span><br>    <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&#x27;sh&#x27;</span>, <span class=\"hljs-string\">&#x27;-c&#x27;</span>, <span class=\"hljs-string\">&#x27;until nslookup myservice; do echo waiting for myservice; sleep 2;done;&#x27;</span>]<br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">init-mydb</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">busybox</span><br>    <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&#x27;sh&#x27;</span>, <span class=\"hljs-string\">&#x27;-c&#x27;</span>, <span class=\"hljs-string\">&#x27;until nslookup mydb; do echo waiting for mydb; sleep 2; done; &#x27;</span>]<br></code></pre></td></tr></table></figure>\n\n<p>myservice模板</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Service</span><br><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">myservice</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">ports:</span><br>    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">protocol:</span> <span class=\"hljs-string\">TCP</span><br>      <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br>      <span class=\"hljs-attr\">targetPort:</span> <span class=\"hljs-number\">9376</span><br></code></pre></td></tr></table></figure>\n\n<p>mydb模板</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Service</span><br><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">mydb</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">ports:</span><br>    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">protocol:</span> <span class=\"hljs-string\">TCP</span><br>      <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br>      <span class=\"hljs-attr\">targetPort:</span> <span class=\"hljs-number\">9377</span><br></code></pre></td></tr></table></figure>\n\n<h1 id=\"Init容器操作查看\"><a href=\"#Init容器操作查看\" class=\"headerlink\" title=\"Init容器操作查看\"></a>Init容器操作查看</h1><h2 id=\"第一步：之创建init状态检测pod\"><a href=\"#第一步：之创建init状态检测pod\" class=\"headerlink\" title=\"第一步：之创建init状态检测pod\"></a>第一步：之创建init状态检测pod</h2><p>通过init容器模板创建pod</p>\n<figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs kotlin\"># 先生成<span class=\"hljs-keyword\">init</span>配置清单<br>[<span class=\"hljs-symbol\">root@</span>k8s-master01 <span class=\"hljs-keyword\">init</span>-container]# vi <span class=\"hljs-keyword\">init</span>.yaml<br># 通过<span class=\"hljs-keyword\">init</span>.yaml创建pod<br>[<span class=\"hljs-symbol\">root@</span>k8s-master01 <span class=\"hljs-keyword\">init</span>-container]# kubectl create -f  <span class=\"hljs-keyword\">init</span>.yaml<br># 查看pod的状态<br>[<span class=\"hljs-symbol\">root@</span>k8s-master01 <span class=\"hljs-keyword\">init</span>-container]# kubectl <span class=\"hljs-keyword\">get</span> pod<br>NAME        READY   STATUS     RESTARTS   AGE<br>myapp-pod   <span class=\"hljs-number\">0</span>/<span class=\"hljs-number\">1</span>     Init:<span class=\"hljs-number\">0</span>/<span class=\"hljs-number\">2</span>   <span class=\"hljs-number\">0</span>          3m8s<br></code></pre></td></tr></table></figure>\n\n<p>查看myapp-pod的启动日志</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\">[<span class=\"hljs-string\">root@k8s-master01</span> <span class=\"hljs-string\">init-container</span>]<span class=\"hljs-comment\"># kubectl describe pod myapp-pod</span><br><span class=\"hljs-attr\">Name:</span>         <span class=\"hljs-string\">myapp-pod</span><br><span class=\"hljs-attr\">Namespace:</span>    <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">Priority:</span>     <span class=\"hljs-number\">0</span><br><span class=\"hljs-attr\">Node:</span>         <span class=\"hljs-string\">k8s-node02/fd56:a9ae:cb0f::853</span><br><span class=\"hljs-attr\">Start Time:</span>   <span class=\"hljs-string\">Sat,</span> <span class=\"hljs-number\">16</span> <span class=\"hljs-string\">Jul</span> <span class=\"hljs-number\">2022 20:56:13</span> <span class=\"hljs-string\">+0800</span><br><span class=\"hljs-attr\">Labels:</span>       <span class=\"hljs-string\">app=myapp</span><br><span class=\"hljs-attr\">Annotations:</span>  <span class=\"hljs-string\">&lt;none&gt;</span><br><span class=\"hljs-attr\">Status:</span>       <span class=\"hljs-string\">Pending</span><br><span class=\"hljs-attr\">IP:</span>           <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.2</span><span class=\"hljs-number\">.4</span><br><span class=\"hljs-attr\">IPs:</span><br>  <span class=\"hljs-attr\">IP:</span>  <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.2</span><span class=\"hljs-number\">.4</span><br><span class=\"hljs-attr\">Init Containers:</span><br>  <span class=\"hljs-attr\">init-myservice:</span><br>    <span class=\"hljs-attr\">Container ID:</span>  <span class=\"hljs-string\">docker://b4e6898bf71991f1571f0750d7ed58f54aeb511ca175b9dcafbbdf457aac3971</span><br>    <span class=\"hljs-attr\">Image:</span>         <span class=\"hljs-string\">busybox</span><br>    <span class=\"hljs-attr\">Image ID:</span>      <span class=\"hljs-string\">docker-pullable://busybox@sha256:5acba83a746c7608ed544dc1533b87c737a0b0fb730301639a0179f9344b1678</span><br>    <span class=\"hljs-attr\">Port:</span>          <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Host Port:</span>     <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Command:</span><br>      <span class=\"hljs-string\">sh</span><br>      <span class=\"hljs-string\">-c</span><br>      <span class=\"hljs-string\">until</span> <span class=\"hljs-string\">nslookup</span> <span class=\"hljs-string\">myservice;</span> <span class=\"hljs-string\">do</span> <span class=\"hljs-string\">echo</span> <span class=\"hljs-string\">waiting</span> <span class=\"hljs-string\">for</span> <span class=\"hljs-string\">myservice;</span> <span class=\"hljs-string\">sleep</span> <span class=\"hljs-number\">2</span><span class=\"hljs-string\">;done;</span><br>    <span class=\"hljs-attr\">State:</span>          <span class=\"hljs-string\">Running</span><br>      <span class=\"hljs-attr\">Started:</span>      <span class=\"hljs-string\">Sat,</span> <span class=\"hljs-number\">16</span> <span class=\"hljs-string\">Jul</span> <span class=\"hljs-number\">2022 20:56:33</span> <span class=\"hljs-string\">+0800</span><br>    <span class=\"hljs-attr\">Ready:</span>          <span class=\"hljs-literal\">False</span><br>    <span class=\"hljs-attr\">Restart Count:</span>  <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-attr\">Environment:</span>    <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Mounts:</span><br>      <span class=\"hljs-string\">/var/run/secrets/kubernetes.io/serviceaccount</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">kube-api-access-4vx22</span> <span class=\"hljs-string\">(ro)</span><br>  <span class=\"hljs-attr\">init-mydb:</span><br>    <span class=\"hljs-attr\">Container ID:</span>  <br>    <span class=\"hljs-attr\">Image:</span>         <span class=\"hljs-string\">busybox</span><br>    <span class=\"hljs-attr\">Image ID:</span>      <br>    <span class=\"hljs-attr\">Port:</span>          <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Host Port:</span>     <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Command:</span><br>      <span class=\"hljs-string\">sh</span><br>      <span class=\"hljs-string\">-c</span><br>      <span class=\"hljs-string\">until</span> <span class=\"hljs-string\">nslookup</span> <span class=\"hljs-string\">mydb;</span> <span class=\"hljs-string\">do</span> <span class=\"hljs-string\">echo</span> <span class=\"hljs-string\">waiting</span> <span class=\"hljs-string\">for</span> <span class=\"hljs-string\">mydb;</span> <span class=\"hljs-string\">sleep</span> <span class=\"hljs-number\">2</span><span class=\"hljs-string\">;</span> <span class=\"hljs-string\">done;</span> <br>    <span class=\"hljs-attr\">State:</span>          <span class=\"hljs-string\">Waiting</span><br>      <span class=\"hljs-attr\">Reason:</span>       <span class=\"hljs-string\">PodInitializing</span><br>    <span class=\"hljs-attr\">Ready:</span>          <span class=\"hljs-literal\">False</span><br>    <span class=\"hljs-attr\">Restart Count:</span>  <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-attr\">Environment:</span>    <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Mounts:</span><br>      <span class=\"hljs-string\">/var/run/secrets/kubernetes.io/serviceaccount</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">kube-api-access-4vx22</span> <span class=\"hljs-string\">(ro)</span><br><span class=\"hljs-attr\">Containers:</span><br>  <span class=\"hljs-attr\">myapp-container:</span><br>    <span class=\"hljs-attr\">Container ID:</span>  <br>    <span class=\"hljs-attr\">Image:</span>         <span class=\"hljs-string\">busybox</span><br>    <span class=\"hljs-attr\">Image ID:</span>      <br>    <span class=\"hljs-attr\">Port:</span>          <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Host Port:</span>     <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Command:</span><br>      <span class=\"hljs-string\">sh</span><br>      <span class=\"hljs-string\">-c</span><br>      <span class=\"hljs-string\">echo</span> <span class=\"hljs-string\">The</span> <span class=\"hljs-string\">app</span> <span class=\"hljs-string\">is</span> <span class=\"hljs-string\">running!</span> <span class=\"hljs-string\">&amp;&amp;</span> <span class=\"hljs-string\">sleep</span> <span class=\"hljs-number\">3600</span><br>    <span class=\"hljs-attr\">State:</span>          <span class=\"hljs-string\">Waiting</span><br>      <span class=\"hljs-attr\">Reason:</span>       <span class=\"hljs-string\">PodInitializing</span><br>    <span class=\"hljs-attr\">Ready:</span>          <span class=\"hljs-literal\">False</span><br>    <span class=\"hljs-attr\">Restart Count:</span>  <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-attr\">Environment:</span>    <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Mounts:</span><br>      <span class=\"hljs-string\">/var/run/secrets/kubernetes.io/serviceaccount</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">kube-api-access-4vx22</span> <span class=\"hljs-string\">(ro)</span><br><span class=\"hljs-attr\">Conditions:</span><br>  <span class=\"hljs-string\">Type</span>              <span class=\"hljs-string\">Status</span><br>  <span class=\"hljs-string\">Initialized</span>       <span class=\"hljs-literal\">False</span> <br>  <span class=\"hljs-string\">Ready</span>             <span class=\"hljs-literal\">False</span> <br>  <span class=\"hljs-string\">ContainersReady</span>   <span class=\"hljs-literal\">False</span> <br>  <span class=\"hljs-string\">PodScheduled</span>      <span class=\"hljs-literal\">True</span> <br><span class=\"hljs-attr\">Volumes:</span><br>  <span class=\"hljs-attr\">kube-api-access-4vx22:</span><br>    <span class=\"hljs-attr\">Type:</span>                    <span class=\"hljs-string\">Projected</span> <span class=\"hljs-string\">(a</span> <span class=\"hljs-string\">volume</span> <span class=\"hljs-string\">that</span> <span class=\"hljs-string\">contains</span> <span class=\"hljs-string\">injected</span> <span class=\"hljs-string\">data</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">multiple</span> <span class=\"hljs-string\">sources)</span><br>    <span class=\"hljs-attr\">TokenExpirationSeconds:</span>  <span class=\"hljs-number\">3607</span><br>    <span class=\"hljs-attr\">ConfigMapName:</span>           <span class=\"hljs-string\">kube-root-ca.crt</span><br>    <span class=\"hljs-attr\">ConfigMapOptional:</span>       <span class=\"hljs-string\">&lt;nil&gt;</span><br>    <span class=\"hljs-attr\">DownwardAPI:</span>             <span class=\"hljs-literal\">true</span><br><span class=\"hljs-attr\">QoS Class:</span>                   <span class=\"hljs-string\">BestEffort</span><br><span class=\"hljs-attr\">Node-Selectors:</span>              <span class=\"hljs-string\">&lt;none&gt;</span><br><span class=\"hljs-attr\">Tolerations:</span>                 <span class=\"hljs-string\">node.kubernetes.io/not-ready:NoExecute</span> <span class=\"hljs-string\">op=Exists</span> <span class=\"hljs-string\">for</span> <span class=\"hljs-string\">300s</span><br>                             <span class=\"hljs-string\">node.kubernetes.io/unreachable:NoExecute</span> <span class=\"hljs-string\">op=Exists</span> <span class=\"hljs-string\">for</span> <span class=\"hljs-string\">300s</span><br><span class=\"hljs-attr\">Events:</span><br>  <span class=\"hljs-string\">Type</span>    <span class=\"hljs-string\">Reason</span>     <span class=\"hljs-string\">Age</span>    <span class=\"hljs-string\">From</span>               <span class=\"hljs-string\">Message</span><br>  <span class=\"hljs-string\">----</span>    <span class=\"hljs-string\">------</span>     <span class=\"hljs-string\">----</span>   <span class=\"hljs-string\">----</span>               <span class=\"hljs-string\">-------</span><br>  <span class=\"hljs-string\">Normal</span>  <span class=\"hljs-string\">Scheduled</span>  <span class=\"hljs-string\">4m6s</span>   <span class=\"hljs-string\">default-scheduler</span>  <span class=\"hljs-string\">Successfully</span> <span class=\"hljs-string\">assigned</span> <span class=\"hljs-string\">default/myapp-pod</span> <span class=\"hljs-string\">to</span> <span class=\"hljs-string\">k8s-node02</span><br>  <span class=\"hljs-string\">Normal</span>  <span class=\"hljs-string\">Pulling</span>    <span class=\"hljs-string\">2m34s</span>  <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Pulling</span> <span class=\"hljs-string\">image</span> <span class=\"hljs-string\">&quot;busybox&quot;</span><br>  <span class=\"hljs-string\">Normal</span>  <span class=\"hljs-string\">Pulled</span>     <span class=\"hljs-string\">2m16s</span>  <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Successfully</span> <span class=\"hljs-string\">pulled</span> <span class=\"hljs-string\">image</span> <span class=\"hljs-string\">&quot;busybox&quot;</span> <span class=\"hljs-string\">in</span> <span class=\"hljs-number\">17.</span><span class=\"hljs-string\">673975295s</span><br>  <span class=\"hljs-string\">Normal</span>  <span class=\"hljs-string\">Created</span>    <span class=\"hljs-string\">2m16s</span>  <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Created</span> <span class=\"hljs-string\">container</span> <span class=\"hljs-string\">init-myservice</span><br>  <span class=\"hljs-string\">Normal</span>  <span class=\"hljs-string\">Started</span>    <span class=\"hljs-string\">2m16s</span>  <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Started</span> <span class=\"hljs-string\">container</span> <span class=\"hljs-string\">init-myservice</span><br></code></pre></td></tr></table></figure>\n\n<p>查看日志</p>\n<figure class=\"highlight golo\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs golo\">[root<span class=\"hljs-meta\">@k</span>8s-master01 init-container]<span class=\"hljs-comment\"># kubectl logs myapp-pod -c  init-myservice</span><br>waiting <span class=\"hljs-keyword\">for</span> myservice<br>Server:         <span class=\"hljs-number\">10.96</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.10</span><br>Address:        <span class=\"hljs-number\">10.96</span><span class=\"hljs-number\">.0</span><span class=\"hljs-number\">.10</span>:<span class=\"hljs-number\">53</span><br><br>** server can&#x27;t <span class=\"hljs-keyword\">find</span> myservice.default.svc.cluster.<span class=\"hljs-keyword\">local</span>: NXDOMAIN<br><br>*** Can&#x27;t <span class=\"hljs-keyword\">find</span> myservice.svc.cluster.<span class=\"hljs-keyword\">local</span>: No answer<br>*** Can&#x27;t <span class=\"hljs-keyword\">find</span> myservice.cluster.<span class=\"hljs-keyword\">local</span>: No answer<br>*** Can&#x27;t <span class=\"hljs-keyword\">find</span> myservice.default.svc.cluster.<span class=\"hljs-keyword\">local</span>: No answer<br>*** Can&#x27;t <span class=\"hljs-keyword\">find</span> myservice.svc.cluster.<span class=\"hljs-keyword\">local</span>: No answer<br>*** Can&#x27;t <span class=\"hljs-keyword\">find</span> myservice.cluster.<span class=\"hljs-keyword\">local</span>: No answer<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"第二步：创建myservice\"><a href=\"#第二步：创建myservice\" class=\"headerlink\" title=\"第二步：创建myservice\"></a>第二步：创建myservice</h2><p>通过myservice模板创建svc</p>\n<figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gauss\">vi myservice.yaml<br>kubectl <span class=\"hljs-keyword\">create</span> -f myservice.yaml<br></code></pre></td></tr></table></figure>\n\n<p>查看pod状态，可以看出status中的显示变成了Init:1/2,说明检测状态中，有一个service已经成功启动。</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">[root@k8s-master01 init-container]<span class=\"hljs-comment\"># kubectl get pod</span><br>NAME        READY   STATUS     RESTARTS   AGE<br>myapp-pod   <span class=\"hljs-number\">0</span><span class=\"hljs-regexp\">/1     Init:1/</span><span class=\"hljs-number\">2</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">16</span>m<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"第三步：创建mydb\"><a href=\"#第三步：创建mydb\" class=\"headerlink\" title=\"第三步：创建mydb\"></a>第三步：创建mydb</h2><p>通过myservice模板创建svc</p>\n<figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gauss\">vi mydb.yaml<br>kubectl <span class=\"hljs-keyword\">create</span> -f mydb.yaml<br></code></pre></td></tr></table></figure>\n\n<p>查看pod状态，可以看出READY显示为1/1,status中的显示变成了Running,说明检测状态中，已经成功启动。</p>\n<figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs kotlin\">[<span class=\"hljs-symbol\">root@</span>k8s-master01 <span class=\"hljs-keyword\">init</span>-container]# kubectl <span class=\"hljs-keyword\">get</span> pod<br>NAME        READY   STATUS    RESTARTS   AGE<br>myapp-pod   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          22m<br></code></pre></td></tr></table></figure>\n\n\n\n\n\n\n\n"},{"title":"k8s pod重启策略与状态","date":"2021-08-10T13:32:02.000Z","_content":"\n# 重启策略\n\nPodSpec中有一个 restartPolicy字段，可能的值为Always、OnFailure和Never。默认为Always. \n\nrestartPolicy 适用于Pod中的所有容器。restartPolicy仅指通过同一节点上的kubelet 重新启动容器。失败的容器由kubelet以五分钟为上限的指数退避延迟(10秒,20秒, 40秒.)重新启动,并在成功执行十分钟后重置。如Pod文档中所述,一旦绑定到一个节点, Pod将永远不会重新绑定到另一个节点。\n\n# 状态\n\nPod的status字段是一个PodStatus对象, PodStatus中有一个 phase字段。\n\nPod的相位(phase)是Pod在其生命周期中的简单宏观概述。该阶段并不是对容器或Pod的综合汇总,也不是为了做为综合状态机\n\n挂起(Pending)：Pod已被Kubernetes系统接受,但有一个或者多个容器镜像尚未创建。等待时间包括调度Pod的时间和通过网络下载镜像的时间，这可能需要花点时间\n\n运行中(Running)：该Pod已经绑定到了一个节点上, Pod中所有的容器都已被创建。至少有一个容器正在运行,或者正处于启动或重启状态\n\n成功(Succeeded)： Pod中的所有容器都被成功终止,并且不会再重启\n\n失败(Failed)：Pod中的所有容器都已终止了,并且至少有一个容器是因为失败终止。也就是说,容器以非0状态退出或者被系统终止\n\n未知(Unknown)：因为某些原因无法取得Pod的状态,通常是因为与Pod所在主机通信失败\n\n# 状态示例\n\nPod中只有一个容器并且正在运行，容器成功退出\n\n- 记录事件完成\n- 如果restartPolicy为:\n  \tAlways：重启容器；Pod phase 仍为Running\n  \tOnFailure： Pod phase变成 Succeeded\n  \tNever：Pod phase成 Succeeded\n\nPod中只有一个容器并且正在运行。容器退出失败\n\n- 记录失败事件\n- 如果restartPolicy为:\n  \tAlways：重启容器: Pod phase 仍为Running\n  \tOnFailure：重启容器; Pod phase仍为Running\n  \tNever：Pod phase 变成 Failed\n\nPod中有两个容器并且正在运行。容器1退出失败\n\n- 记录失败事件\n- 如果restartPolicy为:\n  \tAlways：重启容器; Pod phase仍为Running\n  \tOnFailure：重启容器: Pod phase仍为Running\n  \tNever： 重启容器: Pod phase为Running\n- 如果有容器1没有处于运行状态,并且容器2退出:\n          记录失败事件\n          如果restartPolicy为:\n                  Always: 重启容器: Pod phase为 Running\n                 OnFailure: 重启容器; Pod phase仍为Running\n                 Never: Pod phase 变成 Failed\n\nPod 中只有一个容器并处于运行状态。容器运行时内存超出限制\n\n- 容器以失败状态终止\n- 记录OOM事件\n- 如果restartPolicy为:\n  Always: 重启容器: Pod phase为Running\n  OnFailure:重启容器; Pod phase 为Running\n  Never: 记录失败事件: Pod phase仍为Failed\n\nPod正在运行,磁盘故障.\n\n- 杀掉所有容器。记录适当事件\n- Pod phase变成 Failed\n- 如果使用控制器来运行, Pod将在别处重建\n\nPod正在运行,其节点被分段\n\n- 节点控制器等待直到超时\n- 节点控制器将Pod phase设置为Failed\n- 如果是用控制器来运行, Pod将在别处重建\n\n# 启动退出\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: lifecycle-demo\nspec:\n  containers:\n  - name: lifecycle-demo-containen\n    image: harborcloud.com/library/myapp:v1.23   #本地搭建仓库  \n    lifecycle:\n      postStart: #pod创建后执行\n        exec:\n          command: [\"/bin/sh\",\"-c\",\"touch /tmp/live\"]\n      preStop: #pod退出前执行\n        exec:\n          command: [\"/bin/sh\",\"-c\",\"rm -rf /tmp/live\"]\n```\n\n查看是否成功：\n\n```\n[root@k8s-master01 probe]# kubectl exec lifecycle-demo -it -- /bin/sh\n# ls /tmp\nlive\n```\n\n\n\n","source":"_posts/k8s pod重启策略与状态.md","raw":"---\ntitle: k8s pod重启策略与状态\ndate: 2021-08-10 21:32:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - 重启策略\n---\n\n# 重启策略\n\nPodSpec中有一个 restartPolicy字段，可能的值为Always、OnFailure和Never。默认为Always. \n\nrestartPolicy 适用于Pod中的所有容器。restartPolicy仅指通过同一节点上的kubelet 重新启动容器。失败的容器由kubelet以五分钟为上限的指数退避延迟(10秒,20秒, 40秒.)重新启动,并在成功执行十分钟后重置。如Pod文档中所述,一旦绑定到一个节点, Pod将永远不会重新绑定到另一个节点。\n\n# 状态\n\nPod的status字段是一个PodStatus对象, PodStatus中有一个 phase字段。\n\nPod的相位(phase)是Pod在其生命周期中的简单宏观概述。该阶段并不是对容器或Pod的综合汇总,也不是为了做为综合状态机\n\n挂起(Pending)：Pod已被Kubernetes系统接受,但有一个或者多个容器镜像尚未创建。等待时间包括调度Pod的时间和通过网络下载镜像的时间，这可能需要花点时间\n\n运行中(Running)：该Pod已经绑定到了一个节点上, Pod中所有的容器都已被创建。至少有一个容器正在运行,或者正处于启动或重启状态\n\n成功(Succeeded)： Pod中的所有容器都被成功终止,并且不会再重启\n\n失败(Failed)：Pod中的所有容器都已终止了,并且至少有一个容器是因为失败终止。也就是说,容器以非0状态退出或者被系统终止\n\n未知(Unknown)：因为某些原因无法取得Pod的状态,通常是因为与Pod所在主机通信失败\n\n# 状态示例\n\nPod中只有一个容器并且正在运行，容器成功退出\n\n- 记录事件完成\n- 如果restartPolicy为:\n  \tAlways：重启容器；Pod phase 仍为Running\n  \tOnFailure： Pod phase变成 Succeeded\n  \tNever：Pod phase成 Succeeded\n\nPod中只有一个容器并且正在运行。容器退出失败\n\n- 记录失败事件\n- 如果restartPolicy为:\n  \tAlways：重启容器: Pod phase 仍为Running\n  \tOnFailure：重启容器; Pod phase仍为Running\n  \tNever：Pod phase 变成 Failed\n\nPod中有两个容器并且正在运行。容器1退出失败\n\n- 记录失败事件\n- 如果restartPolicy为:\n  \tAlways：重启容器; Pod phase仍为Running\n  \tOnFailure：重启容器: Pod phase仍为Running\n  \tNever： 重启容器: Pod phase为Running\n- 如果有容器1没有处于运行状态,并且容器2退出:\n          记录失败事件\n          如果restartPolicy为:\n                  Always: 重启容器: Pod phase为 Running\n                 OnFailure: 重启容器; Pod phase仍为Running\n                 Never: Pod phase 变成 Failed\n\nPod 中只有一个容器并处于运行状态。容器运行时内存超出限制\n\n- 容器以失败状态终止\n- 记录OOM事件\n- 如果restartPolicy为:\n  Always: 重启容器: Pod phase为Running\n  OnFailure:重启容器; Pod phase 为Running\n  Never: 记录失败事件: Pod phase仍为Failed\n\nPod正在运行,磁盘故障.\n\n- 杀掉所有容器。记录适当事件\n- Pod phase变成 Failed\n- 如果使用控制器来运行, Pod将在别处重建\n\nPod正在运行,其节点被分段\n\n- 节点控制器等待直到超时\n- 节点控制器将Pod phase设置为Failed\n- 如果是用控制器来运行, Pod将在别处重建\n\n# 启动退出\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: lifecycle-demo\nspec:\n  containers:\n  - name: lifecycle-demo-containen\n    image: harborcloud.com/library/myapp:v1.23   #本地搭建仓库  \n    lifecycle:\n      postStart: #pod创建后执行\n        exec:\n          command: [\"/bin/sh\",\"-c\",\"touch /tmp/live\"]\n      preStop: #pod退出前执行\n        exec:\n          command: [\"/bin/sh\",\"-c\",\"rm -rf /tmp/live\"]\n```\n\n查看是否成功：\n\n```\n[root@k8s-master01 probe]# kubectl exec lifecycle-demo -it -- /bin/sh\n# ls /tmp\nlive\n```\n\n\n\n","slug":"k8s pod重启策略与状态","published":1,"updated":"2022-09-23T17:36:01.364Z","_id":"cl8eritso0006w8vj92ezgvfn","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"重启策略\"><a href=\"#重启策略\" class=\"headerlink\" title=\"重启策略\"></a>重启策略</h1><p>PodSpec中有一个 restartPolicy字段，可能的值为Always、OnFailure和Never。默认为Always. </p>\n<p>restartPolicy 适用于Pod中的所有容器。restartPolicy仅指通过同一节点上的kubelet 重新启动容器。失败的容器由kubelet以五分钟为上限的指数退避延迟(10秒,20秒, 40秒.)重新启动,并在成功执行十分钟后重置。如Pod文档中所述,一旦绑定到一个节点, Pod将永远不会重新绑定到另一个节点。</p>\n<h1 id=\"状态\"><a href=\"#状态\" class=\"headerlink\" title=\"状态\"></a>状态</h1><p>Pod的status字段是一个PodStatus对象, PodStatus中有一个 phase字段。</p>\n<p>Pod的相位(phase)是Pod在其生命周期中的简单宏观概述。该阶段并不是对容器或Pod的综合汇总,也不是为了做为综合状态机</p>\n<p>挂起(Pending)：Pod已被Kubernetes系统接受,但有一个或者多个容器镜像尚未创建。等待时间包括调度Pod的时间和通过网络下载镜像的时间，这可能需要花点时间</p>\n<p>运行中(Running)：该Pod已经绑定到了一个节点上, Pod中所有的容器都已被创建。至少有一个容器正在运行,或者正处于启动或重启状态</p>\n<p>成功(Succeeded)： Pod中的所有容器都被成功终止,并且不会再重启</p>\n<p>失败(Failed)：Pod中的所有容器都已终止了,并且至少有一个容器是因为失败终止。也就是说,容器以非0状态退出或者被系统终止</p>\n<p>未知(Unknown)：因为某些原因无法取得Pod的状态,通常是因为与Pod所在主机通信失败</p>\n<h1 id=\"状态示例\"><a href=\"#状态示例\" class=\"headerlink\" title=\"状态示例\"></a>状态示例</h1><p>Pod中只有一个容器并且正在运行，容器成功退出</p>\n<ul>\n<li>记录事件完成</li>\n<li>如果restartPolicy为:<pre><code class=\"hljs\">Always：重启容器；Pod phase 仍为Running\nOnFailure： Pod phase变成 Succeeded\nNever：Pod phase成 Succeeded\n</code></pre>\n</li>\n</ul>\n<p>Pod中只有一个容器并且正在运行。容器退出失败</p>\n<ul>\n<li>记录失败事件</li>\n<li>如果restartPolicy为:<pre><code class=\"hljs\">Always：重启容器: Pod phase 仍为Running\nOnFailure：重启容器; Pod phase仍为Running\nNever：Pod phase 变成 Failed\n</code></pre>\n</li>\n</ul>\n<p>Pod中有两个容器并且正在运行。容器1退出失败</p>\n<ul>\n<li>记录失败事件</li>\n<li>如果restartPolicy为:<pre><code class=\"hljs\">Always：重启容器; Pod phase仍为Running\nOnFailure：重启容器: Pod phase仍为Running\nNever： 重启容器: Pod phase为Running\n</code></pre>\n</li>\n<li>如果有容器1没有处于运行状态,并且容器2退出:<pre><code class=\"hljs\">    记录失败事件\n    如果restartPolicy为:\n            Always: 重启容器: Pod phase为 Running\n           OnFailure: 重启容器; Pod phase仍为Running\n           Never: Pod phase 变成 Failed\n</code></pre>\n</li>\n</ul>\n<p>Pod 中只有一个容器并处于运行状态。容器运行时内存超出限制</p>\n<ul>\n<li>容器以失败状态终止</li>\n<li>记录OOM事件</li>\n<li>如果restartPolicy为:<br>Always: 重启容器: Pod phase为Running<br>OnFailure:重启容器; Pod phase 为Running<br>Never: 记录失败事件: Pod phase仍为Failed</li>\n</ul>\n<p>Pod正在运行,磁盘故障.</p>\n<ul>\n<li>杀掉所有容器。记录适当事件</li>\n<li>Pod phase变成 Failed</li>\n<li>如果使用控制器来运行, Pod将在别处重建</li>\n</ul>\n<p>Pod正在运行,其节点被分段</p>\n<ul>\n<li>节点控制器等待直到超时</li>\n<li>节点控制器将Pod phase设置为Failed</li>\n<li>如果是用控制器来运行, Pod将在别处重建</li>\n</ul>\n<h1 id=\"启动退出\"><a href=\"#启动退出\" class=\"headerlink\" title=\"启动退出\"></a>启动退出</h1><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">lifecycle-demo</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">lifecycle-demo-containen</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/myapp:v1.23</span>   <span class=\"hljs-comment\">#本地搭建仓库  </span><br>    <span class=\"hljs-attr\">lifecycle:</span><br>      <span class=\"hljs-attr\">postStart:</span> <span class=\"hljs-comment\">#pod创建后执行</span><br>        <span class=\"hljs-attr\">exec:</span><br>          <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&quot;/bin/sh&quot;</span>,<span class=\"hljs-string\">&quot;-c&quot;</span>,<span class=\"hljs-string\">&quot;touch /tmp/live&quot;</span>]<br>      <span class=\"hljs-attr\">preStop:</span> <span class=\"hljs-comment\">#pod退出前执行</span><br>        <span class=\"hljs-attr\">exec:</span><br>          <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&quot;/bin/sh&quot;</span>,<span class=\"hljs-string\">&quot;-c&quot;</span>,<span class=\"hljs-string\">&quot;rm -rf /tmp/live&quot;</span>]<br></code></pre></td></tr></table></figure>\n\n<p>查看是否成功：</p>\n<figure class=\"highlight coffeescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs coffeescript\">[root@k8s-master01 probe]<span class=\"hljs-comment\"># kubectl exec lifecycle-demo -it -- /bin/sh</span><br><span class=\"hljs-comment\"># ls /tmp</span><br>live<br></code></pre></td></tr></table></figure>\n\n\n\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"重启策略\"><a href=\"#重启策略\" class=\"headerlink\" title=\"重启策略\"></a>重启策略</h1><p>PodSpec中有一个 restartPolicy字段，可能的值为Always、OnFailure和Never。默认为Always. </p>\n<p>restartPolicy 适用于Pod中的所有容器。restartPolicy仅指通过同一节点上的kubelet 重新启动容器。失败的容器由kubelet以五分钟为上限的指数退避延迟(10秒,20秒, 40秒.)重新启动,并在成功执行十分钟后重置。如Pod文档中所述,一旦绑定到一个节点, Pod将永远不会重新绑定到另一个节点。</p>\n<h1 id=\"状态\"><a href=\"#状态\" class=\"headerlink\" title=\"状态\"></a>状态</h1><p>Pod的status字段是一个PodStatus对象, PodStatus中有一个 phase字段。</p>\n<p>Pod的相位(phase)是Pod在其生命周期中的简单宏观概述。该阶段并不是对容器或Pod的综合汇总,也不是为了做为综合状态机</p>\n<p>挂起(Pending)：Pod已被Kubernetes系统接受,但有一个或者多个容器镜像尚未创建。等待时间包括调度Pod的时间和通过网络下载镜像的时间，这可能需要花点时间</p>\n<p>运行中(Running)：该Pod已经绑定到了一个节点上, Pod中所有的容器都已被创建。至少有一个容器正在运行,或者正处于启动或重启状态</p>\n<p>成功(Succeeded)： Pod中的所有容器都被成功终止,并且不会再重启</p>\n<p>失败(Failed)：Pod中的所有容器都已终止了,并且至少有一个容器是因为失败终止。也就是说,容器以非0状态退出或者被系统终止</p>\n<p>未知(Unknown)：因为某些原因无法取得Pod的状态,通常是因为与Pod所在主机通信失败</p>\n<h1 id=\"状态示例\"><a href=\"#状态示例\" class=\"headerlink\" title=\"状态示例\"></a>状态示例</h1><p>Pod中只有一个容器并且正在运行，容器成功退出</p>\n<ul>\n<li>记录事件完成</li>\n<li>如果restartPolicy为:<pre><code>Always：重启容器；Pod phase 仍为Running\nOnFailure： Pod phase变成 Succeeded\nNever：Pod phase成 Succeeded\n</code></pre>\n</li>\n</ul>\n<p>Pod中只有一个容器并且正在运行。容器退出失败</p>\n<ul>\n<li>记录失败事件</li>\n<li>如果restartPolicy为:<pre><code>Always：重启容器: Pod phase 仍为Running\nOnFailure：重启容器; Pod phase仍为Running\nNever：Pod phase 变成 Failed\n</code></pre>\n</li>\n</ul>\n<p>Pod中有两个容器并且正在运行。容器1退出失败</p>\n<ul>\n<li>记录失败事件</li>\n<li>如果restartPolicy为:<pre><code>Always：重启容器; Pod phase仍为Running\nOnFailure：重启容器: Pod phase仍为Running\nNever： 重启容器: Pod phase为Running\n</code></pre>\n</li>\n<li>如果有容器1没有处于运行状态,并且容器2退出:<pre><code>    记录失败事件\n    如果restartPolicy为:\n            Always: 重启容器: Pod phase为 Running\n           OnFailure: 重启容器; Pod phase仍为Running\n           Never: Pod phase 变成 Failed\n</code></pre>\n</li>\n</ul>\n<p>Pod 中只有一个容器并处于运行状态。容器运行时内存超出限制</p>\n<ul>\n<li>容器以失败状态终止</li>\n<li>记录OOM事件</li>\n<li>如果restartPolicy为:<br>Always: 重启容器: Pod phase为Running<br>OnFailure:重启容器; Pod phase 为Running<br>Never: 记录失败事件: Pod phase仍为Failed</li>\n</ul>\n<p>Pod正在运行,磁盘故障.</p>\n<ul>\n<li>杀掉所有容器。记录适当事件</li>\n<li>Pod phase变成 Failed</li>\n<li>如果使用控制器来运行, Pod将在别处重建</li>\n</ul>\n<p>Pod正在运行,其节点被分段</p>\n<ul>\n<li>节点控制器等待直到超时</li>\n<li>节点控制器将Pod phase设置为Failed</li>\n<li>如果是用控制器来运行, Pod将在别处重建</li>\n</ul>\n<h1 id=\"启动退出\"><a href=\"#启动退出\" class=\"headerlink\" title=\"启动退出\"></a>启动退出</h1><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">lifecycle-demo</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">lifecycle-demo-containen</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/myapp:v1.23</span>   <span class=\"hljs-comment\">#本地搭建仓库  </span><br>    <span class=\"hljs-attr\">lifecycle:</span><br>      <span class=\"hljs-attr\">postStart:</span> <span class=\"hljs-comment\">#pod创建后执行</span><br>        <span class=\"hljs-attr\">exec:</span><br>          <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&quot;/bin/sh&quot;</span>,<span class=\"hljs-string\">&quot;-c&quot;</span>,<span class=\"hljs-string\">&quot;touch /tmp/live&quot;</span>]<br>      <span class=\"hljs-attr\">preStop:</span> <span class=\"hljs-comment\">#pod退出前执行</span><br>        <span class=\"hljs-attr\">exec:</span><br>          <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&quot;/bin/sh&quot;</span>,<span class=\"hljs-string\">&quot;-c&quot;</span>,<span class=\"hljs-string\">&quot;rm -rf /tmp/live&quot;</span>]<br></code></pre></td></tr></table></figure>\n\n<p>查看是否成功：</p>\n<figure class=\"highlight coffeescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs coffeescript\">[root@k8s-master01 probe]<span class=\"hljs-comment\"># kubectl exec lifecycle-demo -it -- /bin/sh</span><br><span class=\"hljs-comment\"># ls /tmp</span><br>live<br></code></pre></td></tr></table></figure>\n\n\n\n"},{"title":"k8s pod生命周期—探针","date":"2021-08-08T14:32:02.000Z","_content":"\n# 三种类型处理程序\n\n探针是由kubelet对容器执行的定期诊断。要执行诊断, kubelet调用由容器实现的Handler。有三种类型的处理程序:\n\nExecAction：在容器内执行指定命令。如果命令退出时返回码为0则认为诊断成功。\n\nTCPSocketAction：对指定端口上的容器的IP地址进行TCP检查。如果端口打开,则诊断被认为是成功的。\n\nHTTPGetAction：对指定的端口和路径上的容器的IP地址执行HTTP Get请求。如果响应的状态码大于等于200且小于400,则诊断被认为是成功的\n\n每次探测都将获得以下三种结果之一：\n\n成功：容器通过了诊断。\n\n失败：容器未通过诊断。\n\n未知：诊断失败,因此不会采取任何行动\n\n# 探测方式\n\n**livenessProbe**\n\n指示容器是否正在运行。如果存活探测失败,则kubelet会杀死容器,并且容器将受到其重启策略的影响。如果容器不提供存活探针,则默认状态为Success\n\n**readinessProbe**\n\n指示容器是否准备好服务请求。如果就绪探测失败,端点控制器将从与Pod匹配的所有Service的端点中删除该Pod的IP地址。初始延迟之前的就绪状态默认为Failure。如果容器不提供就绪探针,则默认状态为Success\n\n# Pod hook \n\nPod hook (子)是由Kubernetes 管理的kubelet发起的,当容器中的进程启动前或者容器中的进程终止之前运行,这是包含在容器的生命周期之中。可以同时为Pod中的所有容器都配置hook\n\nHook 的类型包括两种:\n\n- exec:执行一段命令\n- HTTP:发送HTTP请求\n\n# 探针示例\n\n注意：harborcloud.com是我本地搭建的云仓库\n\n```\nharborcloud.com/library/myapp:v1.23 =>nginx\nharborcloud.com/library/busybox:v1.35 =>busybox\n```\n\n## 就绪探针\n\n### 资源清单\n\nreadinessProbe-httpget\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: readiness-httpget-pod\n  namespace: default\nspec:\n  containers:\n  - name: readiness-httpget-container\n    image: harborcloud.com/library/myapp:v1.23\n    imagePullPolicy: IfNotPresent\n    readinessProbe:\n      httpGet:\n        port: 80\n        path: /index1.html\n      initialDelaySeconds: 1\n      periodSeconds: 3\n```\n\n### 清单应用\n\n```\n[root@k8s-master01 probe]# vi readinessProbe-httpget.ymal\n[root@k8s-master01 probe]# kubectl create -f readinessProbe-httpget.ymal\n# kubectl get pod 可能需要等待一会才会 status：running\n[root@k8s-master01 probe]# kubectl get pod\nNAME                    READY   STATUS    RESTARTS   AGE\nreadiness-httpget-pod   0/1     Running   0          2m3s\n```\n\n结果分析：为什么会出现READY 0/1\n\n```\n[root@k8s-master01 probe]# kubectl describe pod readiness-httpget-pod\nName:         readiness-httpget-pod\nNamespace:    default\nPriority:     0\nNode:         k8s-node02/fd56:a9ae:cb0f::853\nStart Time:   Sun, 17 Jul 2022 00:10:36 +0800\nLabels:       <none>\nAnnotations:  <none>\nStatus:       Running\nIP:           10.244.2.5\nIPs:\n  IP:  10.244.2.5\nContainers:\n  readiness-httpget-container:\n    Container ID:   docker://692f676aa6a3b9a16eac5373d78398df1780d6e7b87e129a3035a871e3617d61\n    Image:          wangyanglinux/myapp:v1\n    Image ID:       docker-pullable://wangyanglinux/myapp@sha256:9c3dc30b5219788b2b8a4b065f548b922a34479577befb54b03330999d30d513\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Sun, 17 Jul 2022 00:12:13 +0800\n    Ready:          False\n    Restart Count:  0\n    Readiness:      http-get http://:80/index1.html delay=1s timeout=1s period=3s #success=1 #failure=3\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-2n7st (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  kube-api-access-2n7st:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type     Reason     Age                             From               Message\n  ----     ------     ----                            ----               -------\n  Normal   Scheduled  2m17s                           default-scheduler  Successfully assigned default/readiness-httpget-pod to k8s-node02\n  Warning  Failed     <invalid>                       kubelet            Failed to pull image \"wangyanglinux/myapp:v1\": rpc error: code = Unknown desc = Get https://registry-1.docker.io/v2/: net/http: TLS handshake timeout\n  Warning  Failed     <invalid>                       kubelet            Error: ErrImagePull\n  Normal   BackOff    <invalid>                       kubelet            Back-off pulling image \"wangyanglinux/myapp:v1\"\n  Warning  Failed     <invalid>                       kubelet            Error: ImagePullBackOff\n  Normal   Pulling    <invalid> (x2 over 45s)         kubelet            Pulling image \"wangyanglinux/myapp:v1\"\n  Normal   Pulled     <invalid>                       kubelet            Successfully pulled image \"wangyanglinux/myapp:v1\" in 16.208867618s\n  Normal   Created    <invalid>                       kubelet            Created container readiness-httpget-container\n  Normal   Started    <invalid>                       kubelet            Started container readiness-httpget-container\n  Warning  Unhealthy  <invalid> (x15 over <invalid>)  kubelet            Readiness probe failed: HTTP probe failed with statuscode: 404\n```\n\n通过上面分析可以看出 \n\n```\nReadiness:      http-get http://:80/index1.html delay=1s timeout=1s period=3s #success=1 #failure=3\nerror: code = Unknown desc = Get https://registry-1.docker.io/v2/: net/http: TLS handshake timeout\nstatuscode: 404\n```\n\n处理异常\n\n```\n[root@k8s-master01 probe]# kubectl exec readiness-httpget-pod -it -- /bin/sh\n# cd /usrshare/nginx/html\n# echo \"234srwerwe\">>index1.html\n[root@k8s-master01 probe]# kubectl get pod\nNAME                    READY   STATUS    RESTARTS   AGE\nreadiness-httpget-pod   1/1     Running   0          6m22s\n```\n\n当index1.html添加后pod正常启动\n\n## 存活检测\n\n### livenessProbe-exec\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: liveness-exec-pod\n  namespace: default\nspec:\n  containers:\n  - name: liveness-exec-containen\n    image: harborcloud.com/library/busybox:v1.35\n    imagePullPolicy: IfNotPresent\n    command: [\"/bin/sh\",\"-c\",\"touch /tmp/live;sleep 60;rm -rf /tmp/live;sleep 3600\"]\n    livenessProbe:\n      exec:\n        command: [\"test\",\"-e\",\"/tmp/live\"]\n      initialDelaySeconds: 1\n      periodSeconds: 3\n```\n\n操作：\n\n```\n[root@k8s-master01 probe]# kubectl create -f livenessProbe-exec.yaml \npod/liveness-exec-pod created\n[root@k8s-master01 probe]# kubectl get pod\nNAME                READY   STATUS    RESTARTS   AGE\nliveness-exec-pod   1/1     Running   0          14s\n[root@k8s-master01 probe]# kubectl get pod\nNAME                READY   STATUS    RESTARTS            AGE\nliveness-exec-pod   1/1     Running   1 (<invalid> ago)   2m11s\n```\n\n时间轴：\n\n创建pod成功——等待60秒后删除/tmp/live——存活检测/tmp/live被删除了，然后就重启pod\n\n### livenessProbe-httpget\n\n````yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: liveness-httpget-pod\n  namespace: default\nspec:\n  containers:\n  - name: liveness-httpget-containen\n    image: harborcloud.com/library/myapp:v1.23\n    imagePullPolicy: IfNotPresent\n    ports:\n    - name: http\n      containerPort: 80\n    livenessProbe:\n      httpGet:\n        port: http\n        path: /index.html\n      initialDelaySeconds: 1\n      periodSeconds: 3\n      timeoutSeconds: 10\n````\n\n### livenessProbe-tcp\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: probe-tcp\nspec:\n  containers:\n  - name: nginx\n    image: harborcloud.com/library/myapp:v1.23\n    livenessProbe:\n      initialDelaySeconds: 5\n      timeoutSeconds: 1\n      tcpSocket:\n        port: 80\n```\n\n","source":"_posts/k8s pod生命周期—探针.md","raw":"---\ntitle: k8s pod生命周期—探针\ndate: 2021-08-08 22:32:02\ncategories:\n  - 服务器\ntags:\n  - kubernetes \n  - k8s\n  - 探针\n---\n\n# 三种类型处理程序\n\n探针是由kubelet对容器执行的定期诊断。要执行诊断, kubelet调用由容器实现的Handler。有三种类型的处理程序:\n\nExecAction：在容器内执行指定命令。如果命令退出时返回码为0则认为诊断成功。\n\nTCPSocketAction：对指定端口上的容器的IP地址进行TCP检查。如果端口打开,则诊断被认为是成功的。\n\nHTTPGetAction：对指定的端口和路径上的容器的IP地址执行HTTP Get请求。如果响应的状态码大于等于200且小于400,则诊断被认为是成功的\n\n每次探测都将获得以下三种结果之一：\n\n成功：容器通过了诊断。\n\n失败：容器未通过诊断。\n\n未知：诊断失败,因此不会采取任何行动\n\n# 探测方式\n\n**livenessProbe**\n\n指示容器是否正在运行。如果存活探测失败,则kubelet会杀死容器,并且容器将受到其重启策略的影响。如果容器不提供存活探针,则默认状态为Success\n\n**readinessProbe**\n\n指示容器是否准备好服务请求。如果就绪探测失败,端点控制器将从与Pod匹配的所有Service的端点中删除该Pod的IP地址。初始延迟之前的就绪状态默认为Failure。如果容器不提供就绪探针,则默认状态为Success\n\n# Pod hook \n\nPod hook (子)是由Kubernetes 管理的kubelet发起的,当容器中的进程启动前或者容器中的进程终止之前运行,这是包含在容器的生命周期之中。可以同时为Pod中的所有容器都配置hook\n\nHook 的类型包括两种:\n\n- exec:执行一段命令\n- HTTP:发送HTTP请求\n\n# 探针示例\n\n注意：harborcloud.com是我本地搭建的云仓库\n\n```\nharborcloud.com/library/myapp:v1.23 =>nginx\nharborcloud.com/library/busybox:v1.35 =>busybox\n```\n\n## 就绪探针\n\n### 资源清单\n\nreadinessProbe-httpget\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: readiness-httpget-pod\n  namespace: default\nspec:\n  containers:\n  - name: readiness-httpget-container\n    image: harborcloud.com/library/myapp:v1.23\n    imagePullPolicy: IfNotPresent\n    readinessProbe:\n      httpGet:\n        port: 80\n        path: /index1.html\n      initialDelaySeconds: 1\n      periodSeconds: 3\n```\n\n### 清单应用\n\n```\n[root@k8s-master01 probe]# vi readinessProbe-httpget.ymal\n[root@k8s-master01 probe]# kubectl create -f readinessProbe-httpget.ymal\n# kubectl get pod 可能需要等待一会才会 status：running\n[root@k8s-master01 probe]# kubectl get pod\nNAME                    READY   STATUS    RESTARTS   AGE\nreadiness-httpget-pod   0/1     Running   0          2m3s\n```\n\n结果分析：为什么会出现READY 0/1\n\n```\n[root@k8s-master01 probe]# kubectl describe pod readiness-httpget-pod\nName:         readiness-httpget-pod\nNamespace:    default\nPriority:     0\nNode:         k8s-node02/fd56:a9ae:cb0f::853\nStart Time:   Sun, 17 Jul 2022 00:10:36 +0800\nLabels:       <none>\nAnnotations:  <none>\nStatus:       Running\nIP:           10.244.2.5\nIPs:\n  IP:  10.244.2.5\nContainers:\n  readiness-httpget-container:\n    Container ID:   docker://692f676aa6a3b9a16eac5373d78398df1780d6e7b87e129a3035a871e3617d61\n    Image:          wangyanglinux/myapp:v1\n    Image ID:       docker-pullable://wangyanglinux/myapp@sha256:9c3dc30b5219788b2b8a4b065f548b922a34479577befb54b03330999d30d513\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Sun, 17 Jul 2022 00:12:13 +0800\n    Ready:          False\n    Restart Count:  0\n    Readiness:      http-get http://:80/index1.html delay=1s timeout=1s period=3s #success=1 #failure=3\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-2n7st (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  kube-api-access-2n7st:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type     Reason     Age                             From               Message\n  ----     ------     ----                            ----               -------\n  Normal   Scheduled  2m17s                           default-scheduler  Successfully assigned default/readiness-httpget-pod to k8s-node02\n  Warning  Failed     <invalid>                       kubelet            Failed to pull image \"wangyanglinux/myapp:v1\": rpc error: code = Unknown desc = Get https://registry-1.docker.io/v2/: net/http: TLS handshake timeout\n  Warning  Failed     <invalid>                       kubelet            Error: ErrImagePull\n  Normal   BackOff    <invalid>                       kubelet            Back-off pulling image \"wangyanglinux/myapp:v1\"\n  Warning  Failed     <invalid>                       kubelet            Error: ImagePullBackOff\n  Normal   Pulling    <invalid> (x2 over 45s)         kubelet            Pulling image \"wangyanglinux/myapp:v1\"\n  Normal   Pulled     <invalid>                       kubelet            Successfully pulled image \"wangyanglinux/myapp:v1\" in 16.208867618s\n  Normal   Created    <invalid>                       kubelet            Created container readiness-httpget-container\n  Normal   Started    <invalid>                       kubelet            Started container readiness-httpget-container\n  Warning  Unhealthy  <invalid> (x15 over <invalid>)  kubelet            Readiness probe failed: HTTP probe failed with statuscode: 404\n```\n\n通过上面分析可以看出 \n\n```\nReadiness:      http-get http://:80/index1.html delay=1s timeout=1s period=3s #success=1 #failure=3\nerror: code = Unknown desc = Get https://registry-1.docker.io/v2/: net/http: TLS handshake timeout\nstatuscode: 404\n```\n\n处理异常\n\n```\n[root@k8s-master01 probe]# kubectl exec readiness-httpget-pod -it -- /bin/sh\n# cd /usrshare/nginx/html\n# echo \"234srwerwe\">>index1.html\n[root@k8s-master01 probe]# kubectl get pod\nNAME                    READY   STATUS    RESTARTS   AGE\nreadiness-httpget-pod   1/1     Running   0          6m22s\n```\n\n当index1.html添加后pod正常启动\n\n## 存活检测\n\n### livenessProbe-exec\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: liveness-exec-pod\n  namespace: default\nspec:\n  containers:\n  - name: liveness-exec-containen\n    image: harborcloud.com/library/busybox:v1.35\n    imagePullPolicy: IfNotPresent\n    command: [\"/bin/sh\",\"-c\",\"touch /tmp/live;sleep 60;rm -rf /tmp/live;sleep 3600\"]\n    livenessProbe:\n      exec:\n        command: [\"test\",\"-e\",\"/tmp/live\"]\n      initialDelaySeconds: 1\n      periodSeconds: 3\n```\n\n操作：\n\n```\n[root@k8s-master01 probe]# kubectl create -f livenessProbe-exec.yaml \npod/liveness-exec-pod created\n[root@k8s-master01 probe]# kubectl get pod\nNAME                READY   STATUS    RESTARTS   AGE\nliveness-exec-pod   1/1     Running   0          14s\n[root@k8s-master01 probe]# kubectl get pod\nNAME                READY   STATUS    RESTARTS            AGE\nliveness-exec-pod   1/1     Running   1 (<invalid> ago)   2m11s\n```\n\n时间轴：\n\n创建pod成功——等待60秒后删除/tmp/live——存活检测/tmp/live被删除了，然后就重启pod\n\n### livenessProbe-httpget\n\n````yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: liveness-httpget-pod\n  namespace: default\nspec:\n  containers:\n  - name: liveness-httpget-containen\n    image: harborcloud.com/library/myapp:v1.23\n    imagePullPolicy: IfNotPresent\n    ports:\n    - name: http\n      containerPort: 80\n    livenessProbe:\n      httpGet:\n        port: http\n        path: /index.html\n      initialDelaySeconds: 1\n      periodSeconds: 3\n      timeoutSeconds: 10\n````\n\n### livenessProbe-tcp\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: probe-tcp\nspec:\n  containers:\n  - name: nginx\n    image: harborcloud.com/library/myapp:v1.23\n    livenessProbe:\n      initialDelaySeconds: 5\n      timeoutSeconds: 1\n      tcpSocket:\n        port: 80\n```\n\n","slug":"k8s pod生命周期—探针","published":1,"updated":"2022-09-23T17:35:08.924Z","_id":"cl8eritti0007w8vj7o8m4dz7","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"三种类型处理程序\"><a href=\"#三种类型处理程序\" class=\"headerlink\" title=\"三种类型处理程序\"></a>三种类型处理程序</h1><p>探针是由kubelet对容器执行的定期诊断。要执行诊断, kubelet调用由容器实现的Handler。有三种类型的处理程序:</p>\n<p>ExecAction：在容器内执行指定命令。如果命令退出时返回码为0则认为诊断成功。</p>\n<p>TCPSocketAction：对指定端口上的容器的IP地址进行TCP检查。如果端口打开,则诊断被认为是成功的。</p>\n<p>HTTPGetAction：对指定的端口和路径上的容器的IP地址执行HTTP Get请求。如果响应的状态码大于等于200且小于400,则诊断被认为是成功的</p>\n<p>每次探测都将获得以下三种结果之一：</p>\n<p>成功：容器通过了诊断。</p>\n<p>失败：容器未通过诊断。</p>\n<p>未知：诊断失败,因此不会采取任何行动</p>\n<h1 id=\"探测方式\"><a href=\"#探测方式\" class=\"headerlink\" title=\"探测方式\"></a>探测方式</h1><p><strong>livenessProbe</strong></p>\n<p>指示容器是否正在运行。如果存活探测失败,则kubelet会杀死容器,并且容器将受到其重启策略的影响。如果容器不提供存活探针,则默认状态为Success</p>\n<p><strong>readinessProbe</strong></p>\n<p>指示容器是否准备好服务请求。如果就绪探测失败,端点控制器将从与Pod匹配的所有Service的端点中删除该Pod的IP地址。初始延迟之前的就绪状态默认为Failure。如果容器不提供就绪探针,则默认状态为Success</p>\n<h1 id=\"Pod-hook\"><a href=\"#Pod-hook\" class=\"headerlink\" title=\"Pod hook\"></a>Pod hook</h1><p>Pod hook (子)是由Kubernetes 管理的kubelet发起的,当容器中的进程启动前或者容器中的进程终止之前运行,这是包含在容器的生命周期之中。可以同时为Pod中的所有容器都配置hook</p>\n<p>Hook 的类型包括两种:</p>\n<ul>\n<li>exec:执行一段命令</li>\n<li>HTTP:发送HTTP请求</li>\n</ul>\n<h1 id=\"探针示例\"><a href=\"#探针示例\" class=\"headerlink\" title=\"探针示例\"></a>探针示例</h1><p>注意：harborcloud.com是我本地搭建的云仓库</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">harborcloud.com<span class=\"hljs-regexp\">/library/my</span>app:v1.<span class=\"hljs-number\">23</span> =&gt;nginx<br>harborcloud.com<span class=\"hljs-regexp\">/library/</span>busybox:v1.<span class=\"hljs-number\">35</span> =&gt;busybox<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"就绪探针\"><a href=\"#就绪探针\" class=\"headerlink\" title=\"就绪探针\"></a>就绪探针</h2><h3 id=\"资源清单\"><a href=\"#资源清单\" class=\"headerlink\" title=\"资源清单\"></a>资源清单</h3><p>readinessProbe-httpget</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">readiness-httpget-pod</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">readiness-httpget-container</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/myapp:v1.23</span><br>    <span class=\"hljs-attr\">imagePullPolicy:</span> <span class=\"hljs-string\">IfNotPresent</span><br>    <span class=\"hljs-attr\">readinessProbe:</span><br>      <span class=\"hljs-attr\">httpGet:</span><br>        <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br>        <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">/index1.html</span><br>      <span class=\"hljs-attr\">initialDelaySeconds:</span> <span class=\"hljs-number\">1</span><br>      <span class=\"hljs-attr\">periodSeconds:</span> <span class=\"hljs-number\">3</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"清单应用\"><a href=\"#清单应用\" class=\"headerlink\" title=\"清单应用\"></a>清单应用</h3><figure class=\"highlight coffeescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs coffeescript\">[root@k8s-master01 probe]<span class=\"hljs-comment\"># vi readinessProbe-httpget.ymal</span><br>[root@k8s-master01 probe]<span class=\"hljs-comment\"># kubectl create -f readinessProbe-httpget.ymal</span><br><span class=\"hljs-comment\"># kubectl get pod 可能需要等待一会才会 status：running</span><br>[root@k8s-master01 probe]<span class=\"hljs-comment\"># kubectl get pod</span><br>NAME                    READY   STATUS    RESTARTS   AGE<br>readiness-httpget-pod   <span class=\"hljs-number\">0</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">2</span>m3s<br></code></pre></td></tr></table></figure>\n\n<p>结果分析：为什么会出现READY 0/1</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\">[<span class=\"hljs-string\">root@k8s-master01</span> <span class=\"hljs-string\">probe</span>]<span class=\"hljs-comment\"># kubectl describe pod readiness-httpget-pod</span><br><span class=\"hljs-attr\">Name:</span>         <span class=\"hljs-string\">readiness-httpget-pod</span><br><span class=\"hljs-attr\">Namespace:</span>    <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">Priority:</span>     <span class=\"hljs-number\">0</span><br><span class=\"hljs-attr\">Node:</span>         <span class=\"hljs-string\">k8s-node02/fd56:a9ae:cb0f::853</span><br><span class=\"hljs-attr\">Start Time:</span>   <span class=\"hljs-string\">Sun,</span> <span class=\"hljs-number\">17</span> <span class=\"hljs-string\">Jul</span> <span class=\"hljs-number\">2022 00:10:36</span> <span class=\"hljs-string\">+0800</span><br><span class=\"hljs-attr\">Labels:</span>       <span class=\"hljs-string\">&lt;none&gt;</span><br><span class=\"hljs-attr\">Annotations:</span>  <span class=\"hljs-string\">&lt;none&gt;</span><br><span class=\"hljs-attr\">Status:</span>       <span class=\"hljs-string\">Running</span><br><span class=\"hljs-attr\">IP:</span>           <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.2</span><span class=\"hljs-number\">.5</span><br><span class=\"hljs-attr\">IPs:</span><br>  <span class=\"hljs-attr\">IP:</span>  <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.2</span><span class=\"hljs-number\">.5</span><br><span class=\"hljs-attr\">Containers:</span><br>  <span class=\"hljs-attr\">readiness-httpget-container:</span><br>    <span class=\"hljs-attr\">Container ID:</span>   <span class=\"hljs-string\">docker://692f676aa6a3b9a16eac5373d78398df1780d6e7b87e129a3035a871e3617d61</span><br>    <span class=\"hljs-attr\">Image:</span>          <span class=\"hljs-string\">wangyanglinux/myapp:v1</span><br>    <span class=\"hljs-attr\">Image ID:</span>       <span class=\"hljs-string\">docker-pullable://wangyanglinux/myapp@sha256:9c3dc30b5219788b2b8a4b065f548b922a34479577befb54b03330999d30d513</span><br>    <span class=\"hljs-attr\">Port:</span>           <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Host Port:</span>      <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">State:</span>          <span class=\"hljs-string\">Running</span><br>      <span class=\"hljs-attr\">Started:</span>      <span class=\"hljs-string\">Sun,</span> <span class=\"hljs-number\">17</span> <span class=\"hljs-string\">Jul</span> <span class=\"hljs-number\">2022 00:12:13</span> <span class=\"hljs-string\">+0800</span><br>    <span class=\"hljs-attr\">Ready:</span>          <span class=\"hljs-literal\">False</span><br>    <span class=\"hljs-attr\">Restart Count:</span>  <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-attr\">Readiness:</span>      <span class=\"hljs-string\">http-get</span> <span class=\"hljs-string\">http://:80/index1.html</span> <span class=\"hljs-string\">delay=1s</span> <span class=\"hljs-string\">timeout=1s</span> <span class=\"hljs-string\">period=3s</span> <span class=\"hljs-comment\">#success=1 #failure=3</span><br>    <span class=\"hljs-attr\">Environment:</span>    <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Mounts:</span><br>      <span class=\"hljs-string\">/var/run/secrets/kubernetes.io/serviceaccount</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">kube-api-access-2n7st</span> <span class=\"hljs-string\">(ro)</span><br><span class=\"hljs-attr\">Conditions:</span><br>  <span class=\"hljs-string\">Type</span>              <span class=\"hljs-string\">Status</span><br>  <span class=\"hljs-string\">Initialized</span>       <span class=\"hljs-literal\">True</span> <br>  <span class=\"hljs-string\">Ready</span>             <span class=\"hljs-literal\">False</span> <br>  <span class=\"hljs-string\">ContainersReady</span>   <span class=\"hljs-literal\">False</span> <br>  <span class=\"hljs-string\">PodScheduled</span>      <span class=\"hljs-literal\">True</span> <br><span class=\"hljs-attr\">Volumes:</span><br>  <span class=\"hljs-attr\">kube-api-access-2n7st:</span><br>    <span class=\"hljs-attr\">Type:</span>                    <span class=\"hljs-string\">Projected</span> <span class=\"hljs-string\">(a</span> <span class=\"hljs-string\">volume</span> <span class=\"hljs-string\">that</span> <span class=\"hljs-string\">contains</span> <span class=\"hljs-string\">injected</span> <span class=\"hljs-string\">data</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">multiple</span> <span class=\"hljs-string\">sources)</span><br>    <span class=\"hljs-attr\">TokenExpirationSeconds:</span>  <span class=\"hljs-number\">3607</span><br>    <span class=\"hljs-attr\">ConfigMapName:</span>           <span class=\"hljs-string\">kube-root-ca.crt</span><br>    <span class=\"hljs-attr\">ConfigMapOptional:</span>       <span class=\"hljs-string\">&lt;nil&gt;</span><br>    <span class=\"hljs-attr\">DownwardAPI:</span>             <span class=\"hljs-literal\">true</span><br><span class=\"hljs-attr\">QoS Class:</span>                   <span class=\"hljs-string\">BestEffort</span><br><span class=\"hljs-attr\">Node-Selectors:</span>              <span class=\"hljs-string\">&lt;none&gt;</span><br><span class=\"hljs-attr\">Tolerations:</span>                 <span class=\"hljs-string\">node.kubernetes.io/not-ready:NoExecute</span> <span class=\"hljs-string\">op=Exists</span> <span class=\"hljs-string\">for</span> <span class=\"hljs-string\">300s</span><br>                             <span class=\"hljs-string\">node.kubernetes.io/unreachable:NoExecute</span> <span class=\"hljs-string\">op=Exists</span> <span class=\"hljs-string\">for</span> <span class=\"hljs-string\">300s</span><br><span class=\"hljs-attr\">Events:</span><br>  <span class=\"hljs-string\">Type</span>     <span class=\"hljs-string\">Reason</span>     <span class=\"hljs-string\">Age</span>                             <span class=\"hljs-string\">From</span>               <span class=\"hljs-string\">Message</span><br>  <span class=\"hljs-string\">----</span>     <span class=\"hljs-string\">------</span>     <span class=\"hljs-string\">----</span>                            <span class=\"hljs-string\">----</span>               <span class=\"hljs-string\">-------</span><br>  <span class=\"hljs-string\">Normal</span>   <span class=\"hljs-string\">Scheduled</span>  <span class=\"hljs-string\">2m17s</span>                           <span class=\"hljs-string\">default-scheduler</span>  <span class=\"hljs-string\">Successfully</span> <span class=\"hljs-string\">assigned</span> <span class=\"hljs-string\">default/readiness-httpget-pod</span> <span class=\"hljs-string\">to</span> <span class=\"hljs-string\">k8s-node02</span><br>  <span class=\"hljs-string\">Warning</span>  <span class=\"hljs-string\">Failed</span>     <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Failed</span> <span class=\"hljs-string\">to</span> <span class=\"hljs-string\">pull</span> <span class=\"hljs-string\">image</span> <span class=\"hljs-attr\">&quot;wangyanglinux/myapp:v1&quot;:</span> <span class=\"hljs-attr\">rpc error:</span> <span class=\"hljs-string\">code</span> <span class=\"hljs-string\">=</span> <span class=\"hljs-string\">Unknown</span> <span class=\"hljs-string\">desc</span> <span class=\"hljs-string\">=</span> <span class=\"hljs-attr\">Get https://registry-1.docker.io/v2/: net/http:</span> <span class=\"hljs-string\">TLS</span> <span class=\"hljs-string\">handshake</span> <span class=\"hljs-string\">timeout</span><br>  <span class=\"hljs-string\">Warning</span>  <span class=\"hljs-string\">Failed</span>     <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-attr\">kubelet            Error:</span> <span class=\"hljs-string\">ErrImagePull</span><br>  <span class=\"hljs-string\">Normal</span>   <span class=\"hljs-string\">BackOff</span>    <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Back-off</span> <span class=\"hljs-string\">pulling</span> <span class=\"hljs-string\">image</span> <span class=\"hljs-string\">&quot;wangyanglinux/myapp:v1&quot;</span><br>  <span class=\"hljs-string\">Warning</span>  <span class=\"hljs-string\">Failed</span>     <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-attr\">kubelet            Error:</span> <span class=\"hljs-string\">ImagePullBackOff</span><br>  <span class=\"hljs-string\">Normal</span>   <span class=\"hljs-string\">Pulling</span>    <span class=\"hljs-string\">&lt;invalid&gt;</span> <span class=\"hljs-string\">(x2</span> <span class=\"hljs-string\">over</span> <span class=\"hljs-string\">45s)</span>         <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Pulling</span> <span class=\"hljs-string\">image</span> <span class=\"hljs-string\">&quot;wangyanglinux/myapp:v1&quot;</span><br>  <span class=\"hljs-string\">Normal</span>   <span class=\"hljs-string\">Pulled</span>     <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Successfully</span> <span class=\"hljs-string\">pulled</span> <span class=\"hljs-string\">image</span> <span class=\"hljs-string\">&quot;wangyanglinux/myapp:v1&quot;</span> <span class=\"hljs-string\">in</span> <span class=\"hljs-number\">16.</span><span class=\"hljs-string\">208867618s</span><br>  <span class=\"hljs-string\">Normal</span>   <span class=\"hljs-string\">Created</span>    <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Created</span> <span class=\"hljs-string\">container</span> <span class=\"hljs-string\">readiness-httpget-container</span><br>  <span class=\"hljs-string\">Normal</span>   <span class=\"hljs-string\">Started</span>    <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Started</span> <span class=\"hljs-string\">container</span> <span class=\"hljs-string\">readiness-httpget-container</span><br>  <span class=\"hljs-string\">Warning</span>  <span class=\"hljs-string\">Unhealthy</span>  <span class=\"hljs-string\">&lt;invalid&gt;</span> <span class=\"hljs-string\">(x15</span> <span class=\"hljs-string\">over</span> <span class=\"hljs-string\">&lt;invalid&gt;)</span>  <span class=\"hljs-attr\">kubelet            Readiness probe failed: HTTP probe failed with statuscode:</span> <span class=\"hljs-number\">404</span><br></code></pre></td></tr></table></figure>\n\n<p>通过上面分析可以看出 </p>\n<figure class=\"highlight subunit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs subunit\">Readiness:      http-get http://:80/index1.html delay=1s timeout=1s period=3s #success=1 #failure=3<br><span class=\"hljs-keyword\">error: </span>code = Unknown desc = Get https://registry<span class=\"hljs-string\">-1</span>.docker.io/v2/: net/http: TLS handshake timeout<br>statuscode: 404<br></code></pre></td></tr></table></figure>\n\n<p>处理异常</p>\n<figure class=\"highlight autoit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs autoit\">[root<span class=\"hljs-symbol\">@k8s</span>-master01 probe]<span class=\"hljs-meta\"># kubectl exec readiness-httpget-pod -it -- /bin/sh</span><br><span class=\"hljs-meta\"># cd /usrshare/nginx/html</span><br><span class=\"hljs-meta\"># echo <span class=\"hljs-string\">&quot;234srwerwe&quot;</span>&gt;&gt;index1.html</span><br>[root<span class=\"hljs-symbol\">@k8s</span>-master01 probe]<span class=\"hljs-meta\"># kubectl get pod</span><br>NAME                    READY   STATUS    RESTARTS   AGE<br>readiness-httpget-pod   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">6</span>m22s<br></code></pre></td></tr></table></figure>\n\n<p>当index1.html添加后pod正常启动</p>\n<h2 id=\"存活检测\"><a href=\"#存活检测\" class=\"headerlink\" title=\"存活检测\"></a>存活检测</h2><h3 id=\"livenessProbe-exec\"><a href=\"#livenessProbe-exec\" class=\"headerlink\" title=\"livenessProbe-exec\"></a>livenessProbe-exec</h3><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">liveness-exec-pod</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">liveness-exec-containen</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/busybox:v1.35</span><br>    <span class=\"hljs-attr\">imagePullPolicy:</span> <span class=\"hljs-string\">IfNotPresent</span><br>    <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&quot;/bin/sh&quot;</span>,<span class=\"hljs-string\">&quot;-c&quot;</span>,<span class=\"hljs-string\">&quot;touch /tmp/live;sleep 60;rm -rf /tmp/live;sleep 3600&quot;</span>]<br>    <span class=\"hljs-attr\">livenessProbe:</span><br>      <span class=\"hljs-attr\">exec:</span><br>        <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&quot;test&quot;</span>,<span class=\"hljs-string\">&quot;-e&quot;</span>,<span class=\"hljs-string\">&quot;/tmp/live&quot;</span>]<br>      <span class=\"hljs-attr\">initialDelaySeconds:</span> <span class=\"hljs-number\">1</span><br>      <span class=\"hljs-attr\">periodSeconds:</span> <span class=\"hljs-number\">3</span><br></code></pre></td></tr></table></figure>\n\n<p>操作：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\">[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 probe]# kubectl <span class=\"hljs-keyword\">create</span> <span class=\"hljs-operator\">-</span>f livenessProbe<span class=\"hljs-operator\">-</span>exec.yaml <br>pod<span class=\"hljs-operator\">/</span>liveness<span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">exec</span><span class=\"hljs-operator\">-</span>pod created<br>[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 probe]# kubectl <span class=\"hljs-keyword\">get</span> pod<br>NAME                READY   STATUS    RESTARTS   AGE<br>liveness<span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">exec</span><span class=\"hljs-operator\">-</span>pod   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">14</span>s<br>[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 probe]# kubectl <span class=\"hljs-keyword\">get</span> pod<br>NAME                READY   STATUS    RESTARTS            AGE<br>liveness<span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">exec</span><span class=\"hljs-operator\">-</span>pod   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">1</span> (<span class=\"hljs-operator\">&lt;</span>invalid<span class=\"hljs-operator\">&gt;</span> ago)   <span class=\"hljs-number\">2</span>m11s<br></code></pre></td></tr></table></figure>\n\n<p>时间轴：</p>\n<p>创建pod成功——等待60秒后删除/tmp/live——存活检测/tmp/live被删除了，然后就重启pod</p>\n<h3 id=\"livenessProbe-httpget\"><a href=\"#livenessProbe-httpget\" class=\"headerlink\" title=\"livenessProbe-httpget\"></a>livenessProbe-httpget</h3><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">liveness-httpget-pod</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">liveness-httpget-containen</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/myapp:v1.23</span><br>    <span class=\"hljs-attr\">imagePullPolicy:</span> <span class=\"hljs-string\">IfNotPresent</span><br>    <span class=\"hljs-attr\">ports:</span><br>    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">http</span><br>      <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">80</span><br>    <span class=\"hljs-attr\">livenessProbe:</span><br>      <span class=\"hljs-attr\">httpGet:</span><br>        <span class=\"hljs-attr\">port:</span> <span class=\"hljs-string\">http</span><br>        <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">/index.html</span><br>      <span class=\"hljs-attr\">initialDelaySeconds:</span> <span class=\"hljs-number\">1</span><br>      <span class=\"hljs-attr\">periodSeconds:</span> <span class=\"hljs-number\">3</span><br>      <span class=\"hljs-attr\">timeoutSeconds:</span> <span class=\"hljs-number\">10</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"livenessProbe-tcp\"><a href=\"#livenessProbe-tcp\" class=\"headerlink\" title=\"livenessProbe-tcp\"></a>livenessProbe-tcp</h3><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">probe-tcp</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">nginx</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/myapp:v1.23</span><br>    <span class=\"hljs-attr\">livenessProbe:</span><br>      <span class=\"hljs-attr\">initialDelaySeconds:</span> <span class=\"hljs-number\">5</span><br>      <span class=\"hljs-attr\">timeoutSeconds:</span> <span class=\"hljs-number\">1</span><br>      <span class=\"hljs-attr\">tcpSocket:</span><br>        <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"三种类型处理程序\"><a href=\"#三种类型处理程序\" class=\"headerlink\" title=\"三种类型处理程序\"></a>三种类型处理程序</h1><p>探针是由kubelet对容器执行的定期诊断。要执行诊断, kubelet调用由容器实现的Handler。有三种类型的处理程序:</p>\n<p>ExecAction：在容器内执行指定命令。如果命令退出时返回码为0则认为诊断成功。</p>\n<p>TCPSocketAction：对指定端口上的容器的IP地址进行TCP检查。如果端口打开,则诊断被认为是成功的。</p>\n<p>HTTPGetAction：对指定的端口和路径上的容器的IP地址执行HTTP Get请求。如果响应的状态码大于等于200且小于400,则诊断被认为是成功的</p>\n<p>每次探测都将获得以下三种结果之一：</p>\n<p>成功：容器通过了诊断。</p>\n<p>失败：容器未通过诊断。</p>\n<p>未知：诊断失败,因此不会采取任何行动</p>\n<h1 id=\"探测方式\"><a href=\"#探测方式\" class=\"headerlink\" title=\"探测方式\"></a>探测方式</h1><p><strong>livenessProbe</strong></p>\n<p>指示容器是否正在运行。如果存活探测失败,则kubelet会杀死容器,并且容器将受到其重启策略的影响。如果容器不提供存活探针,则默认状态为Success</p>\n<p><strong>readinessProbe</strong></p>\n<p>指示容器是否准备好服务请求。如果就绪探测失败,端点控制器将从与Pod匹配的所有Service的端点中删除该Pod的IP地址。初始延迟之前的就绪状态默认为Failure。如果容器不提供就绪探针,则默认状态为Success</p>\n<h1 id=\"Pod-hook\"><a href=\"#Pod-hook\" class=\"headerlink\" title=\"Pod hook\"></a>Pod hook</h1><p>Pod hook (子)是由Kubernetes 管理的kubelet发起的,当容器中的进程启动前或者容器中的进程终止之前运行,这是包含在容器的生命周期之中。可以同时为Pod中的所有容器都配置hook</p>\n<p>Hook 的类型包括两种:</p>\n<ul>\n<li>exec:执行一段命令</li>\n<li>HTTP:发送HTTP请求</li>\n</ul>\n<h1 id=\"探针示例\"><a href=\"#探针示例\" class=\"headerlink\" title=\"探针示例\"></a>探针示例</h1><p>注意：harborcloud.com是我本地搭建的云仓库</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">harborcloud.com<span class=\"hljs-regexp\">/library/my</span>app:v1.<span class=\"hljs-number\">23</span> =&gt;nginx<br>harborcloud.com<span class=\"hljs-regexp\">/library/</span>busybox:v1.<span class=\"hljs-number\">35</span> =&gt;busybox<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"就绪探针\"><a href=\"#就绪探针\" class=\"headerlink\" title=\"就绪探针\"></a>就绪探针</h2><h3 id=\"资源清单\"><a href=\"#资源清单\" class=\"headerlink\" title=\"资源清单\"></a>资源清单</h3><p>readinessProbe-httpget</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">readiness-httpget-pod</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">readiness-httpget-container</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/myapp:v1.23</span><br>    <span class=\"hljs-attr\">imagePullPolicy:</span> <span class=\"hljs-string\">IfNotPresent</span><br>    <span class=\"hljs-attr\">readinessProbe:</span><br>      <span class=\"hljs-attr\">httpGet:</span><br>        <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br>        <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">/index1.html</span><br>      <span class=\"hljs-attr\">initialDelaySeconds:</span> <span class=\"hljs-number\">1</span><br>      <span class=\"hljs-attr\">periodSeconds:</span> <span class=\"hljs-number\">3</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"清单应用\"><a href=\"#清单应用\" class=\"headerlink\" title=\"清单应用\"></a>清单应用</h3><figure class=\"highlight coffeescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs coffeescript\">[root@k8s-master01 probe]<span class=\"hljs-comment\"># vi readinessProbe-httpget.ymal</span><br>[root@k8s-master01 probe]<span class=\"hljs-comment\"># kubectl create -f readinessProbe-httpget.ymal</span><br><span class=\"hljs-comment\"># kubectl get pod 可能需要等待一会才会 status：running</span><br>[root@k8s-master01 probe]<span class=\"hljs-comment\"># kubectl get pod</span><br>NAME                    READY   STATUS    RESTARTS   AGE<br>readiness-httpget-pod   <span class=\"hljs-number\">0</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">2</span>m3s<br></code></pre></td></tr></table></figure>\n\n<p>结果分析：为什么会出现READY 0/1</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\">[<span class=\"hljs-string\">root@k8s-master01</span> <span class=\"hljs-string\">probe</span>]<span class=\"hljs-comment\"># kubectl describe pod readiness-httpget-pod</span><br><span class=\"hljs-attr\">Name:</span>         <span class=\"hljs-string\">readiness-httpget-pod</span><br><span class=\"hljs-attr\">Namespace:</span>    <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">Priority:</span>     <span class=\"hljs-number\">0</span><br><span class=\"hljs-attr\">Node:</span>         <span class=\"hljs-string\">k8s-node02/fd56:a9ae:cb0f::853</span><br><span class=\"hljs-attr\">Start Time:</span>   <span class=\"hljs-string\">Sun,</span> <span class=\"hljs-number\">17</span> <span class=\"hljs-string\">Jul</span> <span class=\"hljs-number\">2022 00:10:36</span> <span class=\"hljs-string\">+0800</span><br><span class=\"hljs-attr\">Labels:</span>       <span class=\"hljs-string\">&lt;none&gt;</span><br><span class=\"hljs-attr\">Annotations:</span>  <span class=\"hljs-string\">&lt;none&gt;</span><br><span class=\"hljs-attr\">Status:</span>       <span class=\"hljs-string\">Running</span><br><span class=\"hljs-attr\">IP:</span>           <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.2</span><span class=\"hljs-number\">.5</span><br><span class=\"hljs-attr\">IPs:</span><br>  <span class=\"hljs-attr\">IP:</span>  <span class=\"hljs-number\">10.244</span><span class=\"hljs-number\">.2</span><span class=\"hljs-number\">.5</span><br><span class=\"hljs-attr\">Containers:</span><br>  <span class=\"hljs-attr\">readiness-httpget-container:</span><br>    <span class=\"hljs-attr\">Container ID:</span>   <span class=\"hljs-string\">docker://692f676aa6a3b9a16eac5373d78398df1780d6e7b87e129a3035a871e3617d61</span><br>    <span class=\"hljs-attr\">Image:</span>          <span class=\"hljs-string\">wangyanglinux/myapp:v1</span><br>    <span class=\"hljs-attr\">Image ID:</span>       <span class=\"hljs-string\">docker-pullable://wangyanglinux/myapp@sha256:9c3dc30b5219788b2b8a4b065f548b922a34479577befb54b03330999d30d513</span><br>    <span class=\"hljs-attr\">Port:</span>           <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Host Port:</span>      <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">State:</span>          <span class=\"hljs-string\">Running</span><br>      <span class=\"hljs-attr\">Started:</span>      <span class=\"hljs-string\">Sun,</span> <span class=\"hljs-number\">17</span> <span class=\"hljs-string\">Jul</span> <span class=\"hljs-number\">2022 00:12:13</span> <span class=\"hljs-string\">+0800</span><br>    <span class=\"hljs-attr\">Ready:</span>          <span class=\"hljs-literal\">False</span><br>    <span class=\"hljs-attr\">Restart Count:</span>  <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-attr\">Readiness:</span>      <span class=\"hljs-string\">http-get</span> <span class=\"hljs-string\">http://:80/index1.html</span> <span class=\"hljs-string\">delay=1s</span> <span class=\"hljs-string\">timeout=1s</span> <span class=\"hljs-string\">period=3s</span> <span class=\"hljs-comment\">#success=1 #failure=3</span><br>    <span class=\"hljs-attr\">Environment:</span>    <span class=\"hljs-string\">&lt;none&gt;</span><br>    <span class=\"hljs-attr\">Mounts:</span><br>      <span class=\"hljs-string\">/var/run/secrets/kubernetes.io/serviceaccount</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">kube-api-access-2n7st</span> <span class=\"hljs-string\">(ro)</span><br><span class=\"hljs-attr\">Conditions:</span><br>  <span class=\"hljs-string\">Type</span>              <span class=\"hljs-string\">Status</span><br>  <span class=\"hljs-string\">Initialized</span>       <span class=\"hljs-literal\">True</span> <br>  <span class=\"hljs-string\">Ready</span>             <span class=\"hljs-literal\">False</span> <br>  <span class=\"hljs-string\">ContainersReady</span>   <span class=\"hljs-literal\">False</span> <br>  <span class=\"hljs-string\">PodScheduled</span>      <span class=\"hljs-literal\">True</span> <br><span class=\"hljs-attr\">Volumes:</span><br>  <span class=\"hljs-attr\">kube-api-access-2n7st:</span><br>    <span class=\"hljs-attr\">Type:</span>                    <span class=\"hljs-string\">Projected</span> <span class=\"hljs-string\">(a</span> <span class=\"hljs-string\">volume</span> <span class=\"hljs-string\">that</span> <span class=\"hljs-string\">contains</span> <span class=\"hljs-string\">injected</span> <span class=\"hljs-string\">data</span> <span class=\"hljs-string\">from</span> <span class=\"hljs-string\">multiple</span> <span class=\"hljs-string\">sources)</span><br>    <span class=\"hljs-attr\">TokenExpirationSeconds:</span>  <span class=\"hljs-number\">3607</span><br>    <span class=\"hljs-attr\">ConfigMapName:</span>           <span class=\"hljs-string\">kube-root-ca.crt</span><br>    <span class=\"hljs-attr\">ConfigMapOptional:</span>       <span class=\"hljs-string\">&lt;nil&gt;</span><br>    <span class=\"hljs-attr\">DownwardAPI:</span>             <span class=\"hljs-literal\">true</span><br><span class=\"hljs-attr\">QoS Class:</span>                   <span class=\"hljs-string\">BestEffort</span><br><span class=\"hljs-attr\">Node-Selectors:</span>              <span class=\"hljs-string\">&lt;none&gt;</span><br><span class=\"hljs-attr\">Tolerations:</span>                 <span class=\"hljs-string\">node.kubernetes.io/not-ready:NoExecute</span> <span class=\"hljs-string\">op=Exists</span> <span class=\"hljs-string\">for</span> <span class=\"hljs-string\">300s</span><br>                             <span class=\"hljs-string\">node.kubernetes.io/unreachable:NoExecute</span> <span class=\"hljs-string\">op=Exists</span> <span class=\"hljs-string\">for</span> <span class=\"hljs-string\">300s</span><br><span class=\"hljs-attr\">Events:</span><br>  <span class=\"hljs-string\">Type</span>     <span class=\"hljs-string\">Reason</span>     <span class=\"hljs-string\">Age</span>                             <span class=\"hljs-string\">From</span>               <span class=\"hljs-string\">Message</span><br>  <span class=\"hljs-string\">----</span>     <span class=\"hljs-string\">------</span>     <span class=\"hljs-string\">----</span>                            <span class=\"hljs-string\">----</span>               <span class=\"hljs-string\">-------</span><br>  <span class=\"hljs-string\">Normal</span>   <span class=\"hljs-string\">Scheduled</span>  <span class=\"hljs-string\">2m17s</span>                           <span class=\"hljs-string\">default-scheduler</span>  <span class=\"hljs-string\">Successfully</span> <span class=\"hljs-string\">assigned</span> <span class=\"hljs-string\">default/readiness-httpget-pod</span> <span class=\"hljs-string\">to</span> <span class=\"hljs-string\">k8s-node02</span><br>  <span class=\"hljs-string\">Warning</span>  <span class=\"hljs-string\">Failed</span>     <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Failed</span> <span class=\"hljs-string\">to</span> <span class=\"hljs-string\">pull</span> <span class=\"hljs-string\">image</span> <span class=\"hljs-attr\">&quot;wangyanglinux/myapp:v1&quot;:</span> <span class=\"hljs-attr\">rpc error:</span> <span class=\"hljs-string\">code</span> <span class=\"hljs-string\">=</span> <span class=\"hljs-string\">Unknown</span> <span class=\"hljs-string\">desc</span> <span class=\"hljs-string\">=</span> <span class=\"hljs-attr\">Get https://registry-1.docker.io/v2/: net/http:</span> <span class=\"hljs-string\">TLS</span> <span class=\"hljs-string\">handshake</span> <span class=\"hljs-string\">timeout</span><br>  <span class=\"hljs-string\">Warning</span>  <span class=\"hljs-string\">Failed</span>     <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-attr\">kubelet            Error:</span> <span class=\"hljs-string\">ErrImagePull</span><br>  <span class=\"hljs-string\">Normal</span>   <span class=\"hljs-string\">BackOff</span>    <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Back-off</span> <span class=\"hljs-string\">pulling</span> <span class=\"hljs-string\">image</span> <span class=\"hljs-string\">&quot;wangyanglinux/myapp:v1&quot;</span><br>  <span class=\"hljs-string\">Warning</span>  <span class=\"hljs-string\">Failed</span>     <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-attr\">kubelet            Error:</span> <span class=\"hljs-string\">ImagePullBackOff</span><br>  <span class=\"hljs-string\">Normal</span>   <span class=\"hljs-string\">Pulling</span>    <span class=\"hljs-string\">&lt;invalid&gt;</span> <span class=\"hljs-string\">(x2</span> <span class=\"hljs-string\">over</span> <span class=\"hljs-string\">45s)</span>         <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Pulling</span> <span class=\"hljs-string\">image</span> <span class=\"hljs-string\">&quot;wangyanglinux/myapp:v1&quot;</span><br>  <span class=\"hljs-string\">Normal</span>   <span class=\"hljs-string\">Pulled</span>     <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Successfully</span> <span class=\"hljs-string\">pulled</span> <span class=\"hljs-string\">image</span> <span class=\"hljs-string\">&quot;wangyanglinux/myapp:v1&quot;</span> <span class=\"hljs-string\">in</span> <span class=\"hljs-number\">16.</span><span class=\"hljs-string\">208867618s</span><br>  <span class=\"hljs-string\">Normal</span>   <span class=\"hljs-string\">Created</span>    <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Created</span> <span class=\"hljs-string\">container</span> <span class=\"hljs-string\">readiness-httpget-container</span><br>  <span class=\"hljs-string\">Normal</span>   <span class=\"hljs-string\">Started</span>    <span class=\"hljs-string\">&lt;invalid&gt;</span>                       <span class=\"hljs-string\">kubelet</span>            <span class=\"hljs-string\">Started</span> <span class=\"hljs-string\">container</span> <span class=\"hljs-string\">readiness-httpget-container</span><br>  <span class=\"hljs-string\">Warning</span>  <span class=\"hljs-string\">Unhealthy</span>  <span class=\"hljs-string\">&lt;invalid&gt;</span> <span class=\"hljs-string\">(x15</span> <span class=\"hljs-string\">over</span> <span class=\"hljs-string\">&lt;invalid&gt;)</span>  <span class=\"hljs-attr\">kubelet            Readiness probe failed: HTTP probe failed with statuscode:</span> <span class=\"hljs-number\">404</span><br></code></pre></td></tr></table></figure>\n\n<p>通过上面分析可以看出 </p>\n<figure class=\"highlight subunit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs subunit\">Readiness:      http-get http://:80/index1.html delay=1s timeout=1s period=3s #success=1 #failure=3<br><span class=\"hljs-keyword\">error: </span>code = Unknown desc = Get https://registry<span class=\"hljs-string\">-1</span>.docker.io/v2/: net/http: TLS handshake timeout<br>statuscode: 404<br></code></pre></td></tr></table></figure>\n\n<p>处理异常</p>\n<figure class=\"highlight autoit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs autoit\">[root<span class=\"hljs-symbol\">@k8s</span>-master01 probe]<span class=\"hljs-meta\"># kubectl exec readiness-httpget-pod -it -- /bin/sh</span><br><span class=\"hljs-meta\"># cd /usrshare/nginx/html</span><br><span class=\"hljs-meta\"># echo <span class=\"hljs-string\">&quot;234srwerwe&quot;</span>&gt;&gt;index1.html</span><br>[root<span class=\"hljs-symbol\">@k8s</span>-master01 probe]<span class=\"hljs-meta\"># kubectl get pod</span><br>NAME                    READY   STATUS    RESTARTS   AGE<br>readiness-httpget-pod   <span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">1</span>     Running   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">6</span>m22s<br></code></pre></td></tr></table></figure>\n\n<p>当index1.html添加后pod正常启动</p>\n<h2 id=\"存活检测\"><a href=\"#存活检测\" class=\"headerlink\" title=\"存活检测\"></a>存活检测</h2><h3 id=\"livenessProbe-exec\"><a href=\"#livenessProbe-exec\" class=\"headerlink\" title=\"livenessProbe-exec\"></a>livenessProbe-exec</h3><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">liveness-exec-pod</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">liveness-exec-containen</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/busybox:v1.35</span><br>    <span class=\"hljs-attr\">imagePullPolicy:</span> <span class=\"hljs-string\">IfNotPresent</span><br>    <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&quot;/bin/sh&quot;</span>,<span class=\"hljs-string\">&quot;-c&quot;</span>,<span class=\"hljs-string\">&quot;touch /tmp/live;sleep 60;rm -rf /tmp/live;sleep 3600&quot;</span>]<br>    <span class=\"hljs-attr\">livenessProbe:</span><br>      <span class=\"hljs-attr\">exec:</span><br>        <span class=\"hljs-attr\">command:</span> [<span class=\"hljs-string\">&quot;test&quot;</span>,<span class=\"hljs-string\">&quot;-e&quot;</span>,<span class=\"hljs-string\">&quot;/tmp/live&quot;</span>]<br>      <span class=\"hljs-attr\">initialDelaySeconds:</span> <span class=\"hljs-number\">1</span><br>      <span class=\"hljs-attr\">periodSeconds:</span> <span class=\"hljs-number\">3</span><br></code></pre></td></tr></table></figure>\n\n<p>操作：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\">[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 probe]# kubectl <span class=\"hljs-keyword\">create</span> <span class=\"hljs-operator\">-</span>f livenessProbe<span class=\"hljs-operator\">-</span>exec.yaml <br>pod<span class=\"hljs-operator\">/</span>liveness<span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">exec</span><span class=\"hljs-operator\">-</span>pod created<br>[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 probe]# kubectl <span class=\"hljs-keyword\">get</span> pod<br>NAME                READY   STATUS    RESTARTS   AGE<br>liveness<span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">exec</span><span class=\"hljs-operator\">-</span>pod   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">0</span>          <span class=\"hljs-number\">14</span>s<br>[root<span class=\"hljs-variable\">@k8s</span><span class=\"hljs-operator\">-</span>master01 probe]# kubectl <span class=\"hljs-keyword\">get</span> pod<br>NAME                READY   STATUS    RESTARTS            AGE<br>liveness<span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">exec</span><span class=\"hljs-operator\">-</span>pod   <span class=\"hljs-number\">1</span><span class=\"hljs-operator\">/</span><span class=\"hljs-number\">1</span>     <span class=\"hljs-keyword\">Running</span>   <span class=\"hljs-number\">1</span> (<span class=\"hljs-operator\">&lt;</span>invalid<span class=\"hljs-operator\">&gt;</span> ago)   <span class=\"hljs-number\">2</span>m11s<br></code></pre></td></tr></table></figure>\n\n<p>时间轴：</p>\n<p>创建pod成功——等待60秒后删除/tmp/live——存活检测/tmp/live被删除了，然后就重启pod</p>\n<h3 id=\"livenessProbe-httpget\"><a href=\"#livenessProbe-httpget\" class=\"headerlink\" title=\"livenessProbe-httpget\"></a>livenessProbe-httpget</h3><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">liveness-httpget-pod</span><br>  <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">default</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">liveness-httpget-containen</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/myapp:v1.23</span><br>    <span class=\"hljs-attr\">imagePullPolicy:</span> <span class=\"hljs-string\">IfNotPresent</span><br>    <span class=\"hljs-attr\">ports:</span><br>    <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">http</span><br>      <span class=\"hljs-attr\">containerPort:</span> <span class=\"hljs-number\">80</span><br>    <span class=\"hljs-attr\">livenessProbe:</span><br>      <span class=\"hljs-attr\">httpGet:</span><br>        <span class=\"hljs-attr\">port:</span> <span class=\"hljs-string\">http</span><br>        <span class=\"hljs-attr\">path:</span> <span class=\"hljs-string\">/index.html</span><br>      <span class=\"hljs-attr\">initialDelaySeconds:</span> <span class=\"hljs-number\">1</span><br>      <span class=\"hljs-attr\">periodSeconds:</span> <span class=\"hljs-number\">3</span><br>      <span class=\"hljs-attr\">timeoutSeconds:</span> <span class=\"hljs-number\">10</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"livenessProbe-tcp\"><a href=\"#livenessProbe-tcp\" class=\"headerlink\" title=\"livenessProbe-tcp\"></a>livenessProbe-tcp</h3><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">apiVersion:</span> <span class=\"hljs-string\">v1</span><br><span class=\"hljs-attr\">kind:</span> <span class=\"hljs-string\">Pod</span><br><span class=\"hljs-attr\">metadata:</span><br>  <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">probe-tcp</span><br><span class=\"hljs-attr\">spec:</span><br>  <span class=\"hljs-attr\">containers:</span><br>  <span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">nginx</span><br>    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">harborcloud.com/library/myapp:v1.23</span><br>    <span class=\"hljs-attr\">livenessProbe:</span><br>      <span class=\"hljs-attr\">initialDelaySeconds:</span> <span class=\"hljs-number\">5</span><br>      <span class=\"hljs-attr\">timeoutSeconds:</span> <span class=\"hljs-number\">1</span><br>      <span class=\"hljs-attr\">tcpSocket:</span><br>        <span class=\"hljs-attr\">port:</span> <span class=\"hljs-number\">80</span><br></code></pre></td></tr></table></figure>\n\n"}],"PostAsset":[{"_id":"source/_posts/k8s快速集成KubeSphere/1662953701465.png","slug":"1662953701465.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/k8s快速集成KubeSphere/1662954363702.png","slug":"1662954363702.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/k8s快速集成KubeSphere/1662954670517.png","slug":"1662954670517.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/k8s快速集成KubeSphere/1662954686176.png","slug":"1662954686176.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/k8s快速集成KubeSphere/1662954729101.png","slug":"1662954729101.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/k8s快速集成KubeSphere/1662954919071.png","slug":"1662954919071.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/k8s快速集成KubeSphere/1662955108731.png","slug":"1662955108731.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/k8s快速集成KubeSphere/1662955217850.png","slug":"1662955217850.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/k8s快速集成KubeSphere/1662955316163.png","slug":"1662955316163.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/k8s快速集成KubeSphere/1662955481272.png","slug":"1662955481272.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/k8s快速集成KubeSphere/1662955721051.png","slug":"1662955721051.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/k8s快速集成KubeSphere/1662956356797.png","slug":"1662956356797.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/k8s快速集成KubeSphere/1662979858086.png","slug":"1662979858086.png","post":"cl8elmh7x0000o0vjfg954bo2","modified":0,"renderable":0},{"_id":"source/_posts/如何用hexo在github上搭建自己的博客/image-20220923174506204.png","slug":"image-20220923174506204.png","post":"cl8elutuq0000i4vj4ix9e6w8","modified":0,"renderable":0},{"_id":"source/_posts/如何用hexo在github上搭建自己的博客/image-20220923175440656.png","slug":"image-20220923175440656.png","post":"cl8elutuq0000i4vj4ix9e6w8","modified":0,"renderable":0},{"_id":"source/_posts/如何用hexo在github上搭建自己的博客/image-20220923175557661.png","slug":"image-20220923175557661.png","post":"cl8elutuq0000i4vj4ix9e6w8","modified":0,"renderable":0},{"_id":"source/_posts/如何用hexo在github上搭建自己的博客/image-20220923180413762.png","slug":"image-20220923180413762.png","post":"cl8elutuq0000i4vj4ix9e6w8","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/1663084944194.png","slug":"1663084944194.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/add-credentials.png","slug":"add-credentials.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-config-1.png","slug":"sonarqube-config-1.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-config-2.png","slug":"sonarqube-config-2.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-config-3.png","slug":"sonarqube-config-3.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-example.png","slug":"sonarqube-example.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-webhook-1.png","slug":"sonarqube-webhook-1.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-webhook-2.png","slug":"sonarqube-webhook-2.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/webhook-page-info.png","slug":"webhook-page-info.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-jenkins-settings.png","slug":"sonarqube-jenkins-settings.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/sonarqube-create-project.png","slug":"sonarqube-create-project.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/jenkins-projet-key.png","slug":"jenkins-projet-key.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/generate-a-token.png","slug":"generate-a-token.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/token-created.png","slug":"token-created.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/devops之KubeSphere流水线部署/1662986862067.png","slug":"1662986862067.png","post":"cl8eo3tp80000yovjd055c90n","modified":0,"renderable":0},{"_id":"source/_posts/devops之KubeSphere流水线部署/1662990207401.png","slug":"1662990207401.png","post":"cl8eo3tp80000yovjd055c90n","modified":0,"renderable":0},{"_id":"source/_posts/devops之KubeSphere流水线部署/1662995264415.png","slug":"1662995264415.png","post":"cl8eo3tp80000yovjd055c90n","modified":0,"renderable":0},{"_id":"source/_posts/devops之KubeSphere流水线部署/1662995312671.png","slug":"1662995312671.png","post":"cl8eo3tp80000yovjd055c90n","modified":0,"renderable":0},{"_id":"source/_posts/devops之KubeSphere流水线部署/1662997272162.png","slug":"1662997272162.png","post":"cl8eo3tp80000yovjd055c90n","modified":0,"renderable":0},{"_id":"source/_posts/devops之KubeSphere流水线部署/1663057834843.png","slug":"1663057834843.png","post":"cl8eo3tp80000yovjd055c90n","modified":0,"renderable":0},{"_id":"source/_posts/devops之KubeSphere流水线部署/1663136377931.png","slug":"1663136377931.png","post":"cl8eo3tp80000yovjd055c90n","modified":0,"renderable":0},{"_id":"source/_posts/devops之KubeSphere流水线部署/jenkins-edit--2.png","slug":"jenkins-edit--2.png","post":"cl8eo3tp80000yovjd055c90n","modified":0,"renderable":0},{"_id":"source/_posts/devops之KubeSphere流水线部署/pipeline-overview.png","slug":"pipeline-overview.png","post":"cl8eo3tp80000yovjd055c90n","modified":0,"renderable":0},{"_id":"source/_posts/kubesphere快速部署mysql/1663169211109.png","slug":"1663169211109.png","post":"cl8eoklci00004kvj0jo71dt3","modified":0,"renderable":0},{"_id":"source/_posts/kubesphere快速部署mysql/1663169165653.png","slug":"1663169165653.png","post":"cl8eoklci00004kvj0jo71dt3","modified":0,"renderable":0},{"_id":"source/_posts/kubesphere快速部署mysql/1663167951290.png","slug":"1663167951290.png","post":"cl8eoklci00004kvj0jo71dt3","modified":0,"renderable":0},{"_id":"source/_posts/kubesphere快速部署mysql/1663168060307.png","slug":"1663168060307.png","post":"cl8eoklci00004kvj0jo71dt3","modified":0,"renderable":0},{"_id":"source/_posts/kubesphere快速部署mysql/1663167746173.png","slug":"1663167746173.png","post":"cl8eoklci00004kvj0jo71dt3","modified":0,"renderable":0},{"_id":"source/_posts/kubesphere快速部署mysql/1663170735856.png","slug":"1663170735856.png","post":"cl8eoklci00004kvj0jo71dt3","modified":0,"renderable":0},{"_id":"source/_posts/kubesphere快速部署redis/1663213016039.png","slug":"1663213016039.png","post":"cl8ep14ml000e4kvj8rm76xxp","modified":0,"renderable":0},{"_id":"source/_posts/kubesphere快速部署redis/1663220903688.png","slug":"1663220903688.png","post":"cl8ep14ml000e4kvj8rm76xxp","modified":0,"renderable":0},{"_id":"source/_posts/kubernetes组件介绍/image-1-1024x478.png","slug":"image-1-1024x478.png","post":"cl8epkzh10007v4vjfd21hfkd","modified":0,"renderable":0},{"_id":"source/_posts/kubernetes的历史与介绍/image-1024x388.png","slug":"image-1024x388.png","post":"cl8epnweg000dv4vjclra4b10","modified":0,"renderable":0},{"_id":"source/_posts/k8s网络通讯方式/1411165-20210604153215333-1022736403-990x1024.png","slug":"1411165-20210604153215333-1022736403-990x1024.png","post":"cl8eptfvl000nv4vj8ukgfs4i","modified":0,"renderable":0},{"_id":"source/_posts/k8s网络通讯方式/1411165-20210604153302687-2143265992.png","slug":"1411165-20210604153302687-2143265992.png","post":"cl8eptfvl000nv4vj8ukgfs4i","modified":0,"renderable":0},{"_id":"source/_posts/k8s网络通讯方式/1411165-20210604153732180-730315756.png","slug":"1411165-20210604153732180-730315756.png","post":"cl8eptfvl000nv4vj8ukgfs4i","modified":0,"renderable":0},{"_id":"source/_posts/k8s网络通讯方式/image-2.png","slug":"image-2.png","post":"cl8eptfvl000nv4vj8ukgfs4i","modified":0,"renderable":0},{"_id":"source/_posts/k8s网络通讯方式/image-4.png","slug":"image-4.png","post":"cl8eptfvl000nv4vj8ukgfs4i","modified":0,"renderable":0},{"_id":"source/_posts/k8s网络通讯方式/image-5.png","slug":"image-5.png","post":"cl8eptfvl000nv4vj8ukgfs4i","modified":0,"renderable":0},{"_id":"source/_posts/k8s网络通讯方式/image-6.png","slug":"image-6.png","post":"cl8eptfvl000nv4vj8ukgfs4i","modified":0,"renderable":0},{"_id":"source/_posts/k8s dashboard/1630834989795.png","slug":"1630834989795.png","post":"cl8eqccz80000d4vjd3w15j4r","modified":0,"renderable":0},{"_id":"source/_posts/k8s dashboard/1630835361904.png","slug":"1630835361904.png","post":"cl8eqccz80000d4vjd3w15j4r","modified":0,"renderable":0},{"_id":"source/_posts/kubeadm快速部署kubernetes集群/1629031322356.png","slug":"1629031322356.png","post":"cl8eqf8po0006d4vj61te6fa7","modified":0,"renderable":0},{"_id":"source/_posts/kubeadm快速部署kubernetes集群/image-25.png","slug":"image-25.png","post":"cl8eqf8po0006d4vj61te6fa7","modified":0,"renderable":0},{"_id":"source/_posts/kubeadm快速部署kubernetes集群/image-26.png","slug":"image-26.png","post":"cl8eqf8po0006d4vj61te6fa7","modified":0,"renderable":0},{"_id":"source/_posts/devops安装配置SonarQube/1663953257964.png","slug":"1663953257964.png","post":"cl8en1r1700015cvj9hl88xej","modified":0,"renderable":0},{"_id":"source/_posts/RC与RS与Deployment关联/1657973507960.png","slug":"1657973507960.png","post":"cl8er1d4d000628vjeuva6s6v","modified":0,"renderable":0},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658044956049.png","slug":"1658044956049.png","post":"cl8er9ep7000p28vj5nhv0mps","modified":0,"renderable":0},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658044977401.png","slug":"1658044977401.png","post":"cl8er9ep7000p28vj5nhv0mps","modified":0,"renderable":0},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658045067670.png","slug":"1658045067670.png","post":"cl8er9ep7000p28vj5nhv0mps","modified":0,"renderable":0},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658045231642.png","slug":"1658045231642.png","post":"cl8er9ep7000p28vj5nhv0mps","modified":0,"renderable":0},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658045368211.png","slug":"1658045368211.png","post":"cl8er9ep7000p28vj5nhv0mps","modified":0,"renderable":0},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658046066962.png","slug":"1658046066962.png","post":"cl8er9ep7000p28vj5nhv0mps","modified":0,"renderable":0},{"_id":"source/_posts/k8s Service的概述、类型及代理模式/1658064476544.png","slug":"1658064476544.png","post":"cl8er9ep7000p28vj5nhv0mps","modified":0,"renderable":0},{"_id":"source/_posts/k8s pod生命周期/1657944206659.png","slug":"1657944206659.png","post":"cl8erfec50000w8vjf909hlpz","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cl8ektvnt00008svjgpvt9grk","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8ektvo000038svj5db2gvgp"},{"post_id":"cl8elmh7x0000o0vjfg954bo2","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8elmh9b0002o0vjh4bp2m6k"},{"post_id":"cl8elutuq0000i4vj4ix9e6w8","category_id":"cl8egrg0w0003lsvj1sevbxin","_id":"cl8elutuw0003i4vjemh25h0a"},{"post_id":"cl8en1r1700015cvj9hl88xej","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8enrxdi00045cvj5m1o4vyd"},{"post_id":"cl8eo3tp80000yovjd055c90n","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8eo3tpn0002yovjap7f4eii"},{"post_id":"cl8eoklci00004kvj0jo71dt3","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8eoln5j00034kvj8g680of6"},{"post_id":"cl8ep14ml000e4kvj8rm76xxp","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8ep14mn000h4kvj9qvxfrvi"},{"post_id":"cl8epi5n20000v4vjg8938wzp","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8epjaf50003v4vj32yiahne"},{"post_id":"cl8epkzh10007v4vjfd21hfkd","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8epn90i0009v4vj2i927e8s"},{"post_id":"cl8epnweg000dv4vjclra4b10","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8eppnqa000gv4vjfl736sb4"},{"post_id":"cl8epr3d7000hv4vjg0su48e1","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8epsvrd000jv4vj7j482vq7"},{"post_id":"cl8eptfvl000nv4vj8ukgfs4i","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8epvg2r000qv4vj2zq4dnh3"},{"post_id":"cl8epy0rf000uv4vj5bwc0xqj","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8epze1k000wv4vja2mi431z"},{"post_id":"cl8eq0sz70012v4vjf9oibiju","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8eq1lzx0014v4vj279d23ut"},{"post_id":"cl8eqccz80000d4vjd3w15j4r","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8eqcczg0002d4vjaqt58qc8"},{"post_id":"cl8eqf8po0006d4vj61te6fa7","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8eqhdyj0008d4vj0nhf2van"},{"post_id":"cl8eqiw1g000cd4vje4iyg1w2","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8eqk552000ed4vje3oictlx"},{"post_id":"cl8eqx9sn000128vj4zyi19ns","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8eqy3j6000428vjeg5o1rks"},{"post_id":"cl8er1d4d000628vjeuva6s6v","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8er2fm0000928vj0mdo7js0"},{"post_id":"cl8er3rmy000b28vjf7kl0z9j","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8er4s6x000d28vje9ho53nm"},{"post_id":"cl8er7e3s000h28vj73dhh0o0","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8er87jm000j28vj7hlg5efn"},{"post_id":"cl8er9ep7000p28vj5nhv0mps","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8erbd63000r28vjhbyi4xh2"},{"post_id":"cl8erfec50000w8vjf909hlpz","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8erhrlz0002w8vjequ736bp"},{"post_id":"cl8eritti0007w8vj7o8m4dz7","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8erjk86000aw8vj22j6fmrc"},{"post_id":"cl8eritso0006w8vj92ezgvfn","category_id":"cl8ekpwbn0001aovjd1czgil3","_id":"cl8erl0s8000fw8vj9hbt8tbx"}],"PostTag":[{"post_id":"cl8ektvnt00008svjgpvt9grk","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8ektvo000028svjedja2fg3"},{"post_id":"cl8ektvnt00008svjgpvt9grk","tag_id":"cl8ekpwbx0005aovj4d9xdrxz","_id":"cl8ektvo000048svjaombf6wq"},{"post_id":"cl8elmh7x0000o0vjfg954bo2","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8elmh9c0006o0vj3dv37q2x"},{"post_id":"cl8elmh7x0000o0vjfg954bo2","tag_id":"cl8elmh990001o0vjfx6fg46i","_id":"cl8elmh9c0007o0vjawrg73xr"},{"post_id":"cl8elmh7x0000o0vjfg954bo2","tag_id":"cl8elmh9b0003o0vjb68uatae","_id":"cl8elmh9d0008o0vj46ug3fg1"},{"post_id":"cl8elmh7x0000o0vjfg954bo2","tag_id":"cl8elmh9c0004o0vj194xdvx1","_id":"cl8elmh9d0009o0vj6h5af0ju"},{"post_id":"cl8ektvnt00008svjgpvt9grk","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8elmh9d000ao0vj5vm8bev8"},{"post_id":"cl8elutuq0000i4vj4ix9e6w8","tag_id":"cl8egrg0x0004lsvjhsn700gh","_id":"cl8elutuv0001i4vj8vu51lin"},{"post_id":"cl8elutuq0000i4vj4ix9e6w8","tag_id":"cl8egrg0y0005lsvjbcsu56n7","_id":"cl8elutuw0002i4vjhmrva8tu"},{"post_id":"cl8elutuq0000i4vj4ix9e6w8","tag_id":"cl8egrg0z0007lsvj73ge6qxq","_id":"cl8elutux0004i4vj582r7q76"},{"post_id":"cl8en1r1700015cvj9hl88xej","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8enrxdh00025cvjbl28ays5"},{"post_id":"cl8en1r1700015cvj9hl88xej","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8enrxdh00035cvjhr9s0wmo"},{"post_id":"cl8en1r1700015cvj9hl88xej","tag_id":"cl8ens6cc00065cvja4puhsnw","_id":"cl8ens6cd00075cvjb6iz19gi"},{"post_id":"cl8eo3tp80000yovjd055c90n","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8eo3tpo0004yovjgikp2oaf"},{"post_id":"cl8eo3tp80000yovjd055c90n","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8eo3tpo0005yovjdqkd2x7p"},{"post_id":"cl8eo3tp80000yovjd055c90n","tag_id":"cl8eo3tpi0001yovj6cg4cml3","_id":"cl8eo3tpo0006yovjaau4abp4"},{"post_id":"cl8eo3tp80000yovjd055c90n","tag_id":"cl8eo3tpn0003yovja7m0fg85","_id":"cl8eo3tpo0007yovj5i36cd5i"},{"post_id":"cl8eoklci00004kvj0jo71dt3","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8eoln5j00014kvj0ssdg1ea"},{"post_id":"cl8eoklci00004kvj0jo71dt3","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8eoln5j00024kvj5jgigxqs"},{"post_id":"cl8eoklci00004kvj0jo71dt3","tag_id":"cl8eo3tpi0001yovj6cg4cml3","_id":"cl8eoln5j00044kvjduxdhn6q"},{"post_id":"cl8eoklci00004kvj0jo71dt3","tag_id":"cl8eolv1200064kvjeq8h3edq","_id":"cl8eolv1300074kvj1lhv36dp"},{"post_id":"cl8ep14ml000e4kvj8rm76xxp","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8ep14mm000f4kvjgj2n99tq"},{"post_id":"cl8ep14ml000e4kvj8rm76xxp","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8ep14mn000g4kvja83bgiz3"},{"post_id":"cl8ep14ml000e4kvj8rm76xxp","tag_id":"cl8eo3tpi0001yovj6cg4cml3","_id":"cl8ep14mn000i4kvj1t9j1whj"},{"post_id":"cl8ep14ml000e4kvj8rm76xxp","tag_id":"cl8epanle000k4kvj8iwt1vd4","_id":"cl8epanlf000l4kvj1hkhhbhc"},{"post_id":"cl8epi5n20000v4vjg8938wzp","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8epjaf30001v4vjcfn4gi1o"},{"post_id":"cl8epi5n20000v4vjg8938wzp","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8epjaf50002v4vjdwd00wbj"},{"post_id":"cl8epkzh10007v4vjfd21hfkd","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8epn90i000av4vjefzogy1m"},{"post_id":"cl8epkzh10007v4vjfd21hfkd","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8epn90i000bv4vjebub33e6"},{"post_id":"cl8epkzh10007v4vjfd21hfkd","tag_id":"cl8epn90h0008v4vj1xme788p","_id":"cl8epn90j000cv4vjbpi243og"},{"post_id":"cl8epnweg000dv4vjclra4b10","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8eppnqa000ev4vj7lz587lr"},{"post_id":"cl8epnweg000dv4vjclra4b10","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8eppnqa000fv4vj5oem08sh"},{"post_id":"cl8epr3d7000hv4vjg0su48e1","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8epsvre000kv4vj26kd1ozi"},{"post_id":"cl8epr3d7000hv4vjg0su48e1","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8epsvre000lv4vjeian5mrs"},{"post_id":"cl8epr3d7000hv4vjg0su48e1","tag_id":"cl8epsvrd000iv4vjh6ex1h57","_id":"cl8epsvre000mv4vjayzo8hrf"},{"post_id":"cl8eptfvl000nv4vj8ukgfs4i","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8epvg2r000ov4vj1xlwdexw"},{"post_id":"cl8eptfvl000nv4vj8ukgfs4i","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8epvg2r000pv4vjexvhc1in"},{"post_id":"cl8eptfvl000nv4vj8ukgfs4i","tag_id":"cl8epvtgc000sv4vj4ika6fjl","_id":"cl8epvtgf000tv4vj31hofup0"},{"post_id":"cl8epy0rf000uv4vj5bwc0xqj","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8epze1l000yv4vj2oi8bjyo"},{"post_id":"cl8epy0rf000uv4vj5bwc0xqj","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8epze1l000zv4vj7tax3mnd"},{"post_id":"cl8epy0rf000uv4vj5bwc0xqj","tag_id":"cl8epze1k000vv4vj0a19hj5e","_id":"cl8epze1l0010v4vj157ca4x8"},{"post_id":"cl8epy0rf000uv4vj5bwc0xqj","tag_id":"cl8epze1l000xv4vj90v8dmb0","_id":"cl8epze1l0011v4vjekfr4nsb"},{"post_id":"cl8eq0sz70012v4vjf9oibiju","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8eq1lzy0016v4vjf3cl7vvw"},{"post_id":"cl8eq0sz70012v4vjf9oibiju","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8eq1lzy0017v4vjc20t6zfd"},{"post_id":"cl8eq0sz70012v4vjf9oibiju","tag_id":"cl8eq1lzw0013v4vj2hu57h1g","_id":"cl8eq1lzy0018v4vjbgsfhfro"},{"post_id":"cl8eq0sz70012v4vjf9oibiju","tag_id":"cl8eq1lzx0015v4vj9vu89clp","_id":"cl8eq1lzy0019v4vjgq4q1l39"},{"post_id":"cl8eqccz80000d4vjd3w15j4r","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8eqcczh0003d4vj9oq59nhk"},{"post_id":"cl8eqccz80000d4vjd3w15j4r","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8eqcczh0004d4vj3qva07x0"},{"post_id":"cl8eqccz80000d4vjd3w15j4r","tag_id":"cl8eqccze0001d4vj3r7nefut","_id":"cl8eqcczi0005d4vjg64hga6g"},{"post_id":"cl8eqf8po0006d4vj61te6fa7","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8eqhdyj0009d4vj6tpidhh2"},{"post_id":"cl8eqf8po0006d4vj61te6fa7","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8eqhdyj000ad4vj90qfe2u8"},{"post_id":"cl8eqf8po0006d4vj61te6fa7","tag_id":"cl8eqhdyh0007d4vj3b4p0oad","_id":"cl8eqhdyj000bd4vjcut1gdhi"},{"post_id":"cl8eqiw1g000cd4vje4iyg1w2","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8eqk552000fd4vjhycr9m71"},{"post_id":"cl8eqiw1g000cd4vje4iyg1w2","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8eqk552000gd4vj2e8acwsw"},{"post_id":"cl8eqiw1g000cd4vje4iyg1w2","tag_id":"cl8eqk551000dd4vj5gl41r1j","_id":"cl8eqk552000hd4vj06cb0w5u"},{"post_id":"cl8eqx9sn000128vj4zyi19ns","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8eqy3j5000228vj31vt2wzz"},{"post_id":"cl8eqx9sn000128vj4zyi19ns","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8eqy3j6000328vjguvle9yy"},{"post_id":"cl8eqx9sn000128vj4zyi19ns","tag_id":"cl8eqk551000dd4vj5gl41r1j","_id":"cl8eqy3j6000528vj1w4k3naa"},{"post_id":"cl8er1d4d000628vjeuva6s6v","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8er2flz000728vj1inpdgcc"},{"post_id":"cl8er1d4d000628vjeuva6s6v","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8er2fm0000828vj4jf686ln"},{"post_id":"cl8er3rmy000b28vjf7kl0z9j","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8er4s6y000e28vj1nsj1iww"},{"post_id":"cl8er3rmy000b28vjf7kl0z9j","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8er4s6y000f28vjfmx0h4af"},{"post_id":"cl8er3rmy000b28vjf7kl0z9j","tag_id":"cl8er4s6x000c28vjg5fpcooz","_id":"cl8er4s6y000g28vj2mha8dkq"},{"post_id":"cl8er7e3s000h28vj73dhh0o0","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8er87jn000l28vjdwqw5dvt"},{"post_id":"cl8er7e3s000h28vj73dhh0o0","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8er87jn000m28vj2fej2509"},{"post_id":"cl8er7e3s000h28vj73dhh0o0","tag_id":"cl8er87jm000i28vj3y5l38i1","_id":"cl8er87jn000n28vjbemv61h2"},{"post_id":"cl8er7e3s000h28vj73dhh0o0","tag_id":"cl8er87jm000k28vj76jd5x2t","_id":"cl8er87jn000o28vj2euwhwnv"},{"post_id":"cl8er9ep7000p28vj5nhv0mps","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8erbd64000s28vj5e689uxt"},{"post_id":"cl8er9ep7000p28vj5nhv0mps","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8erbd64000t28vjaukafstz"},{"post_id":"cl8er9ep7000p28vj5nhv0mps","tag_id":"cl8erbd60000q28vjfaosdh8v","_id":"cl8erbd64000u28vjhowb1su9"},{"post_id":"cl8erfec50000w8vjf909hlpz","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8erhrm00003w8vjc6034o8i"},{"post_id":"cl8erfec50000w8vjf909hlpz","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8erhrm00004w8vjcx7b8a2v"},{"post_id":"cl8erfec50000w8vjf909hlpz","tag_id":"cl8erhrly0001w8vj6u1ggzyt","_id":"cl8erhrm00005w8vjfcdk2mrl"},{"post_id":"cl8eritti0007w8vj7o8m4dz7","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8erjk850008w8vj8kmzhgxo"},{"post_id":"cl8eritti0007w8vj7o8m4dz7","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8erjk860009w8vj9g83ecjc"},{"post_id":"cl8eritti0007w8vj7o8m4dz7","tag_id":"cl8erjvsv000cw8vj7nkldt5k","_id":"cl8erjvsx000dw8vjbm7abmo2"},{"post_id":"cl8eritso0006w8vj92ezgvfn","tag_id":"cl8elmh9c0005o0vjdg69hqd9","_id":"cl8erl0s9000gw8vj3bwv6dt0"},{"post_id":"cl8eritso0006w8vj92ezgvfn","tag_id":"cl8ekpwbw0003aovj684s05qc","_id":"cl8erl0s9000hw8vjdkr90otn"},{"post_id":"cl8eritso0006w8vj92ezgvfn","tag_id":"cl8erl0s7000ew8vj9pyr0ts8","_id":"cl8erl0s9000iw8vj3pjrb8iu"}],"Tag":[{"name":"hexo","_id":"cl8egrg0x0004lsvjhsn700gh"},{"name":"github","_id":"cl8egrg0y0005lsvjbcsu56n7"},{"name":"博客","_id":"cl8egrg0z0007lsvj73ge6qxq"},{"name":"Kubernetes","_id":"cl8ekpwbq0002aovjdu2pcooc"},{"name":"k8s","_id":"cl8ekpwbw0003aovj684s05qc"},{"name":"openebs","_id":"cl8ekpwbx0005aovj4d9xdrxz"},{"name":"kubernetes ","_id":"cl8elmh990001o0vjfx6fg46i"},{"name":"kubesphere","_id":"cl8elmh9b0003o0vjb68uatae"},{"name":"wordpress","_id":"cl8elmh9c0004o0vj194xdvx1"},{"name":"kubernetes","_id":"cl8elmh9c0005o0vjdg69hqd9"},{"name":"sonarqube","_id":"cl8ens6cc00065cvja4puhsnw"},{"name":"kubeshpere","_id":"cl8eo3tpi0001yovj6cg4cml3"},{"name":"流水线","_id":"cl8eo3tpn0003yovja7m0fg85"},{"name":"mysql","_id":"cl8eolv1200064kvjeq8h3edq"},{"name":"redis","_id":"cl8epanle000k4kvj8iwt1vd4"},{"name":"组件","_id":"cl8epn90h0008v4vj1xme788p"},{"name":"kubectl","_id":"cl8epsvrd000iv4vjh6ex1h57"},{"name":"网络通讯","_id":"cl8epvtgc000sv4vj4ika6fjl"},{"name":"firewalld","_id":"cl8epze1k000vv4vj0a19hj5e"},{"name":"防火墙","_id":"cl8epze1l000xv4vj90v8dmb0"},{"name":"scheduler","_id":"cl8eq1lzw0013v4vj2hu57h1g"},{"name":"调度器","_id":"cl8eq1lzx0015v4vj9vu89clp"},{"name":"dashboard","_id":"cl8eqccze0001d4vj3r7nefut"},{"name":"集群部署","_id":"cl8eqhdyh0007d4vj3b4p0oad"},{"name":"控制器","_id":"cl8eqk551000dd4vj5gl41r1j"},{"name":"daemonset","_id":"cl8er4s6x000c28vjg5fpcooz"},{"name":"job","_id":"cl8er87jm000i28vj3y5l38i1"},{"name":"cronjob","_id":"cl8er87jm000k28vj76jd5x2t"},{"name":"service","_id":"cl8erbd60000q28vjfaosdh8v"},{"name":"pod","_id":"cl8erhrly0001w8vj6u1ggzyt"},{"name":"探针","_id":"cl8erjvsv000cw8vj7nkldt5k"},{"name":"重启策略","_id":"cl8erl0s7000ew8vj9pyr0ts8"}]}}